{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif du projet : Utiliser le corpus export_articles_EGC_2004_2018 et faire le bilan de l'évolution de la communauté EGC ces 20 dernières années et tenter d'en prédire l'avenir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Notes :\n",
    "J'ai abandonné l'utilisation de TreeTagger pour lemmatiser : j'ai pas réussi à le faire fonctionner.\n",
    "\n",
    "Ainsi que Gensim : la forme de ses corpus est étrange et je pense que c'est une perte de temps à se conformer à leur modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouverture du fichier de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fichier de données original.\n",
    "doc = pd.read_csv(\"export_articles_EGC_2004_2018.csv\", sep='\\t')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier de données corrigé.\n",
    "# La correction va jusqu'à la ligne 66.\n",
    "doc = pd.read_csv(\"export_articles_EGC_2004_2018_Copie.csv\", sep='\\t')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En travaillant avec title et abstract, on va réaliser les transformations.\n",
    "Tous les documents ont des titres mais ils n'ont pas tous d'abstract.\n",
    "On va donc utiliser une concaténation du titre et de l'abstract afin d'être sûr d'avoir de l'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisation et nettoyage des sujets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut mettre les textes en minuscules, tokeniser, retirer la ponctuation, retirer les stopwords puis lemmatiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        if item not in stopwords.words(\"french\"):\n",
    "            stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'étape qui suit est un peu longue. Voir si elle pourrait être réduite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = [tokenize(doc[\"title\"][0].lower())]\n",
    "abstract = [tokenize(str(doc[\"abstract\"][0].lower()))]\n",
    "for line in range(len(doc)): # title et abstract ont la même taille.\n",
    "    if line != 0:\n",
    "        resume.append(tokenize(doc[\"title\"][line].lower()))\n",
    "        abstract.append(tokenize(str(doc[\"abstract\"][line]).lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le traitment des données est acceptable. Un meilleur traitement pourrait être envisagé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut obtenir un seul jeu de données avec les titres et les abstracts pour pouvoir les traiter et éliminer les cas qui n'ont pas d'abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible que seul le titre suffise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in range(len(abstract)):\n",
    "    if abstract[line] != \"nan\":\n",
    "        for element in abstract[line]:\n",
    "            resume[line].append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention : l'étape suivante est longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = []\n",
    "for line in resume:\n",
    "    for word in line:\n",
    "        dico.append(word)\n",
    "for word in dico:\n",
    "    if dico.count(word) != 1:\n",
    "        dico.remove\n",
    "len(dico)\n",
    "# 93849 (2 fois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faudrait s'assurer que dico ne contienne que des mots distincts. Pour réduire sa taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du Tf.\n",
    "tf = []\n",
    "for x in range(len(resume)):\n",
    "    tf.append([])\n",
    "    for y in range(len(resume[x])):\n",
    "        tf[x].append(resume[x].count(resume[x][y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention : l'étape suivante est longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du Df.\n",
    "df = {}\n",
    "for x in range(len(dico)):\n",
    "    sum = 0\n",
    "    for y in range(len(resume)):\n",
    "        if dico[x] in resume[y]:\n",
    "            sum = sum + 1\n",
    "    df[dico[x]] = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'Idf\n",
    "idf = {}\n",
    "for word in df:\n",
    "    idf[word] = np.log10(len(resume)/df[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du Tf-Idf.\n",
    "tfidf = []\n",
    "for x in range(len(resume)):\n",
    "    tfidf.append({})\n",
    "    for y in range(len(resume[x])):\n",
    "        tfidf[x][resume[x][y]] = tf[x][y] * idf[resume[x][y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut trier les Tf-Idf par valeur et récupérer les 3 (ou 5) meilleurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le LSA va calculer, pour un document donné, les documents les plus similaires à son sujet. On classe le résultat le plus similaire dans le cluster du document donné. On reproduit cette étape et on arrête quand à un nombre de clusters ou une similarité trop faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En gros, le LSA nous fournit une similarité qu'on utilise pour former une classification hiérarchique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On aura donc des clusters par sujets. On pourra élaborer nos techniques de datation pour déterminer les tendances et, si possible, créer de nouveaux clusters (avec les K-moyennes) plus précis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK Learn semble être une bonne option mais doit être testée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
