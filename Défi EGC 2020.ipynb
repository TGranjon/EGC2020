{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif du projet : Utiliser le corpus export_articles_EGC_2004_2018 et faire le bilan de l'évolution de la communauté EGC ces 20 dernières années et tenter d'en prédire l'avenir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Notes :\n",
    "J'ai abandonné l'utilisation de TreeTagger pour lemmatiser : j'ai pas réussi à le faire fonctionner. Remplacé par FrenchLefffLemmatizer.\n",
    "\n",
    "Ainsi que Gensim : la forme de ses corpus est étrange et je pense que c'est une perte de temps à se conformer à leur modèle. Remplacé par SKLearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "from random import randint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Thomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.process_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouverture du fichier de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fichier de données original.\n",
    "doc = pd.read_csv(\"export_articles_EGC_2004_2018.csv\", sep='\\t')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>series</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>pdf1page</th>\n",
       "      <th>pdfarticle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>#Idéo2017 : une plateforme citoyenne dédiée à ...</td>\n",
       "      <td>Cette plateforme a pour objectif de permettre ...</td>\n",
       "      <td>Claudia Marinica, Julien Longhi, Nader Hassine...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>A two level co-clustering algorithm for very l...</td>\n",
       "      <td>La classification croisée (co-clustering) est ...</td>\n",
       "      <td>Marius Barctus, Marc Boullé, Fabrice Clérot</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>ALGeoSPF: Un modèle de factorisation basé sur ...</td>\n",
       "      <td>La recommandation de points d'intérêts est dev...</td>\n",
       "      <td>Jean-Benoît Griesner, Talel Abdesssalem, Huber...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Analyse des sentiments à partir des commentair...</td>\n",
       "      <td>L'analyse des sentiments est un processus pend...</td>\n",
       "      <td>Abdeljalil Elouardighi, Mohcine Maghfour, Hafd...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Analyse en rôles sémantiques pour le résumé au...</td>\n",
       "      <td>Cet article présente une approche visant à ext...</td>\n",
       "      <td>Elyase Lassouli, Yasmine Mesbahi, Camille Prad...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Analyse Ontologique de scénario dans un contex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marwan Batrouni, Aurélie Bertaux, Christophe N...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apport de la fouille de données pour la préven...</td>\n",
       "      <td>Avec plus de 800 000 décès par an dans le mond...</td>\n",
       "      <td>Romain Billot, Sofian Berrouiguet, Mark Larsen...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apport des modèles locaux pour les K-moyennes ...</td>\n",
       "      <td>Dans le cadre du clustering prédictif, pour at...</td>\n",
       "      <td>Vincent Lemaire, Oumaima Alaoui Ismaili</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apprendre les relations de préférence et de co...</td>\n",
       "      <td>En classification multi-labels, chaque instanc...</td>\n",
       "      <td>Khalil Laghmari, Christophe Marsala, Mohammed ...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Approche contextuelle par régression pour les ...</td>\n",
       "      <td>Les tests A/B sont des procédures utilisées pa...</td>\n",
       "      <td>Emmanuelle Claeys, Pierre Gançarski, Myriam Ma...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Big Data for understanding human dynamics: the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fosca Giannotti</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Cartes Auto-Organisatrices Incrémentales appli...</td>\n",
       "      <td>Le Clustering Collaboratif (CC) vise à faire r...</td>\n",
       "      <td>Denis Maurel, Jérémie Sublime, Sylvain Lefebvre</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Catégorisation d'articles scientifiques basée ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bastien Latard, Jonathan Weber, Germain Forest...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Classification de Données Complexes par Global...</td>\n",
       "      <td>La plupart des méthodes de classification sont...</td>\n",
       "      <td>Étienne-Cuvelier, Marie-Aude-Aufaure</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Community structure in complex networks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Santo Fortunato</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Comparaison de mesures de centralité basées su...</td>\n",
       "      <td>Définir l'importance des noeuds dans les résea...</td>\n",
       "      <td>Marwan Ghanem, Clémence Magnien, Fabien Tarissan</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Complémentarités de représentations vectoriell...</td>\n",
       "      <td>La tâche de similarité sémantique textuelle co...</td>\n",
       "      <td>Julien Hay, Tim Van de Cruys, Philippe Muller,...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Contextualisation de Singularités en Temps-Rée...</td>\n",
       "      <td>L'émergence de l'IoT et du traitement en temps...</td>\n",
       "      <td>Badre Belabbess, Jérémy Lhez, Musab Bairat, Ol...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Contraintes prescriptives compatibles avec OWL...</td>\n",
       "      <td>L'article définit les contraintes prescriptive...</td>\n",
       "      <td>Philippe Martin, Jun Jo</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Contribution à l'étude de la distributivité d'...</td>\n",
       "      <td>Nous nous intéressons aux treillis distributif...</td>\n",
       "      <td>Alain Gély, Miguel Couceiro, Yassine Namir, Am...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Découverte de motifs graduels partiellement or...</td>\n",
       "      <td>Les données séquentielles sont aujourd'hui omn...</td>\n",
       "      <td>Simon Ser, Fatiha Saïs, Maguelonne Teisseire</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Définir les catégories de DBpédia avec des règ...</td>\n",
       "      <td>DBpédia, qui encode les connaissances de Wikip...</td>\n",
       "      <td>Justine Reynaud, Esther Galbrun, Mehwish Alam,...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Détection de Singularités en temps-réel par co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Badre Belabbess, Musab Bairat, Jérémy Lhez, Ol...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Echantillonnage de motifs séquentiels sous con...</td>\n",
       "      <td>L'échantillonnage de motifs est une méthode no...</td>\n",
       "      <td>Lamine Diop, Cheikh Talibouya Diop, Arnaud Gia...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>eDOI : exploration itérative de grands graphes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antoine Laumond, Norbert Feron, Guy Melançon, ...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Elaboration et utilisation d'une base de conna...</td>\n",
       "      <td>Ce poster rend compte d'une entreprise d'élabo...</td>\n",
       "      <td>Nicolas Faure, René-Michel Faure</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Élimination des liens inter-langues erronés da...</td>\n",
       "      <td>Un lien inter-langue dans Wikipédia est un lie...</td>\n",
       "      <td>Nacéra Bennacer Seghouani, Francesca Bugiotti,...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Et si les réseaux sociaux pouvaient nous aider...</td>\n",
       "      <td>Dans cet article, nous présentons une méthode ...</td>\n",
       "      <td>Rémy Kessler, Guy Lapalme, Fabrizio Gotti, Abd...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Étiquetage thématique automatisé de corpus par...</td>\n",
       "      <td>Dans les corpus de textes scientifiques, certa...</td>\n",
       "      <td>Lucie Martinet, Hussein T. Al-Natsheh, Fabien ...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2018</td>\n",
       "      <td>Évaluation comparative d'algorithmes de centra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kévin Deturck, Damien Nouvel, Frédérique Segond</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1002405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1239</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>MUSETTE : a framework for knowledge capture fr...</td>\n",
       "      <td>Nous présentons dans cet article une nouvelle ...</td>\n",
       "      <td>Pierre-Antoine Champin, Yannick Prié, Alain Mille</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>1240</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>OpAC : Opérateur d'analyse en ligne basé sur u...</td>\n",
       "      <td>L'analyse en ligne OLAP (On-Line Analysis Proc...</td>\n",
       "      <td>Riadh Ben Messaoud, Sabine Rabaseda, Omar Bous...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1241</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Optimisation des requêtes temporelles sur le web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rim Faiz, Nizar Khayati, Khaled Mellouli</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>1242</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Outil de représentation des évolutions de comm...</td>\n",
       "      <td>Cet article présente un système de visualisati...</td>\n",
       "      <td>Anne Lavallard, Luigi Lancieri</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1243</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>PoBOC : un algorithme de</td>\n",
       "      <td>Nous décrivons l'algorithme PoBOC (Pole-Based ...</td>\n",
       "      <td>Guillaume Cleuziou, Lionel Martin, Christel Vrain</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>1244</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Positionnement multidimensionnel et partitionn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antoine Naud</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1245</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Qualité et datawarehouse dans le milieu hospit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mireille Cosquer, François Gros, Alain Livarto...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1246</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Recherche ciblée de documents sur le web</td>\n",
       "      <td>Les langages de requêtes mots-clés pour le web...</td>\n",
       "      <td>Amar-Djalil Mezaour</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1247</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Recherche dans de grandes bases d'images fixes...</td>\n",
       "      <td>Une base d'images fixes peut être décrite de p...</td>\n",
       "      <td>Anicet Kouomou Choupo, Annie Morin, Laure Bert...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Recherche de règles d'association hiérarchique...</td>\n",
       "      <td>L'Extraction de Connaissances dans la Bases de...</td>\n",
       "      <td>Olivier Couturier, Engelbert Mephu Nguifo, Bri...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1249</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Réduction d'un jeu de règles d'association par...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martine Cadot, Joseph Di Martino, Amedeo Napoli</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>1250</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Réduction du coût d'évaluation d'une règle rel...</td>\n",
       "      <td>De nombreuses tâches en Fouille de Données vis...</td>\n",
       "      <td>Agnès Braud, Teddy Turmeaux</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1251</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Règles d'identification et méthodes de visuali...</td>\n",
       "      <td>Dans l'étude du patrimoine bâti, la gestion d'...</td>\n",
       "      <td>Iwona Dudek, Jean-Yves Blaise</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>1252</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Régression linéaire symbolique avec variables ...</td>\n",
       "      <td>Le présent papier concerne l'extension des mét...</td>\n",
       "      <td>Filipe Afonso, Lynne Billard, Edwin Diday</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1253</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Relations entre gènes impliqués dans les cance...</td>\n",
       "      <td>Des relations entre gènes et protéines impliqu...</td>\n",
       "      <td>Jean Royauté, Claire François, Alain Zasadzins...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1254</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Représentation condensée de motifs émergents</td>\n",
       "      <td>Les motifs émergents sont des associations de ...</td>\n",
       "      <td>Arnaud Soulet, Bruno Crémilleux, François Rioult</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1255</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Représentation de graphes par ACP granulaire</td>\n",
       "      <td>L'extraction d'information de grands graphes r...</td>\n",
       "      <td>Bruno Gaume, Louis Ferré</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>1256</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Résumé de cubes de données multidimensionnelle...</td>\n",
       "      <td>Dans le contexte des entrepôts de données, et ...</td>\n",
       "      <td>Yeow Wei Choong, Anne Laurent, Dominique Laure...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>1257</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Sélection d'attributs et classification d'obje...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexandre Blansché, Pierre Gançarski</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>1258</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Sélection rapide en apprentissage supervisé</td>\n",
       "      <td>La sélection de variables (SdV) permet de rédu...</td>\n",
       "      <td>Nicolas Nicoloyannis, Gaëlle Legrand, Pierre-E...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>1259</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Sous-ensembles flous définis sur une ontologie</td>\n",
       "      <td>Les sous-ensembles flous peuvent être utilisés...</td>\n",
       "      <td>Rallou Thomopoulos, Patrice Buche, Ollivier Ha...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>1260</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Uitliation de connaissances pour l'aide à la r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amedeo Napoli, Rim Al Hulou</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1261</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Un algorithme de génération des itemsets fermé...</td>\n",
       "      <td>Le traitement de grand volume de données est u...</td>\n",
       "      <td>Engelbert Mephu Nguifo, Huaiguo Fu</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>1262</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Une approche probabiliste pour le classement d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lamis Hawarah, Ana Simonet, Michel Simonet</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>1263</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Une étude d'algorithmes de classification supe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huaiyu Fu, Huaiguo Fu, Patrick Njiwoua, Engelb...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1264</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Une méthode pour l'appropriation de savoir-fai...</td>\n",
       "      <td>La gestion explicite des savoirs et savoir-fai...</td>\n",
       "      <td>Oswaldo Castillo, Nada Matta, Jean-Louis Ermine</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>1265</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Utilisation des graphes de proximité dans le c...</td>\n",
       "      <td>La classification suivant les plus proches voi...</td>\n",
       "      <td>Sylvain Ferrandiz, Marc Boullé</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1266</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Validation de graphes conceptuels</td>\n",
       "      <td>Les travaux menés en validation des connaissan...</td>\n",
       "      <td>Juliette Dibie-Barthélemy, Ollivier Haemmerlé,...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1267</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Veille technologique assistée par la Fouille d...</td>\n",
       "      <td>Le domaine de la veille technologique vise à r...</td>\n",
       "      <td>François Jacquenet, Christine Largeron, Stépha...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1268</td>\n",
       "      <td>Revue des Nouvelles Technologies de l'Information</td>\n",
       "      <td>EGC</td>\n",
       "      <td>2004</td>\n",
       "      <td>Vers un entrepôt de données pour la gestion de...</td>\n",
       "      <td>Les entrepôts de données sont l'un des plus im...</td>\n",
       "      <td>Hicham Hajji, Nourdine Badji, Jean-Pierre Asté</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p1&amp;p=10...</td>\n",
       "      <td>http://editions-rnti.fr/render_pdf.php?p=1001163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1269 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                             series booktitle  \\\n",
       "0              0  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1              1  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "2              2  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "3              3  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "4              4  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "5              5  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "6              6  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "7              7  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "8              8  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "9              9  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "10            10  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "11            11  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "12            12  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "13            13  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "14            14  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "15            15  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "16            16  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "17            17  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "18            18  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "19            19  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "20            20  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "21            21  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "22            22  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "23            23  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "24            24  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "25            25  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "26            26  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "27            27  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "28            28  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "29            29  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "...          ...                                                ...       ...   \n",
       "1239        1239  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1240        1240  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1241        1241  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1242        1242  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1243        1243  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1244        1244  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1245        1245  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1246        1246  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1247        1247  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1248        1248  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1249        1249  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1250        1250  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1251        1251  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1252        1252  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1253        1253  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1254        1254  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1255        1255  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1256        1256  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1257        1257  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1258        1258  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1259        1259  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1260        1260  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1261        1261  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1262        1262  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1263        1263  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1264        1264  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1265        1265  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1266        1266  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1267        1267  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "1268        1268  Revue des Nouvelles Technologies de l'Information       EGC   \n",
       "\n",
       "      year                                              title  \\\n",
       "0     2018  #Idéo2017 : une plateforme citoyenne dédiée à ...   \n",
       "1     2018  A two level co-clustering algorithm for very l...   \n",
       "2     2018  ALGeoSPF: Un modèle de factorisation basé sur ...   \n",
       "3     2018  Analyse des sentiments à partir des commentair...   \n",
       "4     2018  Analyse en rôles sémantiques pour le résumé au...   \n",
       "5     2018  Analyse Ontologique de scénario dans un contex...   \n",
       "6     2018  Apport de la fouille de données pour la préven...   \n",
       "7     2018  Apport des modèles locaux pour les K-moyennes ...   \n",
       "8     2018  Apprendre les relations de préférence et de co...   \n",
       "9     2018  Approche contextuelle par régression pour les ...   \n",
       "10    2018  Big Data for understanding human dynamics: the...   \n",
       "11    2018  Cartes Auto-Organisatrices Incrémentales appli...   \n",
       "12    2018  Catégorisation d'articles scientifiques basée ...   \n",
       "13    2018  Classification de Données Complexes par Global...   \n",
       "14    2018            Community structure in complex networks   \n",
       "15    2018  Comparaison de mesures de centralité basées su...   \n",
       "16    2018  Complémentarités de représentations vectoriell...   \n",
       "17    2018  Contextualisation de Singularités en Temps-Rée...   \n",
       "18    2018  Contraintes prescriptives compatibles avec OWL...   \n",
       "19    2018  Contribution à l'étude de la distributivité d'...   \n",
       "20    2018  Découverte de motifs graduels partiellement or...   \n",
       "21    2018  Définir les catégories de DBpédia avec des règ...   \n",
       "22    2018  Détection de Singularités en temps-réel par co...   \n",
       "23    2018  Echantillonnage de motifs séquentiels sous con...   \n",
       "24    2018  eDOI : exploration itérative de grands graphes...   \n",
       "25    2018  Elaboration et utilisation d'une base de conna...   \n",
       "26    2018  Élimination des liens inter-langues erronés da...   \n",
       "27    2018  Et si les réseaux sociaux pouvaient nous aider...   \n",
       "28    2018  Étiquetage thématique automatisé de corpus par...   \n",
       "29    2018  Évaluation comparative d'algorithmes de centra...   \n",
       "...    ...                                                ...   \n",
       "1239  2004  MUSETTE : a framework for knowledge capture fr...   \n",
       "1240  2004  OpAC : Opérateur d'analyse en ligne basé sur u...   \n",
       "1241  2004   Optimisation des requêtes temporelles sur le web   \n",
       "1242  2004  Outil de représentation des évolutions de comm...   \n",
       "1243  2004                          PoBOC : un algorithme de    \n",
       "1244  2004  Positionnement multidimensionnel et partitionn...   \n",
       "1245  2004  Qualité et datawarehouse dans le milieu hospit...   \n",
       "1246  2004           Recherche ciblée de documents sur le web   \n",
       "1247  2004  Recherche dans de grandes bases d'images fixes...   \n",
       "1248  2004  Recherche de règles d'association hiérarchique...   \n",
       "1249  2004  Réduction d'un jeu de règles d'association par...   \n",
       "1250  2004  Réduction du coût d'évaluation d'une règle rel...   \n",
       "1251  2004  Règles d'identification et méthodes de visuali...   \n",
       "1252  2004  Régression linéaire symbolique avec variables ...   \n",
       "1253  2004  Relations entre gènes impliqués dans les cance...   \n",
       "1254  2004       Représentation condensée de motifs émergents   \n",
       "1255  2004       Représentation de graphes par ACP granulaire   \n",
       "1256  2004  Résumé de cubes de données multidimensionnelle...   \n",
       "1257  2004  Sélection d'attributs et classification d'obje...   \n",
       "1258  2004        Sélection rapide en apprentissage supervisé   \n",
       "1259  2004     Sous-ensembles flous définis sur une ontologie   \n",
       "1260  2004  Uitliation de connaissances pour l'aide à la r...   \n",
       "1261  2004  Un algorithme de génération des itemsets fermé...   \n",
       "1262  2004  Une approche probabiliste pour le classement d...   \n",
       "1263  2004  Une étude d'algorithmes de classification supe...   \n",
       "1264  2004  Une méthode pour l'appropriation de savoir-fai...   \n",
       "1265  2004  Utilisation des graphes de proximité dans le c...   \n",
       "1266  2004                  Validation de graphes conceptuels   \n",
       "1267  2004  Veille technologique assistée par la Fouille d...   \n",
       "1268  2004  Vers un entrepôt de données pour la gestion de...   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     Cette plateforme a pour objectif de permettre ...   \n",
       "1     La classification croisée (co-clustering) est ...   \n",
       "2     La recommandation de points d'intérêts est dev...   \n",
       "3     L'analyse des sentiments est un processus pend...   \n",
       "4     Cet article présente une approche visant à ext...   \n",
       "5                                                   NaN   \n",
       "6     Avec plus de 800 000 décès par an dans le mond...   \n",
       "7     Dans le cadre du clustering prédictif, pour at...   \n",
       "8     En classification multi-labels, chaque instanc...   \n",
       "9     Les tests A/B sont des procédures utilisées pa...   \n",
       "10                                                  NaN   \n",
       "11    Le Clustering Collaboratif (CC) vise à faire r...   \n",
       "12                                                  NaN   \n",
       "13    La plupart des méthodes de classification sont...   \n",
       "14                                                  NaN   \n",
       "15    Définir l'importance des noeuds dans les résea...   \n",
       "16    La tâche de similarité sémantique textuelle co...   \n",
       "17    L'émergence de l'IoT et du traitement en temps...   \n",
       "18    L'article définit les contraintes prescriptive...   \n",
       "19    Nous nous intéressons aux treillis distributif...   \n",
       "20    Les données séquentielles sont aujourd'hui omn...   \n",
       "21    DBpédia, qui encode les connaissances de Wikip...   \n",
       "22                                                  NaN   \n",
       "23    L'échantillonnage de motifs est une méthode no...   \n",
       "24                                                  NaN   \n",
       "25    Ce poster rend compte d'une entreprise d'élabo...   \n",
       "26    Un lien inter-langue dans Wikipédia est un lie...   \n",
       "27    Dans cet article, nous présentons une méthode ...   \n",
       "28    Dans les corpus de textes scientifiques, certa...   \n",
       "29                                                  NaN   \n",
       "...                                                 ...   \n",
       "1239  Nous présentons dans cet article une nouvelle ...   \n",
       "1240  L'analyse en ligne OLAP (On-Line Analysis Proc...   \n",
       "1241                                                NaN   \n",
       "1242  Cet article présente un système de visualisati...   \n",
       "1243  Nous décrivons l'algorithme PoBOC (Pole-Based ...   \n",
       "1244                                                NaN   \n",
       "1245                                                NaN   \n",
       "1246  Les langages de requêtes mots-clés pour le web...   \n",
       "1247  Une base d'images fixes peut être décrite de p...   \n",
       "1248  L'Extraction de Connaissances dans la Bases de...   \n",
       "1249                                                NaN   \n",
       "1250  De nombreuses tâches en Fouille de Données vis...   \n",
       "1251  Dans l'étude du patrimoine bâti, la gestion d'...   \n",
       "1252  Le présent papier concerne l'extension des mét...   \n",
       "1253  Des relations entre gènes et protéines impliqu...   \n",
       "1254  Les motifs émergents sont des associations de ...   \n",
       "1255  L'extraction d'information de grands graphes r...   \n",
       "1256  Dans le contexte des entrepôts de données, et ...   \n",
       "1257                                                NaN   \n",
       "1258  La sélection de variables (SdV) permet de rédu...   \n",
       "1259  Les sous-ensembles flous peuvent être utilisés...   \n",
       "1260                                                NaN   \n",
       "1261  Le traitement de grand volume de données est u...   \n",
       "1262                                                NaN   \n",
       "1263                                                NaN   \n",
       "1264  La gestion explicite des savoirs et savoir-fai...   \n",
       "1265  La classification suivant les plus proches voi...   \n",
       "1266  Les travaux menés en validation des connaissan...   \n",
       "1267  Le domaine de la veille technologique vise à r...   \n",
       "1268  Les entrepôts de données sont l'un des plus im...   \n",
       "\n",
       "                                                authors  \\\n",
       "0     Claudia Marinica, Julien Longhi, Nader Hassine...   \n",
       "1           Marius Barctus, Marc Boullé, Fabrice Clérot   \n",
       "2     Jean-Benoît Griesner, Talel Abdesssalem, Huber...   \n",
       "3     Abdeljalil Elouardighi, Mohcine Maghfour, Hafd...   \n",
       "4     Elyase Lassouli, Yasmine Mesbahi, Camille Prad...   \n",
       "5     Marwan Batrouni, Aurélie Bertaux, Christophe N...   \n",
       "6     Romain Billot, Sofian Berrouiguet, Mark Larsen...   \n",
       "7               Vincent Lemaire, Oumaima Alaoui Ismaili   \n",
       "8     Khalil Laghmari, Christophe Marsala, Mohammed ...   \n",
       "9     Emmanuelle Claeys, Pierre Gançarski, Myriam Ma...   \n",
       "10                                      Fosca Giannotti   \n",
       "11      Denis Maurel, Jérémie Sublime, Sylvain Lefebvre   \n",
       "12    Bastien Latard, Jonathan Weber, Germain Forest...   \n",
       "13                 Étienne-Cuvelier, Marie-Aude-Aufaure   \n",
       "14                                      Santo Fortunato   \n",
       "15     Marwan Ghanem, Clémence Magnien, Fabien Tarissan   \n",
       "16    Julien Hay, Tim Van de Cruys, Philippe Muller,...   \n",
       "17    Badre Belabbess, Jérémy Lhez, Musab Bairat, Ol...   \n",
       "18                              Philippe Martin, Jun Jo   \n",
       "19    Alain Gély, Miguel Couceiro, Yassine Namir, Am...   \n",
       "20         Simon Ser, Fatiha Saïs, Maguelonne Teisseire   \n",
       "21    Justine Reynaud, Esther Galbrun, Mehwish Alam,...   \n",
       "22    Badre Belabbess, Musab Bairat, Jérémy Lhez, Ol...   \n",
       "23    Lamine Diop, Cheikh Talibouya Diop, Arnaud Gia...   \n",
       "24    Antoine Laumond, Norbert Feron, Guy Melançon, ...   \n",
       "25                     Nicolas Faure, René-Michel Faure   \n",
       "26    Nacéra Bennacer Seghouani, Francesca Bugiotti,...   \n",
       "27    Rémy Kessler, Guy Lapalme, Fabrizio Gotti, Abd...   \n",
       "28    Lucie Martinet, Hussein T. Al-Natsheh, Fabien ...   \n",
       "29      Kévin Deturck, Damien Nouvel, Frédérique Segond   \n",
       "...                                                 ...   \n",
       "1239  Pierre-Antoine Champin, Yannick Prié, Alain Mille   \n",
       "1240  Riadh Ben Messaoud, Sabine Rabaseda, Omar Bous...   \n",
       "1241           Rim Faiz, Nizar Khayati, Khaled Mellouli   \n",
       "1242                     Anne Lavallard, Luigi Lancieri   \n",
       "1243  Guillaume Cleuziou, Lionel Martin, Christel Vrain   \n",
       "1244                                       Antoine Naud   \n",
       "1245  Mireille Cosquer, François Gros, Alain Livarto...   \n",
       "1246                                Amar-Djalil Mezaour   \n",
       "1247  Anicet Kouomou Choupo, Annie Morin, Laure Bert...   \n",
       "1248  Olivier Couturier, Engelbert Mephu Nguifo, Bri...   \n",
       "1249    Martine Cadot, Joseph Di Martino, Amedeo Napoli   \n",
       "1250                        Agnès Braud, Teddy Turmeaux   \n",
       "1251                      Iwona Dudek, Jean-Yves Blaise   \n",
       "1252          Filipe Afonso, Lynne Billard, Edwin Diday   \n",
       "1253  Jean Royauté, Claire François, Alain Zasadzins...   \n",
       "1254   Arnaud Soulet, Bruno Crémilleux, François Rioult   \n",
       "1255                           Bruno Gaume, Louis Ferré   \n",
       "1256  Yeow Wei Choong, Anne Laurent, Dominique Laure...   \n",
       "1257               Alexandre Blansché, Pierre Gançarski   \n",
       "1258  Nicolas Nicoloyannis, Gaëlle Legrand, Pierre-E...   \n",
       "1259  Rallou Thomopoulos, Patrice Buche, Ollivier Ha...   \n",
       "1260                        Amedeo Napoli, Rim Al Hulou   \n",
       "1261                 Engelbert Mephu Nguifo, Huaiguo Fu   \n",
       "1262         Lamis Hawarah, Ana Simonet, Michel Simonet   \n",
       "1263  Huaiyu Fu, Huaiguo Fu, Patrick Njiwoua, Engelb...   \n",
       "1264    Oswaldo Castillo, Nada Matta, Jean-Louis Ermine   \n",
       "1265                     Sylvain Ferrandiz, Marc Boullé   \n",
       "1266  Juliette Dibie-Barthélemy, Ollivier Haemmerlé,...   \n",
       "1267  François Jacquenet, Christine Largeron, Stépha...   \n",
       "1268     Hicham Hajji, Nourdine Badji, Jean-Pierre Asté   \n",
       "\n",
       "                                               pdf1page  \\\n",
       "0     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "2     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "3     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "4     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "5     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "6     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "7     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "8     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "9     http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "10    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "11    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "12    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "13    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "14    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "15    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "16    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "17    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "18    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "19    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "20    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "21    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "22    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "23    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "24    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "25    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "26    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "27    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "28    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "29    http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "...                                                 ...   \n",
       "1239  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1240  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1241  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1242  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1243  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1244  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1245  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1246  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1247  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1248  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1249  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1250  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1251  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1252  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1253  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1254  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1255  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1256  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1257  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1258  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1259  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1260  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1261  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1262  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1263  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1264  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1265  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1266  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1267  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "1268  http://editions-rnti.fr/render_pdf.php?p1&p=10...   \n",
       "\n",
       "                                            pdfarticle  \n",
       "0     http://editions-rnti.fr/render_pdf.php?p=1002425  \n",
       "1     http://editions-rnti.fr/render_pdf.php?p=1002372  \n",
       "2     http://editions-rnti.fr/render_pdf.php?p=1002380  \n",
       "3     http://editions-rnti.fr/render_pdf.php?p=1002397  \n",
       "4     http://editions-rnti.fr/render_pdf.php?p=1002384  \n",
       "5     http://editions-rnti.fr/render_pdf.php?p=1002414  \n",
       "6     http://editions-rnti.fr/render_pdf.php?p=1002376  \n",
       "7     http://editions-rnti.fr/render_pdf.php?p=1002379  \n",
       "8     http://editions-rnti.fr/render_pdf.php?p=1002381  \n",
       "9     http://editions-rnti.fr/render_pdf.php?p=1002387  \n",
       "10    http://editions-rnti.fr/render_pdf.php?p=1002363  \n",
       "11    http://editions-rnti.fr/render_pdf.php?p=1002418  \n",
       "12    http://editions-rnti.fr/render_pdf.php?p=1002406  \n",
       "13    http://editions-rnti.fr/render_pdf.php?p=1002368  \n",
       "14    http://editions-rnti.fr/render_pdf.php?p=1002362  \n",
       "15    http://editions-rnti.fr/render_pdf.php?p=1002416  \n",
       "16    http://editions-rnti.fr/render_pdf.php?p=1002378  \n",
       "17    http://editions-rnti.fr/render_pdf.php?p=1002369  \n",
       "18    http://editions-rnti.fr/render_pdf.php?p=1002366  \n",
       "19    http://editions-rnti.fr/render_pdf.php?p=1002373  \n",
       "20    http://editions-rnti.fr/render_pdf.php?p=1002382  \n",
       "21    http://editions-rnti.fr/render_pdf.php?p=1002398  \n",
       "22    http://editions-rnti.fr/render_pdf.php?p=1002408  \n",
       "23    http://editions-rnti.fr/render_pdf.php?p=1002367  \n",
       "24    http://editions-rnti.fr/render_pdf.php?p=1002410  \n",
       "25    http://editions-rnti.fr/render_pdf.php?p=1002404  \n",
       "26    http://editions-rnti.fr/render_pdf.php?p=1002417  \n",
       "27    http://editions-rnti.fr/render_pdf.php?p=1002391  \n",
       "28    http://editions-rnti.fr/render_pdf.php?p=1002396  \n",
       "29    http://editions-rnti.fr/render_pdf.php?p=1002405  \n",
       "...                                                ...  \n",
       "1239  http://editions-rnti.fr/render_pdf.php?p=1000912  \n",
       "1240  http://editions-rnti.fr/render_pdf.php?p=1000889  \n",
       "1241  http://editions-rnti.fr/render_pdf.php?p=1001126  \n",
       "1242  http://editions-rnti.fr/render_pdf.php?p=1001140  \n",
       "1243  http://editions-rnti.fr/render_pdf.php?p=1001007  \n",
       "1244  http://editions-rnti.fr/render_pdf.php?p=1001030  \n",
       "1245  http://editions-rnti.fr/render_pdf.php?p=1000905  \n",
       "1246  http://editions-rnti.fr/render_pdf.php?p=1001124  \n",
       "1247  http://editions-rnti.fr/render_pdf.php?p=1000895  \n",
       "1248  http://editions-rnti.fr/render_pdf.php?p=1001154  \n",
       "1249  http://editions-rnti.fr/render_pdf.php?p=1001058  \n",
       "1250  http://editions-rnti.fr/render_pdf.php?p=1001039  \n",
       "1251  http://editions-rnti.fr/render_pdf.php?p=1001157  \n",
       "1252  http://editions-rnti.fr/render_pdf.php?p=1001000  \n",
       "1253  http://editions-rnti.fr/render_pdf.php?p=1001119  \n",
       "1254  http://editions-rnti.fr/render_pdf.php?p=1001022  \n",
       "1255  http://editions-rnti.fr/render_pdf.php?p=1001083  \n",
       "1256  http://editions-rnti.fr/render_pdf.php?p=1000904  \n",
       "1257  http://editions-rnti.fr/render_pdf.php?p=1000994  \n",
       "1258  http://editions-rnti.fr/render_pdf.php?p=1000953  \n",
       "1259  http://editions-rnti.fr/render_pdf.php?p=1000914  \n",
       "1260  http://editions-rnti.fr/render_pdf.php?p=1001125  \n",
       "1261  http://editions-rnti.fr/render_pdf.php?p=1001062  \n",
       "1262  http://editions-rnti.fr/render_pdf.php?p=1001029  \n",
       "1263  http://editions-rnti.fr/render_pdf.php?p=1001025  \n",
       "1264  http://editions-rnti.fr/render_pdf.php?p=1000911  \n",
       "1265  http://editions-rnti.fr/render_pdf.php?p=1001061  \n",
       "1266  http://editions-rnti.fr/render_pdf.php?p=1000913  \n",
       "1267  http://editions-rnti.fr/render_pdf.php?p=1001097  \n",
       "1268  http://editions-rnti.fr/render_pdf.php?p=1001163  \n",
       "\n",
       "[1269 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Fichier de données corrigé.\n",
    "##### La correction va jusqu'à la ligne 112.\n",
    "doc = pd.read_csv(\"export_articles_EGC_2004_2018_Correct.csv\", sep='\\t')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En travaillant avec title et abstract, on va réaliser les transformations.\n",
    "Tous les documents ont des titres mais ils n'ont pas tous d'abstract.\n",
    "On va donc utiliser une concaténation du titre et de l'abstract afin d'être sûr d'avoir de l'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisation et nettoyage des sujets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut mettre les textes en minuscules, tokeniser, retirer la ponctuation, retirer les stopwords puis lemmatiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = FrenchLefffLemmatizer()\n",
    "\n",
    "def lemm_tokens(tokens, lemmer):\n",
    "    lemmed = []\n",
    "    for item in tokens:\n",
    "        lemmed.append(lemmer.lemmatize(item))\n",
    "    return lemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    print(text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemms = lemm_tokens(tokens,lemmer)\n",
    "    #stems = stem_tokens(tokens, stemmer)\n",
    "    return lemms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idéo2017  une plateforme citoyenne dédiée à lanalyse des tweets lors des événements politiques\n",
      "cette plateforme a pour objectif de permettre aux citoyens danalyser par euxmêmes les tweets politiques lors dévénements spécifiques en france pour le cas de lélection présidentielle de 2017 idéo2017 analysait en quasi temps réel les messages des candidats et fournissait leurs principales caractéristiques lusage du lexique politique et des comparaisons entre les candidats\n",
      "a two level coclustering algorithm for very large data sets\n",
      "la classification croisée coclustering est une technique qui permet dextraire la structure sousjacente existante entre les lignes et les colonnes dune table de données sous forme de blocs plusieurs applications utilisent cette technique cependant de nombreux algorithmes de coclustering actuels ne passent pas à léchelle une des approches utilisées avec succès est la méthode modl qui optimise un critère de vraisemblance régularisée cependant pour des tailles plus importante cette méthode atteint sa limite dans cet article nous présentons un nouvel algorithme de coclustering à deux niveaux qui compte tenu du critère modl permet de traiter efficacement de données de très grande taille ne pouvant pas tenir en mémoire nos expériences montrent que lapproche proposée gagne en temps de calcul tout en produisant des solutions de qualité\n",
      "algeospf un modèle de factorisation basé sur du clustering géographique pour la recommandation de poi\n",
      "la recommandation de points dintérêts est devenue une caractéristique essentielle des réseaux sociaux géolocalisés qui a accompagné lémergence des échanges massifs de données digitales cependant les faibles densités de points dintérêts visités par les utilisateurs rendent le problème difficile à traiter dautant plus que les espaces de mobilité des utilisateurs sont très hétérogènes allant de la ville au monde entier dans ce papier nous explorons limpact dune approche de clustering spatial sur la qualité de la recommandation notre approche est basée sur un modèle de factorisation de matrices de poisson et un réseau social inféré des différents comportements de mobilité nous avons conduit une évaluation comparative des performances de notre approche sur un jeu de données réaliste les résultats expérimentaux montrent que notre approche permet une précision supérieure aux techniques de recommandation alternatives\n",
      "analyse des sentiments à partir des commentaires facebook publiés en arabe standard ou dialectal marocain par une approche dapprentissage automatique\n",
      "lanalyse des sentiments est un processus pendant lequel la polarité positive négative ou neutre dun texte donné est déterminée nous nous intéressons dans ce travail à lanalyse des sentiments à partir des commentaires facebook réels partagés en arabe standard ou dialectal marocain par une approche basée sur lapprentissage automatique ce processus commence par la collecte des commentaires et leur annotation à laide du crowdsourcing suivi dune phase de prétraitement du texte afin dextraire des mots arabes réduits à leur racine ces mots vont être utilisés pour la construction des variables dentrée en utilisant plusieurs combinaisons de schémas dextraction et de pondération pour réduire la dimensionnalité une méthode de sélection de variables est appliquée les résultats obtenus des expérimentations sont très prometteurs\n",
      "analyse en rôles sémantiques pour le résumé automatique\n",
      "cet article présente une approche visant à extraire les informations exprimées dans un corpus de textes et en produire un résumé plusieurs variantes de méthodes extractives de résumé de texte ont été implémentées et évaluées leur principale originalité réside dans lexploitation de structures appelées cds pour clause description structure issues dun composant dannotation en rôles sémantiques et non directement des phrases composant les textes le résumé obtenu est un sousensemble des cds issus du corpus dorigine  ce format permettra dans la suite la détection dincohérences textuelles dans ce travail nous retransformons les cds résumés en texte pour permettre la comparaison de notre approche avec celles de la littérature les premiers résultats sont très encourageants les variantes que nous proposons obtiennent généralement de meilleurs scores que des implémentations de méthodes de référence\n",
      "analyse ontologique de scénario dans un contexte big data\n",
      "nan\n",
      "apport de la fouille de données pour la prévention du risque suicidaire\n",
      "avec plus de 800 000 décès par an dans le monde le suicide est la troisième cause de décès évitable il y a 20 fois plus de tentatives impliquant de nombreuses hospitalisations des coûts humains et sociétaux énormes ces dernières années les modalités de collecte de données sociologiques et cliniques concernant les patients reçus en consultation après une tentative ont connu de profonds changements liés aux outils numériques nous présentons les principaux résultats dun processus complet de fouille de données sur un échantillon de suicidants de deux hôpitaux européens le premier objectif est didentifier des groupes de patients similaires et le second didentifier des facteurs de risque associés au nombre de tentatives des méthodes non supervisées acm et clustering et supervisées arbres de régression sont appliquées pour y répondre les résultats mettent en lumière lapport de la fouille de données à des fins descriptives ou explicatives\n",
      "apport des modèles locaux pour les kmoyennes prédictives\n",
      "dans le cadre du clustering prédictif pour attribuer la classe aux groupes formés à la fin de la phase dapprentissage le vote majoritaire est la méthode communément utilisée cependant cette approche comporte certaines limitations qui influent directement sur la qualité des résultats obtenus en termes de prédiction pour surmonter ce problème nous proposons dincorporer des modèles prédictifs localement dans les clusters formés afin daméliorer la qualité prédictive du modèle global les résultats expérimentaux montrent que cette incorporation permet dobtenir des résultats en termes de prédiction significativement meilleurs par rapport à ceux obtenus en utilisant le vote majoritaire ainsi que des résultats très compétitifs avec ceux obtenus par des algorithmes performants dapprentissage supervisé “similaires” ceci est effectué sans dégrader le pouvoir descriptif explicatif du modèle global\n",
      "apprendre les relations de préférence et de cooccurrence entre les labels en classification multilabels\n",
      "en classification multilabels chaque instance est associée à un ou plusieurs labels par exemple un morceau de musique peut être associé aux labels heureux et relaxant des relations de cooccurrence peuvent exister entre les labels  par exemple les labels heureux et triste ne peuvent pas être associés au même morceau de musique les labels peuvent aussi avoir des relations de préférence  par exemple pour un morceau de musique contenant plusieurs piques le label heureux est préféré par rapport au label relaxant les relations entre les labels peuvent aider à mieux prédire les labels associés aux instances les approches existantes peuvent apprendre soit les relations de cooccurrence soit les relations de préférence ce travail introduit une approche permettant de combiner lapprentissage des deux types de relations les expérimentations menées montrent que la nouvelle approche introduite offre les meilleurs résultats de prédiction par rapports à cinq approches de létat de lart\n",
      "approche contextuelle par régression pour les tests ab\n",
      "les tests ab sont des procédures utilisées par les entreprises du web et de la santé entre autres pour mesurer limpact dun changement de version dune variable par rapport à un objectif bien quun nombre de plus en plus important de données soit disponible la mise en place concrète dun tel test peut impliquer un coût important relatif à lobservation et à lévaluation dune variation lorsque celleci nest pas optimale dans ce papier nous présentons une nouvelle approche intégrant le principe dun bandit contextuel prenant en compte ces variables via une procédure de stratification\n",
      "big data for understanding human dynamics the power of networks\n",
      "nan\n",
      "cartes autoorganisatrices incrémentales appliquées au clustering collaboratif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le clustering collaboratif cc vise à faire ressortir les structures communes présentes dans plusieurs vues indépendantes en se basant sur une première étape de clustering locale effectuée dans notre cas à laide de cartes autoorganisatrices som pour self organizing maps en anglais pour faire face à la quantité toujours croissante de données disponibles lutilisation de méthodes de clustering incrémentales est devenue nécessaire ce papier présente un algorithme de som incrémentales compatibles avec les contraintes du cc les expérimentations conduites sur plusieurs jeux de données démontrent la validité de cette méthode et présentent linfluence de la taille du batch utilisé lors de lapprentissage\n",
      "catégorisation darticles scientifiques basée sur les relations sémantiques des motsclés\n",
      "nan\n",
      "classification de données complexes par globalisation de mesures de similarité via les moyennes quasiarithmétiques\n",
      "la plupart des méthodes de classification sont conçues pour des types particuliers de données données numériques textuelles catégoriques fonctionnelles probabilistes ou encore de type graphes cependant les données générées dans notre quotidien sont en général composées de données de types mixtes par exemple si nous considérons la prévention cardiaque dans le domaine de la santé les applications vont combiner des données issues de capteurs avec dautres données telles que lâge le niveau deffort la fréquence cardiaque maximale des histogrammes de fréquences cardiaques moyennes lors de précédents efforts etc ceci nous amène à la problématique de construire des classes en tenant compte de ces différentes données et de définir une mesure de similarité à partir des similarités de paires dobjets sur les différents types de variables dans cet article nous proposons une méthode de classification basée sur la fusion des matrices de similarité à laide des moyennes quasiarithmétiques qui permet de choisir les différentes “dimensions” des données à considérer et ce quel que soit le type de données pour autant quune mesure de similarité ou de dissimilarité existe pour chacun des types de données ce qui est très souvent le cas\n",
      "community structure in complex networks\n",
      "nan\n",
      "comparaison de mesures de centralité basées sur les plus courts chemins dans les réseaux dynamiques\n",
      "définir limportance des noeuds dans les réseaux statiques est une question de recherche très étudiée depuis de nombreuses années dernièrement des adaptations des métriques classiques ont été proposées pour les réseaux dynamiques ces méthodes reposent sur des approches très différentes dans leur façon dévaluer limportance des noeuds à un instant donné il est donc nécessaire de pouvoir les évaluer et les comparer dans cet article nous comparons trois approches existes pour mieux comprendre ce qui les différencie nous montrons que la nature des jeux de données influe grandement sur le comportement des méthodes et que pour certains dentre eux la notion dimportance nest pas toujours pertinente\n",
      "complémentarités de représentations vectorielles pour la similarité sémantique\n",
      "la tâche de similarité sémantique textuelle consiste à exprimer automatiquement un nombre reflétant la similarité sémantique de deux fragments de texte chaque année depuis 2012 les campagnes de semeval déroulent cette tâche de similarité sémantique textuelle cet article présente une méthode associant différentes représentations vectorielles de phrases dans lobjectif daméliorer les résultats obtenus en similarité sémantique notre hypothèse est que différentes représentations permettraient de représenter différents aspects sémantiques et par extension daméliorer les similarités calculées la principale difficulté étant de sélectionner les représentations les plus complémentaires pour cette tâche notre système se base sur le système vainqueur de la campagne de 2015 ainsi que sur notre méthode de sélection par complémentarité les résultats obtenus viennent confirmer lintérêt de cette méthode lorsquils sont comparés aux résultats de la campagne de 2016\n",
      "contextualisation de singularités en tempsréel par extraction de connaissances du web des données\n",
      "lémergence de liot et du traitement en tempsréel oblige les entreprises à considérer la détection danomalies comme un élément clé de leur activité afin de garantir une haute précision dans le processus de détection des métadonnées fournissant un contexte spatiotemporel sur les mesures des capteurs sont nécessaires dans cet article nous présentons un système générique qui aide à capturer analyser qualifier et stocker les informations contextuelles dun domaine dapplication donné lapproche proposée est basée sur des méthodes sémantiques qui exploitent des ontologies pour évaluer la pertinence de linformation contextuelle après une description des composants principaux de larchitecture la performance et la pertinence du système sont démontrées par une évaluation sur des ensembles de données du monde réel\n",
      "contraintes prescriptives compatibles avec owl2er pour évaluer la complétude dontologies\n",
      "larticle définit les contraintes prescriptives comme des règles permettant aux moteurs dinférence de vérifier que certains objets formels sont réellement utilisés – pas seulement inférés – ou non dans certaines conditions il montre que ces contraintes nécessitent de ne pas exploiter de mécanisme dhéritage ou autres mécanismes ajoutant des relations à des objets durant les tests des conclusions des règles il donne une méthode générale pour effectuer cela et des commandes sparql pour implémenter cette méthode lorsque les règles sont représentées via des relations sousclassede entre conditions et conclusions larticle illustre ces commandes avec la vérification de patrons de conception dontologies plus généralement lapproche peut être utilisée pour vérifier la complétude dune ontologie ou représenter dans une ontologie plutôt que par des requêtes ou des procédures ad hoc des contraintes permettant de calculer un degré de complétude dontologie lapproche peut ainsi aider lélicitation la modélisation ou la validation de connaissances\n",
      "contribution à létude de la distributivité dun treillis de concepts\n",
      "nous nous intéressons aux treillis distributifs dans le cadre de lanalyse formelle de concepts fca la motivation primitive vient de la phylogénie et des graphes médians pour représenter les dérivations biologiques et les arbres parcimonieux la fca propose des algorithmes efficaces de construction de treillis de concepts cependant un treillis de concepts nest pas en correspondance avec un graphe médian sauf sil est distributif doù lidée détudier la transformation dun treillis de concepts en un treillis distributif pour ce faire nous nous appuyons sur le théorème de représentation de birkhoff qui nous permet de systématiser la transformation dun contexte quelconque en un contexte de treillis de concepts distributif ainsi nous pouvons bénéficier de lalgorithmique de fca pour construire mais aussi visualiser les treillis de concepts distributifs et enfin étudier les graphes médians associés\n",
      "découverte de motifs graduels partiellement ordonnés  application aux données dexpériences scientifiques\n",
      "les données séquentielles sont aujourdhui omniprésentes et concernent divers domaines dapplication la fouille de données de séquences permet dextraire des informations et des connaissances pouvant être à forte valeur ajoutée cependant lorsque les données de séquences sont riches en données numériques des méthodes de fouille de données plus fines sont nécessaires pour extraire des connaissances plus expressives représentant la variabilité des valeurs numériques ainsi que leur éventuelle interdépendance dans cet article nous présentons une nouvelle méthode de découverte de séquences graduelles fréquentes représentées par des graphes à partir dune source de données de séquences en rdf resource description framework 1 ces dernières sont transformées en graphes graduels partiellement ordonnés gpo nous proposons un algorithme permettant de découvrir les sousgraphes gpo fréquents une expérimentation sur deux jeux de données réelles ont montré la faisabilité et la pertinence de notre approche\n",
      "définir les catégories de dbpédia avec des règles dassociations et des redescriptions\n",
      "dbpédia qui encode les connaissances de wikipédia est devenue une base de référence pour le web des données les ressources peuvent y être répertoriées par des catégories définies manuellement dont la sémantique nest pas directement accessible par des machines dans cet article nous proposons de remédier à cette lacune au moyen de méthodes de fouille de données à savoir la recherche de règles dassociations et de motifs apparentés nous présentons une étude comparative de ces variantes sur une partie de dbpédia et discutons le potentiel des différentes approches\n",
      "détection de singularités en tempsréel par combinaison dapprentissage automatique et web sémantique basés sur spark\n",
      "nan\n",
      "echantillonnage de motifs séquentiels sous contrainte sur la norme\n",
      "léchantillonnage de motifs est une méthode nonexhaustive pour découvrir des motifs pertinents qui assure une bonne interactivité tout en offrant des garanties statistiques fortes grâce à sa nature aléatoire curieusement une telle approche explorée pour les motifs ensemblistes et les sousgraphes ne la pas encore été pour les données séquentielles dans cet article nous proposons la première méthode déchantillonnage de motifs séquentiels outre le passage aux séquences loriginalité de notre approche est dintroduire une contrainte sur la norme pour maîtriser la longueur des motifs tirés et éviter lécueil de la « longue traîne » nous démontrons que notre méthode fondée sur une procédure aléatoire en deux étapes effectue un tirage exact malgré le recours à un échantillonnage avec rejet les expérimentations montrent quelle reste performante\n",
      "edoi  exploration itérative de grands graphes multicouches basée sur une mesure de lintérêt de lutilisateur\n",
      "nan\n",
      "elaboration et utilisation dune base de connaissances dun domaine technique\n",
      "ce poster rend compte dune entreprise délaboration dun système de représentation des connaissances pour le domaine géotechnique\n",
      "élimination des liens interlangues erronés dans wikipédia\n",
      "un lien interlangue dans wikipédia est un lien qui mène dun article appartenant à une édition linguistique à un autre article décrivant le même concept dans une autre langue ces liens sont ajoutés manuellement par les utilisateurs de wikipédia et ainsi ils sont susceptibles dêtre erronés dans ce papier nous proposons une approche pour lélimination automatique des liens interlangues le principe de base est que la présence dun lien erroné est révélée par lexistence dun chemin de liens interlangues reliant deux articles appartenant à une même édition linguistique notre approche élimine des liens interlangues à partir de ceux qui ont un faible score de correction jusquà ce quil ny ait plus de chemins entre deux articles dune même édition linguistique les résultats de notre évaluation sur un sousgraphe de wikipédia consistant en 8 langues montre que lapproche est prometteuse\n",
      "et si les réseaux sociaux pouvaient nous aider dans nos choix de carrière\n",
      "dans cet article nous présentons une méthode danalyse de corpus afin de générer deux interfaces originales de visualisation dans le domaine de lerecrutement notre approche sappuie sur des millions de profils issus de plusieurs réseaux sociaux et sur des milliers doffres demploi collectées sur internet nous décrivons dans ces travaux les étapes nécessaires pour leur réalisation la première visualisation est une carte dynamique indiquant les métiers qui recrutent dans quel domaine dans quelle région tandis que la seconde met en avant les parcours professionnels et permet dobserver les perspectives ainsi que les antécédents à plus ou moins long terme pour chaque métier considéré\n",
      "étiquetage thématique automatisé de corpus par représentation sémantique\n",
      "dans les corpus de textes scientifiques certains articles issus de communautés de chercheurs différentes peuvent ne pas être décrits par les mêmes motsclés alors quils partagent la même thématique ce phénomène cause des problèmes dans la recherche dinformation ces articles étant mal indexés et limite les échanges potentiellement fructueux entre disciplines scientifiques notre modèle permet dattribuer automatiquement une étiquette thématique aux articles au moyen dun apprentissage des représentations sémantiques darticles du corpus déjà étiquetés passant bien à léchelle cette méthode a pu être testée sur une bibliothèque numérique darticles scientifiques comportant des millions de documents nous utilisons un réseau sémantique de synonymes pour extraire davantage darticles sémantiquement similaires et nous les fusionnons avec ceux obtenus par un modèle de classement thématique cette méthode combinée présente de meilleurs taux de rappel que les versions utilisant soit le réseau sémantique seul soit la seule représentation sémantique des textes\n",
      "évaluation comparative dalgorithmes de centralité pour la détection dinfluenceurs\n",
      "nan\n",
      "exploration et analyses multiobjectifs de séries temporelles de données météorologiques\n",
      "cet article présente les investigations menées sur les données mesurées par des capteurs positionnés dans cinq villes de lîle de la réunion des analyses exploratoires préalables permettent de comparer les caractéristiques statistiques des villes considérées relativement aux différentes variables météorologiques mesurées flux solaires diffus et global pression atmosphérique humidité température force et direction du vent nous appliquons diverses transformations sur les données avant danalyser les séries univariées ou multivariées agrégées au pas de lheure ou de la journée afin de construire des modèles de prédiction une approche classique de clustering de séries temporelles est testée deux algorithmes de biclustering appliqués successivement ont permis de grouper les journées dobservations partageant des paramètres météorologiques horaires une caractérisation des biclusters une visualisation calendaire de leur succession ainsi quune recherche de séquences fréquentes permettent dexploiter les résultats et de faciliter leur interprétation\n",
      "extraction de chaînes cohérentes en vue de reconstuire la trajectoire de linformation\n",
      "sur internet linformation se propage en particulier au travers des documents textuels cette propagation soulève de nombreux défis  identifier une information suivre son évolution dans le temps comprendre les mécanismes qui régissent sa propagation etc étant donné un document parmi un grand corpus dans lequel de nombreuses informations circulent pouvonsnous retrouver les chemins empruntés par linformation pour arriver à ce document  nous proposons de définir la notion de trajectoire comme lensemble des chemins le long desquels de linformation sest propagée et nous proposons une méthode pour lestimer nous avons mis en oeuvre une évaluation humaine pour juger de la qualité des chemins calculés nous montrons que les évaluations concordent la plupart du temps et que notre algorithme est efficace pour retrouver les bons chemins\n",
      "extraction de connaissances sur les défaillances de compteurs dessieux\n",
      "cet article propose une méthode danalyse pour des enregistrements opérationnels dun ensemble de compteurs dessieux qui constituent un élément central à linfrastructure ferroviaire notre objectif est de fournir une façon efficace dextraire automatiquement des éléments de connaissance concernant les défaillances de ces systèmes puisque les données fournies ne contiennent pas de vérité de terrain sur les causes de défaillances les informations et leurs causes doivent être extraites des relations soustendant les événements enregistrés après une phase de prétraitement les événements sont groupés en fonction des relations qui ont été mises en lumière entre eux ces regroupements peuvent ensuite être utilisés pour créer des classes dévénements en utilisant un système de classification adapté au de là de cette application spécifique cette approche est une façon nouvelle daborder les problèmes danalyse de fiabilité\n",
      "fouille de motifs graduels fermés fréquents sous contrainte de la temporalité\n",
      "nan\n",
      "fouille de motifs temporels négatifs\n",
      "dans cet article nous étudions le problème de lextraction de motifs fréquents contenant des événements positifs des événements négatifs spécifiant labsence dévénement ainsi que des informations temporelles sur le délai entre ces événements nous définissons la sémantique de tels motifs et proposons la méthode ntgsp basée sur des approches de létat de lart les performances de la méthode sont évaluées sur des données commerciales fournies par edf électricité de france\n",
      "interrogation de données structurellement hétérogènes dans les bases de données orientées documents\n",
      "les systèmes orientés documents permettent de stocker tout document quel que soit leur schéma cette flexibilité génère une potentielle hétérogénéité des documents qui complexifie leur interrogation car une même entité peut être décrite selon des schémas différents cet article présente une approche d’interrogation transparente des systèmes orientés documents pour cela nous proposons de générer un dictionnaire de façon automatique lors de l’insertion des documents et qui associe à chaque attribut tous les chemins permettant d’y accéder ce dictionnaire permet de réécrire la requête utilisateur à partir de disjonctions de chemins afin de retrouver tous les documents quelles que soient leurs structures nos expérimentations montrent des coûts d’exécution de la requête réécrite largement acceptables comparés au coût d’une requête sur schémas homogènes\n",
      "ktimooc un système de recommandation pour la personnalisation du processus déchange dinformations dans les moocs\n",
      "afin daider les apprenants à tirer profit du mooc massive open online course quils suivent nous proposons un outil pour recommander à chacun dentre eux une liste ordonnée des “apprenants leaders” capables de le soutenir durant son processus dapprentissage la phase de recommandation est basée sur une approche daide à la décision multicritère pour la prédiction périodique des “apprenants leaders” etant donnée lhétérogénéité des profils des apprenants nous recommandons à chacun dentre eux les leaders appropriés à son profil en utilisant la distance euclidienne et le filtrage démographique\n",
      "lexploitation de données contextuelles pour la recommandation dhôtels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les systèmes de recommandation ont pour rôle daider les utilisateurs submergés par la quantité dinformation à faire de bons choix à partir de vastes catalogues de produits le déploiement de ces systèmes dans lindustrie hôtelière est confronté à des contraintes spécifiques limitant la performance des approches traditionnelles les systèmes de recommandation dhôtels souffrent en particulier dun problème de démarrage à froid continu à cause de la volatilité des préférences des voyageurs et du changement de comportements en fonction du contexte dans cet article nous présentons le problème de recommandation dhôtels ainsi que ses caractéristiques distinctives nous proposons de nouvelles méthodes contextuelles qui prennent en compte les dimensions géographique et temporelle ainsi que la raison du voyage afin de générer les listes de recommandation nos expérimentations sur des jeux de données réels soulignent la contribution des données contextuelles à lamélioration de la qualité de recommandation\n",
      "lontologie ontobiotope pour létude de la biodiversité microbienne\n",
      "lintégration des données hétérogènes en sciences de la vie est un sujet de recherche majeur limportance et le volume considérable des informations sur les milieux de vie des micro organismes dans tous les domaines tels que la santé lagriculture ou lenvironnement justifie le développement de traitements automatisés nous proposons ici lontologie ontobiotope dont nous décrivons les principes de construction ainsi que des exemples dutilisation pour lannotation et lindexation sémantique des habitats microbiens décrits en langue naturelle dans les documents scientifiques\n",
      "longrange influences in social networks\n",
      "nan\n",
      "mainmise sur les médias et suivi de communautés dans les graphes dynamiques\n",
      "ce court article présente le design et lutilisation dun tableau de bord visuel permettant dexplorer questionner et comprendre lévolution des communautés dun graphe dynamique lexemple ayant motivé la conception et la réalisation de ce tableau de bord est celui dun réseau daffiliation des personnalités présentes dans les médias français le suivi de communautés savère utile pour cerner le biais potentiel induit de la coprésence répétée des mêmes personnalités dans les émissions de radio et de télévision au cours du temps\n",
      "meanshift  clustering scalable et distribué\n",
      "nous présentons dans ce papier un nouvel algorithme meanshift utilisant les kplus proches voisins pour la montée du gradient nnms  nearest neighbours mean shift le coût computationnel intensif de ce dernier a longtemps limité son utilisation sur des jeux de données complexes où un partitionnement en clusters non ellipsoïdaux serait bénéfique or une implémentation scalable de lalgorithme ne compense pas laugmentation du temps dexécution en fonction de la taille du jeu de données en raison de sa complexité quadratique afin de pallier ce problème nous avons introduit le locality sensitive hashing lsh qui est une approximation de la recherche des kplus proches voisins ainsi quune règle empirique pour le choix du k la combinaison de ces améliorations au sein du nnms offre lopportunité dun traitement pertinentaux problématiques du clustering appliquée aux données massives\n",
      "métaanalyse ordinale denquêtes dopinion application aux usages de linternet des objets en entreprise\n",
      "la multiplicité des enquêtes dopinion sur un même sujet nécessite la construction de synthèses qui agrègent les résultats obtenus dans des conditions indépendantes dans cet article nous proposons une nouvelle approche ordinale de métaanalyse qui consiste à rechercher un ordre consensus qui rend compte « au mieux » des ordres partiels entre les modalités issus des résultats des différentes enquêtes nous modélisons ce problème par une variante dune recherche dun ordre médian sur les sommets dun graphe orienté pondéré et nous développons un algorithme de séparationévaluation pour le résoudre notre approche est appliquée sur un ensemble denquêtes internationales portant sur les motivations et les freins à lintégration de linternet des objets dans les entreprises\n",
      "méthode basée sur les ensembles approximatifs pour lapprentissage incrémental en présence des données déséquilibrées\n",
      "ce papier propose une méthode basée sur la théorie des ensembles approximatifs et dédiée à lapprentissage supervisé incrémental dans un contexte de données déséquilibrées cette méthode consiste en trois phases  la construction dune table de décision linférence dun ensemble de règles de décision et la classification de chaque action potentielle dans lune des classes de décision prédéfinies la méthode mai2p est validée dans le contexte des moocs massive open online courses\n",
      "méthode dapprentissage pour extraire les localisations dans les microblogs\n",
      "nan\n",
      "modélisation des métadonnées dun data lake en data vault\n",
      "avec lavènement des mégadonnées linformatique décisionnelle a dû trouver des solutions pour gérer des données de très grands volume et variété les lacs de données data lakes répondent à ces besoins du point du vue du stockage mais nécessitent la gestion de métadonnées adéquates pour garantir un accès efficace aux données sur la base dun modèle multidimensionnel de métadonnées conçu pour un lac de données présentant un défaut dévolutivité de schéma nous proposons lutilisation dun data vault pour traiter ce problème pour montrer la faisabilité de cette approche nous instancions notre modèle conceptuel de métadonnées en modèles logiques et physiques relationnel et orienté document nous comparons également les modèles physiques en termes de stockage et de temps de réponse aux requêtes sur les métadonnées\n",
      "nfb protocole de notarisation des documents dans la blockchain\n",
      "nan\n",
      "nouveau modèle de sélection de caractéristiques basé sur la théorie des ensembles approximatifs pour les données massives\n",
      "nan\n",
      "palm un algorithme parallèle pour extraire des clusters de liens dans les réseaux sociaux\n",
      "dans cet article nous nous intéressons à loptimisation du processus de recherche de clusters de liens nous proposons en particulier lalgorithme palm stattner et al 2017 qui vise à améliorer lefficacité du processus dextraction par lexploration conjointe de plusieurs zones de lespace de recherche ainsi nous commençons par démontrer que lespace des solutions forme un treillis de concepts nous proposons ensuite une approche qui explore en parallèle les branches de ce treillis tout en réduisant lespace de recherche en sappuyant sur différentes propriétés les bonnes performances de notre algorithme sont démontrées en le comparant avec lalgorithme dextraction dorigine\n",
      "peerus review un outil de recherche dexperts scientifiques\n",
      "nous proposons un outil de recherche dexperts appliqué au monde académique sur les données générées par lentreprise dsrt dans le cadre de son application peerus 1 un utilisateur soumet le titre le résumé et optionnellement les auteurs et le journal de publication dun article scientifique et se voit proposerune liste dexperts potentiels reviewers de larticle soumis lalgorithme de recherche est un système de votes reposant sur un modèle du langage entrainé à partir dun ensemble de plusieurs millions darticles scientifiques loutil est accessible à chacun sous la forme dune application web intitulée peerus review 2\n",
      "perforecast  un outil de prévision de lévolution de séries temporelles pour le planning capacitaire\n",
      "nous présentons perforecast un outil qui vise à automatiser le processus de planning capacitaire en utilisant des données temporelles univariées et des modèles prédictifs configurés automatiquement lobjectif est danticiper les problèmes de dimensionnement dans les infrastructures dorange qui assurent la délivrance dun service aux clients il sagira par exemple de prévoir au plus « tôt » la surcharge dun serveur afin de commander en avance de nouvelles machines avant la détérioration du service considéré les démarches de dimensionnent et dachat étant longues et coûteuses plus elles sont effectuées tôt meilleure sera la qualité de service\n",
      "prédiction du rayonnement solaire par apprentissage automatique\n",
      "cet article décrit une approche flexible pour la prédiction à court terme de variables météorologiques en particulier nous nous intéressons à la prédiction du rayonnement solaire à une heure cette tâche est dune grande importance pratique dans loptique doptimiser les resources énergétiques solaires comme le défi egc 2018 nous fournit des données météorologiques enregistrées sur cinq sites géographiques de lîle de la réunion nous utilisons ces données historiques comme base pour créer des modèles de prédiction et nous testons la performance de ces modèles selon le site considéré après avoir décrit notre méthode de nettoyage de données et de normalisation nous combinons une méthode de sélection de variables basée sur les modèles arima autoregressive integrated moving average à lutilisation de méthodes de régression génériques telles que les arbres de régression et les réseaux de neurones\n",
      "prétraitement de données spatialement imprécises pour une classification supervisée basée sur les images satellitaires\n",
      "dans un problème de classification supervisée les données dapprentissage proviennent souvent dinventaires acquis sur le terrain par des experts du domaine toutefois la localisation de ces inventaires est approximative en raison de la précision intrinsèque des gps portables utilisés cette imprécision spatiale est particulièrement problématique lorsque ces données sont utilisées pour entrainer un classifieur sur des images satellitaires très haute résolution thr en effet la précision spatiale des inventaires peut être dans certains cas bien inférieure à celles de ces images dans ce papier nous proposons trois approches visant à améliorer la précision spatiale des données terrain via des prétraitements le principe est dexploiter les images satellitaires thr disponibles pour corriger spatialement les données terrain nos expérimentations mettent en avant lintérêt de ces prétraitements sur un jeu de données constitué de 24 inventaires dhabitats coralliens et une image satellitaire thr worldview2\n",
      "prise en compte de la structure des documents pour une indexation performante\n",
      "nan\n",
      "propositions pour améliorer une méthode de prédiction du succès dune campagne de financement participatif\n",
      "le financement participatif est un mode de financement dun projet faisant appel à un grand nombre de personnes qui a connu une forte croissance avec lémergence dinternet et des réseaux sociaux cependant plus de 60  des projets ne sont pas financés il est donc important de bien préparer sa campagne de financement de plus en cours de campagne il est crucial davoir une estimation rapide de son succès afin de pouvoir réagir rapidement restructuration communication  des outils de prédiction sont alors indispensables nous proposons dans cet article plusieurs pistes damélioration pour la prédiction du montant levé lors dune campagne de financement participatif en utilisant lalgorithme knn la première proposition consiste à utiliser un algorithme de clustering afin de segmenter lensemble dapprentissage et faciliter le passage à léchelle la seconde proposition consiste à extraire des caractéristiques pertinentes depuis les séries temporelles et les informations sur les campagnes pour avoir une représentation vectorielle\n",
      "questce quun bon système dapprentissage  la réponse a évolué avec le temps et demain\n",
      "lapprentissage automatique pardon le « machine learning » a envahi la sphère médiatique grâce à des succès impressionnants comme la victoire dune machine au go ou la promesse de véhicules autonomes arrivant très prochainement sur nos routes de fait tant lexploitation des données massives que la production de code machine à partir de lexpérience de la machine plutôt que par des humains met lapprentissage automatique au coeur de lintelligence artificielle très certainement cela signifie que nous savons répondre à la question « questce quun bon système dapprentissage  » et quil ne nous reste plus quà en décliner la réponse pour obtenir des systèmes adaptés à chaque domaine applicatif pourtant la réponse à cette question a profondément évolué au cours des 60 dernières années au point que les publications sur lapprentissage automatique dil y a quelques décennies semblent venir dune autre planète et ne sont dailleurs plus enseignés aux étudiants et ceci pas seulement parce que les connaissances passées seraient jugées obsolètes mais parce quelles ne semblent pas pertinentes avonsnous donc raison  nos précurseurs avaientils tort  et nos successeurs nous citerontils dans leurs manuels  dans cette présentation nous examinerons quelques moments clés de lhistoire de lapprentissage automatique correspondant à des tournants dans la manière de considérer ce quest un bon système dapprentissage et nous nous demanderons si nous vivons un autre moment charnière dans lequel changent notre perspective la question que nous cherchons à résoudre dans nos recherches les concepts manipulés et la manière décrire nos papiers\n",
      "recommendationbased keyword search over relational databases\n",
      "récemment la recherche par motsclés dans les bases de données relationnelles a suscité un intérêt grandissant en raison de sa facilité dutilisation bien que des recherches approfondies fussent dernièrement effectuées dans ce contexte la plupart de ces recherches non seulement nécessitent un accès préalable aux données ce qui restreint leur applicabilité si cette condition nest pas vérifiée mais aussi renvoient des réponses très génériques cependant fournir aux utilisateurs des réponses personnalisées est devenu plus que jamais nécessaire en raison de la surabondance de données qui peut déranger lutilisateur le défi de retourner des réponses pertinentes et personnalisées qui satisfont les besoins des utilisateurs demeure inspiré par lapplication réussie de la technique de filtrage collaboratif dans les systèmes de recommandation nous proposons une nouvelle approche basée sur les motsclés pour fournir aux utilisateurs des résultats personnalisés basés sur lhypothèse que seulement une information sur le schéma de la base de données est disponible\n",
      "reconnaissance et indexation automatique des registres de la chancellerie française 13001483\n",
      "les documents manuscrits sont parmi les témoins les plus importants de lhistoire européenne ces dernières années dimportantes collections de manuscrits historiques ont été numérisées et mises à disposition du public et des chercheurs cependant la richesse des informations quils contiennent est encore largement inaccessible car seul les images et quelques métadonnées sont disponibles lidéal pour les utilisateurs serait de pouvoir faire des recherches textuelles comme pour les livres imprimés modernes httpsbooksgooglefr si les technologies danalyse de documents historiques et de reconnaissance décriture manuscrite sont encore trop peu performantes pour permettre lutilisation directe de la transcription brute il est possible de mettre à la disposition des utilisateurs un moteur de recherche textuel basé sur une indexation automatique des images de documents manuscrits cette indexation se base sur une transcription automatique mais tire profit de la capacité de la machine à générer des hypothèses reconnaissance multiples et pondérées cette technologie a permis de rendre accessible pour la première fois à la recherche textuelle les registres de la chancellerie royale française 1302 1483 un des corpus de documents historiques les plus emblématiques pour la france ouvrant ainsi la voie à de nouvelles méthodes de recherche en histoire  httpwwwhimanisorg\n",
      "reframing for nonlinear dataset shift\n",
      "les modèles de classification discriminante supposent que les données de formation et de déploiement ont les mêmes distributions dattributs de données ces modèles donnent des performances très variées lorsquils sont déployés dans des conditions variées avec différentes distributions de données ce phénomène est appelé dataset shift dans cet article nous avons fourni une méthode qui détermine dabord sil y a un changement significatif dans les distributions dattributs entre les ensembles de données dapprentissage et de déploiement sil existe un changement dans les données la méthode proposée utilise ensuite une approche de hill climbing pour cartographier ce décalage quelle que soit sa nature cestàdire linéaire ou non linéaire à léquation pour la transformation quadratique les résultats expérimentaux sur trois jeux de données réels montrent de forts gains de performance obtenus par la méthode proposée par rapport aux méthodes précédemment établies telles que le reconditionnement et le recadrage linéaire\n",
      "régression laplacienne semisupervisée pour la reconstitution des dates de pose des réseaux dassainissement\n",
      "la date de pose est souvent un facteur principal dexplication de la dégradation des conduites dassainissement pour les gestionnaires de ces réseaux connaître cette information permet ainsi par lutilisation de modèles de détérioration de prédire létat de santé actuel des conduites non encore inspectées cette connaissance est primordiale pour prendre des décisions dans un contexte de forte contrainte budgétaire lobjectif est ainsi de reconstituer ces dates de pose à partir des caractéristiques du patrimoine et de son environnement les données à manipuler présentent plusieurs niveaux de complexité importants leurs sources sont hétérogènes leur volume est important et les informations sur leur étiquetage dates sont limitées  seulement 24  du linéaire est connu pour les réseaux dassainissement de la métropole de lyon la base de données sousjacente contient les caractéristiques connues des conduites profil géométrique matériau utilisé etc dans ce papier nous proposons de mesurer leffet et limpact de quelques méthodes dapprentissage statistique semisupervisé et de proposer ainsi une approche alternative adaptée à la reconstitution de ce type de données\n",
      "réseau bayésien pour la gestion de lobsolescence dans une base dinformations en vue de lévaluation du risque de chute des personnes âgées\n",
      "lévaluation périodique du risque de chute des personnes âgées requiert des informations fiables et nombreuses comme il nest pas possible de recueillir régulièrement toutes ces informations les observations sont faites au fil du temps et conservées ce qui entraîne une problématique liée au vieillissement des informations cet article traite de la détection des informations obsolètes dans une base dinformations sur une personne âgée nous proposons une solution comportant un modèle de connaissances sur les personnes âgées sous forme dun réseau bayésien et un module de raisonnement chargé de la détection et de la gestion des contradictions et des doutes sur les informations\n",
      "savoir au dela de voir vision artificielle et raisonnement logique\n",
      "nan\n",
      "sémantique des données dobservation en neuroimagerie selon un point de vue réaliste\n",
      "lobjectif de ce travail est de décrire avec une approche réaliste la signification des données dobservation en neuroimagerie sous un format formel pour faciliter leur interprétation par les cliniciens et leur réutilisation dans dautres contextes\n",
      "temporal hints in the cultural heritage discourse what can an ontology of time as it is worded reveal\n",
      "dans le champ des sciences patrimoniales la dimension temporelle de linformation joue un rôle à lévidence majeur tant pour linterpréter et lanalyser que pour relier des faits isolés mais la façon dont cette dimension est verbalisée pose des problèmes de formalisation non triviaux pourtant cette verbalisation que lon associe souvent au termechapeau dincertitude peut être lue en dissociant dune part le caractère mal connu dun fait documenté irréductible et les choix faits par le producteur de linformation pour la relativiser dans cette contribution nous proposons un modèle formel permettant dobserver et danalyser de façon systématique cette couche de verbalisation lexpérience est menée sur des données fortement hétérogènes souvent dorigine citoyenne documentant le petit patrimoine matériel et immatériel ce cas détude est donc limité mais il apparait néanmoins comme portant une question de fond allant audelà du cas despèce la contribution détaille dabord la grille danalyse dindices temporels proposée puis relate lexpérimentation concrète associée ontologie owl il nest pas fait état dune quelconque prétention à un résultat généralisable stricto sensu mais cette expérience peut contribuer à nourrir de façcon pragmatique un débat nécessaire sur la formalisation dindices temporels dans les sciences historiques\n",
      "un modèle bayésien de coclustering de données mixtes\n",
      "nous proposons un modèle de coclustering de données mixtes et un critère bayésien de sélection du meilleur modèle le modèle infère automatiquement les discrétisations optimales de toutes les variables et effectue un coclustering en minimisant un critère bayésien de sélection de modèle un avantage de cette approche est quelle ne nécessite aucun paramètre utilisateur de plus le critère proposé mesure de façon exacte la qualité dun modèle tout en étant régularisé loptimisation de ce critère permet donc daméliorer continuellement les modèles trouvés sans pour autant surapprendre les données les expériences réalisées sur des données réelles montrent lintérêt de cette approche pour lanalyse exploratoire des grandes bases de données\n",
      "une approche sémantique hybride pour la recommandation des articles dactualité à large échelle\n",
      "les portails dactualités en ligne produisent un flux dinformation ayant un volume et une vélocité importants dans ce contexte il devient plus difficile de proposer en temps réel des recommandations dynamiques adaptées aux intérêts de chaque utilisateur dans cet article nous présentons une approche hybride pour la recommandation des articles dactualité reposant sur lanalyse sémantique du contenu disponible lapproche est basée sur lhybridation de plusieurs approches personnalisées et non personnalisées pour remédier au problème de démarrage à froid lexpérimentation de notre approche dans un environnement à large échelle et à fortes contraintes temps réel dans le cadre du challenge newsreel a permis dévaluer la qualité de ses recommandations et de confirmer lapport de la sémantique dans le processus de recommandation\n",
      "une méthode pour lestimation désagrégée de données de population à laide de données ouvertes\n",
      "nous présentons dans ce travail une méthode de désagrégation pour lestimation de population à léchelle locale à partir de données ouvertes globales notre but est destimer notamment le nombre de personnes résidant dans chaque bâtiment de la zone dintérêt à partir de données à plus grande échelle une description fine à léchelle résidentielle est tout dabord effectuée à partir des données dopenstreetmap les surfaces des bâtiments dhabitation ou dusage mixte habitation et activités sont notamment identifiées nous effectuons ensuite une désagrégation à partir de données de grille de population à grande échelle 1km2 par carreau guidée par les surfaces des bâtiments compris dans chaque carreau de la grille ensuite nous effectuons une désagrégation à partir de données de grille de population à grande échelle 1km2 par carreau guidée par les distributions spatiales découvertes à létape précédente nous utilisons exclusivement des données ouvertes pour favoriser la réplicabilité et pour pouvoir appliquer notre méthode à toute région dintérêt pour peu que la qualité des données soit suffisante lévaluation et la validation du résultat dans le cas de plusieurs villes françaises sont effectuées à laide de données de recensement insee\n",
      "unitexgramlab plateforme libre basée sur des lexiques et des grammaires pour le traitement des corpus textuels\n",
      "lobjectif de notre recherche est de répondre aux besoins croissants et divers dextraction dinformation pertinente exprimés par de nombreuses disciplines nous utilisons pour cela lanalyseur multilingue de corpus unitexgramlab développé à luniversité parisest marnelavallée il fait appel à une approche symbolique et utilise des ressources linguistiques dictionnaires électroniques et grammaires locales cette présentation ne constitue quune prise en main dunitexgramlab et ne reflète que très partiellement les possibilités du logiciel et son champ dutilisation notamment pour lextraction dinformation qui sétend du monde de la recherche à celui de lindustrie\n",
      "universalendpointcom  une plateforme daccès simple au web des données\n",
      "universalendpointcom est une plateforme web permettant un accès simple au web des données par trois aspects  i une plateforme de correspondance pour laccès aux bases du web des données depuis un seul point daccès centralisé ii le langage simpleparql pour une écriture intuitive de requêtes sous forme de triplets à la manière de sparql mais ne nécessitant pas une connaissance préalable des bases du web des données et iii une aide à la rédaction de requêtes sparql\n",
      "utilisation de techniques de modélisation thématiques pour la détection de nouveauté dans des flux de données textuelles\n",
      "avec lavènement des réseaux sociaux et la multiplication des messages produits au sujet des entreprises mieux comprendre les retours clients est devenu un enjeu primordial des techniques de classification automatique et de modélisation thématique permettent dors et déjà dobserver les principales tendances observées dans ces données il est intéressant dans une optique danticipation dobserver les thématiques émergentes et de les identifier avant quelles ne prennent de lampleur afin de résoudre cette problématique nous avons étudié la piste de lutilisation de modèles lda pour détecter les documents relatifs à ces thématiques émergentes nous avons testé trois systèmes sur plusieurs scénarios darrivées de la nouveauté dans le flux de données nous montrons que les modèles thématiques permettent de détecter cette nouveauté mais que cela dépend du scénario envisagé\n",
      "visualisation dynamique de connaissances  application aux interactions entre facteurs de risque des maladies cardiovasculaires\n",
      "nan\n",
      "a hybrid approach for detecting influencers in social media\n",
      "la détection dinfluenceurs dans les réseaux sociaux sappuie généralement sur une structure de graphe représentant les utilisateurs et leurs interactions récemment cette tâche a tenu compte en sus de la structure du graphe du contenu textuel généré par les utilisateurs notre approche sinscrit dans cette lignée  des informations sont extraites du contenu textuel par des règles linguistiques puis sont intégrées dans un système dapprentissage automatique nous montrerons le prototype développé et son interface de visualisation qui facilite linterprétation des résultats\n",
      "analyse des dynamiques spatiotemporelles à partir de séries temporelles dimages satellitaires\n",
      "la télédétection est un domaine qui regroupe les techniques et les outils permettant lobservation de la terre notamment lacquisition dimages satellitaires la méthode proposée dans cet article permet une analyse automatique de séries temporelles de telles images nos travaux introduisent un nouvelle approche pour lanalyse et le clustering de séries temporelles dimages satellitaire stis ce processus se divise en deux parties dans un premier temps nous retraçons les changements radiométriques dune zone en représentant son évolution au cours du temps par un graphe dit graphe dévolution dans un deuxième temps nous introduisons une représentation synthétique des graphes dévolutions afin de pouvoir appliquer un algorithme de clustering permettant un regroupement par types dévolutions identifiées les expérimentations menées nous ont permis de valider notre approche sur une zone détude\n",
      "analyse exploratoire de corpus textuels pour le journalisme dinvestigation\n",
      "nous proposons un outil de visualisation analytique conçu pour et avec une journaliste dinvestigation pour lexploration de corpus textuels notre outil combine une technique de biclustering disjoint pour extraire des sujets de haut niveau avec une méthode de biclustering nondisjoint pour révéler plus finement les variantes de sujets une vue densemble des sujets de haut niveau est proposée sous forme dune treemap puis une visualisation hiérarchique radiale coordonnée avec une heatmap permet dinspecter et de comparer les variantes de sujet et daccéder aux contenus dorigine à la demande\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anonymiser des données multidimensionnelles à laide du coclustering\n",
      "dans cet article nous proposons une méthodologie pour anonymiser une table de données multidimensionnelles contenant des données individuelles soit n individus décrits par m variables lobjectif est de publier une table anonyme construite à partir dune table initiale qui protège contre le risque de réidentification en dautres termes on ne doit pas pouvoir retrouver dans les données publiées un individu présent dans la table originale la solution proposée consite à agréger les données à laide dune technique de coclustering puis à utiliser le modèle produit pour générer une table de données synthétiques du même format que les données initiales les données synthétiques qui contiennent des individus fictifs peuvent maintenant être publiées les données produites sont évaluées en termes dutilité pour différentes tâches de fouille analyse exploratoire classification et de niveau de protection\n",
      "application du coclustering à lanalyse exploratoire dune table de données\n",
      "la classification croisée est une technique danalyse non supervisée qui permet dextraire la structure sousjacente existante entre les individus et les variables dune table de données sous forme de blocs homogènes cette technique se limitant aux variables de même nature soit numériques soit catégorielles nous proposons de létendre en proposant une méthodologie en deux étapes lors de la première étape toutes les variables sont binarisées selon un nombre de parties choisi par lanalyste par discrétisation en fréquences égales dans le cas numérique ou en gardant les valeurs les plus fréquentes dans le cas catégoriel la deuxième étape consiste à utiliser une méthode de coclustering entre individus et variables binaires conduisant à des regroupements dindividus dune part et de parties de variables dautre part nous appliquons cette méthodologie sur plusieurs jeux de donnée en la comparant aux résultats dune analyse par correspondances multiples acm appliquée aux même données binarisées\n",
      "application mobile pour lévaluation dun algorithme de calcul de distance entre des items musicaux\n",
      "les systèmes de recommandation permettent de présenter à un utilisateur des éléments susceptibles de lintéresser la mise en place de tels systèmes dans les domaines culturels soulève souvent le questionnement de la place de la diversité de la nouveauté et surtout de la découverte nous pensons que lêtre humain bien quayant ordinairement une tendance à se placer dans une zone de confort correspondant à ce quil connaît apprécie occasionnellement dêtre poussé à des explorations le faisant sortir de sa routine nous avons développé dans cette optique une méthode basée sur la dissimilarité qui élargit les centres dintérêt des utilisateurs nous avons réussi à délimiter une zone intermédiaire entre des items « trop similaires » et des items « trop différents » afin de valider cette hypothèse nous avons développé une application qui permet de tester et de valider cette méthode dans cet article de démonstration nous expliquons le concept de « zone intermédiaire » nous détaillons le fonctionnement de lapplication puis nous présentons les résultats obtenus à partir des tests effectués\n",
      "apprentissage despaces prétopologiques dans un cadre multiinstance pour la structuration de données\n",
      "nous présentons dans cet article une méthode supervisée de structuration en dag dun ensemble déléments étant donnés une structure cible et un ensemble de relations sur ces éléments il sagit dapprendre un modèle de structuration par combinaison des relations initiales nous formalisons ce problème dans le cadre de la théorie de la prétopologie qui permet datteindre des modèles de structuration complexes nous montrons que la nonidempotence de la fonction dadhérence rentre dans le cadre du formalisme de lapprentissage supervisé multiinstance et nous proposons un algorithme dapprentissage reposant sur le dénombrement des «sacs» positifs et négatifs plutôt que sur un ensemble dapprentissage standard une première expérimentation de cette méthode est présentée dans un cadre applicatif de fouille de textes consistant à apprendre un modèle de structuration taxonomique dun ensemble de termes\n",
      "apprentissage de structures séquentielles pour lextraction dentités et de relations dans des textes dappels doffres\n",
      "dans cet article nous présentons une étude exploitant des méthodes dapprentissage automatique de structures séquentielles pour extraire des relations sémantiques dans des textes issus de bases dappels doffres lune des relations que nous considérons concerne lemprise dun projet daménagement caractérisée par une association entre les concepts qui définissent les infrastructures bâtiments et les concepts qui définissent leurs surfaces dimplantation létude propose une analyse comparée dapproches à base de champs conditionnels aléatoires crf de crf dordre supérieur hcrf de crf semimarkoviens modèles de markov cachés hmm et de perceptrons structurés\n",
      "approche préventive pour une gestion élastique du traitement parallèle et distribué de flux de données\n",
      "dans un contexte de traitement de flux de données il est important de garantir à lutilisateur des propriétés de performance qualité des résultats et passage à léchelle mettre en adéquation ressources et besoins pour nallouer que les ressources nécessaires au traitement efficace des flux est un défi dactualité majeur au croisement des problématiques du big data et du green it lapproche que nous suggérons permet dadapter dynamiquement et automatiquement le degré de parallélisme des différents opérateurs composant une requête continue selon lévolution du débit des flux traités nous proposons i une métrique permettant destimer lactivité future des opérateurs selon lévolution des flux en entrée ii lapproche autoscale évaluant a priori lintérêt dune modification du degré de parallélisme des opérateurs en prenant en compte limpact sur le traitement des données dans sa globalité iii grâce à une intégration de notre proposition à apache storm nous exposons des tests de performance comparant notre approche par rapport à la solution native de cet outil\n",
      "cadre devaluation pour la méta analyse de données\n",
      "nan\n",
      "classification ascendante hiérarchique à noyaux et une application aux données textuelles\n",
      "la formule de lance et williams permet dunifier plusieurs méthodes de classification ascendante hiérarchique cah dans cet article nous supposons que les données sont représentées dans un espace euclidien et nous établissons une nouvelle expression de cette formule en utilisant les similarités cosinus au lieu des distances euclidiennes au carré notre approche présente les avantages suivants dune part elle permet détendre naturellement les méthodes classiques de cah aux fonctions noyau dautre part elle permet dappliquer des méthodes décrêtage permettant de rendre la matrice de similarités creuse afin daméliorer la complexité de la cah lapplication de notre approche sur des tâches de classification automatique de données textuelles montre dune part que le passage à léchelle est amélioré en mémoire et en temps de traitement dautre part que la qualité des résultats est préservée voire améliorée\n",
      "classification dobjets 3d par extraction aléatoire de sousparties discriminantes pour létude du soussol en prospection pétrolière\n",
      "dans cet article nous proposons une nouvelle approche de classification dobjets 3d inspirée des time series shapelets de ye et keogh 2009 lidée est dutiliser des soussurfaces discriminantes pour la classification concernée afin de prendre en compte la nature locale des éléments pertinents cela permet à lutilisateur davoir connaissance des sousparties qui ont été utiles pour déterminer lappartenance dun objet à une classe les résultats obtenus confirment lintérêt de la sélection aléatoire de caractéristiques candidates pour la présélection dattributs en classification supervisée\n",
      "classification multilabels graduée apprendre les relations entre les labels ou limiter la propagation derreur \n",
      "la classification multilabels graduée est la tâche daffecter à chaque donnée lensemble des labels qui lui correspondent selon une échelle graduelle de degrés dappartenance les labels peuvent donc avoir à la fois des relations dordre et de cooccurrence dun côté le fait dignorer les relations entre les labels risque daboutir à des prédictions incohérentes et dun autre côté le fait de prendre en compte ces relations risque de propager lerreur de prédiction dun label à tous les labels qui lui sont reliés les approches de létat dart permettent soit dignorer les relations entre les labels soit dapprendre uniquement les relations correspondant à une structure de dépendance figée lapproche que nous proposons permet lapprentissage des relations entre les labels sans fixer une structure de dépendance au préalable elle est basée sur un ensemble de classifieurs monolabels un pour chaque label lidée est dapprendre dabord toutes les relations entre les labels y compris les relations cycliques ensuite les dépendances cycliques sont résolues en supprimant les relations dintérêt minimal des mesures sont proposées pour évaluer lintérêt dapprendre chaque relation ces mesures permettent dagir sur le compromis entre lapprentissage de relations pour une prédiction cohérente et la minimisation du risque de la propagation derreur de prédiction\n",
      "classification parcimonieuse pour laide à la reconnaissance de cibles radar\n",
      "dans le présent papier nous proposons létude et lapplication dune nouvelle approche pour laide à la reconnaissance automatique de cibles atr pour automatic target recognition à partir des images à synthèse douverture inverse isar pour inverse synthetic aperture radar cette approche est composée de deux phases principales dans la première phase nous utilisons deux méthodes statistiques pour extraire les caractéristiques discriminants à partir des images isar nous nous intéressons dans ce travail aux deux descripteurs multiéchelles issus des deux méthodes sift scaleinvariant feature transform et la décomposition en ondelettes complexes dtcwt dualtree complex wavelet transform qui sont calculées disjointement ensuite nous modélisons séparément les descripteurs issus des deux méthodes précédentes sift et dtcwt par la loi gamma les paramètres statistiques estimés sont utilisés pour la deuxième phase dédiée à la classification dans cette deuxième phase une classification parcimonieuse src pour sparse representationbased classification est proposée afin dévaluer et valider notre approche nous avons eu recours aux données réelles dimages issues dune chambre anéchoïque les résultats expérimentaux montrent que lapproche proposée peut atteindre un taux de reconnaissance élevé et dépasse largement lutilisation du même descripteur avec le classifieur machine à vecteurs de support svm pour support vector machine\n",
      "coclustering de données mixtes à base des modèles de mélange\n",
      "la classification croisée coclustering est une technique non supervisée qui permet dextraire la structure sousjacente existante entre les lignes et les colonnes dune table de données sous forme de blocs plusieurs approches ont été étudiées et ont démontré leur capacité à extraire ce type de structure dans une table de données continues binaires ou de contingence cependant peu de travaux ont traité le coclustering des tables de données mixtes dans cet article nous étendons lutilisation du coclustering par modèles à blocs latents au cas des données mixtes variables continues et variables binaires nous évaluons lefficacité de cette extension sur des données simulées et nous discutons ses limites potentielles\n",
      "comparaison et évaluation de mesures de similarité entre concepts dun treillis\n",
      "cet article se situe dans le cadre de lanalyse de concepts formels acf qui fournit des classes les extensions dobjets partageant des caractères similaires les intensions une description par des attributs étant associée à chaque classe dans un article récent une nouvelle mesure de similarité entre deux concepts dans un treillis de concepts a été introduite permettant une normalisation par la taille du treillis dans cet article nous comparons cette mesure de similarité avec des mesures existantes soit basées sur la cardinalité des ensembles ou issues de la conception dontologies et basées sur la structure hiérarchique du treillis une comparaison statistique avec des méthodes existantes est effectuée et testée pour leur consistance\n",
      "conception dun modèle généraliste pour lévaluation dun test ab\n",
      "nan\n",
      "découverte de sousgroupes avec les arbres de recherche de monte carlo\n",
      "découvrir des règles qui distinguent clairement une classe dune autre reste un problème difficile de tels motifs permettent de suggérer des hypothèses pouvant expliquer une classe la découverte de sousgroupes subgroup discovery sd un cadre qui définit formellement cette tâche dextraction de motifs est toujours confrontée à deux problèmes majeurs i définir des mesures de qualité appropriées qui caractérisent la singularité dun motif et ii choisir une heuristique dexploration de lespace de recherche correcte lorsquune énumération complète est irréalisable à ce jour les algorithmes de sd les plus efficaces sont basés sur une recherche en faisceau beam search bs la collection de motifs extraits manque cependant de diversité en raison de la nature gloutonne de lexploration nous proposons ici dutiliser une technique dexploration récente la recherche arborescente de monte carlo monte carlo tree search mcts le compromis entre lexploitation et lexploration ainsi que la puissance de la recherche aléatoire permettent dobtenir une solution disponible à tout moment et de surpasser généralement les approches de type bs notre étude empirique avec plusieurs mesures de qualité sur divers jeux de données de référence et du monde réel démontre la qualité de notre approche\n",
      "deep dive on smart cities by scaling reasoning and interpreting the semantics of iot\n",
      "modern cities are facing tremendous amount of information captured from internal infrastructures andor exogenous sensors human included this talk presents how big and heterogenous city data has been captured represented unified to serve one of the most pressing city objective improving quality of city in particular how understanding and reducing traffic congestion we will also present lessons learnt from the deployment of our system and experimentation in dublin ireland bologna italy miami usa and rio brazil\n",
      "défi egc 2017 modélisation costsensitive et enrichissement de données\n",
      "la conférence egc2017 propose un défi dont le contexte est la gestion des espaces verts pour la ville de grenoble et notamment des arbres qui y sont présents lobjectif est de proposer un modèle basé sur des données fournies qui permettrait de prédire au mieux les arbres malades ainsi que la localisation potentielle de la maladie après avoir obtenu quelques résultats intéressants avec des modèles standards notre approche utilisant un modèle costsensitive one against all csoaa nous permet dobtenir une exactitude de 086 une précision de 088 et un rappel de 091 sur la prédiction unilabel et une précisionrappel micro de 082074 ainsi quune précisionrappel macro de 066046 pour la prédiction multilabel lextraction de connaissances pour la tâche 2 nous a permis de mettre en relief lintérêt de lajout de données sur la nature des maladies et la concentration de la pollution dans la ville\n",
      "description interactive de lintérêt de lutilisateur via léchantillonnage de motifs\n",
      "la plupart des méthodes dextraction de motifs requièrent que lutilisateur formalise son intérêt avec une mesure dintérêt et des seuils lutilisateur est souvent incapable dexpliciter son intérêt mais il saura juger si un motif donné est pertinent ou non dans cet article nous proposons une nouvelle méthode de découverte de motifs interactive en supposant que seule une partie des données est intéressante pour lutilisateur en intégrant le retour utilisateur de motifs proposés un à un notre méthode vise à échantillonner des motifs avec une probabilité proportionnelle à leur fréquence dapparition au sein des transactions implicitement préférées par lutilisateur nous démontrons que notre méthode identifie exactement les transactions implicitement préférées par lutilisateur sous réserve de la consistance de ses retours des expérimentations montrent les bonnes performances de lapproche en terme de précision et rappel\n",
      "détection de fausses informations dans les réseaux sociaux  vers des approches multimodales\n",
      "nan\n",
      "enhanced useruser collaborative filtering recommendation algorithm based on semantic ratings\n",
      "nan\n",
      "evolution temporelle de communautés représentatives  mesures et visualisation\n",
      "la problématique de ce papier est didentifier dans un graphe dynamique les communautés les plus représentatives sur une période donnée de mesurer leur stabilité et den visualiser les évolutions majeures notre cas dusage concerne létude de la visibilité médiatique des communautés et des individus grâce aux données relatives aux émissions télévisuelles et radiophoniques entre 2011 et 2015 a partir dune détection de communautés sur lintégralité de la période nous proposons des mesures de stabilité et dactivité des communautés et proposons une visualisation de leur évolution temporelle\n",
      "expression des connaissances en langage naturel  singularité et normalité dune sélection\n",
      "nan\n",
      "extraction automatique de paysages en imagerie satellitaire et enrichissement sémantique\n",
      "nous présentons ici une méthode originale pour lautomatisation de la détection de paysages dans une image satellite deux enjeux majeurs apparaissent dans ce processus le premier réside dans la faculté à prendre en compte lensemble des connaissances expertes tout au long du travail danalyse de limage le second est de réussir à structurer et pérenniser ces connaissances de façon à les rendre interopérables et exploitables dans le cadre du web de données nous présentons en quoi la collaboration de plusieurs stratégies alliant les traitements de limage le calcul de caractéristiques spécifiques et la programmation logique inductive pli vient alimenter le processus dautomatisation et comment lintégration de la connaissance au travers de la construction dontologies dédiées permet de répondre pleinement à ces enjeux\n",
      "extraction de chroniques discriminantes\n",
      "lextraction de motifs séquentiels vise à extraire des comportements récurrents dans un ensemble de séquences lorsque ces séquences sont étiquetées lextraction de motifs discriminants engendre des motifs caractéristiques de chaque classe de séquences cet article sintéresse à lextraction des chroniques discriminantes où une chronique est un type de motif temporel représentant des durées interévènements quantitatives larticle présente lalgorithme dcm dont loriginalité réside dans lutilisation de méthodes dapprentissage automatique pour extraire les intervalles temporels les performances computationnelles et le pouvoir discriminant des chroniques extraites sont évalués sur des données synthétiques et réelles\n",
      "extraction de relations pour le peuplement dune base de connaissance à partir de tweets\n",
      "dans une base de connaissance les entités se veulent pérennes mais certains événements induisent que les relations entre ces entités sont instables cest notamment le cas pour des relations entre organisations produits ou marques entités qui peuvent être rachetées dans cet article nous proposons une approche permettant dextraire des relations dappartenance entre deux entités afin de peupler une base de connaissance lextraction des relations à partir dune source dynamique dinformations telle que twitter permet datteindre cet objectif en temps réel lapproche consiste à modéliser les événements en sappuyant sur une ressource lexicosémantique une fois les entités liées au web des données ouvertes en particulier dbpedia des règles linguistiques sont appliquées pour finalement générer les triplets rdf qui représentent les événements\n",
      "extraction des évolutions récurrentes dans un unique graphe dynamique attribué\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un grand nombre dapplications nécessitent danalyser un unique graphe attribué évoluant dans le temps cette tâche est particulièrement complexe car la structure du graphe et les attributs associés à chacun de ses noeuds ne sont pas figés dans ce travail nous nous focalisons sur la découverte de motifs récurrents dans un tel graphe ces motifs des séquences de sousgraphes connexes représentent les évolutions récurrentes de sousensembles de noeuds et de leurs attributs différentes contraintes ont été définies eg fréquence volume connectivité non redondance continuité et un algorithme original a été proposé les expérimentations réalisées sur des jeux de données synthétiques et réelles démontrent lintérêt de lapproche proposée et son passage à léchelle\n",
      "extraction et chaînage supervisés de connaissances dun corpus dentretiens en histoire des sciences\n",
      "nan\n",
      "extraction et inférence de connaissances à partir dassemblages mécaniques définis par une représentation cao 3d\n",
      "lextraction de connaissances à partir de modèles géométriques 3det les raisonnements associés constituent un enjeu important pour permettre le développement dontologies capables de décrire fonctionnellement des produits manufacturés dans ce contexte nous nous appuyons sur la logique déductive apportée par une base de connaissances étroitement couplée à un modeleur géométrique3d les raisonnements faisant appel au concept de forme 3d restent difficiles à formaliser et les informations géométriques difficiles à extraire nousproposons une formalisation de propriétés telles que à la même forme que est de la même famille que pour montrer comment lextraction dinformations géométriques 3d est reliée à ces propriétés par la suite une formalisation de propriétés telles que est un empilage est un regroupement est introduite pour montrer les raisonnements qui contribuent à la structuration dassemblages 3d ces propriétés sont illustrées à laide dun exemple de pompe hydraulique\n",
      "face2graph base de données graphe et visualisation pour lannotation darchives vidéos\n",
      "nous proposons dans ce travail dutiliser la flexibilité des modèles de base de données graphe et la représentation intuitive du réseau social afin de visuellement explorer annoter et vérifier des détections de visages dans une archive de 15 années de journaux télévisés\n",
      "faciliter les contributions personnelles pour préserver la mémoire des événements historiques\n",
      "un aspect essentiel dans la préservation du patrimoine culturel réside dans la collecte et lassemblage des témoignages provenant de citoyens ordinaires dans cet article nous présentons une architecture logicielle facilitant la saisie et le partage de témoignages concernant la période de la construction européenne au luxembourg en rédigeant son témoignage lutilisateur obtient les résultats dune extraction de connaissances sur le contenu saisi indiquant notamment des entités et informations liées\n",
      "génération de rdf à partir de sources de données aux formats hétérogènes\n",
      "contrairement à ce que promeut le web des données les données exposées par la plupart des organisations sont dans des formats nonrdf tels que csv json ou xml de plus sur le web des objets les objets contraints préféreront des formats binaires tels que exi ou cbor aux formats rdf textuels dans ce contexte rdf peut toutefois servir de lingua franca pour linteropérabilité sémantique lintégration de données aux formats hétérogènes le raisonnement et le requêtage dans ce but plusieurs outils et formalismes permettentde transformer des documents nonrdf vers rdf les plus flexibles étant basés sur des langages de transformation ou de correspondance grddl xsparql r2rml rml csvw etc cet article définit un nouveau langage sparqlgenerate qui permet de générer du rdf à partir i dune base de données rdf et ii dun nombre quelconque de documents aux formats arbitraires loriginalité de sparqlgenerate est quil étend sparql 11 et peut donc i être appris facilement par les ingénieurs de la connaissance familiers de sparql ii être implémenté au dessus de nimporte quel moteur sparql existant iii tirer parti des mécanismes dextension de sparql pour prendre en compte de futurs formats\n",
      "gestion de connaissances en temps réel depuis des flux massifs de données et apprentissage automatique\n",
      "lanalyse en tempsréel de données massives envoyées par des capteurs a connu ces dernières années un essor important du fait de lhétérogénéité de ces données lapplication de modèles de machine learning spécialement calibrés pour des cas dusages précis a permis dextraire et dinférer des informations de très grandes valeurs néanmoins peu de systèmes proposent une implémentation distribuée sur un vrai cluster industriel permettant de tirer profit de capacités de calcul décuplées nous présentons ici une démonstration de détection danomalie sur réseau souterrain deau potable en îledefrance réalisé avec notre plateforme dénotée waves\n",
      "interopérabilité sémantique libérale pour les services et les objets\n",
      "le web des données promeut lutilisation de rdf comme modèle pour les données structurées sur le web cependant la majorité des services web consomment et exposent principalement du csv json ou xml des format nonrdf il est peu probable que tous ces services se convertissent un jour aux formats rdf existants ceci est dautant plus vrai dans le contexte du web des objets puisque les formats rdf sont pour la plupart textuels alors que les objets contraints préféreront des formats binaires tels que exi ou cbor dans cet article nous proposons une approche pour permettre linteropérabilité sémantique de ces services et objets tout en leur laissant la liberté dutiliser leurs formats préférés notre approche sancre sur les principes de larchitecture du web et ceux du web des données liées et repose sur la définition de présentation rdf en supposant quune présentation rdf soit identifiée par une iri et déréférençable sur le web nous montrons comment avec différents protocoles du web un clientserveur peut faire comprendre à lautre partie comment le contenu dune message peut être interprété en rdf ou généré à partir de rdf nous nommons ceci la négociation de présentation rdf en utilisant ces principes nous montrons comment les services et objets existants pourraient être rendus interopérables à moindre coût sur le web sémantique\n",
      "kspectral centroïd pour des données massives\n",
      "nous nous intéressons à la classification non supervisée de séries chronologiques pour ce faire nous utilisons lalgorithme kspectral centroïd ksc une variante des kmeans kspectral centroïd utilise une mesure de dissimilarité entre séries chronologiques invariante par translation et par changement déchelle cet algorithme est coûteux en temps de calcul  lors de la phase daffectation il nécessite de tester toutes les translations possibles pour identifier la meilleure  lors de la phase de représentation le calcul du nouveau barycentre nécessite lextraction de la plus petite valeur propre dune matrice nous proposons dans ce travail trois optimisations de ksc lidentification de la meilleure translation peut être réalisée efficacement en utilisant la transformée de fourier discrète chaque matrice peut être calculée incrémentalement le calcul du nouveau barycentre peut seffectuer à moindre coût grâce à la méthode de la puissance itérée ces trois optimisations fournissent exactement la même classification que ksc\n",
      "machine learning based classification of android apps through text features\n",
      "nan\n",
      "machine learning for the semantic web filling the gaps in ontology mining\n",
      "in the semantic web view ontologies play a key role they act as shared vocabularies to be used for semantically annotating web resources and they allow to perform deductive reasoning for making explicit knowledge that is implicitly contained within them howevernoisyinconsistent ontological knowledge bases may occur being the web a shared and distributed environment thus making deductive reasoning no more straightforwardly applicable machine learning techniques and specifically inductive learning methods could be fruitfully exploited in this case additionally machine learning methods jointly with standard reasoning procedure could be usefully employed for discovering new knowledge from an ontological knowledge base that is not logically derivable the focus of the talk will be on various ontology mining problems and on how machine learning methods could be exploited for coping with them for ontology mining are meant all those activities that allow to discover hidden knowledge from ontological knowledge bases by possibly using only a sample of data specificallyby exploiting the volume of the information within an ontology machine learning methods could be of great help for semiautomatically enriching and refining existing ontologies for detecting concept drift and novelties within ontologies and for discovering hidden knowledge patterns also possibly exploiting other sources of information if on one hand this means to abandon sound and complete reasoning procedures for the advantage of uncertain conclusions on the other hand this could allow to reason on large scale and to to dial with the intrinsic uncertainty characterizing the web that for its nature could have incomplete andor contradictory information\n",
      "mesure de la confiance dans les systèmes dinformation  application aux données de navires\n",
      "ces dernières années la prolifération rapide des capteurs et des objets communicants de tous types a significativement enrichi le contenu des systèmes dinformation cependant cela suscite de nouvelles questions quant à la confiance que lon peut accorder aux informations et aux sources dinformations en effet ces sources peuvent être leurrées ou sous lemprise dun tiers qui falsifie ou altère les informations cet article propose donc daborder la sécurité des systèmes dinformations sous langle de la confiance dans les sources dinformations en premier lieu la définition puis lévaluation de la confiance dans un réseau hétérogène sont introduits une modélisation des sources est ensuite proposée la confiance dans ces sources dinformations est abordée au travers de deux caractéristiques la compétence et la sincérité lextraction de la confiance est réalisée via un ensemble de mesures de ces deux caractéristiques une expérience basée sur plusieurs sources simulées à partir dun jeu de données réelles montrent la pertinence de lapproche approche qui peut être transposée à dautres systèmes dinformation cette étude est appliquée à lanalyse des données de navigation et de positionnement dun navire\n",
      "mesure de similarité entre treillis basée sur des correspondances explicites\n",
      "ce document se situe dans le cadre de lanalyse de concepts formelsacf une méthode de hiérarchisation algébrique des données basée sur la notion dintension  extension partageant maximalement attributs et objets nousprésentons ici une mesure de similarité basée sur des correspondances entre deuxtreillis de galois définie par un modèle expressif utilisant des correspondancesentre objets et entre attributs des deux treillis un point clé de notre approcheest que ces correspondances peuvent ne pas être des fonctions associant un objet resp attribut dun treillis avec plusieurs objets resp attributs de lautretreillis\n",
      "nouveau modèle pour un passage à léchelle de la 0subsomption\n",
      "le test de \u0012subsomption opération fondamentale en programmation logique inductive pli pour tester la validité dune hypothèse sur les exemplesest particulièrement coûteux ainsi les systèmes dapprentissage de pli les plusrécents ne passent pas à léchelle nous proposons donc un nouveau modèle de\u0012subsomption fondé sur un réseau dacteurs dans le but de pouvoir décider lasubsomption sur de très grandes clauses\n",
      "optimisation des performances dans les entrepôts de données nosql en colonnes\n",
      "le modèle nosql orienté colonnes propose un schéma de donnéesflexible et hautement dénormalisé dans cet article nous proposonsune méthode dimplantation dun entrepôt de données dans un systèmenosql en colonnes notre méthode est basée sur une stratégie de regroupementdes attributs issus des tables de faits et de dimensions sous formede familles de colonnes nous utilisons deux algorithmes oep et kmeanspour évaluer notre méthode nous avons effectué plusieurs tests sur lebenchmark tpcds au sein du sgbd nosql orienté colonnes hbaseavec une architecture de type mapreduce sur une plateforme hadoop\n",
      "pharmacovigilance du web social par une approche fondée sur les bases de connaissances du web sémantique\n",
      "nan\n",
      "porgy  a visual analytics platform for system modelling and analysis based on graph rewriting\n",
      "porgy est un environnement interactif utilisé pour la modélisationde systèmes obtenus àpartir de règles de réécriture pilotés à laide de stratégies et basées sur des graphes utilisantdes noeuds à ports cette démonstration présente quelques uns des aspects de visualisation analytique proposés par porgy cette dernière facilite la modélisation du système sa simulationainsi que lanalyse des résultats à différentes échelles\n",
      "prédiction de défauts dans les arbres du parc végétal grenoblois et préconisations pour les futures plantations\n",
      "nous décrivons dans cet article notre réponse au défi egc 2017 uneanalyse exploratoire des données a tout dabord permis de comprendre les distributions des différentes variables et de détecter de fortes corrélations nous avonsdéfini deux variables supplémentaires à partir des variables du jeu de donnéesplusieurs algorithmes de classification supervisée ont été expérimentés pour répondre à la tâche numéro 1 du défi les performances ont été évaluées par validation croisée cela nous a permis de sélectionner les meilleurs classifieursunilabel et multilabel autant sur la tâche unilabel que multilabel le meilleurclassifieur dépasse les références denviron 2 nous avons également exploréla tâche numéro 2 du défi dune part des règles dassociation ont été recherchées dautre part le jeu de données a été enrichi avec des connaissances tellesque des données climatiques pluviométrie température vent ou des donnéestaxonomiques dans le domaine de la botanique famille ordre superordre enoutre des données géographiques et cartographiques sont exploitées dans unoutil de visualisation dune partie des données sur les arbres\n",
      "prédiction du montant levé lors dune campagne de financement participatif par la méthode des plus proches voisins\n",
      "le financement participatif est un mode de financement dunprojet faisant appel à un grand nombre de personnes contrairement auxmodes de financement traditionnels il a connu une forte croissance aveclémergence dinternet et des réseaux sociaux cependant plus de 60 des projets ne sont pas financés il est donc important de bien préparersa campagne de financement de plus en cours de campagne il est crucial davoir une estimation rapide de son succès afin de pouvoir réagirrapidement restructuration communication  des outils de prédictionsont alors indispensables nous proposons dans cet article une méthodede prédiction du montant final levé lors dune campagne de financementparticipatif utilisant lalgorithme knn  en utilisant lhistorique de campagnes passées nous déterminons celles qui sont les plus similaires à unecampagne en cours nous utilisons alors les montants finaux pour faireune estimation nous comparons plusieurs mesures de distance pour déterminer les plus proches voisins nos résultats indiquent que le dernierétat dune campagne seul est suffisant pour obtenir une bonne prédiction\n",
      "prévision à court terme des flux de voyageurs du réseau ferré urbain  une approche par les réseaux bayésiens dynamiques\n",
      "nous proposons une approche de prévision à court terme des flux devoyageurs du réseau ferré dîledefrance basée sur les réseaux bayésiens dynamiques la structure du modèle repose sur les relations de causalité entre lesflux adjacents et permet dintégrer loffre de transport en présence de donnéesmanquantes lapprentissage est réalisé via lalgorithme espérancemaximisationem structurel en appliquant notre approche sur une ligne de métro les résultats obtenus sont globalement supérieurs à ceux des autres méthodes testées\n",
      "prototype de clustering exploratoire pour laide à la segmentation des clients\n",
      "le clustering est une technique largement répandue pour la définitionde profils dans le cadre de laide à la gestion de la relation client crm cependant les outils classiques sont généralement limités car ils ne prennent pas encompte la connaissance métier de lanalyste et ne permettent pas lexplorationinteractive des données nous décrivons ici un prototype qui permet à un expertmarketing dexplorer interactivement les données pour la recherche de profilsdes clients mais aussi danalyser les profils construits à laide de différentesvisualisations synthétiques et détudier leurs évolutions au cours du temps\n",
      "recommandations et prédictions de préférences basées sur la combinaison de données sémantiques et de folksonomie\n",
      "dans les systèmes de recommandation lapproche du filtrage sur lecontenu est revenue en force face à celle du filtrage collaboratif grâce à larrivéedu paradigme de lapprentissage profond et des techniques de word embeddingdans cette même veine lavènement des folksonomies et du web sémantique aapporté une meilleure compréhension des profils des utilisateurs et des caractéristiques des articles à recommander dans cet article nous nous intéressons audomaine musical et nous introduisons un nouveau calcul de mesure de préférence intégrée dans un système de recommandations basées sur le contenu entestant notre approche sur le jeu de données lastfm nous montrons que lutilisation de termes issus dune folksonomie associés à des informations issues duweb sémantique permet daméliorer le processus de recommandation musicale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconnaissance de sections et dentités dans les décisions de justice  application des modèles probabilistes hmm et crf\n",
      "une décision de justice est un document textuel rapportant le dénouement dune affaire judiciaire les juristes sen servent régulièrement commesource dinterprétation de la loi et de compréhension de lopinion des jugesla masse disponible de décisions exige des solutions automatiques pour aiderles acteurs du droit nous proposons dadresser certains des défis liés à la recherche et lanalyse du volume croissant de décisions de justice en france dansun projet plus global la première phase de ce projet porte sur lextraction dinformation des décisions dans lobjectif de construire une base de connaissancesjurisprudentielles structurant et organisant les décisions une telle base facilitelanalyse descriptive et prédictive de corpus de décisions cet article présenteune application des modèles probabilistes pour la segmentation des décisions etla reconnaissance dentités dans leur contenu lieu date participants règles deloi  nos tests montrent lavantage dapproches basées sur les champs aléatoires conditionnels crf par rapport à des modèles plus simples et rapidesbasés sur les modèles cachés de markov hmm nous présentons ici les aspects techniques de la sélection et lannotation du corpus dapprentissage et ladéfinition de descripteurs discriminants la spécificité des textes est importanteet doit être prise en compte lors de lapplication de méthodes dextraction dinformation dans un domaine spécifique\n",
      "sélection ciblée des descripteurs visuels pour la recherche dimages une approche basée sur les règles dassociation\n",
      "nan\n",
      "sélection et transformation de variables pour la classification multilabel par une approche mdl\n",
      "la classification multilabel est une extension de la classification supervisée au cas de plusieurs labels elle a connu un regain dintérêt récent dansla communauté du machine learning de par son utilité dans plusieurs domainescomme pour tout problème de machine learning le besoin de prétraiter les données multilabel est apparu comme une nécessité afin daméliorer les performances des classifieurs dans cet article nous introduisons une nouvelle méthode permettant de prétraiter des variables descriptives par discrétisation ougroupement de valeur dans le cas de plusieurs labels à prédire le choix dumeilleur prétraitement est posé comme un problème de sélection de modèle etest résolu au moyen dune approche bayésienne une étude comparative est réalisée avec dautres méthodes de létat de lart afin de positionner la nouvelleméthode et de montrer lintérêt de la sélection de variables pour la classification\n",
      "subspace clustering et visualisation des flux de données\n",
      "dans ce papier nous proposons une nouvelle approche de subspaceclustering pour les flux de données permettant à lutilisateur de suivre visuellement le changement dans le comportement du flux cette approche détectelimpact des variables sur lévolution du flux tout en visualisant les étapes dusubspace clustering en temps réel en premier lieu nous appliquons un clusteringsur lensemble de variables afin didentifer les sousespaces ensuite un clustering est appliqué sur les individus dans chaque sousespace\n",
      "suivi de lévolution de clusters de liens dans des réseaux sociaux dynamiques\n",
      "de nombreuses méthodes ont été proposées pour extraire des clusters des réseaux sociaux si un travail important est aujourdhui mené sur laconception de méthodes innovantes capables de rechercher des clusters de nature différente la plupart des approches font lhypothèse de réseaux statiqueslune des récentes méthodes concerne notamment la recherche de liens conceptuels il sagit dune nouvelle approche de clustering de liens qui exploite à lafois la structure du réseau et les attributs des noeuds dans le but didentifier desliens fréquents entre des groupes de noeuds au sein desquels les noeuds partagent des attributs communs dans ce travail nous nous intéressons au suivides liens conceptuels dans des réseaux dynamiques cestàdire des réseaux quiconnaissent des changements structurels importants nous cherchons en particulier à comprendre comment les liens conceptuels se forment et évoluent aucours du développement du réseau pour ce faire nous proposons un ensemblede mesures qui visent à capturer des comportements caractérisant lévolutionde ces clusters notre approche est ainsi utilisée pour comprendre lévolutiondes liens conceptuels extraits sur deux réseaux réels  un réseau de coauteursdarticles scientifiques et un réseau de communications mobiles les résultatsobtenus permettent de mettre en lumière des tendances significatives dans lévolution des clusters sur ces deux réseaux\n",
      "support uniforme de types de données personnalisés dans rdf et sparql\n",
      "les littéraux sont les noeuds terminaux du modèle de données rdf etpermettent dencoder des données telles que des nombres 125ˆˆxsddecimaldes dates 20170126t235715ˆˆxsddatetime ou tout autre type dinformationvert pommeˆˆexcouleur les moteurs rdfsparql savent tester légalité oucomparer les littéraux rdf dont le type de données leur est connu ce qui estle cas de xsddecimal et xsddatetime mais lorsquun type de données est inconnudun moteur rdfsparql comme excouleur il na à priori aucun moyen den« découvrir » la sémantique dans cet article nous attaquons ce problème et étudions comment permettre i aux éditeurs de données de publier la définition detypes de données personnalisés sur leweb et ii aux moteurs rdfsparql dedécouvrir à la volée ces types de données personnalisés et de les utiliser de manière uniforme nous discutons de différentes solutions possibles qui tirent partiedes principes du web des données et détaillons une solution concrète basée surle déréférencement et le langage javascript suffisemment générique pour êtreutilisée pour des types de données personnalisés arbitrairement complexes\n",
      "sur lévaluation et lélaboration dun jeu de données de référence de bonne qualité en télédétection\n",
      "en analyse dimages de télédétection les données de référence venant étiqueter les objets des images y jouent un rôle crucial mais sont parfois imprécises voire incertaines et en nombre limité dans cet article nous présentonsune méthodologie pour lamélioration de données de référence pour la télédétection en trois étapes  réalignement des données évaluation via crowdsourcinget création dun jeu de données de référence de bonne qualité\n",
      "un critère dévaluation pour les kmoyennes prédictives\n",
      "lalgorithme des kmoyennes prédictives est un des algorithmes declustering prédictif visant à décrire et à prédire dune manière simultanée contrairement à la classification supervisée et au clustering traditionnel la performance de ce type dalgorithme est étroitement liée à sa capacité à réaliser unbon compromis entre la description et la prédiction or à notre connaissanceil nexiste pas dans la littérature un critère analytique permettant de mesurer cecompromis cet article a pour objectif de proposer une version modifiée de lindice daviesbouldin nommée sdb permettant ainsi dévaluer la qualité des résultats issus de lalgorithme des kmoyennes prédictives cette modification sebase sur lintégration dune nouvelle mesure de dissimilarité permettant détablir une relation entre la proximité des observations en termes de distance etleur classe dappartenance les résultats expérimentaux montrent que la versionmodifiée de lindice db parvient à mesurer la qualité des résultats issus de lalgorithme des kmoyennes prédictives\n",
      "un générateur de réseaux dynamiques attribués avec structure communautaire\n",
      "nous proposons une nouvelle approche pour générer des graphes dynamiques avec attributs munis dune structure communautaire reflétant les propriétés connues des graphes de terrain comme lattachement préférentiel ou lhomophilie le générateur développé permet de construire une suite de graphesformant ainsi un réseau dynamique il offre la possibilité de visualiser lévolution de ces graphes à travers une interface dédiée cette interface présente aussiplusieurs mesures évaluées sur chacun des graphes du réseau pour vérifier dansquelle mesure les propriétés du réseau sont préservées au cours de son évolution\n",
      "un modèle de factorisation de poisson pour la recommandation de points dintérêt\n",
      "lexplosion des volumes de données circulant sur les réseauxsociaux géolocalisés lbsn rend possible lextraction des préférencesdes utilisateurs en particulier ces préférences peuvent être utilisées pourrecommander à lutilisateur des points dintérêt en adéquation avec sonprofil aujourdhui la recommandation de points dintérêt est devenueune composante essentielle des lbsn malheureusement les méthodesde recommandation traditionnelles échouent à sadapter aux contraintespropres aux lbsn telles que la ”sparsité” très élevée des données ouprendre en compte linfluence géographique dans ce papier nous présentons un modèle de recommandation basée sur la factorisation de poisson qui offre une solution efficace à ces contraintes nous avons testénotre modèle via des expérimentations sur un jeu de données réalisteissu du lbsn foursquare ces expériences nous ont permis de démontrer une meilleure qualité de recommandation que 3 modèles de létatdelart\n",
      "une approche dextraction de motifs graduels fermés fréquents sous contrainte de la temporalité\n",
      "la fouille de motifs graduels a pour but la découverte de covariationsfréquentes entre attributs numériques dans une base de données plusieurs algorithmes dextraction automatique de tels motifs ont été proposés la principaledifférence entre ces algorithmes réside dans la sémantique de variation considérée dans certains domaines dapplication on trouve des bases de données dontles objets sont munis dune relation dordre temporel ainsi du fait de leur sémantique de variation les algorithmes de la littérature sont inadaptés pour detelles données dans ce contexte nous proposons une approche de fouille demotifs graduels sous contrainte dordre temporel qui réduit le nombre de motifsgénérés une étude expérimentale sur des bases de données paléoécologiquespermet dapprendre les groupements dindicateurs qui modélisent lévolution dela biodiversité les connaissances apportées par ces groupements montre lintérêt de notre approche pour le domaine environnemental\n",
      "une approche innovante pour la compréhension des comportements de diffusion  personnalité et neutralité\n",
      "nan\n",
      "une approche logique pour la fouille de règles dassociation\n",
      "la découverte de règles dassociation à partir de données transactionnelles est une tâche largement étudiée en fouille de données les algorithmesproposés dans ce cadre partagent la même méthodologie en deux étapes à savoirlénumération des itemsets fréquents suivie par létape de génération de règlesdans cet article nous proposons une nouvelle approche basée sur la satisfiabilitépropositionnelle pour extraire les règles dassociation en une seule étape pourmontrer la flexibilité et la déclarativité de notre approche nous considérons également deux autres variantes à savoir la fouille de règles dassociation ferméeset la fouille de règles indirectes les expérimentation sur plusieurs jeux de données montrent que notre approche offre de meilleures performances comparée àdes approches spécialisées\n",
      "une approche sociologique de la place des calculs dans les mondes numériques\n",
      "dans cette présentation on souhaite présenter un regard de sociologue sur les transformationssociales politiques et culturelles du développement des mondes numériques dans nos sociétésles enjeux que doivent relever la fabrication denvironnements informatiques prennentaujourdhui de plus en plus dimportance  protection de la vie privée personnalisation descalculs guidage des conduites ouverture des données éthique des automates etc commentnos sociétés réagissentelles et sadaptentelles à ces mutations  dans cette cnférence on proposeune réflexion sur le rôle joué par les algorithmes du web dans la construction de lespacepublic numérique comment les calculateurs produisentils de la visibilité  a partir de quelsprincipes le pagerank de google les métriques du web social ou les outils de recommandationdécidentils de donner la prééminence à telle information plutôt quà telle autre  cesdifférentes familles de calcul cherchent à mesurer et à valoriser des principes différents  lapopularité lautorité la réputation et la prédiction efficace lapproche proposée dans cetteconférence soutient que les manières de calculer enferment des représentations particulièresdes individus et de leur place dans nos sociétés comprendre les algorithmes cest aussi unmoyen de redonner du pouvoir aux utilisateurs et de favoriser une critique éclairée de la manièredont le calcul sintroduit de plus en plus dans nos vies numériques\n",
      "une mesure dexpertise pour le crowdsourcing\n",
      "le crowdsourcing un enjeu économique majeur est le fait dexternaliserune tâche interne dune entreprise vers le grandpublic la foule cestainsi une forme de soustraitance digitale destinée à toute personne susceptiblede pouvoir réaliser la tâche demandée généralement rapide et non automatisablelévaluation de la qualité du travail des participants est cependant un problèmemajeur en crowdsourcing en effet les contributions doivent être contrôlées pourassurer lefficacité et la pertinence dune campagne plusieurs méthodes ont étéproposées pour évaluer le niveau dexpertise des participants ce travail a la particularitéde proposer une méthode de calcul de degrés dexpertise en présencede données dont lordre de classement est connu les degrés dexpertise sont ensuiteconsidérés sur des données sans ordre préétabli cette méthode fondée surla théorie des fonctions de croyance tient compte des incertitudes des réponseset est évaluée sur des données réelles dune campagne réalisée en 2016\n",
      "une métrique de sélection de variables appliquée à la centralité et à la détection des rôles communautaires\n",
      "la fmesure de trait est une métrique de sélection de variables statistiquesans paramètres qui a montré de bonnes performances pour la classificationlétiquetage de clusters ou encore la mesure de qualité des clusters danscet article nous proposons dévaluer son utilisation dans le contexte des graphesde terrain et de leur structure communautaire pour bénéficier de son systèmesans paramètres et de ses performances bien évaluées nous étudions donc surdes graphes synthétiques réalistes les corrélations qui existent entre la fmesurede trait et certaines mesures de centralité mais surtout avec des mesures destinéesà caractériser le rôle communautaire des noeuds nous montrons ainsi quecette mesure est liée à la centralité des noeuds du réseau et quelle est particulièrementadaptée à la mesure de leur connectivité au regard de la structurede communautés nous observons par ailleurs que les mesures usuelles de détectiondes rôles communautaires sont fortement dépendantes de la taille descommunautés alors que celles que nous proposons sont par définition liées à ladensité de la communauté ce qui rend les résultats comparables dun réseau àun autre ceci offre donc la possibilité dapplications comme le suivi temporelde la structure des communautés enfin le processus de sélection appliqué auxnoeuds permet de disposer dun système universel contrairement aux seuils fixésauparavant empiriquement pour létablissement des rôles communautaires\n",
      "une plateforme danalyse dopinions en temps réel sur twitter avec recommandation\n",
      "nan\n",
      "veille dinformation sur le web avec rewatch\n",
      "les algorithmes dapprentissage automatique peuvent être utilisés pourcréer des outils de recommandation qui permettent de prédire la pertinence dundocument pour une thématique de veille donnée en se basant sur les précédentsjugements de pertinence donnés pour cette thématique pour dautres documentsces outils de recommandation permettent de filtrer dans un flux entrant de documents ceux qui sont susceptibles dêtre pertinents sans que lutilisateur aitbesoin de déterminer luimême les mots clefs marquant ladéquation dun document pour un sujet de la veille bien que cette problématique de rechercheait été abondamment abordée les outils de veille dinformation pour le web intégrant un apprentissage en sont encore à leur balbutiements nous présentonsici lapplication web rewatch permettant la définition dun thème de veille lasélection de sources dinformation sur le web relatives à ce thème et ladaptationdes scores de pertinence des documents aux retours de lutilisateur lapplicationpermet aussi pour chaque thème une autoévaluation de la qualité du filtrage etune interrogation du moteur de recherche google cette application encore encours de développement est néanmoins actuellement fonctionnelle et accessiblesur le web à lurl suivante  httpwwwspecific searchcom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vers un échantillonnage de flux de données transformé\n",
      "nan\n",
      "vers une instance française de nell  chaîne tln multilingue et modélisation dontologie\n",
      "nous présentons les étapes de préparation de la création dune instance nouvelle de nell dédiée au français nell est à la fois un processusde lecture et de compréhension automatique du web et un ensemble de basede connaissances de faits en anglais en portuguais et très prochainement enfrançais cette mise en place de la nouvelle instance de nell a donné lieu àlamélioration de la chaîne nlp en la généralisant au multilangue ainsi quaudéveloppement dune ontologie par correspondance avec lontologie en anglaisnous présenterons le processus de mise en place et de lancement de la nouvelleinstance nell français avec linterface de visualisation et de supervision humaine des données collectées\n",
      "vipe  un outil interactif de classification multilabel de messages courts\n",
      "nous présentons un outil interactif de classification multilabel développé au sein du groupe orange et utilisé pour lanalyse dopinions basé sur unalgorithme de factorisation rapide de matrice il permet à un utilisateur dimporter des textes courts tweets mails enquêtes  de définir des labels dintérêts« client globalement satisfait » « évoque la rapidité du débit » et de proposer pour chaque texte des recommandations de labels et pour chaque label desrecommandations de textes\n",
      "“engage moi” from retrieval effectiveness user satisfaction to user engagement\n",
      "the effective prediction of a click remains a primary challenge in the areas of search digitalmedia and online advertising in the context of search satisfying a userâ728a ´ zs information needby returning results that they will click on is an important objective in any information retrievalsystem consequently information retrieval systems have had a long and varied history of howto evaluate their effectiveness of responding to a given query however building such a systemthat not only only returns relevant results to a user query but also encourages a longtermrelationship between the user and the system is far more challenging in this talk we reviewthe current stateoftheart evaluation approaches for search before exploring other ways ofquantifying more longterm engagement measures finally the talk ends with a proposal ofhow the two approaches can be considered together to create a service that optimises for thequery and the longer term engagement aspects\n",
      "a relevant passage retrieval and reranking approach for opendomain question answering\n",
      "les systèmes de questionsréponses sqrs visent à retourner directement des réponsesprécises à des questions posées en langage naturel lextraction et le reclassement des passagessont considérés comme les tâches les plus difficiles dans un sqr typique et exigent encore uneffort non trivial dans cet article nous proposons une nouvelle approche pour lextraction etle reclassement des passages en utilisant les ngrammes et svm notre système dextractionde passages basé sur la technique des ngrammes repose sur une nouvelle mesure de similaritéentre un passage et une question les passages extraits sont ensuite réordonnés en utilisant unmodèle basé sur ranksvm combinant différentes mesures de similarité afin de retourner lepassage le plus pertinent pour une question donnée nos expériences et nos résultats étaientprometteurs et ont démontré que notre approche est concurrentielle\n",
      "adaptation des mappings entre systèmes dorganisation de la connaissance du domaine biomédical\n",
      "cette thèse de doctorat propose une approche originale pour adapter les mappingsbasés sur les changements détectés dans lévolution de socs du domaine biomédicalnotre proposition consiste à comprendre précisément les mappings entre socs à exploiterles types de changements intervenant lorsque les socs évoluent puis à proposerdes actions de modification des mappings appropriées nos contributions sont multiples i nous avons réalisé un travail expérimental approfondi pour comprendre lévolutiondes mappings entre socs nous proposons des méthodes automatiques ii pour analyserles mappings affectés par lévolution de socs et iii pour reconnaître lévolutiondes concepts impliqués dans les mappings via des patrons de changement enfin ivnous proposons des techniques dadaptation des mappings à base dheuristiques nousproposons un cadre complet pour ladaptation des mappings appelé dykosmap etun prototype logiciel nous avons évalué les méthodes proposées et le cadre formel avecdes jeux de données réelles contenant plusieurs versions de mappings entre socs du domaine biomédical les résultats des expérimentations ont démontré lefficacité desprincipes sousjacents à lapproche proposée la maintenance des mappings en grandepartie automatique est de bonne qualité\n",
      "analyse dactivité et exposition de la vie privée sur les médias sociaux\n",
      "anonymous use of social network do not prevent users from privacy risks resulting frominfering and crosschecking information published by themselves or their relationhips withthis in mind we have conducted a survey in order to measure sensitiveness of personal datapublished on social media and to analyze the users behaviors we have shown that 76 of internet users that have answered the survey are vulnerable to identity or sensitive datadisclosure our study is completed by the description of an automatic procedure that showshow easily these vulnerabilities can be exploited and motivates the need for more advancedprotection mechanisms\n",
      "analyse exploratoire par kcoclustering avec khiops coviz\n",
      "en analyse exploratoire lidentification et la visualisation des interactionsentre variables dans les grandes bases de données est un défi dhillon et al2003 kolda et sun 2008 nous présentons khiops coviz un outil qui permetdexplorer par visualisation les relations importantes entre deux ou plusieursvariables quelles soient catégorielles etou numériques la visualisation dunrésultat de coclustering de variables prend la forme dune grille ou matrice dontles dimensions sont partitionnées les variables catégorielles sont partitionnéesen clusters et les variables numériques en intervalles loutil permet plusieurs variantesde visualisations à différentes échelles de la grille au moyen de plusieurscritères dintérêt révélant diverses facettes des relations entre les variables\n",
      "analyse géographique de séries de publications  application aux conférences egc\n",
      "dans cet article nous présentons une méthodologie originale permettantde faire des analyses scientométriques basées sur trois dimensions spatialetemporelle et thématique à partir dun corpus de publications cette méthodologiecomporte 3 étapes  1 la préparation et la validation des données pourcompléter les critères usuels tels que les noms dauteurs affiliation  par descritères spatiaux temporels et thématiques  2 lindexation des contenus despublications et métadonnées associées  3 lanalyse etou la recherche dinformationmultidimentionnelle les expérimentations sont menées sur la série depublications des conférences egc de 2004 à 2015\n",
      "analyses synchroniques et diachroniques des thématiques egc défi ecg 2016\n",
      "les articles scientifiques publiés dans les actes des conférences egcqui se déroulent chaque année depuis 2001 constituent la richesse de ces évènementsmettant en avant le fer de lance de la recherche francophone portantsur la gestion et lextraction de connaissances nous nous sommes penchés surlanalyse de ces publications scientifiques afin den extraire lessence en termesde thématiques de recherches abordées premièrement nous avons analysé lespoints communs et les spécificités des publications dans les différentes éditionsde la conférence ainsi que les principales différences entre les éditions consécutivespuis nous nous sommes intéressés à la façon dont les publications sarticulentautour des thématiques extraites et sur lesquelles nous avons essayé devisualiser une approximation sémantique enfin nous nous sommes intéresséà lévolution des thématiques depuis les débuts de cette conférence et jusquàlédition 2015\n",
      "apprentissage du signal prix de lélectricité arbres de régression séries temporelles et prédictions à long terme\n",
      "predicting the price of the electricity commodity in the long term is a challenge that currenttechniques do not meet satisfactorily karakatsani et bunn 2010 weron 2014 in this paperwe introduce a new regression tree based model that yields good predictions on a longtermperiod with low computational resources requirements our approach is validated by temporalseries collected from an electricity provider\n",
      "approche de clustering de flux basée sur les graphes de voisinage\n",
      "we propose a neighborhoodbased approach for data streams clustering instead of processingeach new element one by one we propose to process each group of new elements simultaneouslya neighborhoodbased clustering is applied on each new group we also definean incremental construction method of the neighborhood graph based on the stream evolutionto validate the approach we apply it to multiple data sets and we compare it with variousstream clustering approaches\n",
      "arbres de modèles et flux de données incomplets\n",
      "model tree is a useful and convenient method for predictive analytics in data streamsoften this issue is solved by preprocessing techniques applied prior to the training phase ofthe model in this article we propose a new method that estimates and adjusts missing valuesbefore the model tree training a prototype was developed and tested on several data streams\n",
      "associer argumentation et simulation en aide à la décision  illustration en agroalimentaire\n",
      "prendre une décision impliquant plusieurs acteurs aux objectifs divergentsnécessite de considérer des informations tant qualitatives – les préférencesdes acteurs sur les décisions possibles – que quantitatives – les paramètres servantdindicateurs pour les acteurs dans cet article nous nous intéressons à lassociationde ces deux types dapproches le modèle qualitatif considéré est largumentationle modèle quantitatif simulant les scénarios découlant de chaquedécision est la dynamique des systèmes cet article sintéresse aux éléments permettantde connecter les deux formalismes un exemple en agroalimentaire vienten appui à cette réflexion\n",
      "caractérisation dinstances dapprentissage pour un métamining évolutionnaire\n",
      "machine learning has proven to be a powerful tool in diverse fields and is getting moreand more widely used by nonexperts one of the foremost difficulties they encounter liesin the choice and calibration of the machine learning algorithm to use our objective is thusto provide assistance in the matter using a metalearning approach based on an evolutionaryheuristic we introduce here this approach as a potential solution to the limitation of currentdata characterization\n",
      "catégorisation et désambiguïsation des intérêts des individus dans le web social\n",
      "cet article présente une approche pour la catégorisation et la désambiguïsationdes intérêts que les individus renseignent sur les réseaux sociaux enutilisant wikipédia\n",
      "clustering par apprentissage de distance guidé par des préférences sur les attributs\n",
      "ces dernières années de nombreuses méthodes semisupervisées declustering ont intégré des contraintes entre paires dobjets ou détiquettes declasse afin que le partitionnement final soit en accord avec les besoins de lutilisateurpourtant dans certains cas où les dimensions détudes sont clairementdéfinies il semble opportun de pouvoir directement exprimer des contraintessur les attributs pour explorer des données de plus une telle formulation permettraitdéviter les écueils classiques de la malédiction de la dimensionnalitéet de linterprétation des clusters cet article propose de prendre en compte lespréférences de lutilisateur sur les attributs afin de guider lapprentissage de ladistance pendant le clustering plus précisément nous montrons comment paramétrerla distance euclidienne par une matrice diagonale dont les coefficientsdoivent être au plus proche des poids fixés par lutilisateur cette approche permetdajuster le clustering pour obtenir un compromis entre les approches guidéespar les données et par lutilisateur nous observons que lajout des préférencesest parfois essentiel pour atteindre un clustering de meilleure qualité\n",
      "clustering visuel semiinteractif\n",
      "nous proposons dans cet article une approche de clustering visuelsemiinteractif lapproche proposée utilise la perception visuelle pour guiderlutilisateur dans le processus interactif les clusters sont extraits de manièresuccessive et itérative puis évalués selon leur ordre dextraction pour lutilisateurlapproche semiinteractive permet non seulement dévaluer les classes enfonction dun critère déterminé mais aussi dévaluer linfluence de lextractiondun cluster sur ceux précédemment extraits un protocole de test est présentéafin de comparer cette approche avec les approches purement automatiques etpurement interactives cet article est un résumé dun papier accepté 1 pour unjournal international\n",
      "combinaison de méthodes numériques et symboliques pour lanalyse de données métabolomiques\n",
      "our work consists in developing a workflow using knowledge discovery methodologiesto propose advanced predictive biomarkers discovery solutions from metabolomic data wepropose to use machine learning algorithms for feature selection and fca for visualization\n",
      "concept drift vs suicide comment lun peut prévenir lautre\n",
      "le suicide devient dannée en année une problématique plus préoccupanteles organismes de santé tels que loms se sont engagés à réduire lenombre de suicides de 10 dans lensemble des pays membres dici 2020 sile suicide est généralement un geste impulsif il existe souvent des actes et desparoles qui peuvent révéler un mal être et représenter des signes précurseurs deprédispositions au suicide lobjectif de cette étude est de mettre en place unsystème pour détecter semiautomatiquement ces comportements et ces parolesau travers des réseaux sociaux des travaux précédents ont proposé la classificationde messages issus de twitter suivant des thèmes liés au suicide  tristesseblessures psychologiques état mental etc dans cette étude nous ajoutons la dimensiontemporelle pour prendre en compte lévolution de létat des personnesmonitorées nous avons implémenté pour cela différentes méthodes dapprentissagedont une méthode originale de concept drift nous avons expérimenté avecsuccès cette méthode sur des données réelles issues du réseau social facebook\n",
      "construction incrémentale dune structure hiérarchique pour lexploration visuelle et interactive de larges collections dimages\n",
      "dans cet article nous étudions de manière conjointe la construction etlexploration visuelle dune structure de classification pour de très grande basedimages pour garantir que la structure construite vérifiera les contraintes detaille nécessaires à sa visualisation dans une interface web tout en reflétant lespropriétés topologiques des données clusters nous combinons la classificationhiérarchique de birch balanced iterative reducing and clustering using hierarchiesavec la construction de graphes de voisinage  un graphe de voisinageest créé et mis à jour de manière incrémentale pour représenter les fils de chaquenoeud de larbre de plus un ensemble dimages représentatives est remonté àchaque noeud interne pour guider lutilisateur lors de lexploration visuelle delarbre lensemble des algorithmes utilisés sont incrémentaux pour gérer linsertionde nouvelles images dans la collection nous présentons les premiersrésultats sur des dizaines de milliers dimages qui peuvent être ainsi structuréesen une minute de temps de calcul lexploration dans linterface est fluide grâceaux propriétés de la structure construite\n",
      "contributions à la coloration des hypergraphes basées sur les traverses minimales\n",
      "in this paper we propose two contributions about the determination of chromatic numberand the verification of the 2colorability property we introduce an unreleased relation betweenthe problem of hypergraph coloring and the computation of minimal transversals hypergraphand especially a subset of them thereby we propose two algorithms in order to optimize theverification of the 2colorability property of hypergraphs and the evaluation of the chromaticnumber experiments carried out on several types of hypergraphs showed that our algorithmobtains very interesting results\n",
      "découverte de labels dupliqués par lexploration du treillis des classifieurs binaires\n",
      "lanalyse des données comportementales représente aujourdhui ungrand enjeu tout individu génère des traces dactivité et de mobilité lorsquellessont associées aux individus ou labels qui les ont créées il est possiblede construire un modèle qui prédit avec précision lappartenance dune nouvelletrace sur internet il est cependant fréquent quun utilisateur possède différentesidentités virtuelles ou labels doublons les ignorer provoque une grande réductionde la précision de lidentification il est ainsi question dans cet article du problèmede déduplication de labels et lon présente une méthode originale baséesur lexploration du treillis des classifieurs binaires chaque sousensemble delabels est classifié face à son complémentaire et des contraintes rendent possiblelidentification des labels doublons en élaguant lespace de recherche des expérimentationssont menées sur des données issues du jeu vidéo starcraft 2les résultats sont de bonne qualité et encourageants\n",
      "découverte de motifs intelligibles et caractéristiques danomalies dans les traces unitaires\n",
      "de nombreuses industries manufacturières sintéressent aujourdhui àlexploitation des grandes collections de traces unitaires les applications sontmultiples et vont du simple reporting à la détection de fraudes en passant parla gestion de retours ou encore la mise en évidence dincohérences dans lescircuits de distribution une étape importante consiste à détecter des anomaliesdans des collections de traces si les travaux concernant la détection danomaliessont assez nombreux peu permettent de caractériser les anomalies détectées parune description intelligible étant donné un ensemble de traces unitaires nousdéveloppons une méthode dextraction de motifs pour détecter et contextualiserdes comportements non conformes à un modèle expert fourni ou construit àpartir des données le degré danomalie est alors quantifié grâce à la proportiondu nombre de mouvements des objets qui ne sont pas prévus dans le modèleexpert cette recherche est financée partiellement par un programme industrielqui ne permet ni de dévoiler le contexte concret ni de parler des données réellesainsi nous validons empiriquement la valeur ajoutée de la méthode proposéepar létude de traces de mobilité dans un jeu vidéo  nous pouvons alors discuterdun motif qui explicite les raisons de linexpérience de certains joueurs\n",
      "défi egc 2016  analyse par motifs fréquents et topic modeling\n",
      "dans le domaine de lanalyse de textes lextraction de motifs est unetechnique très populaire pour mettre en évidence des relations fréquentes entreles mots de même les techniques de topic modeling ont largement fait leurspreuves lorsquil sagit de classer automatiquement des ensembles de textes partageantdes thématiques similaires ainsi ce papier a pour ambition de montrerlintérêt de lutilisation conjointe de ces deux techniques afin de mettre en évidencesous la forme dun graphe biparti des mots partageant des thématiquessimilaires mais aussi leurs relations fréquentes intra et inter thématiques lesdonnées du défi egc 2016 permettent de valider lintérêt de lapproche touten montrant lévolution des thématiques et des mots clés parmi les papiers de laconférence egc sur ces onze dernières années\n",
      "défi egc 2016 vues conceptuelles des collaborations aux conférences egc depuis 2004 une modélisation descriptive\n",
      "dans ce travail nous analysons les données concernant les articles publiés à laconférence egc notre objectif est didentifier et de comprendre les tendances en matièrede collaborations pour ce faire nous adoptons une modélisation descriptive à travers uneapproche réseau qui consiste à générer tout dabord le réseau de collaborations des auteursà partir des données nous enrichissons ensuite les noeuds de ce réseau dune dizainedattributs individuels extraits à partir des données enfin nous recherchons des vuesconceptuelles une approche récente de clustering de liens qui permet de synthétiser desréseaux en mettant en évidence les ensembles dattributs retrouvés fréquemment liés dansle réseau les résultats obtenus montrent les tendances existantes dans les comportementsde collaborations dans ce papier nous présentons ces tendances et montrons commentelles évoluent selon différents seuils dextraction\n",
      "détection de données aberrantes à partir de motifs fréquents sans énumération exhaustive\n",
      "la détection de données aberrantes outliers consiste à détecter desobservations anormales au sein des données durant la dernière décennie desméthodes de détection doutliers utilisant les motifs fréquents ont été proposéeselles extraient dans une première phase tous les motifs fréquents puis assignentà chaque transaction un score mesurant son degré daberration en fonction dunombre de motifs fréquents qui la couvre dans cet article nous proposons deuxnouvelles méthodes pour calculer le score daberration fondé sur les motifs fréquentsfpof la première méthode retourne le fpof exact de chaque transactionsans extraire le moindre motif cette méthode savère en temps polynomialpar rapport à la taille du jeu de données la seconde méthode est une méthodeapprochée où lutilisateur final peut contrôler lerreur maximale sur lestimationdu fpof une étude expérimentale montre lintérêt des deux méthodes pour lesjeux de données volumineux où une approche exhaustive échoue à calculer unesolution exacte pour un même nombre de motifs la précision de notre méthodeapprochée est meilleure que celle de la méthode classique\n",
      "détection de messages falsifiés de localisation de navires\n",
      "the automatic identification system was initially designed for safety purposes howeverthe system is not secured and the messages contain errors and undergo attacks and falsificationsthis article proposes a methodological approach for the detection of falsified aismessages\n",
      "enrichissement de schéma multidimensionnel en constellation grâce à la classification ascendante hiérarchique\n",
      "les hiérarchies sont des structures cruciales dans un entrepôt de donnéespuisquelles permettent lagrégation de mesures dans le but de proposerune vue analytique plus ou moins globale sur les données entreposées selon leniveau hiérarchique auquel on se place cependant peu de travaux sintéressentà la construction de hiérarchies via un algorithme de fouille de données prenanten compte le contexte multidimensionnel de la dimension concernée danscet article nous proposons donc un algorithme implémenté sur une architecturerolap permettant denrichir une dimension avec des données factuelles\n",
      "évaluation et prédiction de la centralité de groupes de recherche dans un réseau de collaborations scientifiques\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de nos jours il y a un fort intérêt pour de nouvelles méthodes dévaluationdes groupes de recherche afin de quantifier limpact de leur travail surtoute la communauté scientifique et de tenter de prédire leurs performances dansle futur dans ce contexte nous proposons une nouvelle approche hybride quimesure la centralité dun groupe de chercheurs publiants cette mesure profitede lexpressivité et de la capacité dinférence apportées par une modélisationontologique des groupes et des thématiques inférées et dune modélisation engraphe qui permet dexplorer les interactions entre ces différents groupes aufil du temps ce modèle permet également de détecter les groupes capables decollaborer avec dautres tout en maintenant un haut niveau de production etdidentifier ceux qui sont plus déterminants sur les thématiques déduites afin dedévelopper des collaborations de recherche plus fructueuses\n",
      "exploration des données du défi egc 2016 à laide dun système dinformation logique\n",
      "nous présentons dans cet article les méthodes employées et les résultatsobtenus en réponse au défi egc 2016 notre approche repose dune partsur des chaînes automatiques de traitements linguistiques en français et en anglaisutilisant le plus possible des ressources et outils publics et dautre part surun environnement dexploration des données basé sur les systèmes dinformationlogiques  ces systèmes exploitent une généralisation des treillis de conceptsformels appliquée aux données attributvaleur ou au web sémantique\n",
      "extension de csparql pour léchantillonnage de flux de graphes rdf\n",
      "les technologies du web sémantique sont de plus en plus utiliséespour la gestion de flux de données plusieurs systèmes de traitement de fluxrdf ont été proposés  csparql cqels sparqlstream epsparqlsparkwave etc ces derniers étendent tous à la base le langage dinterrogationsémantique sparql les données à lentrée du système sont volumineuseset générées en continu à un rythme rapide et variable de ce fait le stockage etle traitement de la totalité du flux deviennent coûteux et le raisonnement presqueimpossible par conséquent le recours à des techniques permettant de réduire lacharge tout en conservant la sémantique des données permet doptimiser les traitementsvoire le raisonnement cependant aucune des extensions de sparqlninclut cette fonctionnalité ainsi dans cet article nous proposons détendre lesystème csparql pour générer des échantillons à la volée sur flux de graphesrdf nous ajoutons trois opérateurs déchantillonnage uniform reservoiret chain à la syntaxe de csparql les expérimentations montrent laperformance de notre extension en terme de temps dexécution et de la préservationde la sémantique des données\n",
      "extraction automatique daffixes pour la reconnaissance dentités nommées chimiques\n",
      "nous détaillerons ici une approche permettant de détecter des affixes àpartir de dictionnaires en se basant sur lalgorithme de la plus longue souschaînecommune dans le cadre de la reconnaissance dentités nommées chimiques surchemdner nous verrons ensuite des méthodes de sélection et de tri afin deles intégrer au mieux dans un système dapprentissage automatique\n",
      "extraction de clés de liage de données résumé étendu\n",
      "de grandes quantités de données sont publiées sur le web des donnéesles lier consiste à identifier les mêmes ressources dans deux jeux de donnéespermettant lexploitation conjointe des données publiées mais lextractionde liens nest pas une tâche facile nous avons développé une approche qui extraitdes clés de liage link keys les clés de liage étendent la notion de cléde lalgèbre relationnelle à plusieurs sources de données elles sont fondées surdes ensembles de couples de propriétés identifiant les objets lorsquils ont lesmêmes valeurs ou des valeurs communes pour ces propriétés on présenteraune manière dextraire automatiquement les clés de liage candidates à partir dedonnées cette opération peut être exprimée dans lanalyse formelle de conceptsla qualité des clés candidates peutêtre évaluée en fonction de la disponibilitécas supervisé ou non cas non supervisé dun échantillon de liens la pertinenceet de la robustesse de telles clés seront illustrées sur un exemple réel\n",
      "extraction de commentaires utilisateurs sur le web\n",
      "dans cet article nous présentons commentsminer une solution dextractionnon supervisée pour lextraction de commentaires utilisateurs notreapproche se base sur une combinaison de techniques de fouille de sousarbresfréquents dextraction de données et dapprentissage de classement nos expérimentationsmontrent que commentsminer permet de résoudre le problèmedextraction de commentaires sur 84 dun jeu de données représentatif et publiquementaccessible loin devant les techniques existantes dextraction\n",
      "extraction de connaissances dans les systèmes dinformation pervasifs par lanalyse formelle de concepts\n",
      "nous présentons une méthode dextraction de connaissances dans dessystèmes dinformation pervasifs nous étudions limpact du contexte environnementdun utilisateur sur les applications quil utilise sur son smartphonenotre proposition pour gérer la complexité des données contextuelles repose surlanalyse formelle de concepts et les treillis de galois nous nous focalisonssur lautomatisation du processus dinterprétation de ces treillis pour généraliserlextraction de connaissances et passer à léchelle nous présentons desmétriques originales illustrées sur des données réelles\n",
      "fabrique logicielle de réseaux sociaux spécialisés aspects fonctionnels\n",
      "this paper introduces a software factory for developing social networks this factory takesan abstract social network and creates a concrete one using mechanisms such as subtypingand behavior overloading\n",
      "fairnessaware data mining\n",
      "in data mining we often have to learn from biased data because for instance data comesfrom different batches or there was a gender or racial bias in the collection of social data insome applications it may be necessary to explicitly control this bias in the models we learn fromthe data recently this topic received considerable interest both in the research community aswell as more general as witnessed by several recent articles in popular news media such asthe new york times in this talk i will introduce and motivate research in fairnessaware datamining different techniques in unsupervised and supervised data mining will be discusseddividing these techniques into three categories algorithms of the first category adapt the inputdata in such a way to remove harmful biases while the second adapts the learning algorithmsand the third category modifies the output models in such a way that its predictions becomeunbiased furthermore different ways to quantify unfairness and indirect and conditionaldiscrimination will be discussed each with their own pros and cons with this talk i hope toconvincingly argument the validity and necessity of this often contested research area\n",
      "fodomust une plateforme pour la fouille de données multistratégie multitemporelle\n",
      "la plateforme fodomust 1 est une implantation concrète des méthodeslibrairies et interfaces proposées au sein dicube elle intègre une versionmultisource de la méthode de classification collaborative multistratégie samarahelle propose aussi un ensemble dalgorithmes de segmentation soitpropres à icube soit faisant appel à lotb enfin trois interfaces dédiées chacuneà un type de données différent permettent une interaction avec lutilisateursa principale originalité est quelle permet la classification basée sur dtw dynamictimewarping de données temporelles symboliques ou numériques et deséries temporelles dimages\n",
      "fouille de motifs séquentiels avec asp\n",
      "cet article présente lutilisation de la programmation par ensemblesréponses asp pour répondre à une tâche de fouille de motifs séquentiels lasyntaxe de lasp proche du prolog en fait un langage très pertinent pour représenterdes connaissances de manière aisée et ses mécanismes de résolutionbasés sur des solveurs efficaces en font une solution alternative aux approchesde programmation par contraintes pour la fouille déclarative de motifs nousproposons un premier encodage de la tâche classique dextraction de motifs séquentielset de ses variantes motifs clos et maximaux nous comparons lesperformances calculatoires de ses encodages avec une approche de programmationpar contraintes les performances obtenues sont inférieures aux approchesde programmation par contraintes mais lencodage purement déclaratif offreplus de perspectives dintégration de connaissances expertes\n",
      "fusion de données redondantes  une approche explicative\n",
      "nous nous intéressons dans le cadre du projet anr qualinca au traitementdes données redondantes nous supposons dans cet article que cette redondancea déjà été établie par une étape préalable de liage de données laquestion abordée est la suivante  comment proposer une représentation uniqueen fusionnant les duplicats identifiés  plus spécifiquement comment déciderpour chaque propriété de la donnée considérée quelle valeur choisir parmi cellesfigurant dans les duplicats à fusionner  quelle méthode adopter dans le butde pouvoir par la suite retracer et expliquer le résultat obtenu de façon transparenteet compréhensible par lutilisateur  nous nous appuyons pour cela surune approche de décision multicritère et dargumentation\n",
      "génération de contraintes pour le clustering à partir dune ontologie  application à la classification dimages satellites\n",
      "lutilisation des connaissances a priori peut fortement améliorer laclassification nonsupervisée linjection de ces connaissances sous forme decontraintes sur les données figure parmi les techniques les plus efficaces de lalittérature cependant la génération des contraintes est très coûteuse et demandelintervention de lexpert  la sémantique apportée par létiquetage de lexpertest aussi perdue dans ce type de techniques seuls les contraintes sont retenuespar le clustering dans cet article nous proposons une nouvelle approche hybrideexploitant le raisonnement à base dontologie pour générer automatiquementdes contraintes permettant de guider et améliorer le clustering lutilisationdune ontologie comme connaissance a priori a plusieurs avantages elle permetlinterprétation automatisée des connaissances ajoute de la modularité dans lachaîne de traitement et améliore la qualité du clustering en prenant en comptela vision de lutilisateur pour évaluer notre approche nous lavons appliquée àla classification dimages satellites et les résultats obtenus démontrent des améliorationsnotables à la fois au niveau de la qualité du clustering et au niveau delétiquetage sémantique des clusters sans intervention de lexpert\n",
      "identification de classes sémantiques basée sur des mesures de proximité sémantique\n",
      "semantic relations are the core of a growing number of knowledgeintensive systems theneed to validate automatically such relations remains an uptodate challenge in this paper wepresent a webbased method enabling the automatic identification of the class of a semantic relationusing measures based on syntactic patterns as entry features for a learning algorithmwe are able to successfully identify 72 of semantic relations divided in 4 classes in a semanticallyrich environment\n",
      "intégration de connaissances lexicales et sémantiques pour lanalyse de sentiments dans les sms\n",
      "with the explosive growth of the social media forums blogs and social networks on theweb the exploitation of these new information sources became essential in this paper wepresent a new automatic method to integrate knowledge for sentiment detection from a smscorpus by combining lexical and semantic information\n",
      "intégration des influences géographique et temporelle pour la recommandation de points dintérêt\n",
      "la recommandation de points dintérêts ou poi est devenue un problèmemajeur avec lémergence des réseaux sociaux ou lbsn à la différencedes approches de recommandation traditionnelles les données des lbsn présententdes caractéristiques géographique et temporelle importantes qui limitentles performances des algorithmes traditionnels existant lintégration de ces caractéristiquesdans un unique modèle de factorisation pour augmenter la qualitéde la recommandation na pas été un problème très étudié jusquà présent dansce papier nous présentons geomftd une extension dun modèle de factorisationgéographique avec des dépendances temporelles nos expérimentationssur un jeu de données réel montre jusquà 20 de gain sur la précision de larecommandation\n",
      "khiops outil dapprentissage supervisé automatique pour la fouille de grandes bases de données multitables\n",
      "khiops est un outil dapprentissage supervisé automatique pour lafouille de grandes bases de données multitables limportance prédictive desvariables est évaluée au moyen de modèles de discrétisation dans le cas numériqueet de groupement de valeurs dans le cas catégoriel dans le cas dunebase multitables par exemple des clients avec leurs achats une table danalyseindividus × variables est produite par construction automatique de variablesle modèle de classification utilisé est un classifieur bayésien naïf avec sélectionde variables et moyennage de modèles loutil est adapté à lanalyse desgrandes bases de données avec des millions dindividus des dizaines de milliersde variables et des centaines de millions denregistrements dans les tablessecondaires\n",
      "lanalyse relationnelle de concepts pour la fouille de données temporelles – application à létude de données hydroécologiques\n",
      "cet article présente une méthode dexploration de données temporellesfondée sur lanalyse relationnelle de concepts arc et appliquée à desdonnées séquentielles construites à partir déchantillons physicochimiques etbiologiques prélevés dans des cours deau notre but est de mettre au jour dessousséquences pertinentes et hiérarchisées associant les deux types de paramètrespour faciliter la lecture ces sousséquences sont représentées sous laforme de motifs partiellement ordonnés pomotifs le processus de fouille dedonnées se décompose en plusieurs étapes  construction dun modèle temporelad hoc et mise en oeuvre de larc  extraction des sousséquences synthétiséessous la forme de pomotifs  sélection des pomotifs intéressants grâce à unemesure exploitant la distribution des extensions de concepts le processus a ététesté sur un jeu de données réelles et évalué quantitativement et qualitativement\n",
      "la génération des résumés visuels de flux de données de capteurs météorologiques avec des chorèmes\n",
      "this paper describes a new approach for the automatic generation of visual summariesdealing with cartographic visualization methods and modeling of data coming from sensors inreal time for meteorology indeed the concept of chorems seems to be an interesting candidateto visualize real time geographic database summaries\n",
      "la rconfiance pour lidentification de trajectoires de patients\n",
      "sequential patterns mining consist in identifying frequent sequences of ordered events tosolve the problem of the large number of patterns obtained we extend the interest measurecalled confidence conventionally used to select association rules to sequential patterns wefocused on a case study myocardial infarction mi in order to predict the trajectory of patientswith mi between 2009 and 2013 the results were submitted to an expert for discussionand validation\n",
      "la révolution de lassurance par la donnée  défis scientifiques de lextraction à la gestion de connaissances\n",
      "la quantité de données dans notre monde a explosé et lanalyse de grands ensemblesde données – aussi connu dans lindustrie sous le nom « big data » – deviendra un atoutmajeur de compétitivité principalement dû à une croissance de productivité et surtoutà grâce à plus dinnovation la croissance exponentielle de données est alimentée parla facilité de la captation et par la multiplication de canaux numériques dacquisitionon pense non seulement à tous les processus qui sont informatisés aujourdhui maisaussi aux médias sociaux et aux objets connectéslassurance vie une révolution tout particulière lassureur traditionnellement gestionnairedu risque en sappuyant sur une longue expérience quon traduirait aujourdhuipar une captation systématique de données est après la révolution numériquepartiellement exclus de canaux digitauxceci est en même temps une menace et une opportunité il sagit dun défi puisquelindustrie doit réaliser une forte mutation pour se positionner la où la donnée setrouve aujourdhui ie dans le digital il sagit dune opportunité puisque ces nouvellesdonnées permettront de mieux appréhender les risques et plus particulièrementpermettront destimer au plus près les risques à la source plutôt que passer par devariables intermédiaires comme peut lêtre lâge pour le risque daccident en conduitelopportunité est dautant plus grande quen accédant aux données au plus près desutilisateurs il est possible de faire de la prévention évitant ainsi des accidents coûteuxpour lassureur mais surtout désastreux pour les victimesune fois la révolution engagée ceci implique un certain nombre de transformationsdans les processus dextraction et gestion de connaissances les défis scientifiques sontnombreux allant de la captation nonintrusive de la donnée à la visualisation et gestionde connaissances extraites en passant par de lapprentissage artificiel pour pouvoirservir à de millions dutilisateurs simultanément dans cette présentation nous allonscouvrir rapidement chacune de ces thématiques avec une attention particulière auxdéfis scientifiques sousjacentsnous allons illustrer notre propos par un exemple phare de cette révolution  lafamille doffres dassurance dite « pay as you drive » où généralement on obtient unedécote ou réduction en fonction de sa façon de conduire nous allons ce que ceci impliqueen termes dextraction et de gestion de connaissancespour conclure il est important de mentionner que cette révolution implique dautreschallenges cruciaux qui dépassent ce qui est abordé ici en particulier pour ne mentionnerque deux grands axes  la protection de la vie privée aussi bien du point de vuetechnique que juridique  et la transformation de métiers accompagné dune pénurie detalents déjà entamé\n",
      "learning from massive incompletely annotated  structured data\n",
      "the maestra project httpmaestraprojecteu addresses the ambitious taskof predicting different types of structured outputs in several challenging settings suchas semisupervised learning mining data streams and mining network data it developsmachine learning methods that work in each of these settings as well as combinationsthereof the techniques developed are applied to problems from the area of biology andbioinformatics sensor data analysis multimedia annotation and retrieval and socialnetwork analysis the talk will give an introduction to the project and the topicsit addresses an overview of the results of the project and a detailed description ofselected techniques and applications semisupervised learning for structuredoutputprediction sop and sop on data streams will be discussed for the task of multitargetregression mtr as well as applications of mtr for the annotationretrievalof images\n",
      "libre protocole de gestion de la cohérence dans les systèmes de stockage distribués\n",
      "nous présentons dans ce papier un protocole de gestion de la cohérenceappelé libre adapté aux systèmes de stockage orientés cloud telles queles bases de données nosql ce protocole garantit laccès à la donnée la plusrécente tout en ne consultant quune seule réplique cet algorithme est évaluépar simulation et est également implémenté au sein du système de stockage cassandrales résultats de ces expérimentations ont démontré lefficacité de notreapproche\n",
      "manipulation interactive densemble de motifs  application aux parcours hospitaliers\n",
      "dans cette démonstration nous proposons une application de visualisationdes résultats de la fouille de données séquentielles pour illustrer le fonctionnementde cette application nous avons utilisé des données pmsi hospitalièresplus précisément dans le cas de linfarctus du myocarde im les résultatsobtenus ont été soumis à un spécialiste pour discussion et validation\n",
      "nettoyage de données guidé par la sémantique intercolonnes\n",
      "today the volume of unstructured and heterogeneous data is exploding coming from multiplesources with different levels of quality therefore it is very likely to manipulate datawithout knowledge about their structures and their semantics in fact the metadata may beinsufficient or totally absent data anomalies may be due to the poverty of their semantic descriptionsor even the absence of their descriptions we propose an approach to understandbetter the semantics and the structure of the data it helps to correct the intracolumn anomalieshomogenization and then the intercolumns ones caused by the violation of semanticdependencies\n",
      "nouveaux algorithmes de fouilles de données relationnelles de clowdflows\n",
      "clowdflows est un logiciel open source qui permet à un utilisateur deréaliser des processus entiers de fouille de données à partir dun navigateur etdune connexion internet les calculs sont réalisés dans le “nuage” cestàdirede façon transparente sur plusieurs serveurs exécutant les calculs ou hébergeantles données dans cet article nous rappelons les points forts de clowdflows etnous présentons trois familles dalgorithmes de fouille de données relationnellesque nous venons dy intégrer en effet clowdflows est la seule plateforme webpermettant dexécuter voire comparer plusieurs techniques de fouille de donnéesrelationnelles souvent appelée programmation logique inductive\n",
      "nouvelle méthode de calcul de la réputation dans les forums de santé\n",
      "de plus en plus de forums tels que slashdot ou stack exchange proposentdes systèmes de réputations qui se basent sur le vote collaboratif lesutilisateurs peuvent ainsi donner un score à chaque message posté selon sa pertinenceou son utilité cependant ces fonctionnalités de vote sont rarement utiliséesdans de nombreuses communautés en ligne tels que les forums de santédans ces forums les utilisateurs préfèrent poster un nouveau message exprimantde laccord ou du remerciement vis à vis des messages pertinents plutôtque de cliquer sur un bouton de vote dans ce travail nous proposons dutiliserces formes implicites dexpression de la confiance pour estimer la réputation desutilisateurs dans les forums de santé\n",
      "observations sur les distributions latentes aux matrices laplaciennes de graphes\n",
      "lalgorithme de clustering spectral permet en principe dextraire desclusters de formes arbitraires à partir de données numériques cette propriété acontribué à sa popularité et même si ses bases théoriques sont établies depuisplus dune décennie des variantes en ont été proposées jusquà récemment sonfonctionnement repose sur une transformation vers un espace latent dans lequeldes formes de clusters arbitraires sont converties en structures faciles à traiterpar un algorithme tel que kmeans toutefois les distributions dans cet espacelatent nont été que peu discutées beaucoup dauteurs supposant que les propriétésprédites par la théorie sont vérifiées cet article propose alternativementune approche qualitative pour vérifier si cette structure idéale est effectivementobtenue en pratique le travail consiste également à identifier les paramètresde variabilité commandant à la transformation vers lespace latent via un étatde lart synthétique de la théorie sousjacente au clustering spectral les observationstirées de nos expériences permettent didentifier les combinaisons deparamètres efficaces et les conditions de cette efficacité\n",
      "persorec  un système personnalisé de recommandations pour les folksonomies basé sur les concepts quadratiques\n",
      "nous proposons un nouveau système appelé persorec afin de personnaliserles recommandations damis de tags ou de ressources faites aux utilisateursdans les folksonomies la personnalisation des recommandations estréalisée en prenant en compte le profil des utilisateurs cette nouvelle donnéepermet de proposer aux utilisateurs des tags ouet ressources plus adaptées àleurs besoins en plus du profil des utilisateurs nous avons recours à leur historiquede partage de tags et de ressources dans le but de regrouper les utilisateursayant partagé des tags et des ressources en commun tout en ayant des profilséquivalents ie des structures appelées concepts quadratiques ces deux donnéesprises en compte au moment du processus de recommandation a permisdaméliorer la qualité des recommandations faites aux utilisateurs persorec estdonc capable de générer une recommandation personnalisée pour chaque utilisateurselon le mode de recommandation quil désire recommandation damisde tags ou de ressources et selon le profil quil possède\n",
      "plongement de métrique pour le calcul de similarité sémantique à léchelle\n",
      "nous explorons le plongement de la métrique de plus court chemindans lhypercube de hamming dans lobjectif daméliorer les performances desimilarité sémantique dans wordnet subercaze et al 2015 nous montronsque bien quun plongement isométrique est impossible en pratique nous obtenonsde très bons plongements non isométriques nous obtenons une améliorationdes performances de trois ordres de grandeur pour le calcul de la similaritéde leacock et chodorow lch\n",
      "prédiction de la qualité dans les plateformes collaboratives  une approche générique par les graphes hétérogènes\n",
      "la qualité des contenus sur les plateformes collaboratives est très hétérogènedans la littérature scientifique les algorithmes danalyse structurelleappliqués à la tâche de détection de contenu de qualité reposent généralement surdes graphes définis à partir dun seul type de noeuds et de relations pourtant lesgraphes sur lesquels reposent ces récentes plateformes présentent de nombreusessémantiques de noeuds et relations différentes eg producteursconsommateursquestionsréponses etc ces solutions souffrent dun manque de généricité et nepeuvent sadapter facilement à lévolution des plateformes nous proposons unemodélisation générique de ces platformes par les graphes hétérogènes pouvantintégrer automatiquement de nouvelles sémantiques de noeuds et de relations unalgorithme de prédiction de qualité des contenus reposant sur ce modèle est proposénous montrons quil généralise plusieurs travaux de la littérature enfinen intégrant certaines relations interutilisateurs nous montrons que notre solutionévaluée surwikipedia et stack exchange améliore la tâche de détection decontenu de qualité\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recherche de groupes parallèles en classification nonsupervisée\n",
      "dans cet article nous nous intéressons à une situation de classificationnon supervisée dans laquelle nous souhaitons imposer une forme commune àtous les clusters dans cette approche la forme commune sera caractérisée parun hyperplan qui sera le même pour tous les groupes à une translation prèsles points sont donc supposés être distribués autour dhyperplans parallèles lafonction objectif utilisée peut naturellement sexprimer comme la minimisationde la somme des distances de chaque point à son hyperplan comme pour le casde kmeans la résolution est effectuée par lalternance de phases daffectationde chaque point à lhyperplan le plus proche et de phases de calcul de lhyperplanqui ajuste au mieux lensemble des points qui lui sont affectés lobjectifétant dobtenir des hyperplans parallèles cette phase de calcul est menée simultanémentpour tous les hyperplans par une méthode de régression\n",
      "régression logistique pour la classification dimages à grande échelle\n",
      "nous présentons un nouvel algorithme parallèle de régression logistiqueparmclr pour la classification dimages à grande échelle nous proposonsplusieurs extensions de lalgorithme original de régression logistique àdeux classes pour en développer une version efficace pour les grands ensemblesde données dimages avec plusieurs centaines de classes nous présentons unnouvel algorithme lrbbatchsgd de descente de gradient stochastique de régressionlogistique en batch équilibré avec un apprentissage parallèle approcheun contre le reste multiclasses sur de multiples coeurs les résultats expérimentauxsur des ensembles de données dimagenet montrent que notre algorithmeest efficace comparés aux algorithmes de classification linéaires de létat de lart\n",
      "relaxation des requêtes skyline  une approche centrée utilisateur\n",
      "les requêtes skyline constituent un outil puissant pour lanalyse dedonnées multidimensionnelles et la décision multicritère en pratique le calculdu skyline peut conduire à deux scénarios  soit i un nombre important dobjetssont retournés soit ii un nombre réduit dobjets sont retournés ce qui peut êtreinsuffisant pour la prise de décisions dans cet article nous abordons le secondproblème et proposons une approche permettant de le traiter lidée consiste àrendre le skyline plus permissive en lui ajoutant les objets non skyline les pluspréférés lapproche sappuie sur une nouvelle relation de dominance floue appelée«much preferred» un algorithme efficace pour calculer le skyline relaxéest proposé une série dexpériences sont menées pour démontrer la pertinencede lapproche et la performance de lalgorithme proposé\n",
      "requêtes discriminantes pour lexploration des données\n",
      "à lère du big data les profils dutilisateurs deviennent de plus enplus diversifiés et les données de plus en plus complexes rendant souvent trèsdifficile lexploration des données dans cet article nous proposons une techniquede réécriture de requêtes pour aider les analystes à formuler leurs interrogationspour explorer rapidement et intuitivement les données nous introduisonsles requêtes discriminantes une restriction syntaxique de sql avecune condition de sélection qui dissocie des exemples positifs et négatifs nousconstruisons un ensemble de données dapprentissage dont les exemples positifscorrespondent aux résultats souhaités par lanalyste et les exemples négatifs àceux quil ne veut pas en utilisant des techniques dapprentissage automatiquela requête initiale est reformulée en une nouvelle requête qui amorce un processusitératif dexploration des données nous avons implémenté cette idée dansun prototype isql et nous avons mené des expérimentations dans le domainede lastrophysique\n",
      "saffiet  un système dextraction de règles dassociations spatiales et fonctionnelles dans les séries de données géographiques\n",
      "nous partons de lhypothèse que les dynamiques spatiales et lévolutiondes usages des objets géographiques peuvent en partie être explicitéesvoire anticipées par leurs différentes évolutions précédentes et les configurationsspatiales dans lesquelles ils se situent aussi afin danalyser et comprendreles changements de fonction des objets géographiques au cours du temps et endéduire un modèle prospectif et puis prédictif nous proposons loutil saffietqui exploite la recherche des motifs fréquents et des règles dassociations pourextraire des règles dévolution régissant les dynamiques spatiales\n",
      "sarem un métamodèle pour la spécification des processus dextraction darchitectures logicielles\n",
      "we propose a metamodel called sarem that specifies the basic elements of the softwarearchitecture extraction sarem serves as a tool to compare the different software architectureextraction approaches that aim to extract a system architecture from the source code\n",
      "segmentation comportementale à laide des réseaux communautaires\n",
      "la mise en place dactions marketing efficaces passe par la segmentationde la clientèle cestàdire que les clients sont regroupés en ensembles homogènesen fonction de leurs habitudes de consommation ce qui rend possibleles actions ciblées ces dernières en personnalisant loffre permettent dobtenirdes taux de transformation plus importants et de meilleures ventesdans cet article une méthode originale de segmentation comportementale de laclientèle est présentée elle permet de visualiser les segments de clients à traversdes réseaux de communautés et de déceler aisément des mutations soudainesou graduelles dans les comportements de quelques individus ou dun ensembleplus important lanalyste bénéficie alors dune meilleure visibilité et peut adapterloffre à tout moment\n",
      "sélection topologique de variables dans un contexte de discrimination\n",
      "en apprentissage automatique la présence dun grand nombre de variablesexplicatives conduit à une plus grande complexité des algorithmes et àune forte dégradation des performances des modèles de prédiction pour celaune sélection dun sousensemble optimal discriminant de ces variables savèrenécessaire dans cet article une approche topologique est proposée pour la sélectionde ce sousensemble optimal elle utilise la notion de graphe de voisinagepour classer les variables par ordre de pertinence ensuite une méthode pas à pasde type ascendante forward est appliquée pour construire une suite de modèlesdont le meilleur sousensemble est choisi selon son degré déquivalence topologiquede discrimination pour chaque sousensemble le degré déquivalence estmesuré en comparant la matrice dadjacence induite par la mesure de proximitéchoisie à celle induite par la meilleure mesure de proximité discriminante ditede référence les performances de cette approche sont évaluées à laide de donnéessimulées et réelles des comparaisons de sélection de variables en discriminationavec une approche métrique montrent une bien meilleure sélection àpartir de lapproche topologique proposée\n",
      "slider  un raisonneur incrémental évolutif\n",
      "the main drawbacks of current reasoning methods over ontologies are they struggle toprovide scalability for large datasets the batch processing reasoners who provide the bestscalability so far are unable to infer knowledge from evolving data we contribute to solvingthese problems by introducing slider an efficient incremental reasoner slider exhibits a performanceimprovement by more than a 70 compared to the owlimse reasoner slider isconceived to handle expanding data from streams with a growing background knowledge baseit natively supports \u001adf and rdfs and its architecture allows to extend it to more complexfragments with a minimal effort\n",
      "structures de haies dans un paysage agricole  une étude par chemin de hilbert adaptatif et chaînes de markov\n",
      "dans cet article nous présentons une approche couplant une courberemplissant lespace et une chaîne de markov pour analyser des données spatialesconcernant la localisation de haies du fait de lhétérogénéité spatiale desdonnées nous utilisons une courbe adaptative de hilbert qui permet de linéariserlespace en sajustant localement à la densité des données pour ensuite exploiterla séquence produite il est nécessaire de caractériser la distance entre un pointet son prédecesseur sur la courbe ainsi que la densité locale nous proposonsde calculer un temps daccès à un point à partir du point précédent en utilisantla notion de profondeur de découpe cette variable couplée avec les variablescaractérisant les haies est ensuite analysée avec un modèle de markov nousprésentons et interprétons les résultats obtenus sur un jeu de données denviron10000 segments de haies dune zone de la basse vallée de la durance\n",
      "supervision de comportements remarquables dobjets mobiles à partir du suivi et de lanalyse de leurs trajectoires spatiotemporelles\n",
      "we propose a new generic knowledge model dedicated to the consideration of temporaland spatial dimensions of moving objects we extend usual approaches to meet the specificityof the representation of moving objects and their trajectories an application on shipping andboat trip scenarii is done\n",
      "tom a library for topic modeling and browsing\n",
      "in this paper we present tom topic modeling a python libraryfor topic modeling and browsing its objective is to allow for an efficient analysisof a text corpus from start to finish via the discovery of latent topics to thisend tom features advanced functions for preparing and vectorizing a text corpusit also offers a unified interface for two topic models namely lda usingeither variational inference or gibbs sampling and nmf using alternating leastsquarewith a projected gradient method and implements three stateoftheartmethods for estimating the optimal number of topics to model a corpus what ismore tom constructs an interactive webbased browser that makes exploringa topic model and the related corpus easy\n",
      "topic modeling and hypergraph mining to analyze the egc conference history\n",
      "dans le cadre du défi proposé à lédition 2016 de la conférence egc nous exploitons lesarticles qui y ont été publiés de 2004 à 2015 avec pour but dexpliquer sa structure et sonévolution a partir des thématiques latentes découvertes et dautres propriétés des articles egauteurs affiliations nous mettons en lumière des caractéristiques intéressantes des structuresthématique et collaborative degc a laide dune méthode dextraction ditemsets dans leshypergraphes nous mettons aussi en avant des liens latents entre auteurs ou entre thématiquesde plus nous proposons des recommandations dauteurs ou de thématiques enfin nous décrivonsune interface web pour explorer les connaissances découvertes\n",
      "towards generic and efficient constraintbased mining a constraint programming approach\n",
      "in todays datarich world pattern mining techniques allow us to extract knowledge fromdata however such knowledge can take many forms and often depends on the application athand this calls for generic techniques that can be used in a wide range of settings in recentyears constraint programming has been shown to offer a generic methodology that fits manypattern mining settings including novel ones existing constraint programming solvers do notscale very well though in this talk i will review different ways in which this limitation hasbeen overcome often this is through principled integration of techniques and data structuresfrom pattern mining into the constraint solvers\n",
      "transmute  un outil interactif pour assister lextraction de connaissances à partir de traces\n",
      "alors que lextraction de connaissances à partir de donnéesecd est un processus qualifié dinteractif et ditératif linteractivité desoutils est souvent limitée et son étude est relativement récente elle estpourtant déterminante lors de linterprétation pour choisir les motifs quideviendront des connaissances nous proposons transmute un outildassistance à linterprétation dans le processus decd dans le cadre dela recherche dépisodes séquentiels à partir de traces la phase dinterprétationest itérative et à chaque itération les résultats de la fouille sontmis à jour dynamiquement en fonction des interactions avec lanalystedes outils de visualisation et des mesures de qualité indépendantes dudomaine permettent de caractériser lintérêt des motifs à interpréter pourfaciliter leur choix et accompagner le travail de lanalyste afin de laider àse focaliser plus rapidement sur les motifs potentiellement intéressants\n",
      "un cadre collaboratif pour la segmentation et la classification dimages de télédétection\n",
      "dans cet article nous présentons cosc un cadre collaboratif pour lasegmentation et la classification dimages de télédétection permettant dextraireles objets dune classe thématique donnée le processus de collaboration estguidé par la qualité des données évaluée par des critères dhomogénéité ainsique des critères implicitement liés à la sémantique des objets afin dextraire uneclasse thématique donnée nos expériences montrent que cosc atteint des bonsrésultats en termes de classification et améliore notablement la segmentation delimage de manière globale\n",
      "un outil dexploration pour le défi egc 2016\n",
      "dans le cadre du défi egc 2016 nous avons développé une applicationweb pour explorer les données décrivant les articles publiés depuis 2004 lorsdes conférences egc loutil permet de découvrir les thèmes importants qui ontété abordés dans ces papiers de plus il permet de déterminer automatiquementles articles sémantiquement similaires à des thèmes donnés\n",
      "un protocole dexpérimentation sur les propriétés graphémiques avec lalgorithme som\n",
      "nous présentons une recherche sur la distribution et la classificationnonsupervisée des graphèmes nous visons à réduire lécart entre les résultatsde recherches récentes qui montrent la capacité des algorithmes dapprentissageet de classification nonsupervisée pour détecter les propriétés de phonèmes etles possibilités actuelles de la représentation textuelle dunicode nos procéduresdoivent assurer la reproductibilité des expériences et garantir que linformationrecherchée nest pas implicitement présente dans le prétraitement desdonnées notre approche est capable de catégoriser correctement de potentielsgraphèmes ce qui montre que les propriétés phonologiques sont présentes dansles données textuelles et peuvent être automatiquement extraites à partir desdonnées textuelles brutes en unicode sans avoir besoin de les traduire en représentationsphonologiques\n",
      "un regard lexicoscientométrique sur le défi egc 2016\n",
      "depuis 2001 les conférences egc ont rassemblé 1 782 chercheursautour de lextraction et la gestion de connaissances en 2016 lassociationegc réfléchit à son histoire et se projette en lançant un défi à sa communautéque peuton révéler sur la communauté egc via des approches développées enegc  notre étude lexicoscientométrique apporte un éclairage sur les thématiquesdu congrès les lieux de publication investis par ses auteurs ou encore lesauteurs sollicitables comme évaluateurs les résultats sont intégrés à un site websoustendu par un système dinformation décisionnel\n",
      "une approche basée sur des données mixtes – mesures et estimations – pour la détection de défaillances dun système robotisé\n",
      "mettre en place un dispositif de détection de pannes représente denos jours lun des défis majeurs pour les constructeurs des systèmes robotisésle processus de détection nécessite lutilisation dun certain nombre de capteursafin de surveiller le fonctionnement de ces systèmes or le coût ainsi queles contraintes liées à la mise en place de ces capteurs conduisent souvent lesconcepteurs à optimiser leurs nombres ce qui mène à un manque de mesuresnécessaires pour la détection de défaillances lune des méthodes pour comblerce manque est destimer les paramètres non mesurables à partir dun modèlemathématique décrivant la dynamique du système réel cet article présente uneapproche basée sur des données mixtes données mesurées et données estiméespour la détection de défaillances dans les systèmes robotisés cette détection esteffectuée en utilisant un classifieur de type arbre de décision les données utiliséespour son apprentissage proviennent des mesures prises sur le système réelces données sont ensuite enrichies par des données estimées en provenance dunobservateur basé sur un modèle analytique cet enrichissement sous forme dattributssupplémentaires a pour but daugmenter la connaissance du classifieursur le fonctionnement du système et par conséquent améliorer le taux de bonnedétection de défaillances une expérience sur un système dactionnement dunsiège robotisé montrant lintérêt de notre approche sera présentée à la fin delarticle\n",
      "une approche combinée pour lenrichissement dontologie à partir de textes et de données du lod\n",
      "cet article porte sur létiquetage automatique de documents décrivantdes produits avec des concepts très spécifiques traduisant des besoins précisdutilisateurs la particularité du contexte est quil se confronte à une triple difficulté 1 les concepts utilisés pour létiquetage nont pas de réalisations terminologiquesdirectes dans les documents 2 leurs définitions formelles ne sontpas connues au départ 3 toutes les informations nécessaires ne sont pas forcémentprésentes dans les documents mêmes pour résoudre ce problème nousproposons un processus dannotation en deux étapes guidé par une ontologiela première consiste à peupler lontologie avec les données extraites des documentscomplétées par dautres issues de ressources externes la deuxièmeest une étape de raisonnement sur les données extraites qui recouvre soit unephase dapprentissage de définitions de concepts soit une phase dapplicationdes définitions apprises lapproche saupodoc est ainsi une approche originaledenrichissement dontologie qui exploite les fondements du web sémantiqueen combinant les apports du lod et doutils danalyse de texte dapprentissageautomatique et de raisonnement lévaluation sur deux domaines dapplicationdonne des résultats de qualité et démontre lintérêt de lapproche\n",
      "une approche dévolution du web de données\n",
      "sharing knowledge and data coming from different sources is one of the biggest advantageof linked data keeping this knowledge graph up to date may take in account both ontologyvocabularies and data since they should be consistent our general problem is to deal with webof data evolution in particular we aim at modifing both levels  abox and tbox\n",
      "une approche de réduction de dimensionnalité pour lagrégation de préférences qualitatives\n",
      "nous présentons une méthode de réduction de dimensionnalité pourdes données de préférences multicritères lorsque lespace des évaluations estun treillis distributif borné cette méthode vise à réduire la complexité desprocédures dapprentissage dun modèle dagrégation sur des données qualitativesainsi nous considérons comme modèle dagrégation lintégrale de sugenolapprentissage dun tel modèle à partir de données empiriques est unproblème doptimisation à 2n paramètres où n est le nombre de critères considérésla méthode de réduction que nous proposons sappuie sur lobservationde certaines relations entre les éléments de ces données et nous donnons despremiers résultats dapplications\n",
      "une mesure de similarité entre phrases basée sur des noyaux sémantiques\n",
      "nous proposons une nouvelle approche pour le calcul de similarité sémantiqueentre phrases en utilisant les noyaux sémantiques qui les composentces noyaux sous la forme de triplets sujet verbe et objet sont supposés porteursde linformation des phrases dont ils sont extraits sur la base de la comparaisonsémantique de noyaux on extrait un ensemble dindicateurs descriptifsnous utilisons ensuite un apprentissage automatique sur un benchmark contenantdes phrases dont la similarité sémantique a été évaluée par des experts humainsafin de déterminer limportance de chaque indicateur et de construireainsi un modèle capable de fournir une mesure de similarité sémantique entrephrases les expérimentations et les études comparatives effectuées avec dautresapproches permettant lestimation des similarités sémantiques entre phrasesmontrent les bonnes performances de notre approche en se basant sur cette dernièreun outil de navigation sémantique est en cours de développement\n",
      "une méthode de découverte de motifs contextualisés dans les traces de mobilité dune personne\n",
      "les traces de mobilité générées par les divers capteurs qui nous entourentpeuvent être analysées à des fins prédictives et explicatives pour répondreà divers problèmes du quotidien si de nombreuses méthodes ont été proposéespour décrire le comportement dun individu de manière globale à partir destransitions entre ses différents points dintérêts par exemple via un modèle demarkov peu de travaux cherchent à lexpliquer de manière locale nous proposonsdans cet article une méthode qui permet dextraire pour un individu donton a une trace de mobilité conséquente des motifs de mobilité dits contextualiséschaque motif est composé dune description sur lensemble des visites auxdifférents points dintérêt de lindividu qui maximise une ou plusieurs mesuresavec une sémantique particulière le motif décrit une phase sédentaire ou exceptionnelde la mobilité de lindividu une expérimentation a été menée à partirde traces de mobilité de véhicules et donne des résultats encourageants\n",
      "une méthode supervisée pour initialiser les centres des kmoyennes\n",
      "au cours des dernières années la classification à base de clusteringsest imposée comme un sujet de recherche important cette approche vise àdécrire et à prédire un concept cible dune manière simultanée partant du faitque le choix des centres pour lalgorithme des kmoyennes standard a un impactdirect sur la qualité des résultats obtenus cet article vise alors à tester à quelpoint une méthode dinitialisation supervisée pourrait aider lalgorithme des kmoyennesstandard à remplir la tâche de la classification à base des kmoyennes\n",
      "vers une approche visual analytics pour explorer les variantes de sujets dun corpus\n",
      "our purpose is to implement a visual analytics tool for exploring topic variants in textcorpora the overlapping biclustering methods extract multiple topics from the documentsbut the interpretation of the results remains difficult we make the assumption that biclusteroverlaps are articulation points between highlevel topics and their multiple variants and viewpointswe propose to extract and visualize a hierarchical structure of bicluster overlaps allowingto explore the corpus and to discover unsuspected viewpoints\n",
      "visualisation interactive de métadonnées pour aider les utilisateurs dun logiciel de cartographie statistique à concevoir de meilleures cartes\n",
      "cd7online est lapplication saas de la 7ème version de cartes données c  d le logiciel de cartographie statistique décisionnelle et de géomarketingédité par articque c  d permet aux utilisateurs occasionnels de réalisersimplement des cartes à partir de données statistiques et géographiques 25ans de retours utilisateurs nous ont permis de voir que la qualité des cartes reposeen partie sur la bonne connaissance des données dont disposent les utilisateurset sur leur capacité à choisir des outils danalyse et de représentation pertinentspour aider les utilisateurs à mieux comprendre leurs données et à réaliser descartes de meilleure qualité nous avons développé une brique sémantique avecun outil de visualisation interactif permettant de visualiser les connaissances extraitesdes espaces de travail des utilisateurs nous décrivons ici lapplicationcd7online ainsi que loutil de visualisation que nous présenterons lors de ladémonstration logicielle\n",
      "a clustering based approach for type discovery in rdf data sources\n",
      "rdfsowl data sources are not organized according to a predefined schema as they are structureless by nature this lack of schema limits their use to express queries or to understand their content our work is a contribution towards the inference of the structure of rdfsowl data sources we present an approach relying on densitybased clustering to discover the types describing the entities of possibly incomplete and noisy data sets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a framework for mesh segmentation and annotation using ontologies\n",
      "la segmentation et annotation de maillages utilisant la sémantique a été lobjet dun intérêt grandissant avec la démocratisation des techniques de reconstruction 3d une approche classique consiste à réaliser cette tâche en deux étapes tout dabord en segmentant le maillage puis en lannotant cependant cette approche ne permet pas à chaque étape de profiter de lautre en traitement dimages quelques méthodes combinent la segmentation et lannotation mais ces approches ne sont pas génériques et nécessitent des ajustements dimplémentation ou des réécritures pour chaque modification des connaissances expertes dans ce travail nous décrivons un cadre de fonctionnement qui mélange segmentation et annotation afin de réduire le nombre détapes de segmentation et nous présentons des résultats préliminaires qui montrent la faisabilité de lapprochenotre système fournit une ontologie générique qui décrit sous forme de concepts les propriétés dun objet géométrie topologie etc ainsi que des algorithmes permettant de détecter ces concepts cette ontologie peut être étendue par un expert pour décrire formellement un domaine spécifique la description formelle du domaine est alors utilisée pour réaliser automatiquement lassemblage de la segmentation et de lannotation dobjets et de leurs propriétés en sélectionnant à chaque étape lalgorithme le plus pertinent étant données les information sémantiques déjà détectées cette approche originale comporte plusieurs avantages tout dabord elle permet de segmenter et dannoter des objets sans aucune connaissance en traitement dimages ou de maillages en décrivant uniquement les propriétés de lobjet en terme de concepts ontologiques de plus ce cadre de fontionnement peut facilement être réutilisé et appliqué à différents contextes dès lors quune ontologie de domaine a été définie finalement la réalisation conjointe de la segmentation et de lannotation permet dutiliser dune manière efficace la connaissance experte en réduisant les erreurs de segmentation et le temps de calcul en lançant toujours lalgorithme le plus pertinent\n",
      "analyse des paramètres de recherche dinformation etude de linfluence des paramètres sur les résultats\n",
      "cet article présente une analyse détaillée dun ensemble de 2 millions de résultats de recherche dinformation obtenus par différents paramétrages de systèmes de recherche dinformation plus spécifiquement nous avons utilisé la plateforme terrier et linterface rungeneration pour créer différentes exécutions run en anglais en modifiant les modèles dindexation et de recherche nous avons ensuite évalué chacun des résultats obtenus selon différentes mesures de performance de recherche dinformation une analyse systématique a été menée sur ces données afin de déterminer dune part quels étaient les paramètres qui ont le plus dinfluence dautre part quels étaient les valeurs de ces paramètres les plus susceptibles de conduire à de bonnes performances du système\n",
      "analyse et visualisation dopinions dans un cadre de veille sur leweb\n",
      "lanalyse dopinions est une tâche qui consiste en lidentification et la classification de textes subjectifs dans ce travail nous nous intéressons au problème danalyse dopinions dans un contexte de veille sur le web nous proposons une approche pour visualiser les résultats danalyse dopinions basée sur lutilisation de termes clés nous décrivons également la plateforme de veille sur leweb amiei au sein de laquelle notre approche a été implémentée la démonstration consistera en une expérimentation de la plateforme de veille amiei et du module danalyse dopinions sur un corpus de tweets politiques\n",
      "analyse olap sur des tweets et des blogs  un retour dexpérience\n",
      "le projet anr imagiweb dans lequel sinscrit ce travail sest donné pour mission détudier les images véhiculées sur internet en se basant sur la détection dopinions deux cas détude ont été définis  1 le premier vise à répondre aux besoins danalyse de chercheurs en science politique grâce à des données issues de twitter durant la campagne présidentielle de 2012  2 le second doit permettre à lentreprise française edf dévaluer lopinion du public en matière de sécurité demploi et de prix à partir de billets de blogs dans cet article nous présentons un retour dexpérience sur lusage de lanalyse en ligne olap online analytical processing pour des données textuelles mettant en avant lintérêt de ce type danalyse pour les membres du projet\n",
      "analyse visuelle pour la détection des intrusions\n",
      "la démocratisation dinternet couplée à leffet de la mondialisation a pour résultat dinterconnecter les personnes les états et les entreprises le côté déplaisant de cette interconnexion mondiale des systèmes dinformation réside dans un phénomène appelé cybercriminalité nous proposons une méthode de visualisation de grands graphes et lexploitation danalyses statiques des flux permettant de détecter les comportements anormaux et dangereux afin dappréhender les risques dune façon compréhensible par tous les acteurs\n",
      "approche dextraction de classes interlangues à partir de documents multilingues à base de concepts fermés\n",
      "in this article we highlight the interest and usefulness of formal concept analysis fca in multilingual document clustering we propose a statistical approach for clustering multilingual documents based on closed concepts and vector model partition the documents of one or more collectionsan experimental evaluation was conducted on the collection of bilingual documents frenchenglish of clef 2 2003 and showed the merits of this method and the interesting degree of comparability of the obtained bilingual classes\n",
      "approche relationnelle de lapprentissage de séquences\n",
      "we observe an increasing amount of sequential data for instance open data sources provide realtime information in order to apply classical learning algorithms sequential data are often modelled in an attributevalue setting using a sliding window in this paper we propose a relational approach a first advantage is to let the relational algorithm choose the length of the window a second advantage is to allow to consider conditions based on the existential quantifier and aggregates a third advantage is to be able to consider several granularities at the same time\n",
      "big data and the dawn of algorithms in everything\n",
      "the mainstream adoption of the internet as a source for knowledge and interaction for the past decades has given rise to new data sources that are characterized by large sizes and rapid creation in addition sensory data from mobile devices and machinery are on the rise with similar characteristics all these sources have the commonality that they will tell us something new or something more detailed than before from a business standpoint these data sources holds the opportunity to create more customized services and improved products in practically anything however they also present a challenge since they are big and typically residing outside the traditional server structure of organizations this talk will explore the challenges of integrating these new socalled big data in decision processes specifically we will explore the paradigm shifts when external data become equally or more important than internal data we will also explore the emerging shift in decision making becoming algorithmic as opposed to human discovery driven\n",
      "big data is all about data that we dont have\n",
      "big data is now becoming a buzz word in information technology industry and research is big data only about large volume of data and if it is yes why is it suddenly becoming a trend hasnt the growth of data volume been gigantic in the last decade from a research point of view it is not surprising to see researchers from all walks of computer science are trying to align their research to big data for the sake of being trendy the question remains whether it tackles the real big data problems in this talk i will describe the misconceptions of big data present motivating cases and discuss the unavoidable challenges faced by industry and research\n",
      "challenges and opportunities in hci visual analytics and knowledge management for the development of sustainable cities\n",
      "while overtly exposed in the media the challenges faced by our societies to transition towards sustainable energy use are quite formidable a simple visual refresher of the cold hard facts should amply reveal the importance of visualization to assess the situation private companies such as ibm and public research centers are joining forces and investing to design and evaluate novel approaches to build and manage cities defined as the rational organisation of dense human habitat information and communication technologies are certainly part of the answers in particular in areas related to knowledge management data mining hci and social computing illustrated with telltaling examples of research work carried at ibm the cstb and the efficacity institute i will argue that interactive information technologies can help managing the energy transition of cities in 3 key aspects   — to support the city design process notably computer supported tooling and information infrastructure that help taming the complexity of the intertwinning actors and interests at play   — to help understand better the citys dynamics identifiy inefficiencies and reveal optimization opportunities where knowledge management and extraction is crucial   — and foremost to ease the necessary changes that will have to happen in our mobility and housing habits with novel tools and services that alleviate our energy needs\n",
      "choix dune mesure de proximité discriminante dans un contexte topologique\n",
      "les résultats de toute opération de classification ou de classement dobjets dépendent fortement de la mesure de proximité choisie lutilisateur est amené à choisir une mesure parmi les nombreuses mesures de proximité existantes or selon la notion déquivalence topologique choisie certaines sont plus ou moins équivalentes dans cet article nous proposons une nouvelle approche de comparaison et de classement de mesures de proximité dans une structure topologique et dans un objectif de discrimination le concept déquivalence topologique fait appel à la structure de voisinage localnous proposons alors de définir léquivalence topologique entre deux mesures de proximité à travers la structure topologique induite par chaque mesure dans un contexte de discrimination nous proposons également un critère pour choisir la meilleure mesure adaptée aux données considérées parmi quelques mesures de proximité les plus utilisées dans le cadre de données quantitatives le choix de la meilleure mesure de proximité discriminante peut être vérifié a posteriori par une méthode dapprentissage supervisée de type svm analyse discriminante ou encore régression logistique appliquée dans un contexte topologiquele principe de lapproche proposée est illustré à partir dun exemple de données quantitatives réelles avec huit mesures de proximité classiques de la littérature des expérimentations ont permis dévaluer la performance de cette approche topologique de discrimination en terme de taille etou de dimension des données considérées et de sélection de la meilleur mesure de proximité discriminante\n",
      "classification évidentielle avec contraintes détiquettes\n",
      "ce papier propose une version améliorée de lalgorithme de classification automatique évidentielle semisupervisée secm celuici bénéficie de lintroduction de données étiquetées pour améliorer la pertinence de ses résultats et utilise la théorie des fonctions de croyance afin de produire une partition crédale qui généralise notamment les concepts de partitions dures et floues le pendant de ce gain dexpressivité est une complexité qui est exponentielle avec le nombre de classes ce qui impose en retour lutilisation de schémas efficaces pour optimiser la fonction objectif nous proposons dans cet article une heuristique qui relâche la contrainte classique de positivité liée aux masses de croyances des méthodes évidentielles nous montrons sur un ensemble de jeux de données de test que notre méthode doptimisation permet daccélérer sensiblement lalgorithme secm avec un schéma doptimisation classique tout en améliorant également la qualité de la fonction objectif\n",
      "classification multilabel par raisonnement logique pour lindexation sémantique de documents\n",
      "cet article présente une solution centrée sur les ontologies pour la classification multilabel automatique dinformation nécessaire à un système de recommandation dinformations économiques\n",
      "clustering topologique pour le flux de données\n",
      "actuellement le clustering de flux de données devient le moyen le plus efficace pour partitionner un très grand ensemble de données dans cet article nous présentons une nouvelle approche topologique appelée gstream pour le clustering de flux de données évolutives la méthode proposée est une extension de lalgorithme gng growing neural gas pour gérer le flux de données gstream permet de découvrir de manière incrémentale des clusters de formes arbitraires en ne faisant quune seule passe sur les données les performances de lalgorithme proposé sont évaluées à la fois sur des données synthétiques et réelles\n",
      "cohérence des données de bases rdf en évolution constante\n",
      "le maintien de la qualité et de la fiabilité de bases de connaissances rdf du web sémantique est un problème courant de nombreuses propositions pour lintégration de « bonnes » données ont été faites se basant soit sur les ontologies de ces bases soit sur des métadonnées additionnelles dans cet article nous proposons une approche originale basée exclusivement sur létude des données de la base le principe est de déterminer si les modifications apportées par la mise à jour candidate rendent la partie ciblée de la base plus similaire – selon certains critères – à dautres parties existantes dans la base la mise à jour est considérée cohérente avec cette base et peut être appliquée\n",
      "comparison of linear modularization criteria using the relational formalism an approach to easily identify resolution limit\n",
      "la modularisation de grands graphes ou recherche de communautés est abordée comme loptimisation dun critère de qualité lun des plus utilisés étant la modularité de newmangirvan dautres critères ayant dautres propriétés aboutissent à des solutions différentes dans cet article nous présentons une réécriture relationnelle de six critères linéaires zahncondorcet owsi´nski zadro729zny lecart à luniformité lecart à lindétermination et la modularité equilibrée nous utilisons une version générique de lalgorithme doptimisation de louvain pour approcher la partition optimale pour chaque critère sur des réseaux réels de différentes tailles les partitions obtenues présentent des caractéristiques différentes concernant notamment le nombre de classes le formalisme relationnel nous permet de justifier ces différences dun point de vue théorique en outre cette notation permet didentifier facilement les critères ayant une limite de résolution phénomène qui empêche en pratique la détection de petites communautés sur de grands graphes une étude de la qualité des partitions trouvées dans les graphes synthétiques lfr permet de confirmer ces résultats\n",
      "compromis précisionrappel dans lévaluation des performances \n",
      "dans de nombreux problèmes dapprentissage automatique la performance des algorithmes est évaluée à laide des mesures précision et rappel or ces deux mesures peuvent avoir une importance très différente en fonction du contexte dans cet article nous étudions le comportement des principaux indices de performance en fonction du couple précisionrappel nous proposons un nouvel outil de visualisation de performances et définissons lespace de compromis qui représente les différents indices en fonction du compromis précisionrappel nous analysons les propriétés de ce nouvel espace et mettons en évidence ses avantages par rapport à lespace précisionrappel\n",
      "contribution au calcul du skyline par réduction de lespace candidat\n",
      "lopérateur skyline est devenu un paradigme dans les bases de données il consiste à localiser sky lensemble des points dun espace vectoriel qui ne sont pas dominés cet opérateur est utile lorsquon narrive pas à se décider dans les situations conflictuelles le calcul des requêtes skyline est pénalisé par le nombre de points que peuvent contenir les bases de données dans ce papier nous présentons une solution analytique pour la réduction de lespace candidat et nous proposons une méthode efficace pour le calcul de ce type de requêtes\n",
      "d113  une plateforme opensource dédiée à lanalyse des flux et à la détection des intrusions\n",
      "ce travail se situe dans le domaine de la cybersécurité le projet d113 permet de visualiser en temps réel les flux transitant sur des équipements de filtrage sans avoir recours au traitement manuel des journaux dévénements nous centrerons notre démonstration sur la visualisation de grands graphes et lexploitation danalyses statiques des flux\n",
      "découverte de proportions analogiques dans les bases de données  une première approche\n",
      "cet article présente un nouveau cadre pour la découverte de connaissances basé sur la notion de proportion analogique qui exprime légalité des rapports entre les attributs de deux paires déléments cette notion est développée dans le contexte des bases de données pour découvrir des parallèles dans les données dans un premier temps nous donnons une définition formelle des proportions analogiques dans le cadre des bases de données relationnelles puis nous étudions le problème de lextraction des proportions analogiques nous montrons quil est possible de suivre une approche de clustering pour découvrir les classes déquivalence de paires de nuplets dans le même rapport de proportion analogique ce travail constitue uncet article présente un nouveau cadre pour la découverte de connaissances basé sur la notion de proportion analogique qui exprime légalité des rapports entre les attributs de deux paires déléments cette notion est développée dans le contexte des bases de données pour découvrir des parallèles dans les données dans un premier temps nous donnons une définition formelle des proportions analogiques dans le cadre des bases de données relationnelles puis nous étudions le problème de lextraction des proportions analogiques nous montrons quil est possible de suivre une approche de clustering pour découvrir les classes déquivalence de paires de nuplets dans le même rapport de proportion analogique ce travail constitue une première étape vers lextension des langages dinterrogation de base de données avec des requêtes « analogiques »e première étape vers lextension des langages dinterrogation de base de données avec des requêtes « analogiques »\n",
      "détection automatique de reformulations  correspondance de concepts appliquée à la détection du plagiat\n",
      "dans le cadre de la détection du plagiat la phase de comparaison de deux documents est souvent réduite à une comparaison mot à mot une recherche de « copiercoller » dans cet article nous proposons une approche naïve de comparaison de deux documents dans le but de détecter automatiquement aussi bien les phrases copiées de lun des textes dans lautre que les paraphrases et reformulations ceci en se focalisant sur lexistence des mots porteurs de sens ainsi que sur leurs mots de substitution possibles nous comparons trois algorithmes utilisant cette approche afin de déterminer la plus efficace pour ensuite lévaluer face à des méthodes existantes lobjectif est de permettre la détection des similitudes entre deux textes en utilisant uniquement des mots clefs lapproche proposée permet de détecter des reformulations non paraphrastiques impossibles à détecter avec des approches conventionnelles faisant appel à une phase dalignement\n",
      "détection et regroupement automatique de style décriture dans un texte\n",
      "la détection de plagiat extrinsèque devient vite inefficace lorsque lon na pas accès aux documents potentiellement sources du plagiat ou lorsque lon se confronte à un espace aussi vaste que leweb ce qui est souvent le cas dans les logiciels antiplagiat actuels dès lors la détection intrinsèque devient nettement plus efficace dans cet article nous traitons justement de la détection automatique dauteurs qui permet de savoir si un passage dun texte nappartient pas au même auteur que le reste du texte et donc en théorie de repérer les passages plagiés dun document nous expliquons notre contribution aux procédures déjà existantes et évaluons les limites de notre approche lobjectif est de permettre la détection et le regroupement de passages dun document par auteur\n",
      "deux approches pour catégoriser le risque\n",
      "le risque chimique ou alimentaire couvre les situations où les produits chimiques sont dangereux pour la santé et consommation humaine ou animale et pour lenvironnement les experts qui assurent le contrôle et la gestion de ces substances se retrouvent face à de gros volumes de littérature scientifique qui doit être analysée pour appuyer la prise de décisions nous proposons une aide automatique pour lanalyse de cette littérature nous abordons la tâche comme une problématique de catégorisation il sagit de catégoriser les phrases des textes dans les classes du risque lié aux substances nous utilisons deux approches par apprentissage supervisé et la recherche dinformation les résultats obtenus avec lapprentissage supervisé toute classe confondue fmesure autour de 08 pour le risque alimentaire entre 061 et 064 pour le risque chimique sont meilleurs que ceux obtenus avec par recherche dinformation toute classe confondue fmesure entre 018 et 0226 pour le risque alimentaire entre 020 et 032 pour le risque chimique le rappel est compétitif avec les deux approches\n",
      "échantillonnage de flux de données sémantiques  une approche orientée graphe\n",
      "nowadays processing online massive data streams with special techniques like load shedding is an unavoidable alternative to optimize system resources use in this paper we propose a graphoriented approach for load shedding semantic data streams our approach unlike the rdf triple based one preserves the semantic level of the data streams which improves the responses quality of the rdf data stream processing systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etude de la pertinence lors de la sélection de collections dans les systèmes distribués\n",
      "this paper presents a new function of collection selection our function is free of any extracollection parameter and is based on the documents relevance the ranking of a collection is proportional to its number of relevant documents\n",
      "extraction complète efficace de chemins pondérés dans un adag\n",
      "un nouveau domaine de motifs appelé chemins pondérés condensés a été introduit en 2013 lors de la conférence ijcai le contexte de fouille est alors un graphe acyclique orienté dag dont les sommets sont étiquetés par des attributs nous avons travaillé à une implémentation efficace de ce type de motifs et nous montrons que lalgorithme proposé était juste mais incomplet nous établissons ce résultat dincomplétude et nous lexpliquons avant de trouver une solution pour réaliser une extraction complète nous avons ensuite développé des structures complémentaires pour calculer efficacement tous les chemins pondérés condensés lalgorithme est amélioré en performance de plusieurs ordres de magnitude sur des jeux de données artificiels et nous lappliquons à des données réelles pour motiver qualitativement lusage des chemins pondérés\n",
      "extraction de lintérêt implicite des utilisateurs dans les attributs des items pour améliorer les systèmes de recommandations\n",
      "les systèmes de recommandation ont pour objectif de sélectionner et présenter dabord les informations susceptibles dintéresser les utilisateurs ce travail expose un système de recommandation qui sappuie sur deux concepts des relations sémantiques sur les données et une technique de filtrage collaboratif distribué basée sur la factorisation des matrices mf dune part les techniques sémantiques peuvent extraire des relations entre les données et par conséquent améliorer la précision des recommandations dautre part mf donne des prévisions très précises avec un algorithme facilement parralélisable notre proposition utilise cette technique en ajoutant des relations sémantiques au processus en effet nous analysons en profondeur les intérêts cachés des utilisateurs dans les attributs des items à recommander nous utilisons dans nos expérimentations le jeu de données movielens enrichi par la base de données imdb nous comparons notre travail à une technique mf classique les résultats montrent une précision dans les recommandations tout en préservant un niveau élevé dabstraction du domaine en outre nous améliorons le passage à léchelle du système en utilisant des techniques parallélisables\n",
      "feedback  study and improvement of the random forest of the mahout library in the context of marketing data of orange\n",
      "lapprentissage automatique a fait son apparition dans lécosystème hadoop créant de par la puissance promise une opportunité sans précédent pour ce domaine dans cet écosystème apache mahout est une réponse à la question du temps de calcul etou de la volumétrie il consiste en un entrepôt dalgorithmes dapprentissage automatique tous portés afin de sexécuter sur mapreduce ce rapport se concentre sur le portage et lutilisation de lalgorithme des random forest dans mahout il montre à travers notre retour dexpérience les difficultés qui peuvent être rencontrées tant pratiques que théoriques et suggère une piste damélioration\n",
      "gapit  un outil visuel pour limputation de valeurs manquantes en hydrologie\n",
      "les données manquantes sont problématiques en hydrologie car elles gênent le calcul de statistiques interannuelles et sur de longues périodes ainsi que lanalyse et linterprétation de la variabilité des données dans cet article nous présentons gapit une plateforme danalyse de données permettant dinspecter visuellement les données manquantes et ensuite de choisir la méthode de correction adéquate nous avons utilisé loutil pour estimer les données manquantes dans des séries temporelles correspondant aux débits mesurés par des stations hydrométriques du luxembourg\n",
      "gestion de lincertitude dans le cadre dune extraction des connaissances à partir de texte\n",
      "the knowledge representation area needs some methods that allow to detect and handle uncertainty indeed a lot of text hold information whose the veracity can be called into question these information should be managed efficiently in order to represent the knowledge in an explicit way as first step we have identified the different forms of uncertainty during a knowledge extraction process then we have introduce an rdf representation for these kind of knowledge based on an ontologie that we developped for this issue\n",
      "heuristiques pour ladaptation des mappings entre ontologies dynamiques\n",
      "les correspondances sémantiques entre ontologies mappings jouent un rôle essentiel dans les systèmes dinformation cependant en vertu de lévolution des connaissances les éléments ontologiques sont sujets à modification invalidant potentiellement les alignements préalablement établis des techniques de maintenance sont donc nécessaires pour maintenir la validité des mappings dans cet article nous présentons un ensemble dheuristiques guidant leur adaptation notre approche sappuie sur lexplication des mappings existants les informations provenant de lévolution des ontologies ainsi que les adaptations possibles applicables aux mappings nous proposons une validation expérimentale à partir dontologies du domaine médical et des mappings qui leur sont associés\n",
      "identification dauteurs par apprentissage automatique\n",
      "etant donné un ensemble de documents rédigés par un même auteur le problème dauthentification dauteurs consiste à décider si un nouveau texte a été rédigé ou non par cet auteur pour résoudre ce problème nous avons proposé et implémenté différentes approches  comptage de similarité techniques de vote et apprentissage supervisé qui exploitent différents modèles de représentation des documents les expérimentations réalisées à partir des collections de la compétition panclef 2013 et 2014 ont confirmé lintérêt de nos approches et leur performance en termes de temps de traitement\n",
      "identification des utilisateurs atypiques dans les systèmes de recommandation sociale\n",
      "malgré des performances très satisfaisantes lapproche sociale de la recommandation ne fournit pas de bonnes recommandations à un sousensemble des utilisateurs nous supposons ici que certains de ces utilisateurs ont des préférences différentes de celles des autres nous les qualifions datypiques nous nous intéressons à leur identification en amont de la tâche de recommandation et proposons plusieurs mesures représentant latypicité des préférences dun utilisateur lévaluation de ces mesures sur un corpus de létat de lart montre quelles permettent didentifier de façon fiable des utilisateurs recevant de mauvaises recommandations\n",
      "lapport dune approche symbolique pour le repérage des entités nommées en langue amazighe\n",
      "le repérage des entités nommées ren en langue amazighe est un prétraitement éventuellement essentiel pour de nombreuses applications du traitement automatique des langues tal en particulier pour la traduction automatique dans cet article nous présentons une chaîne de repérage des entités nommées en amazighe fondée sur une étude synthétique des spécificités de la langue et des entités nommées en amazighe larticle met laccent sur les choix méthodologiques à résoudre les ambiguïtés dues à la langue en exploitant les technologies existantes pour dautres langues\n",
      "leveragingweb 20 for informed realestate services\n",
      "the perception about real estate properties both for individuals and agents is not formed exclusively by their intrinsic characteristics such as surface and age but also from property externalities such as pollution traffic congestion criminality rates proximity to playgrounds schools and stimulating social interactions that are equally important in this paper we present the realestate 20 system that in contrary to existing realestate eservices and applications takes also into account important externalities by leveraging web 20 content from social networks poi listings applications and open data enables the thorough analysis of the current physical and social context of the property the contextbased objective valuation of re properties along with an advanced property search and selection experience that unveils otherwise “hidden” property features and significantly reduces user effort and time spent in their re quest the system encompasses the above to provide services which assist individuals and agents in making more informed and sound re decisions\n",
      "linked data annotation and fusion driven by data quality evaluation\n",
      "dans cet article nous présentons une approche de fusion de données fondée sur lutilisation dinformations sur la qualité des données pour résoudre les éventuels conflits entre valeurs\n",
      "managing big multidimensional data\n",
      "multidimensional database concepts such as cubes dimensions with hierarchies and measures have been a cornerstone of analytical business intelligence tools for decades however the standard data models and system implementations olap for multidimensional databases cannot handle “big multidimensional data” very large amounts of complex and highly dynamic multidimensional data that occur in a number of emerging domains such as energy transport logistics as well as science this talk will discuss similarities and differences between traditional business intelligence bi and big data present examples of big multidimensional data with the characteristics of large volume high velocity fast data andor high variety complex data and discuss how to manage big multidimensional data including modeling algorithmic implementation as well as practical issues\n",
      "mesure dinfluence via les indicateurs de centralité dans les réseaux sociaux\n",
      "for social network analysis existing centrality measures emphasize the importance of an actor considering only the structural position in the network regardless of a priori information on this actors such as popularity accessibility or behavior in this study new variants of centrality measures are proposed operating both the network structure and the specific attributes of an actor experiments have validated the contribution of valuations especially for the detection of broadcasters in social networks\n",
      "méthode alternative à la détection de « copiercoller »  intersection de textes et construction de séquences maximales communes \n",
      "la détection du plagiat passe le plus souvent par la phase de recherche de similitudes la plus naïve la détection de « copiercoller » dans cet article nous proposons une méthode alternative à lapproche standard de comparaison mot à mot le principe étant deffectuer une intersection des deux textes à comparer récupérant ainsi un tableau des mots quils ont en commun et de ne conserver que les séquences maximales des mots se suivant dans lun des textes et existant également dans lautre nous montrons que cette méthode est plus rapide et moins coûteuse en ressources que les méthodes de parcours de textes habituellement utilisées lobjectif étant de détecter les passages identiques entre deux textes plus rapidement que les méthodes de comparaison mot à mot tout en étant plus efficace que les méthodes ngrammes\n",
      "mining classes by multilabel classification\n",
      "we propose a new approach to mine potential classes in news documents by examining close relationship between new classes and probability vectors of multiple labeling of the documents using em algorithm to obtain the distribution over linear mixture models we make clustering and mine classes\n",
      "modèle de biclustering dans un paradigme mapreduce\n",
      "biclustering is a main task in a variety of areas of machine learning providing simultaneous observations and features clustering biclustering approches are more complex compared to the traditional clustering particularly those requiring large dataset and mapreduce platforms we propose a new approach of biclustering based on popular selforganizing maps for cluster analysis of large dataset we have designed scalable implementations of the new biclustering algorithm using mapreduce with the spark platform we report the experiments and demonstrated the performance public dataset using different cores using practical examples we demonstrate that our algorithm works well in practice the experimental results show scalable performance with near linear speedups across different data and 120 cores\n",
      "nouvelle approche de contextualisation de tweets basée sur les règles dassociation intertermes\n",
      "tweets are short messages that do not exceed 140 characters since they must be written respecting this limitation a particular vocabulary is used to make them understandable to a reader it is therefore necessary to know their context in this paper we describe our approach for the tweet contextualization this approach allows the extension of the tweets vocabulary by a set of thematically related words using mining association rules between terms\n",
      "pour une meilleure exploitation de la classification croisée dans les systèmes de filtrage collaboratif\n",
      "pour la prédiction automatique des items préférés par des utilisateurs sur le web différents systèmes de filtrage collaboratif ont été proposés la plupart dentre eux sont basés sur la factorisation matricielle et les approches de type k plus proches voisins malheureusement ces deux approches requièrent un temps de calcul important une partie de ces problèmes a pu être surmontée par la classification croisée ou coclustering qui savère pertinente du fait quelle permet par nature une gestion simultanée des ensembles correspondant aux utilisateurs et aux items cependant des travaux doivent encore être menés pour une meilleure prise en compte des données manquantes dans ce travail nous proposons donc une gestion efficace des données non observées permettant une meilleure exploitation du potentiel de la classification croisée dans le domaine des systèmes de recommandation nous montrons de plus quelle permet dobtenir des représentations à base de graphes bipartis facilitant linterprétation interactive des affinités entre des groupes dutilisateurs et des groupe ditems\n",
      "proposition doutil de clustering visuel et interactif\n",
      "cet article présente un nouvel outil visuel de clustering interactif il utilise une technique de réduction de dimensionnalité pour permettre une représentation 2d des données et des classes associées initialement établies de manière nonsupervisée loriginalité de loutil consiste à autoriser des modifications itératives à la fois du clustering et de la projection 2d grâce à des contrôles adaptés lutilisateur peut ainsi injecter ses préférences et observer le changement induit en temps réel la méthode de projection utilisée suit une métaphore physique qui facilite le suivi des changements par lutilisateur nous montrons un exemple illustrant lintérêt pratique de loutil\n",
      "qualité et complexité en évaluation des mesures dintérêt\n",
      "remplacer des hypothèses sur le modèle de données par des informations mesurées sur les données réelles est lune des forces de la fouille de données cet article étudie cet ajustement entre les données et les méthodes de découverte de motifs pour en évaluer la qualité et la complexité nous formalisons ce lien entre données et mesures dintérêt en identifiant les motifs liés qui sont ceux nécessaires pour lévaluation dune mesure ou dune contrainte nous formulons alors trois axiomes que devraient satisfaire ces motifs liés pour quune méthode dextraction se comporte bien en outre nous définissons la complexité en évaluation qui quantifie finement linterrelation entre les motifs au sein dune méthode dextraction a la lumière de ces axiomes et de cette complexité en évaluation nous dressons une typologie de multiples méthodes de découverte de motifs impliquant la fréquence\n",
      "rankmerging apprentissage supervisé de classements pour la prédiction de liens dans les grands réseaux sociaux\n",
      "trouver les liens manquants dans un grand réseau social est une tâche difficile car ces réseaux sont peu denses et les liens peuvent correspondre à des environnements structurels variés dans cet article nous décrivons rankmerging une méthode dapprentissage supervisé simple pour combiner linformation obtenue par différentes méthodes de classement afin dillustrer son intérêt nous lappliquons à un réseau dutilisateurs de téléphones portables pour montrer comment un opérateur peut détecter des liens entre les clients de ses concurrents nous montrons que rankmerging surpasse les méthodes à disposition pour prédire un nombre variable de liens dans un grand graphe épars\n",
      "réduction de la complexité spatiale et temporelle du compact prediction tree pour la prédiction de séquences\n",
      "la prédiction de séquences de symboles est une tâche ayant de multiples applications plusieurs modèles de prédiction ont été proposés tels que dg allkorder markov et ppm récemment il a été montré quun nouveau modèle nommé compact prediction tree cpt utilisant une structure en arbre et un algorithme de prédiction plus complexe offre des prédictions plus exactes que plusieurs approches de la littérature néanmoins une limite importante de cpt est sa complexité temporelle et spatiale élevée dans cet article nous pallions ce problème en proposant trois stratégies pour réduire la taille et le temps de prédiction de cpt les résultats expérimentaux sur 7 jeux de données réels montrent que le modèle résultant nommé cpt est jusquà 98 fois plus compact et est 45 fois plus rapide que cpt tout en conservant une exactitude très élevée par rapport à allkorder markov dg lz78 ppm et tdag\n",
      "regroupement dattributs par règles dassociation dans les systèmes dinférence floue\n",
      "dans les systèmes dapprentissage supervisé par construction de règles de classification floues un nombre élevé dattributs descriptifs conduit à une explosion du nombre de règles générées et peut affecter la précision des algorithmes dapprentissage afin de remédier à ce problème une solution est de traiter séparément des sousgroupes dattributs cela permet de décomposer le problème dapprentissage en des sousproblèmes de complexité inférieure et dobtenir des règles plus intelligibles car de taille réduite nous proposons une nouvelle méthode de regroupement des attributs qui se base sur le concept des règles dassociation ces règles découvrent des relations intéressantes entre des intervalles de valeurs des attributs ces liaisons locales sont ensuite agrégées au niveau des attributs mêmes en fonction du nombre de liaisons trouvées et de leur importance notre approche testée sur différentes bases dapprentissage et comparée à lapproche classique permet daméliorer la précision tout en garantissant une réduction du nombre de règles\n",
      "régularisation de noyaux temporellement élastiques et analyse en composantes principales nonlinéaire pour la fouille de séries temporelles \n",
      "dans le domaine de la fouille de séries temporelles plusieurs travaux récents exploitent des noyaux construits à partir de distances élastiques de type dynamic time warping dtw au sein dapproches à base de noyaux pourtant les matrices apparentées aux matrices de gram construites à partir de ces noyaux nont pas toujours les propriétés requises ce qui peut les rendre in fine impropres à une telle exploitation des approches émergeantes de régularisation de noyaux élastiques peuvent être mises à profit pour répondre à cette insuffisance nous présentons lune de ces méthodes kdtw pour le noyau dtw puis autour dune analyse en composantes principales nonlinéaire kpca nous évaluons la capacité de quelques noyaux concurrents élastiques vs non élastiques définis vs non définis à séparer les catégories des données analysées tout en proposant une réduction dimensionnelle importante cette étude montre expérimentalement lintérêt dune régularisation de type kdtw\n",
      "requêtes skyline en présence des données évidentielles\n",
      "dans cet article nous nous intéressons à la recherche des points les plus intéressants au sens de lordre de pareto dans les bases de données évidentielles nous présentons le modèle skyline évidentiel qui est adapté à la nature des données incertaines ensuite nous présentons une évaluation expérimentale de notre approche\n",
      "to initiate a corporate memory with a knowledge compendium ten years of learning from experience with the ardans method\n",
      "ardans method ardanssas 2006b and technology ardanssas 2006a of knowledge capitalization and structuration are used with different industries automotive aerospace energy defence steel health etc for more than a decade in france and europethe proposed solutions in knowledge management and especially in expertise capitalisation have set a lot of feedback over time with a view toward ongoing improvement what are the impacts of these feedbacks on the method nowadays put into practice into the industry the return of investment of a capitalization campaign is inferred from the quality of the knowledge base delivered at the end of the campaign therefore the method and the technology are intrinsically connected how it tools can assist with the quality diagnosis of the knowledge basea comparative study was conducted on the basis of the method mariot et al 2007 exposed at egc2007 this article sets out the results of the changes and improvements of the method in conjunction with the latest technical and scientific development on the one hand and the change of the industry needs on the other hand\n",
      "towards linked data extraction from tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "millions of twitter users post messages every day to communicate with other users in real time information about events that occur in their environment most of the studies on the content of tweets have focused on the detection of emerging topics however to the best of our knowledge no approach has been proposed to create a knowledge base and enrich it automatically with information coming from tweets the solution that we propose is composed of four main phases topic identification tweets classification automatic summarization and creation of an rdf triplestore the proposed approach is implemented in a system covering the entire sequence of processing steps from the collection of tweets written in english language based on both trusted and crowd sources to the creation of an rdf dataset anchored in dbpedias namespace\n",
      "ultrametricity of dissimilarity spaces and its significance for data mining\n",
      "nous introduisons une mesure dultramétricité pour les dissimilaritées et examinons les transformations des dissimilaritées et leurs impact sur cette mesure ensuite nous étudions linfluence de lultramétricité sur la comportement de deux classes dalgorithmes dexploration de données le knn algorithme de classification et lalgorithme de regroupement pam appliqués sur les espaces de dissimilarité on montre quil existe une variation inverse entre ultramétricité et la performance des classificateurs pour les clusters une augmentation dultramétricité genere regroupements avec une meilleure séparation une diminution de la ultramétricité produit groupes plus compacts\n",
      "un algorithme em pour une version parcimonieuse de lanalyse en composantes principales probabiliste\n",
      "nous considérons une version parcimonieuse de lanalyse en composantes principales probabiliste la pénalité 1 imposée sur les composantes principales rend leur interprétation plus aisée en ne faisant dépendre ces dernières que dun nombre restreint de variables initiales un algorithme em simple de mise en oeuvre est proposé pour lestimation des paramètres du modèle la méthode de lheuristique de pente est finalement utilisée pour choisir le coefficient de pénalisation\n",
      "un algorithme icm basé sur la compacité pour la segmentation des images satellites à très haute résolution\n",
      "dans cet article nous proposons une modification pour lalgorithme iterated conditional modes icm appliqué à la segmentation dimages à très haute résolution pour ce faire nous introduisons un nouveau critère de convergence basé sur la compacité des clusters et qui repose sur une fonction dénergie adaptée aux modèles de voisinages irréguliers de ce type dimages grâce à cette méthode nos premières expériences ont montré que nous obtenons des résultats plus fiables en terme de convergence et de meilleure qualité quen utilisant lénergie globale comme critère darrêt\n",
      "un langage dinterrogation à la sparql pour les graphes conceptuels\n",
      "cet article propose un langage générique dinterrogation pour le modèle des graphes conceptuels dabord nous introduisons les graphes dinterrogation un graphe dinterrogation est utilisé pour exprimer un « ou » entre deux sousgraphes ainsi quune « option » sur un sousgraphe optionnel ensuite nous proposons quatre types de requêtes interrogation sélection description et construction en utilisant les graphes dinterrogation enfin les réponses à ces requêtes sont calculées à partir dune opération basée sur lhomomorphisme de graphe\n",
      "une approche centrée graine pour la détection de communautés dans les réseaux multiplexes\n",
      "nous nous intéressons dans ce travail au problème de détection de communautés dans les réseaux multiplexes le modèle de réseau multiplexe a été récemment introduit afin de faciliter la modélisation des réseaux multirelationnels des réseaux dynamiques etou des réseaux attribués les approches existantes pour la détection de communautés dans ce genre de graphes sont pour la plupart basées sur des schémas dagrégation de couches ou dagrégation de partitions nous proposons ici une nouvelle approche centrée graine qui permet de prendre en compte directement la nature multicouche dun réseau multiplexe des expérimentations effectuées sur différents réseaux multiplexes montrent que notre approche surpasse les approches de létat de lart en termes de qualité des communautés identifiées\n",
      "une approche de visualisation analytique pour comparer les modèles de propagation dans les réseaux sociaux\n",
      "les modèles de propagation dinformations dinfluence et dactions dans les réseaux sociaux sont nombreux et diversifiés rendant le choix de celui approprié à une situation donnée potentiellement difficile la sélection dun modèle pertinent pour une situation exige de pouvoir les comparer cette comparaison nest possible quau prix dune traduction des modèles dans un formalisme commun et indépendant de ceuxci nous proposons lutilisation de la réécriture de graphes afin dexprimer les mécanismes de propagation sous la forme dun ensemble de règles de transformation locales appliquées selon une stratégie donnée cette démarche prend tout son sens lorsque les modèles ainsi traduits sont étudiés et simulés à partir dune plateforme de visualisation analytique dédiée à la réécriture de graphe après avoir décrit les modèles et effectué différentes simulations nous exhibons comment la plateforme permet dinteragir avec ces formalismes et comparer interactivement les traces dexécution de chaque modèle grâce à diverses mesures soulignant leurs différences\n",
      "une nouvelle formalisation des changements ontologiques composés et complexes\n",
      "lévolution dune ontologie est un processus indispensable dans son cycle de vie elle est exprimée et définie par des changements ontologiques de différents types  élémentaires composés et complexes les changements complexes et composés sont très utiles dans le sens où ils aident lutilisateur à adapter son ontologie sans se perdre dans les détails des changements élémentaires cependant ils cachent derrière une formalisation sophistiquée puisquils affectent à la fois plusieurs entités ontologiques et peuvent causer des inconsistances à lontologie évoluée pour adresser cette problématique cet article présente une nouvelle formalisation des changements ontologiques composés et complexes basée sur les grammaires de graphes typés cette formalisation sappuie sur lapproche algébrique simple pushout spo de transformation de graphes et possède deux principaux avantages  1 fournir une nouvelle formalisation permettant de contrôler les transformations de graphes et éviter les incohérences dune manière a priori 2 simplifier la définition des changements composés et complexes en réduisant le nombre de changements élémentaires nécessaires à leur application\n",
      "une nouvelle méthode de web usage mining basée sur une analyse sémiotique du comportement de navigation\n",
      "lobjectif de nos travaux est de proposer une méthode danalyse automatique du comportement des utilisateurs à des fins de prédiction de leur propension à réaliser une action suggérée nous proposons dans cet article une nouvelle méthode de web usage mining basée sur une étude sémiotique des styles perceptifs considérant lexpérience de lutilisateur comme élément déterminant de sa réaction à une sollicitation létude de ces styles nous a amené à définir de nouveaux indicateurs des descripteurs sémiotiques introduisant un niveau supplémentaire à lapproche sémantique dannotation des sites nous proposons ensuite un modèle neuronal adapté au traitement de ces nouveaux indicateurs nous expliquerons en quoi le modèle proposé est le plus pertinent pour traiter ces informations\n",
      "une plateforme etl parallèle et distribuée pour lintégration de données massives\n",
      "nous nous intéressons dans ce papier à limpact des données massives dans un environnement décisionnel et plus particulièrement sur la phase dintégration des données dans ce contexte nous avons développé une plateforme baptisée petl paralleletl destinée à lentreposage de données massives selon le paradigme mapreduce petl permet le paramétrage de processus etl workflow et un paramétrage avancé relatif à lenvironnement parallèle et distribué ce papier décrit la plateforme petl en vue dune démonstration face à des jeux de données allant de 244  106 à 7 317  109 tuples les expérimentations menées ont montré lamélioration significative des performances de petl lorsque la taille du cluster et le nombre des tâches parallèles augmentent\n",
      "using social conversational context for detecting users interactions on microblogging sites\n",
      "dans ce travail nous proposons une nouvelle méthode de détection des conversations sur les sites des réseaux sociaux cette méthode est basée sur lanalyse et lenrichissement de contenu dans le but de présenter un résultat informatif basé sur les interactions des utilisateurs nous avons évalué notre méthode sur corpus recueillis de réseau social lié à des sujets spécifiques et nous avons obtenu des bons résultats\n",
      "utilisation des pyramides pour visualiser la contamination des manuscrits\n",
      "in this paper we present a new codicum stemma visualization method don quentins modeling is usec to classify the textual traditionwe supplement the genealogical editors information of betweenness triplets obtained directly from the corpus a pyramid depicting the family codicum stemma is then constructed on the basis of information obtained by the triplets\n",
      "vers la découverte de modèles exceptionnels locaux  des règles descriptives liant les molécules à leurs odeurs\n",
      "issue dun phénomène complexe partant dune molécule odorante jusquà la perception dans le cerveau lolfaction reste le sens le plus difficile à appréhender par les neuroscientifiques lenjeu principal est détablir des règles sur les propriétés physicochimiques des molécules poids nombre datomes etc afin de caractériser spécifiquement un sousensemble de qualités olfactives fruité boisé etc on peut trouver de telles règles descriptives grâce à la découverte de sousgroupes “subgroup discovery” cependant les méthodes existantes permettent de caractériser soit une seule qualité olfactive  soit toutes les qualités olfactives à la fois “exceptional model mining” mais pas un sousensemble nous proposons alors une approche de découverte de sousgroupes caractéristiques de seulement certains labels par une nouvelle technique dénumération issue de la fouille de redescriptions nous avons expérimenté notre méthode sur une base de données dolfaction fournie par des neuroscientifiques et pu exhiber des premiers sousgroupes intelligibles et réalistes\n",
      "visualizing shooting spots using geotagged photographs from social media sites\n",
      "hotspots à laquelle de nombreuses photographies ont été prises pourraient être des lieux intéressants pour beaucoup de gens faire du tourisme visualisation des hotspots révèle les intérêts des utilisateurs ce qui est important pour les industries telles que la recherche et du marketing touristiques bien que plusieurs techniques basées sociauxpour hotspots extraction indépendamment ont été proposés un hotspot a une relation à dautres hotspots dans certains cas pour organiser ces hotspots nous proposons une méthode pour détecter et de visualiser les relations entre les hotspots notre méthode proposée détecte et évalue les relations de taches de tir et sujets photographiques notre approche extrait les relations à laide de soushotspots qui sont fendus dun hotspot qui comprend des photographies de différents types\n",
      "xewgraph  outil de visualisation et analyse des hypergraphes pour un système dintelligence economique\n",
      "the competitive intelligence system xplor everywhere helps searching visualizing and sharing useful data in this paper we will intorduce xplor everywhere and its newest feature called xewgraph which is dedicated to the analysis of massive data and visualization of hypergraphs\n",
      "1dsax  une nouvelle représentation symbolique pour les séries temporelles\n",
      "sax symbolic aggregate approximation est une des techniquesmajeures de symbolisation des séries temporelles la non prise en compte destendances dans la symbolisation est une limitation bien connue de sax cet articleprésente 1dsax une méthode pour représenter une série temporelle parune séquence de symboles contenant des informations sur la moyenne et la tendancedes fenêtres successives de la série segmentée nous comparons lefficacitéde 1dsax vs sax dans une tâche de classification de séries temporellesdimages satellites les résultats montrent que 1dsax améliore les taux de classificationpour une quantité dinformation identique utilisée\n",
      "agrégation de sacdesacsdemots pour la recherche dinformation par modèles vectoriels\n",
      "cet article étudie lintérêt de représenter les documents textuels nonplus comme des sacsdemots mais comme des sacsdesacsdemots au coeurde lutilisation de cette représentation le calcul de similarité entre deux objetsnécessite alors dagréger toutes les similarités entre sacs de chacun des objetsnous évaluons cette représentation dans un cadre de recherche dinformationet étudions les propriétés attendues de ces fonctions dagrégation les expériencesrapportées montrent lintérêt de cette représentation lorsque les opérateursdagrégation respectent certaines propriétés avec des gains très importantspar rapport aux représentations standard\n",
      "alignement dontologies  exploitation des ontologies liées sur le web de données\n",
      "nous proposons dans cet article une méthode dalignement dune ontologiesource avec des ontologies cibles déjà publiées et liées sur le web dedonnées nous présentons ensuite un retour dexpérience sur lalignement duneontologie dans le domaine des sciences du vivant et de lenvironnement avecagrovoc et nalt\n",
      "annotation sémantique de documents administratifs\n",
      "la numérisation de documents administratifs est un enjeu économiqueet écologique prioritaire dans le contexte sociétal actuel la dématérialisationmassive de document nest pas sans conséquence et soulève les problèmes dorganisationde stockage et daccès à linformation le défi nest donc plus la numérisationdu document mais lextraction des informations quils contiennentles documents sont produits par lhomme et pour lhomme cette propriétépermet de localiser des informations dans les zones saillantes du document logosla saillance et la reconnaissance sont deux éléments essentiels pour laclassification rapide de documents a lopposé la recherche dun document oudun ensemble de documents repose presque toujours sur le texte brut il estdonc nécessaire de faire une correspondance entre une requête textuelle et ledocument cet article présente une nouvelle approche dannotation automatiquede documents administratifs qui utilise une approche visuel et une approche defouille de texte\n",
      "application du paradigme mapreduce aux données ouvertes cas  accessibilité des personnes à mobilité réduite aux musées\n",
      "le modèle mapreduce est aujourdhui lun des modèles de programmationparallèle les plus utilisés définissant une architecture maîtreesclaveil permet le traitement parallèle de grandes masses de données dans ce papiernous proposons un algorithme basé sur mapreduce qui permet à partir des donnéespubliques du ministère français de la communication et de la culture dedéfinir un classement des galeries et musées nationaux selon leurs degré daccessibilitéaux personnes handicapées tout en profitant de la puissance et de laflexibilité du paradigme mapreduce les décideurs pourront mettre en place desstratégies efficaces à moindre coût et avoir ainsi une vision plus précise sur lesétablissements culturels et leurs limites relatives à cette catégorie de personneslalgorithme que nous proposons peut être exploité et appliqué à dautres casdétudes avec des jeux de données plus volumineux\n",
      "apprentissage de fonctions de tri pour la prédiction dinteractions protéinearn\n",
      "les fonctions biologiques dans la cellule mettent en jeu des interactions3d entre protéines et arn les avancées des techniques exérimentalesrestent insuffisantes pour de nombreuse applications il faut alors pouvoir prédirein silico les interactions protéinearn dans ce contexte nos travaux sontfocalisés sur la construction de fonctions de score permettant dordonner les solutionsgénérées par le programme damarrage protéinearn rosettadock laméthodologie dévaluation utilisée par rosettadock impose de trouver une fonctionde score sexprimant comme une combinaison linéaire de mesures physicochimiquesavec une approche dapprentissage supervisé par algorithme génétiquenous avons appris différentes fonctions de score en imposant descontraintes sur la nature des poids recherchés les résultats obtenus montrentlimportance de la signification des poids à apprendre et de lespace de rechercheassocié\n",
      "apprentissage incrémental anytime dun classifieur bayésien naïf pondéré\n",
      "nous considérons le problème de classification supervisée pour desflux de données présentant éventuellement un très grand nombre de variablesexplicatives le classifieur bayésien naïf se révèle alors simple à calculer etrelativement performant tant que lhypothèse restrictive dindépendance des variablesconditionnellement à la classe est respectée la sélection de variables etle moyennage de modèles sont deux voies connues damélioration qui reviennentà déployer un prédicteur bayésien naïf intégrant une pondération des variablesexplicatives dans cet article nous nous intéressons à lestimation directe duntel modèle bayésien naïf pondéré nous proposons une régularisation parcimonieusede la logvraisemblance du modèle prenant en compte linformativité dechaque variable la logvraisemblance régularisée obtenue étant non convexenous proposons un algorithme de gradient en ligne qui postoptimise la solutionobtenue afin de déjouer les minima locaux les expérimentations menéessintéressent dune part à la qualité de loptimisation obtenue et dautre part auxperformances du classifieur en fonction du paramétrage de la régularisation\n",
      "apprentissage non supervisé de dépendances syntaxiques à partir de texte étiqueté plusieurs variantes de pcfg légères\n",
      "lapprentissage de dépendances est une tâche consistant à établir àpartir des phrases dun texte un modèle de construction darbres traduisant unehiérarchie syntaxique entre les mots nous proposons un modèle intermédiaireentre lanalyse syntaxique complète de la phrase et les sacs de mots il est basésur une grammaire stochastique horscontexte se traduisant par des relations dedépendance entre les catégories grammaticales dune phrase les résultats expérimentauxobtenus sur des benchmarks attestés dépassent pour cinq langues surdix les scores de lalgorithme de référence dmv et pour la première fois desscores sont obtenus pour le français la très grande simplicité de la grammairepermet un apprentissage très rapide et une analyse presque instantanée\n",
      "approche formelle de fusion dontologies à laide des grammaires de graphes typés\n",
      "larticle propose une approche formelle de fusion dontologies se reposantsur les grammaires de graphes typés elle se décompose en trois étapes 1 la recherche de similarités entre concepts  2 la fusion des ontologies parlapproche algébrique spo simple push out  3 ladaptation dune ontologieglobale par le biais de règles de réécriture de graphes contrairement aux solutionsexistantes cette méthode offre une représentation formelle de la fusiondontologies ainsi quune implémentation fonctionnelle basée sur loutil agg\n",
      "approche par motifs pour lanalyse de données multirésolution\n",
      "dans cet article nous nous intéressons aux approches pour lanalysede graphes pouvant évoluer dans le temps et tel quun sommet à un temps donnépeut correspondre à plusieurs sommets au temps suivant et où les sommets sontassociés à un ensemble dattributs catégoriels dans ce type de données nousproposons une nouvelle classe de motifs basée sur des contraintes permettant dedécrire lévolution de structures homogènes ce type dapproche est particulièrementadaptée pour lanalyse dimages multirésolution sans perte dinformationnous présentons un résultat qualitatif dans ce domaine\n",
      "automatic correction of svm for drifted data classification\n",
      "concept drift is an important feature of realworld data streams thatcan make usual machine learning techniques rapidly become unsuitable thispaper addresses the problem of sudden concept drift in classification problemsfor which standard techniques may fail to this end support vector machinessvms are automatically corrected to cope with a new suddenly drifted datasetresults on realworld datasets with several types of sudden drift indicate that themethod is able to correct the svm in order to better classify the new data afterthe concept drift using a correction based on the difference between the initialdataset and the new drifted dataset even when the new dataset is small\n",
      "broad data what happens when the web of data becomes real\n",
      "“big data” is used to refer to the very large datasets generated by scientists to the manypetabytes of data held by companies like facebook and google and to analyzing realtime dataassets like the stream of twitter messages emerging from events around the world key areasof interest include technologies to manage much larger datasets cf nosql technologies for the visualization and analysis of databases cloudbased data management and dataminingalgorithmsrecently however we have begun to see the emergence of another and equally compellingdata challenge – that of the “broad data” that emerges from millions and millions of rawdatasets available on the world wide web for broad data the new challenges that emerge includewebscale data search and discovery rapid and potentially ad hoc integration of datasetsvisualization and analysis of onlypartially modeled datasets and issues relating to the policiesfor data use reuse and combination in this talk we present the broad data challenge anddiscuss potential starting points for solutions we illustrate these approaches using data froma “metacatalog” of over 1000000 open datasets that have been collected from about twohundred governments from around the world\n",
      "classification des actions humaines basée sur les descripteurs spatiotemporels\n",
      "dans cet article nous proposons un nouveau descripteurspatiotemporel appelé stsurf pour lanalyse et la reconnaissance dactionsdans des flux vidéo lidée principale est denrichir le descripteur speed uprobust feature surf en intégrant linformation de mouvement issue du flotoptique seuls les points dintérêts qui ont subi un déplacement sont pris encompte pour générer un dictionnaire de mots visuels dmv robuste basé surlalgorithme des kmoyennes kmeans le dictionnaire est utilisé lors du processusdapprentissage et de reconnaissance dactions basé sur la méthode desmachines à vecteurs supports svm les résultats obtenus confirment lintérêtdu descripteur proposé stsurf pour lanalyse de scènes et en particulierpour la reconnaissance dactions la méthode atteind une précision de reconnaissancede lordre de 807 équivalente aux performances des descripteursspatiotemporels de létat de lart\n",
      "classification et prédiction du flux solaire\n",
      "la prédiction du rayonnement solaire horaire dans une journée estun enjeu primordial pour la production dénergie de type photovoltaïque nousprésentons deux stratégies de classification des jours selon leurs rayonnementssolaires puis une méthode de prédiction du flux solaire cohérente avec la classification\n",
      "classifieur naïf de bayes pondéré pour flux de données\n",
      "un classifieur naïf de bayes est un classifieur probabiliste basé surlapplication du théorème de bayes avec lhypothèse naïve cestàdire que lesvariables explicatives xi sont supposées indépendantes conditionnellement àla variable cible c malgré cette hypothèse forte ce classifieur sest avéré trèsefficace sur de nombreuses applications réelles et est souvent utilisé sur les fluxde données pour la classification supervisée le classifieur naïf de bayes nécessitesimplement en entrée lestimation des probabilités conditionnelles parvariable pxic et les probabilités a priori pc pour une utilisation sur lesflux de données cette estimation peut être fournie à laide dun « résumé superviséenligne de quantiles » létat de lart montre que le classifieur naïf de bayespeut être amélioré en utilisant une méthode de sélection ou de pondération desvariables explicatives la plupart de ces méthodes ne peuvent fonctionner quehorsligne car elles nécessitent de stocker toutes les données en mémoire etoude lire plus dune fois chaque exemple par conséquent elles ne peuvent être utiliséessur les flux de données cet article présente une nouvelle méthode baséesur un modèle graphique qui calcule les poids des variables dentrée en utilisantune estimation stochastique la méthode est incrémentale et produit un classifieurnaïf de bayes pondéré pour flux de données cette méthode est comparéeau classique classifieur naïf de bayes sur les données utilisées lors du challenge« large scale learning »\n",
      "clustering de données relationnelles pour la structuration de flux télévisuels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les approches existantes pour structurer automatiquement un flux detélévision ie reconstituer un guide de programme exact et complet sont superviséeselles requièrent de grandes quantités de données annotées manuellementet aussi de définir a priori les types démissions publicités bandes annoncesprogrammes sponsors pour éviter ces deux contraintes nous proposonsune classification non supervisée la nature multirelationnelle de nosdonnées proscrit lutilisation des techniques de clustering habituelles reposantsur des représentations sous forme attributsvaleurs nous proposons et validonsexpérimentalement une technique de clustering capable de manipuler ces donnéesen détournant la programmation logique inductive pli pour fonctionnerdans ce cadre non supervisé\n",
      "clustering de séquences dévènements temporels\n",
      "nous proposons une nouvelle méthode de clustering et danalyse deséquences temporelles basée sur les modèles en grille à trois dimensions lesséquences sont partitionnées en clusters la dimension temporelle est discrétiséeen intervalles et la dimension évènement est partitionnée en groupes la grille decellules 3d forme ainsi un estimateur nonparamétrique constant par morceauxde densité jointe des séquences et des dimensions des évènements temporelsles séquences dun cluster sont ainsi groupés car elles suivent une distributionsimilaire dévènements au cours du temps nous proposons aussi une méthodedexploitation du clustering par simplification de la grille ainsi que des indicateurspermettant dinterpréter les clusters et de caractériser les séquences quiles composent les expériences sur des données artificielles ainsi que sur desdonnées réelles issues de dblp démontrent le bienfondé de notre approche\n",
      "clusters dans les réseaux sociaux  intersections entre liens conceptuels fréquents et communautés\n",
      "la recherche de liens conceptuels fréquents fcl est une nouvelleapproche de clustering de réseaux qui exploite à la fois la structure et les attributsdes noeuds bien que les travaux récents se soient déjà intéressés à loptimisationdes algorithmes de recherche des fcl peu de travaux sont aujourdhuimenés sur la complémentarité qui existe entre les liens conceptuels et lapprocheclassique de clustering qui consiste en lextraction de communautés ainsi dansce papier nous nous intéressons à ces deux approches notre objectif est dévaluerles relations potentiellement existantes entre les communautés et les fclpour comprendre la façon dont les motifs obtenus par chacune des méthodespeuvent correspondre ou sintersecter ainsi que la connaissance utile résultantde la prise en compte de ces deux types de connaissance nous proposons pourcela un ensemble de mesures originales basées sur la notion dhomogénéité visantà évaluer le niveau dintersection des fcl et des communautés lorsquilssont extraits dun même jeu de données notre approche est appliquée à deuxréseaux et démontre limportance de considérer simultanément plusieurs typesde connaissance et leur intersection\n",
      "comment devenir cybercondriaque \n",
      "nous avons tous déjà eu loccasion deffectuer des recherches dordremédical sur internet si certains sites spécialisés se refusent à tout diagnosticen ligne préférant le renvoi vers des professionnels de santé dautres en revancheconduisent souvent à des déclarations alarmistes faisant état de situationshumaines difficiles dans ce travail nous étudions lampleur de ce phénomèneet montrons que quel que soit le syndrome recherché les résultats obtenusconduisent toujours à lénoncé des mots cancer ou tumeur\n",
      "comparaison de bornes théoriques pour laccélération du clustering incrémental en une passe\n",
      "le clustering incrémental en une passe repose sur laffectation efficacede chaque nouveau point aux clusters existants dans le cas général où lesclusters ne peuvent être représentés par une moyenne la détermination exhaustivedu cluster le plus proche possède une complexité quadratique avec le nombrede données nous proposons dans ce papier une nouvelle méthode daffectationstochastique à chaque cluster qui minimise le nombre de comparaisons à effectuerentre la donnée et chaque cluster pour garantir étant donné un taux derreuracceptable laffectation au cluster le plus proche plusieurs bornes théoriquesbernstein hoeffding et student sont comparées dans ce papier les résultatssur des données artificielles et réelles montrent que la borne de bernstein donneglobalement les meilleurs résultats notamment lorsquelle est réduite car ellepermet une accélération forte du processus de clustering tout en conservant unnombre très faible derreurs\n",
      "comparaison des chemins de hilbert adaptatif et des graphes de voisinage pour la caractérisation dun parcellaire agricole\n",
      "cet article compare deux représentations de données spatiales lesgraphes de voisinages et les chemins de hilbertpeano utilisées par des algorithmesde fouille cette comparaison sappuie sur la mise en oeuvre dune méthodedénumération de « sacs de noeuds » qui permet dobtenir des caractérisationshomogènes à partir des deux représentations la méthode est appliquée àla caractérisation de parcellaires agricoles et les résultats tendent à montrer quela linéarisation de lespace capte la majorité de linformation à lexception deséléments rares sur cet exemple particulier\n",
      "compréhension de recettes de cuisine utilisateurs par extraction de connaissances intrinsèques\n",
      "sur les sites web communautaires les utilisateurs échangent des connaissancesen étant à la fois auteurs et lecteurs nous présentons une méthodepour construire notre propre compréhension de la sémantique de la communautésans recours à une base de connaissances externe nous effectuons une extractionde la connaissance présente dans les contributions analysées nous proposonsune évaluation de la confiance imputable à cette compréhension déduiteafin dévaluer la qualité du contenu avec application à un site web de partagede recettes de cuisine\n",
      "construction de cube olap à partir dun entrepôt de données orienté colonnes\n",
      "loptimisation de la construction de cubes olap 1 a été jusquà présentaxée sur le développement dalgorithmes de calcul performants ces derniersopèrent sur des données extraites de lentrepôt de données qui est généralementimplémenté selon le modèle relationnel qui adopte larchitecture orientéelignes or pour les requêtes décisionnelles larchitecture orientée colonnes offrede meilleures performances cependant les sgbdr 2 selon cette architecture nedisposent pas dopérateurs appropriés pour le calcul de cube olap nous proposonsdans cet article une nouvelle méthode de calcul de cube olap les résultatsobtenus à partir des expérimentations que nous avons menées démontrentque notre approche optimise considérablement le temps de construction de cubeolap et réduit le temps de réponse relatif à lexploitation du cube comparé àlapproche orientée lignes\n",
      "construction de profils de préférences contextuelles basée sur lextraction de motifs séquentiels\n",
      "lutilisation de préférences suscite un intérêt croissant pour personnaliserdes réponses et effectuer des recommandations en amont létape essentielleest lélicitation des préférences qui consiste à construire un profil depréférences en sollicitant le moins possible lutilisateur dans cet article nousprésentons une méthode basée sur lextraction de motifs séquentiels afin de générerdes règles de préférences contextuelles à partir dune base de paires detransactions à partir de ces règles générées qui ont une expressivité plus richeque celle des approches existantes nous montrons comment construire et utiliserun profil modélisant les préférences de lutilisateur de plus notre approchea lavantage de bénéficier des nombreux algorithmes efficaces dextraction deséquences fréquentes lévaluation de notre méthode sur des données réellesmontre que les modèles de préférences construits permettent deffectuer des recommandationsjustes à un utilisateur\n",
      "de lombre à la lumière  plus de visibilité sur leclipse\n",
      "lextraction de connaissances à partir de données issues du génie logicielest un domaine qui sest beaucoup développé ces dix dernières années avecnotamment la fouille de référentiels logiciels mining software repositories etlapplication de méthodes statistiques partitionnement détection doutliers àdes thématiques du processus de développement logiciel cet article présente ladémarche de fouille de données mise en oeuvre dans le cadre de polarsys ungroupe de travail de la fondation eclipse de la définition des exigences à la propositiondun modèle de qualité dédié et à son implémentation sur un prototypeles principaux concepts adoptés et les leçons tirées sont également passés enrevue\n",
      "de nouvelles pondérations adaptées à la classification de petits volumes de données textuelles\n",
      "un des défis actuels dans le domaine de la classification supervisée dedocuments est de pouvoir produire un modèle fiable à partir dun faible volumede données avec un volume conséquent de données les classifieurs fournissentdes résultats satisfaisants mais les performances sont dégradées lorsque celuicidiminue nous proposons dans cet article de nouvelles méthodes de pondérationsrésistant à une diminution du volume de données leur efficacité évaluéeen utilisant des algorithmes de classification supervisés existants naive bayeset classfeaturecentroid sur deux corpus différents est supérieure à celle desautres algorithmes lorsque le nombre de descripteurs diminue nous avons étudiéen parallèle les paramètres influençant les différentes approches telles que lenombre de classes de documents ou de descripteurs\n",
      "des humanités au numérique  interdisciplinarité et réciprocité\n",
      "les humanités numériques aussi contestable et critiquable que soit le terme font maintenantpartie du paysage de la recherche en sciences humaines institutionnalisées par la trèsgrande infrastructure de recherche humanum du cnrs elles sont généralement définiescomme la convergence de disciplines autour dun matériau numérique matériau inévitablementaccompagné dun outillage tout aussi numérique ce matériau suivant la discipline quilobserve pourra être considéré comme un objet éditorial un objet analysable ou un objetcalculable nous tenterons de montrer que ce matériau peut aussi être perçu voire construitcomme un dépôt voire un entrepôt de connaissances notre présentation sappuiera sur diversprojets de recherche en humanités numériques auxquels nous contribuons afin de mettre enexergue le lien qui peut être fait entre extraction et gestion de connaissances dune part ethumanités numériques dautre part  le premier peut trouver un terrain expérimental dans lesecond tandis que le second peut tirer profit des méthodes et outils développés par le premiernous égrainerons par ailleurs dautres problématiques inhérentes aux humanités numériques de la constitution à lanalyse du corpus en passant par la formalisation et la normalisationdes données enfin nous tenterons de montrer par lexemple que les questions posées par leshumanités numériques ne sont pas sans rappeler celles des industries de la connaissance\n",
      "détection dopinions dans des tweets\n",
      "twitter est à lheure actuelle un des réseau sociaux les plus utilisé aumonde et analyser les opinions qui y sont contenues permet de fournir de précieusesinformations notamment aux entreprises commerciales dans cet articlenous décrivons une méthode permettant de déterminer lopinion dun tweet endétectant dans un premier temps sa subjectivité puis sa polarité\n",
      "détection de changements dans des flots de données qualitatives\n",
      "pour mieux analyser et extraire de la connaissance de flots de donnéesdes approches spécifiques ont été proposées ces dernières années lun deschallenges auquel elles doivent faire face est la détection de changement dansles données alors que de plus en plus de données qualitatives sont généréespeu de travaux de recherche se sont intéressés à la détection de changement dansce contexte et les travaux existants se sont principalement focalisés sur la qualitédun modèle appris plutôt quau réel changement dans les données danscet article nous proposons une nouvelle méthode de détection de changementnon supervisée appelée cdcstream change detection in categorical datastreams adaptée aux flux de données qualitatives\n",
      "détection de situations à risque basée sur des détecteurs de mouvement à domicile pour les personnes dépendantes\n",
      "avec le vieillissement de la population dans les décennies à venir laprise en charge de la dépendance est devenu un enjeu majeur les nouvellestechnologies permettent daméliorer le confort et la sécurité des personnes dépendantesà domicile dans cet article nous proposons une méthode de détectionde situations à risques basée sur le seuillage automatique des intervalles dinactivitédes capteurs de mouvement de type infrarouge passif notre contributionconsiste à apprendre de façon automatique la durée maximale dinactivité parpièce et par plage horaire la méthode est évaluée sur des données réelles provenantde lactivité dune personne réelle dans un appartement équipé de capteursdomotiques notre approche permet de réduire le temps dappel des secours\n",
      "du texte à la base de données géographiques\n",
      "avec la prolifération des données géographiques il y a un fort besoinde concevoir des outils automatiques pour lexploitation des connaissances géographiquesincarnées dans les documents textuels cest dans ce contexte quenous proposons une approche permettant de générer une base de données géographiquesbdg à partir de textes notre approche sarticule autour de deuxgrandes phases  la génération du schéma de la bdg et la détermination desdonnées qui serviront au remplissage de cette base limplémentation de notreapproche a donné naissance à un outil que nous avons baptisé gdb generatoret que nous avons intégré dans le sig  openjump\n",
      "dynamique des communautés par prédiction dinteractions dans les réseaux sociaux\n",
      "dans cet article nous proposons une approche générale de prédictiondes communautés basée sur un modèle dapprentissage automatique pour la prédictiondes interactions en effet nous pensons que si on peut prédire avec précisionla structure du réseau alors on a juste à rechercher les communautés surle réseau prédit des expérimentations sur des jeux de données réels montrent lafaisabilité de cette approche\n",
      "evaluation de la pertinence dans un système de recommandation sémantique de nouvelles économiques\n",
      "de nos jours dans les secteurs commerciaux et financiers la veille estcruciale et complexe car la charge dinformations est importante pour répondreà cette problématique nous proposons un système novateur de recommandationdarticles basé sur une modélisation ontologique des connaissances nous présentonségalement une nouvelle méthode dévaluation de la pertinence utilisantle modèle vectoriel intrinsèquement efficace et adapté afin de pallier la confusionnative de ces modèles entre les notions de similarité et de pertinence\n",
      "exploration dune collection de chansons à partir dune interface de visualisation basée sur une analyse des paroles\n",
      "dans cet article nous présentons une approche de fouille de textesainsi quune interface de visualisation afin dexplorer une large collection dechansons frana¸ises à partir des paroles dans un premier temps nous collectonsparoles et métadonnées de différentes sources sur leweb nous utilisons une approchecombinant clustering et analyse sémantique latente afin didentifier différentesthématiques et de déterminer différents descripteurs significatifs noustransformons par la suite le modèle afin dobtenir une visualisation interactivepermettant dexplorer la collection de chansons\n",
      "extension de létiquetage géographique des pixels dune image par fouille de données\n",
      "les techniques de classification modernes permettent détiqueter leszones non couvertes des bases de données cartographiques mais souffrent dunmanque de robustesse important dans cet article nous proposons une méthoderobuste dextension détiquetage sur lemprise dune image satellite par analysehiérarchique des données existantes notre approche est fondée sur une sélectiondattributs par thème de la base de données une sélection des pixels dapprentissageet des classifications par objet de chaque thème la décision finaledétiquetage est prise après fusion des classifications par thème notre méthodeest appliquée avec succès et comparée à plusieurs méthodes de classificationcouplant données doccupation du sol et imagerie spatiale très haute résolution\n",
      "extraction de motifs dans des graphes orientés attribués en présence dautomorphisme\n",
      "les graphes orientés attribués sont des graphes orientés dans lesquelsles noeuds sont associés à un ensemble dattributs de nombreuses données issuesdu monde réel peuvent être représentées par ce type de structure maisencore peu dalgorithmes sont capables de les traiter directement la fouille desgraphes attribués est difficile car elle nécessite de combiner lexploration de lastructure du graphe avec lidentification ditemsets fréquents de plus du fait delexplosion combinatoire des itemsets les isomorphismes de sousgraphes dontla présence impacte énormément les performances des algorithmes de fouillesont beaucoup plus nombreux que dans les graphes étiquetésdans cet article nous présentons une nouvelle méthode de fouille de donnéesqui permet dextraire des motifs fréquents à partir dun ou de plusieurs graphesorientés attribués nous montrons comment réduire lexplosion combinatoireprovoquée par les isomorphismes de sousgraphes en traitant de manière particulièreles motifs automorphes\n",
      "extraction de règles dépisodes minimales dans des séquences complexes\n",
      "les messages déposés quotidiennement sur les réseaux sociaux et lesblogs sont très nombreux et constituent une source dinformations précieuseleur fouille peut être utilisée dans un but de prédiction dinformations notreobjectif dans cet article est de proposer un algorithme permettant la prédictiondinformations au plus tôt et de façon fiable par le biais de lidentification derègles dépisodes\n",
      "extraire les motifs minimaux efficacement et en profondeur\n",
      "les représentations condensées ont fait lobjet de nombreux travauxdepuis 15 ans tandis que les motifs maximaux des classes déquivalence ontreçu beaucoup dattention les motifs minimaux sont restés dans lombre notammentà cause de la difficulté de leur extraction dans ce papier nous présentonsun cadre générique concernant lextraction de motifs minimaux en introduisantla notion de système minimisable densembles il permet de considérer des langagesvariés comme les motifs ensemblistes ou les chaînes de caractères maisaussi différentes métriques dont la fréquence ensuite pour nimporte quel systèmeminimisable densembles nous introduisons un test de minimalité rapidepermettant dextraire en profondeur les motifs minimaux nous démontrons quelalgorithme proposé est polynomialdelay et polynomialspace des expérimentationssur les benchmarks traditionnels complètent notre étude\n",
      "fouille de données par programmation visuelle structurée avec kdariane\n",
      "nous présentons ici la plateforme kdariane un déploiement doutilspour la fouille de données dans lenvironnement de programmation visuelleariane ce déploiement facilite la conception de chaînes structurées de traitementspour lextraction de connaissance dans les données\n",
      "fouille de motifs séquentiels pour lélicitation de stratégies à partir de traces dinteractions entre agents en compétition\n",
      "pour atteindre un but tout agent en compétition élabore inévitablementdes stratégies lorsque lon dispose dune certaine quantité de traces dinteractionsentre agents il est naturel dutiliser la fouille de motifs séquentielspour découvrir de manière automatique ces stratégies dans cet article nous proposonsune méthodologie qui permet lélicitation de stratégies et leur capacité àdiscriminer une réussite ou un échec la méthodologie sarticule en trois étapes i les traces brutes sont transformées en une base de séquences selon des choixqui permettent ii lextraction de stratégies fréquentes iii lesquelles sont muniesdune mesure originale démergence cest donc une méthodologie de découvertede connaissances que nous proposons nous montrons lintérêt des motifsextraits et la faisabilité de lapproche à travers des expérimentations quantitativeset qualitatives sur des données réelles issues du domaine émergent dusport électronique\n",
      "généralisation des kmoyennes pour produire des recouvrements ajustables\n",
      "la recherche de groupes nondisjoints à partir de données nonétiquetéesest une problématique importante en classification nonsupervisée laclassification recouvrante overlapping clustering contribue à la résolution deplusieurs problèmes réels qui nécessitent la détermination de groupes qui se chevauchentcependant bien que les recouvrements entre groupes soient tolérésvoire encouragés dans ces applications il convient de contrôler leur importancenous proposons dans ce papier des généralisations de kmoyennes offrant lecontrôle et le paramétrage des recouvrements deux principes de régulation sontmis en place ils visent à contrôler les recouvrements relativement à leur tailleet à la dispersion des classes les expérimentations réalisées sur des jeux dedonnées réelles montrent lintérêt des principes proposés\n",
      "génération dun extrait textuel à partir de bases de données\n",
      "dans ce papier nous présentons une approche dédiée à la transformationdune base de données en un extrait textuel lidée sousjacente à notreproposition est dapporter plus de sémantique aux données de la base cet objectifest atteint moyennant lutilisation des ontologies comme ressources sémantiquesnotre approche prend comme input un ensemble de bases de donnéeset associe à chacune une ontologie une ontologie globale est générée à partirde laquelle des règles dassociation sont proposées pour mieux expliciter sasémantique enfin la génération dun extrait textuel prend lieu\n",
      "granularité des motifs de covariations dans des graphes attribués dynamiques\n",
      "découvrir des connaissances dans des graphes qui sont dynamiqueset dont les sommets sont attribués est de plus en plus étudié par exemple dansle contexte de lanalyse dinteractions sociales il est souvent possible dexpliciterdes hiérarchies sur les attributs permettant de formaliser des connaissancesa priori sur les descriptions des sommets nous proposons détendre destechniques de fouille sous contraintes récemment proposées pour lanalyse degraphes attribués dynamiques lorsque lon exploite de telles hiérarchies et doncle potentiel de généralisationspécialisation quelles permettent nous décrivonsun algorithme qui calcule des motifs de coévolution multiniveaux cestàdiredes ensembles de sommets qui satisfont une contrainte topologique et qui évoluentde la même façon selon un ensemble de tendances et de pas de temps nosexpérimentations montrent que lutilisation dune hiérarchie permet dextrairedes collections de motifs plus concises sans perdre dinformation\n",
      "identification de classes nondisjointes ayants des densités différentes\n",
      "la classification recouvrante correspond à un enjeu important en classificationnonsupervisée en permettant à une observation dappartenir à plusieursclusters plusieurs méthodes ont été proposées pour faire face à cetteproblématique en utilisant plusieurs approches usuelles de classification cependantmalgré lefficacité de ces méthodes à déterminer des groupes nondisjointselles échouent lorsque les données comportent des groupes de densités différentescar elles ignorent la densité locale de chaque groupe et ne considèrentque la distance euclidienne entres les observations afin de détecter des groupesnondisjoints de densités différentes nous proposons deux méthodes de classificationintégrant la variation de densité des différentes classes dans le processusde classification des expériences réalisées sur des ensembles de données artificiellesmontrent que les méthodes proposées permettent dobtenir de meilleuresperformances lorsque les données contiennent des groupes de densités différentes\n",
      "identification de rôles communautaires dans des réseaux orientés appliquée à twitter\n",
      "la notion de structure de communautés est particulièrement utile pourétudier les réseaux complexes car elle amène un niveau danalyse intermédiairepar opposition aux plus classiques niveaux local voisinage des noeuds et globalréseau entier le concept de rôle communautaire permet de décrire le positionnementdun noeud en fonction de sa connectivité communautaire cependantles approches existantes sont restreintes aux réseaux nonorientés utilisentdes mesures topologiques ne considérant pas tous les aspects de la connectivitécommunautaire et des méthodes didentification des rôles nongénéralisables àtous les réseaux nous proposons de résoudre ces problèmes en généralisant lesmesures existantes et en utilisant une méthode nonsupervisée pour déterminerles rôles nous illustrons lintérêt de notre méthode en lappliquant au réseaude twitter nous montrons que nos modifications mettent en évidence les rôlesspécifiques dutilisateurs particuliers du réseau nommés capitalistes sociaux\n",
      "incremental learning with latent factor models for attribute prediction in socialattribute networks\n",
      "dans ce travail nous nous intéressons au problème de la prédiction dattributs sur lesnoeuds dans un réseau social la plupart des techniques sont hors ligne et ne sont pas adaptéesà des situations où les données arrivent massivement en flux comme dans le cas des médiassociaux dans ce travail nous utilisons les modèles de variables latentes pour prédire les attributsinconnus des noeuds dans un réseau social et proposer une méthode pour mettre à jourincrémentalement le modèle avec des nouvelles données des expérimentations sur un jeu dedonnées issues des médias sociaux montrent que notre méthode est moins coûteuse en tempsde calcul et peut garantir des performances acceptables en comparaison avec les techniquesnonincrémentales de létat de lart\n",
      "intégration de plusieurs formes de représentations spatiales dans un modèle de simulation\n",
      "in this paper we focus on modeling expert knowledge for simulating complex landscapespatial dynamics one modeling tool to do that is the ocelet modeling language that usesinteraction graphs to describe spatial dynamics most present approaches impose an a priorichoice of spatial format between i a vector format representing the shapes of the entities orii a gridding of space into regular elements raster in this paper we show how ocelet wasextended to support the interaction semantics between these two spatial formats vector andraster as case study we present a runoff model in a tropical insular environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intégration et visualisation de données liées thématiques sur un référentiel géographique\n",
      "de nombreuses ressources publiées sur le web des données sont décritespar une composante qui désigne dune manière directe ou indirecte unelocalisation géographique comme toute autre propriété cette information delocalisation peut être mise à profit pour permettre linterconnexion des donnéesavec dautres sources elle permet en outre leur représentation cartographiquecependant les informations de localisation utilisées dans les sources de donnéeslinked data peuvent parfois savérer imprécises ou hétérogènes dune source àlautre ceci rend donc leur exploitation pour réaliser une interconnexion difficilevoire impossible dans cet article nous proposons de pallier ces difficultésen ancrant les données linked data thématiques aux objets dun référentielgéographique nous mettons à profit le référentiel géographique afin de mettreen correspondance des données thématiques dotées dindications de localisationhétérogènes nous exploitons enfin les relations de correspondance créées entredonnées thématiques et référentiel géographique dans une application de visualisationcartographique des données\n",
      "investigation visuelle dévénements dans un grand flot de liens\n",
      "nous présentons une nouvelle méthode danalyse exploratoirede grands flots de liens que nous appliquons à la détection dévénementssignificatifs dans plus de 2 millions dinteractions pendant 4 mois entreutilisateurs du réseau social en ligne github nous combinons une méthodestatistique de détection automatique dévénements dans une série temporelleoutskewer avec un système de visualisation de graphes outskewer identifiedes instants de lévolution du graphe dinteractions méritant dêtre étudiés etun analyste peut valider et interpréter ces événements par la visualisation demotifs anormaux dans les sousgraphes correspondants nous montrons par demultiples exemples que cette approche 1 permet de détecter des événementspertinents et de rejeter ceux qui ne le sont pas 2 est adaptée à une démarcheexploratoire car elle ne nécessite pas de connaissance a priori sur les données\n",
      "lutilisation des entités nommées pour lexpansion sémantique des requêtes web\n",
      "les entités nommées sont des éléments intéressants pour les applicationsfondées sur le traitement du langage naturel dans le cas de la recherchedinformation les entités nommées sont largement employées par les utilisateursdu web dans les requêtes de recherche soit pour définir un concept debase soit pour décrire un autre concept dans la requête du côté du modèlede recherche les entités nommées sont des éléments riches en information quiaident à mieux cibler les documents pertinents dans cet article nous étudionslavantage détendre les entités nommées dans la requête lidée est dutiliserune technique dexpansion sémantique sur une ontologie générale yago pourdésambiguïser les entités nommées et pour trouver leurs différentes appellationsque lon intègre dans la requête en utilisant 3 approches  sac de mots dépendanceséquentielle et concept clé nous mesurons lefficacité de ces expériencesen termes de précision et rappel et nous étudions leffet du rôle des entités nomméessur lexpansion nous concluons que lexpansion des entités nommées estune méthode simple qui améliore significativement la qualité de la recherchequand elle est comparée à un modèle de référence sans expansion de plus cetteméthode est assez compétitive par rapport à lapproche pseudo retour de pertinencesouvent utilisée pour lexpansion de la requête\n",
      "la subjectivité dans le discours médical  sur les traces de lincertitude et des émotions\n",
      "les acteurs et usagers du domaine médical médecins infirmiers patientsinternes pharmaciens etc ne sont pas issus de la même catégorie socioprofessionnelleet ne présentent pas le même niveau de maîtrise du domaineleurs écrits en témoignent et véhiculent de plus la subjectivité qui leur estpropre nous nous intéressons à létude automatisée de la subjectivité dans lediscours médical dans des textes en langue française nous confrontons le discoursdes médecins articles scientifiques rapports cliniques à celui des patientsmessages de forums de santé en analysant contrastivement les différencesdemploi des descripteurs tels que les marqueurs dincertitude et de polaritéles marques émotives non lexicales smileys ponctuations répétées etcet lexicales et les termes médicaux relatifs aux pathologies traitements et procéduresnous effectuons une annotation et catégorisation automatiques des documentsafin de mieux observer les spécificités que présentent les discours médicauxciblés\n",
      "les nouvelles théories de lincertain\n",
      "la notion dincertitude a été longtemps un sujet de controverses en particulier la prééminencede la théorie des probabilités dans les sciences tend à gommer les différences présentesdans les premières tentatives de formalisation remontant au 17ème siècle entre lincertitudedue à la variabilité des phénomènes répétables et lincertitude due au manque dinformationdite épistémique lécole bayésienne affirme que quelle que soit lorigine de lincertitudecelleci peut être modélisée par une distribution de probabilité unique cette affirmation a étébeaucoup remise en cause dans les trente dernières années en effet lemploi systématiquedune distribution unique en cas dinformation partielle mène à des utilisations paradoxales dela théorie des probabilitésdans de nombreux domaines il est crucial de distinguer entre lincertitude due à la variabilitédobservations et lincertitude due à lignorance partielle cette dernière peut être réduitepar lobtention de nouvelles informations mais pas la première dont on ne se prémunit quepar des actions concrètes dans le cas des bases de données il est souvent supposé quellessont précises et lincertitude correspondante est souvent négligée quant elle est abordée onreste souvent dans une approche probabiliste orthodoxenéanmoins les statisticiens ont développé des outils qui ne relèvent pas de la théorie dekolmogorov pour pallier le manque de données intervalles de confiance principe de maximumde vraisemblancede nouvelles théories de lincertain ont émergé qui offrent la possibilité de représenter lesincertitudes épistémiques et aléatoires de façon distincte notamment lincertitude épistémiqueen remplaçant la distribution de probabilité unique par une famille de distributions possiblescette famille étant dautant plus grande que linformation est absente cette représentationcomplexe possède des cas particuliers plus simples à utiliser en pratique comme les ensemblesaléatoires théorie des fonctions de croyance les distributions de possibilité représentant desensembles flous de valeurs possibles et les pboxes notammentle but de cet exposé est de susciter lintérêt pour ces nouvelles théories de lincertainden donner les bases formelles den discuter la philosophie sousjacente de faire le lien aveccertaines notions en statistique et de les illustrer sur des exemples\n",
      "localgenerator  diviser pour régner pour lextraction des traverses minimales dun hypergraphe\n",
      "du fait quelles apportent des solutions dans de nombreuses applicationsles traverses minimales des hypergraphes ne cessent de susciter lintérêt dela communauté scientifique et le développement dalgorithmes pour les calculerdans cet article nous présentons une nouvelle approche pour loptimisation delextraction des traverses minimales basée sur les notions dhypergraphe partielet de traverses minimales locales selon une stratégie diviser pour régner nousintroduisons aussi un nouvel algorithme appelé localgenerator pour lecalcul des traverses minimales les expérimentations effectuées sur divers jeuxde données ont montré lintérêt de notre approche notamment sur les hypergraphesayant un nombre de transversalité élevé et renfermant un nombre trèsimportant de traverses minimales\n",
      "méthodologie 3way dextraction dun modèle articulatoire de la parole à partir des données dun locuteur\n",
      "pour parler le locuteur met en mouvement un ensemble complexedarticulateurs  la mâchoire quil ouvre plus ou moins la langue à laquelle ilfait prendre de nombreuses formes et positions les lèvres qui lui permettent delaisser lair séchapper plus ou moins brutalement etc le modèle articulatoirele plus connu est celui de maeda 1990 obtenu à partir danalyses en composantesprincipales faites sur les tableaux de coordonnées des points des articulateursdun locuteur en train de parler nous proposons ici une analyse 3way dumême type de données après leur transformation en tableaux de distances nousvalidons notre modèle par la prédiction des sons prononcés qui savère presqueaussi bonne que celle du modèle acoustique et même meilleure quand on prenden compte la coarticulation\n",
      "mining the crowd\n",
      "harnessing a crowd of web users for data collection has recently become a widespreadphenomenon a key challenge is that the human knowledge forms an open world and it is thusdifficult to know what kind of information we should be looking for classic databases haveaddressed this problem by data mining techniques that identify interesting data patterns thesetechniques however are not suitable for the crowd this is mainly due to properties of thehuman memory such as the tendency to remember simple trends and summaries rather thanexact details following these observations we develop here a novel model for crowd miningwe will consider in the talk the logical algorithmic and methodological foundations neededfor such a mining process as well as the applications that can benefit from the knowledgemined from crowd\n",
      "modélisation de trajectoires ciblecaméra  requêtes spatiotemporelles dans le cadre de la videosurveillance\n",
      "le nombre de caméras de vidéosurveillance installées dans le monde augmente chaquejour en france le système de la ratp déployé sur paris comprend 9000 caméras fixes et19000 mobiles lors de faits particuliers eg agressions vols les opérateurs de vidéo surveillancese basent sur les indications spatiales et temporelles de la victime et sur leur connaissancede la localisation des caméras pour sélectionner les contenus intéressants pour lenquêtedeux grands problèmes peuvent alors survenir  1 le temps de réponse est long jusquà plusieursjours de traitement et 2 un risque important de perte de résultats à cause dune mauvaiseconnaissance du terrain appel à des opérateurs extérieurs le but de notre recherche estde définir des outils dassistance aux opérateurs qui puissent à partir dune trajectoire donnéesélectionner de façon automatique les caméras pertinentes par rapport à la requête\n",
      "motifs récursifs  extraction ascendante hiérarchique densembles ditems ou dévènements pour le résumé de données transactionnelles ou séquentielles\n",
      "nous proposons une méthode originale pour extraire un résumé compactreprésentatif et intelligible des motifs fréquents dans des données transactionnellesou séquentielles notre approche consiste à extraire un nouveau typede motifs que nous appelons motifs récursifs ie des motifs de motifs à laidedun algorithme hiérarchique agglomératif nommé repaminer nous généronsnon pas un simple ensemble de motifs mais une véritable structure dérivée dedendrogrammes le rpgraph\n",
      "passage aux noyaux en classification recouvrante\n",
      "la classification recouvrante correspond à un domaine détude très actifces dernières années et dont lobjectif est dorganiser un ensemble de donnéesen groupes dindividus similaires avec la particularité dautoriser des chevauchementsentre les groupes parmi les approches étudiées nous nous intéressonsaux extensions recouvrantes des modèles de type moindres carrés et constatonsles difficultés théoriques et pratiques liées à leur adaptation aux noyaux nousformulons alors une nouvelle définition ensembliste pour caractériser un recouvrementde plusieurs classes nous montrons que cette modélisation permet lerecours aux noyaux et nous proposons une solution algorithmique efficace pourrépondre au problème de la classification recouvrante à noyaux\n",
      "pondération de blocs de variables en bipartitionnement topologique\n",
      "dans cet article nous proposons une nouvelle approche permettantà la fois le bipartitionnement topologique biclustering et la pondération deblocs variables le modèle que nous proposons fbrbitm feature block relevanceusing bitm permet de découvrir un espace topologique dun ensembledobservations et de variables en associant un nouveau score de pondération àchaque sous ensemble de variables lestimation des coefficients de pondérationest réalisée dans le même processus dapprentissage que le bipartitionnementces pondérations sont locales et associées à chaque prototype elles reflètentlimportance locale de chaque bloc de variables pour le bipartitionnement lévaluationmontre que lapproche proposée comparée\n",
      "prédiction de valeurs manquantes dans les bases de données— une première approche fondée sur la notion de proportion analogique\n",
      "cet article présente une méthode originale de prédiction de valeursmanquantes dans les bases de données relationnelles fondée sur la notion deproportion analogique nous montrons en particulier comment un algorithmeproposé dans le cadre de la classification automatique peut être adapté à cette findeux cas sont considérés  celui dune base de données transactionnelle attributsbooléens et celui où les valeurs manquantes peuvent être de type numérique\n",
      "que ressentent les patients \n",
      "les forums de santé en ligne sont des espaces déchanges où les patientspartagent leurs sentiments à propos de leurs maladies traitements etcsous couvert danonymat ils expriment très librement leurs expériences personnellesces forums sont donc une source dinformations très utile pour les professionnelsde santé afin de mieux identifier et comprendre les problèmes lescomportements et les sentiments de leurs patients dans cet article nous proposonsdexploiter les messages des forums via des techniques de fouille de textespour extraire des traces démotions eg joie colère surprise  etc\n",
      "réconciliation des profils dans les réseaux sociaux\n",
      "it is not uncommon that individuals create multiple profiles across several snss eachcontaining partially overlapping sets of personal information as a result the creation of aglobal profile that gives an holistic view of the information of an individual requires methodsthat automatically match or reconciliates profiles across snss in this paper we focus on theproblem of identifying or matching the profiles of any individual across social networks\n",
      "reconstruction et analyse sémantique de chronologies cybercriminelles\n",
      "la reconstruction de chronologies dévènements cybercriminels oureconstruction dévènements est une étape primordiale dans une investigationnumérique cette phase permet aux enquêteurs davoir une vue des évènementssurvenus durant un incident la reconstruction dévènements requiert létudedimportants volumes de données en raison de lomniprésence des nouvellestechnologies dans notre quotidien de plus les conclusions produites se doiventde respecter les critères fixés par la justice afin de répondre à ces challengesnous proposons une nouvelle méthodologie basée sur une ontologie permettantdassister les enquêteurs tout au long du processus denquête\n",
      "règles dassociation interlangues au service de la recherche dinformation multilingue\n",
      "dans cet article nous proposons de montrer lintérêt et lutilité de déploiementdes règles dassociation interlangues rails dans le domaine de larecherche dinformation multilingue rim ces règles sont des connaissancesadditionnelles résultantes dun processus de fouille de grands corpus parallèlesalignés au niveau de la phrase en effet leurs conclusions exprimées dans unelangue cible représentent des traductions potentielles de leurs prémisses expriméesdans une langue source nous illus trons lutilisation des rails dans lecontexte de la rim à travers deux propositions à savoir  i la traduction desrequêtes et ii la traduction des termes de lindex lévaluation expérimentale aété menée sur la collection de documents muchmore les résultats ont montréune amélioration significative de la pertinence système\n",
      "representative training sets for classification and the variability of empirical distributions\n",
      "we propose a novel approach for the estimation of the size of trainingsets that are needed for constructing valid models in machine learning and datamining we aim to provide a good representation of the underlying populationwithout making any distributional assumptionsour technique is based on the computation of the standard deviation of the \u001f2statistics of a series of samples when successive statistics are relatively closewe assume that the samples produced represent adequately the true underlyingdistribution of the population and the models learned from these samples willbehave almost as well as models learned on the entire populationwe validate our results by experiments involving classifiers of various levels ofcomplexity and learning capabilities\n",
      "requêtes skyline en présence dexceptions\n",
      "dans cet article nous nous intéressons à la recherche des points lesplus intéressants au sens de lordre de pareto ie à lévaluation de requêtes« skyline »  dans des jeux de données présentant des anomalies il nest pas rareque les données de petites annonces par exemple soient peuplées derreurs oudexceptions qui peuvent perturber la recherche des meilleurs points car cellescisont susceptibles de dominer les autres points lapproche présentée vise àcalculer les requêtes skyline malgré la présence de ces exceptions sans pourautant les écarter définitivement et à présenter graphiquement les résultats defaçon à identifier rapidement les points dintérêt et les anomalies potentielles\n",
      "sélection dune méthode de classification multilabel pour un système interactif\n",
      "lobjectif de cet article est dévaluer la capacité de 12 algorithmesde classification multilabel à apprendre en peu de temps avec peu dexemplesdapprentissage les résultats expérimentaux montrent des différences importantesentre les méthodes analysées pour les 3 mesures dévaluation choisieslogloss rankingloss et temps dapprentissageprédiction et les meilleursrésultats sont obtenus avec multilabel k nearest neighbours mlknn suivide ensemble de classifier chains ecc et ensemble de binary relevance ebr\n",
      "sélection de prototypes en vue dune catégorisation de textes avec les k plus proches voisins  étude comparative\n",
      "la technique des k plus proches voisins knn est une méthodedapprentissage à base dinstances elle a été appliquée dans la catégorisationde textes depuis de nombreuses années en contraste avec ses performances declassification il est reconnu que cet algorithme est lent pendant la classificationdun nouveau document les techniques de sélection de prototypes sont apparuescomme des méthodes très compétitives pour améliorer le knn grâce à laréduction des données létude contenue dans ce papier a pour objectif danalyserlimpact de ces méthodes sur la performance de la classification de textesavec lalgorithme knn\n",
      "sous échantillonnage et machine à noyaux élastiques pour la classification de données de mouvement capturé\n",
      "dans le domaine de la reconnaissance de gestes isolés bon nombrede travaux se sont intéressés à la réduction de dimension sur laxe spatial pourréduire à la fois la complexité algorithmique et la variabilité des réalisationsgestuelles il est assez étonnant de constater que peu de ces méthodes se sontexplicitement penchées sur la réduction de dimension sur laxe temporel enmatière de complexité la réduction de dimension sur cet axe est un enjeu majeurquant à lutilisabilité de distances élastiques en complexité quadratique parailleurs la prise en compte de la variabilité sur cet axe demeure une source avéréede gain de performance pour tenter dapporter un éclairage en matière deréduction de dimension sur laxe temporel nous présentons dans cet article uneapproche basée sur un sous échantillonnage temporel associé à lexploitationdun apprentissage automatique à base de noyaux élastiques nous montronsexpérimentalement sur deux jeux de données très référencés dans la communautéet très opposés en matière de qualité de capture de mouvement quil estpossible de réduire sensiblement le nombre de postures sur les trajectoires temporellestout en conservant grâce à des noyaux élastiques des performances dereconnaissance au niveau de létat de lart du domaine le gain de complexitéobtenu rend une telle approche éligible pour des applications tempsréel\n",
      "stratégies argumentatives pour la classification collaborative multicritères des connaissances cruciales\n",
      "dans cet article nous proposons une approche argumentative visant àautomatiser la résolution des conflits entre les décideurs qui ont des préférencescontradictoires lors dune classification multicritères collaborative des connaissancescruciales notre étude expérimentale a prouvé que cette approche peutrésoudre jusquà 81 des conflits et améliorer la qualité dapproximation dedécideurs dun taux de 062 pour un récepteur et de 015 pour un initiateur\n",
      "symétries et extraction de motifs ensemblistes\n",
      "les symétries sont des propriétés structurelles quon détecte dans ungrand nombre de bases de données dans cet article nous étudions lexploitationdes symétries pour élaguer lespace de recherche dans les problèmes dextractionde motifs ensemblistes notre approche est basée sur une intégrationdynamique des symétries dans les algorithmes de type apriori permettant de réduirelespace des motifs candidats en effet pour un motif donné les symétriesnous permettent de déduire les motifs qui lui sont symétriques et vérifiant parconséquent les mêmes propriétés nous détaillons notre approche en utilisantlexemple des motifs fréquents ensuite nous la généralisons au cadre unificateurde mannila et toivonen pour lextraction des motifs ensemblistes les expériencesmenées montrent la faisabilité et lapport de notre approche délagagebasé sur les symétries\n",
      "the hitchhikers guide to ontology\n",
      "artificial intelligence has long had the dream of making computers smarter for quite sometime this vision has remained just that a dream with the development of large knowledgebases though we now have large amounts of semantic information at our hands this changesthe game of ai computers have indeed become smarter in this talk we present the latestdevelopments in the field the construction of general purpose knowledge bases includingyago and dbpedia as well as nell and textrunner and their applications to tasks thatwere previously out of scope the extraction of finegrained information from natural languagetexts semantic query answering and the interpretation of newspaper texts at large scale\n",
      "un système de détection de thématiques populaires sur twitter\n",
      "with the evergrowing amount of messages exchanged via twitter there is an increasinginterest in filtering this information which is delivered under the form of a stream of messagesin this paper we present a system for detecting popular topics in twitter the system can beapplied to static corpora and can also handle the live twitter stream\n",
      "une approche algébrique au problème du consensus de partitions\n",
      "en classification nonsupervisée le consensus de partitions a pour objectifde produire une partition unique représentant le consensus à partir dunensemble de partitions où chacune est engendrée indépendamment des autresvoire avec des méthodologies différentes en complément des techniques ayantleur qualité propre en terme de robustesse ou de passage à léchelle nous apportonsun point de vue original sur le consensus de partitions cestàdire par lebiais de définitions algébriques qui permettent détablir la nature des déductionspouvant être réalisées dans une approche systématique pex un système à basede connaissances nous fondons notre approche sur le treillis des partitions pourlequel nous montrons comment peuvent être adjoint des opérateurs dans le butde formuler une expression caractérisant le consensus à partir dun ensemble departitions\n",
      "une approche basée sur statis pour la fusion de cartes topologiques autoorganisées\n",
      "dans le cadre des cartes topologiques nous proposons une nouvelleapproche densemble clusters basée sur la méthode statis les méthodes densembleclusters visent à améliorer la qualité de la partition dun jeu de donnéesà travers la combinaison de plusieurs partitionsles différentes partitions peuvent être obtenues en faisant varier les paramètresdun algorithme choix des centres initiaux du voisinage initial et final des cellulesdans le cas des cartes topologiques autoorganisée som etc lapprocheprésentée dans cette communication repose sur la méthode danalyse de donnéesmultitableaux statis pour déterminer une matrice compromis représentant aumieux la similarité entre les partitions issues des cartes topologiques la fusiondes cartes topologiques est alors obtenue à travers une classification basée surcette matrice compromis la méthode proposée est illustrée sur des donnéesréelles issues de luci et sur des données simulées\n",
      "une approche ppc pour la fouille de données séquentielles\n",
      "nous proposons dans cet article une nouvelle approche croisant destechniques de programmation par contraintes et de fouille pour lextraction demotifs séquentiels le modèle que nous proposons offre un cadre générique etdéclaratif pour modéliser et résoudre des contraintes de nature hétérogène\n",
      "une approcheweb sémantique et combinatoire pour un système de recommandation sensible au contexte appliqué à lapprentissage mobile\n",
      "au vu de lémergence rapide des nouvelles technologies mobiles et lacroissance des offres et besoins dune société en mouvement les travaux se multiplientpour identifier de nouvelles plateformes dapprentissage pertinentes afindaméliorer et faciliter lapprentissage à distance la prochaine étape de lapprentissageà distance est naturellement le port de lelearning apprentissageélectronique vers les nouveaux systèmes mobiles on parle de mlearning apprentissagemobile nos travaux portent sur le développement dune nouvellearchitecture pour le mlearning dont lobjectif est dadapter et recommander desparcours de formations selon les contraintes contextuelles de lapprenant\n",
      "une heuristique pour le paramétrage automatique de lalgorithme de clustering spectral\n",
      "trouver le nombre optimal de groupes dans le contexte dun algorithmede clustering est un problème notoirement difficile dans cet articlenous en décrivons et évaluons une solution approchée dans le cas de lalgorithmespectral notre méthode présente lavantage dêtre déterministe et peucoûteuse nous montrons quelle fonctionne de manière satisfaisante dans beaucoupde cas même si quelques limites amènent des perspectives à ce travail\n",
      "une méthode hybride pour la prédiction du profil des auteurs\n",
      "dans cet article nous nous intéressons à la détection du profil desauteurs âge genre à travers leurs discussions la méthode proposée sappuiesur la classification automatique qui utilise certaines données extraites dune manièrestatistique à partir de corpus source nous présentons une méthode hybridequi combine lanalyse de surface dans les textes avec une méthode dapprentissageautomatique a fin dobtenir une meilleure gestion de ces données nousnous sommes basés sur lutilisation des arbres de décision notre méthode adonné des résultats intéressants pour la détection du genre\n",
      "une méthode pour caractériser les communautés des réseaux dynamiques à attributs\n",
      "de nombreux systèmes complexes sont étudiés via lanalyse de réseauxdits complexes ayant des propriétés topologiques typiques parmi cellesciles structures de communautés sont particulièrement étudiées de nombreusesméthodes permettent de les détecter y compris dans des réseaux contenant desattributs nodaux des liens orientés ou évoluant dans le temps la détection prendla forme dune partition de lensemble des noeuds quil faut ensuite caractériserrelativement au système modélisé nous travaillons sur lassistance à cettetâche de caractérisation nous proposons une représentation des réseaux sous laforme de séquences de descripteurs de noeuds qui combinent les informationstemporelles les mesures topologiques et les valeurs des attributs nodaux lescommunautés sont caractérisées au moyen des motifs séquentiels émergents lesplus représentatifs issus de leurs noeuds ceci permet notamment la détectionde comportements inhabituels au sein dune communauté nous décrivons uneétude empirique sur un réseau de collaboration scientifique\n",
      "une méthode pour la détection de thématiques populaires sur twitter\n",
      "lexplosion du volume de messages échangés via twitter entraîne unphénomène de surcharge informationnelle pour ses utilisateurs il est donc crucialde doter ces derniers de moyens les aidant à filtrer linformation brute laquelleest délivrée sous la forme dun flux de messages dans cette optique nousproposons une méthode basée sur la modélisation de lanomalie dans la fréquencede création de liens dynamiques entre utilisateurs pour détecter les picsde popularité et extraire une liste ordonnée de thématiques populaires les expérimentationsmenées sur des données réelles montrent que la méthode proposéeest capable didentifier et localiser efficacement les thématiques populaires\n",
      "une nouvelle approche pour la sélection de variables basée sur une métrique destimation de la qualité\n",
      "la maximisation détiquetage fmax est une métrique non biaiséedestimation de la qualité dune classification non supervisée clustering qui favoriseles clusters ayant une valeur maximale de fmesure détiquetage danscet article nous montrons quune adaptation de cette métrique dans le cadrede la classification supervisée permet de réaliser une sélection de variables etde calculer pour chacune delles une fonction de contraste la méthode est expérimentéesur différents types de données textuelles dans ce contexte nousmontrons que cette technique améliore les performances des méthodes de classificationde façon très significative par rapport à létat de lart des techniquesde sélection de variables notamment dans le cas de la classification de donnéestextuelles déséquilibrées fortement multidimensionnelles et bruitées\n",
      "utilisation de relations ontologiques pour la comparaison dimages décrites par des annotations sémantiques\n",
      "face à la complexité des nouvelles générations dimages médicales les processus de recherche dimages basés sur leurs contenus visuels peuvent savérer insuffisants cet article propose une nouvelle approche basée sur lannotation des images via des termes sémantiques pouvant pallier ce problème elle repose sur la combinaison dune distance hiérarchique permettant de comparer les images en considérant les corrélations entre les termes utilisés pour les décrire et dune mesure de similarité permettant dévaluer la proximité sémantique entre des termes ontologiques cette approche est validée dans le cadre de la recherche dimages tomodensitométriques\n",
      "vectorisation paramétrée des données textuelles\n",
      "automatic processing of textual data enables users to analyze semiautomatically and on alarge scale the data this analysis is based on two successive processes i representation oftexts ii gathering of textual data clustering the software described in this paper focuses onthe first step of the process by offering expert a parameterized representation of textual data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vers une classification non supervisée adaptée pour obtenir des arbres de décision simplifiés\n",
      "linduction darbre de décision est une technique puissante et populairepour extraire de la connaissance néanmoins les arbres de décision obtenusdepuis des données issues du monde réel peuvent être très complexes et donc difficilesà exploiter dans ce cadre cet article présente une solution originale pouradapter le résultat dune classification non supervisée quelconque afin dobtenirdes arbres de décision simplifiés pour chaque cluster\n",
      "vers une modularité pour données vectorielles\n",
      "la modularité introduite par newman pour mesurer la qualité dunepartition des sommets dun graphe ne prend pas en compte déventuelles valeursassociées à ces sommets dans cet article nous introduisons une mesure de modularitécomplémentaire basée sur linertie et adaptée pour évaluer la qualitédune partition déléments représentés dans un espace vectoriel réel cette mesurese veut un pendant pour la classification non supervisée de la modularitéde newman nous présentons également 2modlouvain une méthode utilisantce critère de modularité basée sur linertie conjointement à la modularité denewman pour détecter des communautés dans des réseaux dinformation lesexpérimentations que nous avons menées ont montré quen exploitant à la foisles données relationnelles et vectorielles 2modlouvain détectait plus efficacementles communautés que des méthodes utilisant un seul type de données etquelle était robuste face à des dégradations des données\n",
      "visualisation de données de prosopographie pour la reconstruction de carrières de personnages et de réseaux socioprofessionnels\n",
      "dans cet article nous présentons deux approches de visualisation développéesdans le cadre dun projet collaboratif sur laccès et lexploitation desdonnées prosopographiques de la renaissance en france lobjectif du projetest de modéliser et réaliser un portail sémantique assurant laccès à différentesbases de données prosopographiques existantes afin de permettre une meilleureexploration et exploitation de ces données dans ce cadre nous avons proposédeux interfaces de visualisation prosograph et prosomap qui sappuient respectivementsur la visualisation de graphes de réseaux sociaux et la visualisationde lieux géographiques et de trajectoires spatiotemporelles les deux interfacescommuniquent avec le portail via une couche sémantique et lui offrent des fonctionnalitésdinterrogation supplémentaires\n",
      "20 ans de découverte de motifs  une étude bibliographique quantitative\n",
      "depuis deux décennies la découverte de motifs a été lun des champs de recherche les plus actifs de lexploration de données cet article en établit une étude bibliographique quantitative en nous appuyant sur 1030 publications issues de 5 conférences internationales majeures  kdd pkdd pakdd icdm et sdm nous avons dabord mesuré depuis 2005 un sévère ralentissement de lactivité de recherche dédiée à la découverte de motifs puis nous avons quantifié les principales contributions en terme de langages de contraintes et de représentations condensées de sorte à comprendre ce ralentissement et à esquisser les directions actuelles\n",
      "3d  de nouvelles perspectives en fouille exploratoire avec la stéréoscopie\n",
      "si la 3d est un sujet de débat dans la communauté les expériences sur lesquelles sappuient les discussions concernent le plus souvent des restitutions visuelles basées sur une projection classique en perspective linéaire lobjectif de cette communication est de renouveler le cadre expérimental en étudiant limpact de lajout de la disparité binoculaire nous nous focalisons ici sur une tâche importante en analyse de réseaux  lidentification de communautés et nous comparons la 3d monoscopique et la 3d stéréoscopique à la fois pour la performance de résolution de la tâche et pour le comportement exploratoire à travers lanalyse du mouvement du pointeur de la souris et de la dynamique des modifications de points de vue sur les graphes nos résultats expérimentaux mettent en évidence des performances significativement meilleures pour la 3d stéréoscopique et des différences comportementales dans lexploration avec un centrage plus important sur des zones restreintes en stéréoscopie\n",
      "a pos tagger analysed in collaboration environments and literary texts\n",
      "partofspeech pos tagging is often used in other modules of natural language processing and therefore the results of this process should be as precise as possible many different types of taggers have been developed to improve the accuracy of the results in the field of literature or newspapers nowadays when the internet is widespread the environments for online collaboration as chats forums blogs wikis have become important means of communication the purpose of this research is to analyse the results of tagging the words obtained from the labelling of the words from the online collaboration environments and literary texts with the corresponding parts of speech in the case of pos tagging the ambiguities arise due to the fact that a word may have multiple morphological values depending on context\n",
      "accélération de la méthode des k plus proches voisins pour la catégorisation de textes\n",
      "parmi la panoplie de classificateurs utilisés dans la catégorisation de textes nous nous intéressons à lalgorithme des kvoisins les plus proches ces performances le situent parmi les meilleures méthodes de catégorisation de textes toutefois il présente certaines limites i coût mémoire car il faut stocker lensemble dapprentissage en entier et ii coût élevé de calcul car il doit explorer lensemble dapprentissage pour classer un nouveau document dans ce papier nous proposons une nouvelle démarche pour réduire ce temps de classification sans dégrader les performances de classification\n",
      "analyse conceptuelle de données de simulation de systèmes complexes pour laide à la décision  application à la conception dune cabine davion\n",
      "dans cet article nous présentons une approche conceptuelle daide à la décision dans la conception de systèmes complexes cette approche sappuie sur le formalisme de lanalyse de concepts formels par similarité acfs pour la classification la visualisation et lexploration de données de simulation afin daider les concepteurs de systèmes complexes à identifier les choix de conception les plus pertinents lapproche est illustrée sur un cas test de conception de cabine dun avion de ligne fourni par les partenaires industriels et qui consiste à étudier les données de simulation de différentes configurations du système de ventilation de la cabine afin didentifier celles qui assurent un confort convenable pour les passagers la cabine la classification des données de simulation avec leurs scores de confort en utilisant lacfs permet didentifier pour chaque paramètre de conception simulé la plage de valeurs possibles qui assure un confort convenable pour les passagers les résultats obtenus ont été confirmés et validés par de nouvelles simulations\n",
      "analyse de réseaux sociaux par lanalyse formelle de concepts\n",
      "lanalyse formelle de concepts afc est un formalisme de représentation et dextraction de connaissance fondé sur les notions de concepts et de treillis de concepts galoislafc a été exploitée avec succès dans plusieurs domaines en informatique tels le génie logiciel les bases et entrepôts de données lextraction et la gestion de la connaissance et dans plusieurs applications du monde réel comme la médecine la psychologie la linguistique et la sociologiedans cette présentation nous allons explorer le potentiel de lafc et de quelques extensions de cette théorie ex analyse triadique de concepts dans lanalyse de réseaux sociaux en vue de découvrir des connaissances à partir de réseaux homogènes simples ex détection de communautés et dindividus influents à partir dun réseau damis ou même de réseaux hétérogènes ex extraction de règles dassociation dun réseau bibliographique\n",
      "analyse des réclamations dallocataires de la caf  un cas détude en fouille de données\n",
      "la gestion des réclamations est un élément fondamental dans la relation client cest le cas en particulier pour la caisse nationale des allocations familiales qui veut mettre en place une politique nationale pour faciliter cette gestion dans cet article nous décrivons la démarche que nous avons adoptée afin de traiter automatiquement les réclamations provenant dallocataires de la caf du rhône les données brutes mises à notre disposition nécessitent une série importante de prétraitements pour les rendre utilisables une fois ces données correctement nettoyées des techniques issues de lanalyse des données et de lapprentissage non supervisé nous permettent dextraire à la fois une typologie des réclamations basée sur leur contenu textuel mais aussi une typologie des allocataires réclamants après avoir présenté ces deux typologies nous les mettons en correspondance afin de voir comment les allocataires se distribuent selon les différents types de réclamation\n",
      "analyse relationnelle de concepts pour lexploration de données relationnelles\n",
      "lanalyse relationnelle de concepts arc est une extension de lanalyse formelle de concepts afc une méthode de classification non supervisée dobjets sous forme de treillis de concepts larc supporte en plus la gestion de relations entre objets de différents contextes ce qui permet détablir des liens entre les concepts des différents treillis cette particularité lui permet dêtre plus intuitive à utiliser pour extraire des connaissances à partir de données relationnelles et de donner des résultats plus riches malheureusement lorsque les jeux de données présentent de nombreuses relations les résultats obtenus sont difficilement exploitables et des problèmes de passages à léchelle se posent nous proposons dans cet article une adaptation possible de larc pour explorer les relations de manière supervisée pour augmenter la pertinence des résultats obtenus et réduire le temps de calcul nous prenons pour exemple des données hydrobiologiques ayant trait à la qualité des milieux aquatiques\n",
      "approche orientée objet sémantique et coopérative pour la classification des images de zones urbaines à très haute résolution\n",
      "la classification orientée objet coo prend de plus en plus de dimension dans les travaux de télédétection grâce à sa capacité dintégrer des connaissances de haut niveau telles que la taille la forme et les informations de voisinage cependant les approches existantes restent tributaires de létape de construction des objets à cause de labsence dinteraction entre celleci et celle de leur identification dans cet article nous proposons une approche sémantique hiérarchique et collaborative entre les algorithmes de croissances de régions et une classification orientée objet supervisée permettant une coopération entre lextraction et lidentification des objets de limage les expériences menées sur une image de très haute résolution de la région de strasbourg ont confirmé lintérêt de lapproche introduite\n",
      "classification multiétiquettes pour lalignement multiple de séquences protéiques\n",
      "cet article présente une application de classification multiétiquettes permettant de déterminer le programme à utiliser pour construire un alignement multiple dun ensemble de séquences protéiques donné dans un premier temps nous avons réussi à améliorer le système existant alexsys en ajoutant des attributs dans un second temps nous déterminons pour un ensemble de séquences protéiques donné le ou les aligneurs capable de produire les alignements de meilleur score à epsilon près les mesures de performances propres à la classification multiétiquette nous permettent danalyser linfluence de epsilon et de choisir une valeur assez petite pour distinguer les meilleurs aligneurs des autres\n",
      "classifications croisées de données de trajectoires contraintes par un réseau routier\n",
      "le clustering ou classification non supervisée de trajectoires a fait lobjet dun nombre considérable de travaux de recherche la majorité de ces travaux sest intéressée au cas où les objets mobiles engendrant ces trajectoires se déplacent librement dans un espace euclidien et ne prennent pas en compte les contraintes liées à la structure sousjacente du réseau quils parcourent ex réseau routier dans le présent article nous proposons au contraire la prise en compte explicite de ces contraintes nous représenterons les relations entre trajectoires et segments routiers par un graphe biparti et nous étudierons la classification de ses sommets nous illustrerons sur un jeu de données synthétiques lutilité dune telle étude pour comprendre la dynamique du mouvement dans le réseau routier et analyser le comportement des véhicules qui lempruntent\n",
      "comprendre et interpréter les données  enjeux et implantations dun système de codage dans des gisements de données historiques\n",
      "laccès croissant à une information pléthorique et le développement de gisements de données ambitieux posent aujourdhui deux grands types de difficultés aux historiensle premier consiste à mettre en relation des gisements qui ont été développés de manière indépendante cest par exemple le cas pour lintégration dun ensemble de bases de données prosopographiques développées entre 1980 et 2010 au lamop ou même dans le cadre dun projet dont le seul lien est une problématique spatiale et temporelle projet anrdfg euroscientiale deuxième tient en la nature des données introduites dans ces différents systèmes  elles sont souvent hétérogènes ambiguës floues pour que le chercheur puisse se les approprier les données doivent faire lobjet dun véritable travail afin de comprendre comment elles ont été obtenues structurées lhistorien doit donc les évaluer et les valider sil souhaite les mettre en relation cette évaluation nécessitant ellemême de pouvoir être commentée partagée et critiquée par dautres chercheursdans les deux cas il est nécessaire de développer des outils dappropriation qui permettent dentrer dans le réel historique contenu dans les stocks de données cest là la fonction du projet histobase un système permettant dentrer dans la structuration des gisements den évaluer linformation dajouter des couches dinterprétation qualification de linformation historique de les évaluer et de partager les données « obtenues » chacune des analyses individuelles et collectives fait lobjet dune mémorisation il faut pour cela laisser une place importante aux historiens en tant quexpert en prêtant une attention particulière aux processus métiers quils mettent en oeuvre\n",
      "construction de descripteurs à partir du coclustering pour la classification supervisée de séries temporelles\n",
      "nous présentons un processus de construction de descripteurs pour la classification supervisée de séries temporelles ce processus est libre de tout paramétrage utilisateur et se décompose en trois étapes  i à partir des données originales nous générons de multiples nouvelles représentations simples  ii sur chacune de ces représentations nous appliquons un algorithme de coclustering  iii à partir des résultats de coclustering nous construisons de nouveaux descripteurs pour les séries temporelles nous obtenons une nouvelle base de données objetsattributs dont les objets identifiant les séries temporelles sont décrits par des attributs issus des diverses représentations générées nous utilisons un classifieur bayésien sur cette nouvelle base de données nous montrons expérimentalement que ce processus offre de très bonnes performances prédictives comparées à létat de lart\n",
      "découverte des softskypatterns avec une approche ppc\n",
      "les skypatterns sont des motifs traduisant des préférences de lutilisateur selon une relation de dominance dans cet article nous introduisons la notion de souplesse dans la problématique des skypatterns et nous montrons comment celleci permet de découvrir des motifs intéressants qui seraient manqués autrement nous proposons une méthode efficace dextraction de skypatterns ainsi que de softskypatterns méthode fondée sur la programmation par contraintes la pertinence de notre approche est illustrée à travers une étude de cas en chémoinformatique pour la découverte de toxicophores\n",
      "detecting academic plagiarism with graphs\n",
      "in this paper we tackle the problem of detecting academic plagiarism which is considered as a severe problem owing to the convenience of online publishing typical information retrieval methods stopwordbased methods and \u0002ngerprinting methods are commonly used to detect plagiarism by using the sequence of words as they appear in the article as such they fail to detect plagiarism when an author reconstructs a source article by reordering and recombining phrases because graph structure \u0002ts for representing relationships between entities we propose a novel plagiarism detection method in which we use graphs to represent documents by modeling grammatical relationships between words experimental results show that our proposed method outperforms two ngram methods and increases recall values by 10 to 20\n",
      "détection efficace des traverses minimales dun hypergraphe par élimination de la redondance\n",
      "lextraction des traverses minimales dun hypergraphe est une problématique réputée comme particulièrement difficile et qui a fait lobjet de plusieurs travaux dans la littérature dans cet article nous établissons un lien entre les concepts de la fouille de données et ceux de la théorie des hypergraphes proposant ainsi un cadre méthodologique pour le calcul des traverses minimales le nombre de ces traverses minimales étant souvent exponentiel même pour des hypergraphes simples nous proposons den représenter lensemble de manière concise et exacte pour ce faire nous introduisons la notion de traverses minimales irrédondantes à partir desquelles nous pouvons retrouver lensemble global de toutes les traverses minimales à laide de lalgorithme imtextractor une étude expérimentale de ce nouvel algorithme a confirmé lintérêt de lapproche introduite\n",
      "détection précoce de tendances produits dans le cadre des activités commerciales de la grande distribution\n",
      "dans ce papier nous présentons une nouvelle approche qui permet la détection précoce de tendances produits dans le cadre des activités commerciales de la grande distribution sagissant dun domaine où la concurrence est très vive entre les différentes enseignes avec des enjeux financiers colossaux les stratégies commerciales ont pour principal objectif de fidéliser la clientèle pour limiter leur défection cest là quintervient la détection des changements de tendances produits qui va permettre danticiper lattrition de la clientèle déceler des tendances suffisamment tôt permettra aux décideurs de mettre en place des stratégies préventives efficaces à moindre coût notre objectif est donc danalyser et de modéliser clairement les changements de tendances et leurs impacts potentiels globaux sur les achats des clients nous illustrerons notre approche sur des données réelles dachats de clients dune grande enseigne\n",
      "enrichissement dontologies grâce à lannotation sémantique de pages web\n",
      "nous présentons une approche pour enrichir automatiquement une ontologie à partir dun ensemble de pages web structurées cette approche sappuie sur un noyau dontologie initial son originalité est dexploiter conjointement la structure des documents et des annotations sémantiques produites à laide du noyau dontologie pour identifier de nouveaux concepts et des spécialisations de relations qui enrichissent lontologie nous avons implémenté et évalué ce processus en réalisant une ontologie de plantes à partir de fiches de jardinage\n",
      "étude des corrélations spatiotemporelles des appels mobiles en france\n",
      "nous proposons dans cet article de présenter une application danalyse dune base de données de grande taille issue du secteur des télécommunications le problème consiste à segmenter un territoire et caractériser les zones ainsi définies grâce au comportement des habitants en terme de téléphonie mobile nous disposons pour cela dun réseau dappels interantennes construit pendant une période de cinq mois sur lensemble de la france nous proposons une analyse en deux phases la première couple les antennes émettrices dont les appels sont similairement distribués sur les antennes réceptrices et vice versa une projection de ces groupes dantennes sur une carte de france permet une visualisation des corrélations entre la géographie du territoire et le comportement de ses habitants en terme de téléphonie la seconde phase découpe lannée en périodes entre lesquelles on observe un changement de distributions dappels sortant des groupes dantennes on peut ainsi caractériser lévolution temporelle du comportement des usagers de mobiles dans chacune des zones du pays\n",
      "étude des techniques doubli dans les moindres carrés récursifs pour lapprentissage incrémental de systèmes dinférence floue évolutifs  application à la reconnaissance de formes\n",
      "cet article étudie les possibilités dutilisation doubli dans lapprentissage incrémental enligne de classifieurs évolutifs basés sur des systèmes dinférence floue pour cela nous étudions différentes possibilités existant dans la littérature dédiée au contrôle pour introduire de loubli dans lalgorithme des moindres carrés récursifs nous présentons limpact de ces différentes techniques dans le contexte de lapprentissage incrémental de classifieurs évolutifs en environnement non stationnaire ces approches sont évaluées pour loptimisation des systèmes dinférence floue sur la problématique de la reconnaissance de gestes manuscrits sur surface tactile\n",
      "évolution dune ontologie dédiée à la représentation de relations naires\n",
      "nous nous intéressons dans cet article à la problématique dévolution dune ontologie permettant de représenter des relations naires nous présentons la représentation formelle des changements applicables à notre ontologie permettant de modifier sa structure tout en maintenant sa cohérence structurelle nous illustrerons nos propos sur une ontologie dédiée à la représentation de relations naires entre des données expérimentales quantitatives\n",
      "extraction de motifs condensés dans un unique graphe orienté acyclique attribué\n",
      "les graphes orientés acycliques attribués peuvent être utilisés dans beaucoup de domaines applicatif dans ce papier nous étudions un nouveau domaine de motif pour permettre leur analyse  les chemins pondérés fréquents nous proposons en conséquence des contraintes primitives permettant dévaluer leur pertinence par exemple les contraintes de fréquence et de compacité et un algorithme extrayant ces solutions nous aboutissons à une représentation condensée dont lefficacité et le passage à léchelle sont étudiés empiriquement\n",
      "extraction de motifs fréquents dans des arbres attribués\n",
      "lextraction de motifs fréquents est une tâche importante en fouille de données initialement centrés sur la découverte densembles ditems fréquents les premiers travaux ont été étendus pour extraire des motifs structurels comme des séquences des arbres ou des graphes dans cet article nous proposons une nouvelle méthode de fouille de données qui consiste à extraire de nouveaux types de motifs à partir dune collection darbres attribués les arbres attribués sont des arbres dans lesquels les noeuds sont associés à des ensembles dattributs lextraction de ces motifs appelés sousarbres attribués combine une recherche densembles ditems fréquents à une recherche de sousarbres et nécessite dexplorer un immense espace de recherche nous présentons plusieurs nouveaux algorithmes dextraction darbres attribués et montrons que leurs implémentations peuvent efficacement extraire des motifs fréquents à partir de grands jeux de données\n",
      "extraction des nombres de betti avec un modèle génératif\n",
      "lanalyse exploratoire de données multidimensionnelles est un problème complexe nous proposons dextraire certains invariants topologiques appelés nombre de betti pour synthétiser la topologie de la structure sousjacente aux données nous définissons un modèle génératif basé sur le complexe simplicial de delaunay dont nous estimons les paramètres par loptimisation du critère dinformation bayésien bic ce complexe simplicial génératif nous permet dextraire les nombres de betti de données jouets et dimages dobjets en rotation comparé à la technique géométrique des witness complex le csg apparait plus robuste aux données bruitées\n",
      "extraction et filtrage de syntagmes nominaux pour la recherche dinformation\n",
      "nous proposons dans cet article un système de recherche dinformation sri qui se base sur des techniques dindexation de textes en langue naturelle nous présentons une méthode dindexation de documents qui repose sur une approche hybride pour la sélection de descripteurs textuels cette approche emploie des traitements du langage naturel pour lextraction des syntagmes nominaux et sur un filtrage statistique basé sur linformation mutuelle pour sélectionner les syntagmes nominaux les plus informatifs pour le processus dindexation nous effectuons des expérimentations en utilisant le corpus le monde 94 de la collection clef 2001 et sur le sri lemur pour évaluer lapproche proposée\n",
      "extraction optimisée de règles dassociation positives et négatives rapn\n",
      "la littérature sest beaucoup intéressée à lextraction de règles dassociation positives et peu à lextraction de règles négatives en raison essentiellement du coût de calculs et du nombre prohibitif de règles extraites qui sont pour la plupart redondantes et inintéressantes dans cet article nous nous sommes intéressés aux algorithmes dextraction de rapn règles dassociation positives et négatives reposant sur lalgorithme fondateur apriori nous avons fait une étude de ceuxci en mettant en évidence leurs avantages et leurs inconvénients a lissue de cette étude nous avons proposé un nouvel algorithme qui améliore cette extraction au niveau du nombre et de la qualité des règles extraites et au niveau du parcours de recherche des règles létude sest terminée par une évaluation de cet algorithme sur plusieurs bases de données\n",
      "grille bivariée pour la détection de changement dans un flux étiqueté\n",
      "nous présentons une méthode enligne de détection de changement de concept dans un flux étiqueté notre méthode de détection est basée sur un critère supervisé bivarié qui permet didentifier si les données de deux fenêtres proviennent ou non de la même distribution notre méthode a lintérêt de navoir aucun a priori sur la distribution des données ni sur le type de changement et est capable de détecter des changements de différentes natures changement dans la moyenne dans la variance les expérimentations montrent que notre méthode est plus performante et robuste que les méthodes de létat de lart testées de plus à part la taille des fenêtres elle ne requiert aucun paramètre utilisateur\n",
      "identification de compatibilités entre descripteurs de lieux et apprentissage automatique\n",
      "les travaux présentés dans cet article sinscrivent dans le paradigme des recherches visant à acquérir des relations sémantiques à partir de folksonomies ensemble de tags attribués à des ressources par des utilisateurs nous expérimentons plusieurs approches issues de létat de lart ainsi que lapport de lapprentissage automatique pour lidentification de relations entre tags nous obtenons dans le meilleur des cas un taux derreur de 237  relations non reconnues ou fausses ce qui est encourageant au vu de la difficulté de la tâche les annotateurs humains ont un taux de désaccord de 12\n",
      "identification de complexes protéineprotéine par combinaison de classifieurs application à escherichia coli\n",
      "nous proposons une approche permettant de prédire des complexes impliquant trois protéines appelés trimères à partir de combinaison de classifieurs appris sur des complexes nimpliquant que deux protéines dimères la prédiction de ces trimères repose sur deux hypothèses biologiques  i deux protéines orthologues présentent des caractéristiques fonctionnelles similaires ii deux protéines interagissant sous la forme dun complexe soustendent une fonction biologique essentielle à lespèce concernée ces deux hypothèses sont exploitées pour décrire chaque paire de protéines par lensemble des espèces pour lesquelles elles possèdent un orthologue un ensemble de mesures de qualité classiquement utilisées pour évaluer lintérêt des règles dassociation est utilisé pour évaluer la force du lien entre les deux protéines lorganisme modèle escherichia coli a été utilisé pour évaluer notre approche\n",
      "inférence de réseaux biologiques  un défi pour la fouille de données structurées\n",
      "la réponse cellulaire dun organisme vivant à un signal donné hormone stress ou médicament met en jeu des mécanismes complexes dinteraction et de régulation entre les gènes les arn messagers les protéines et dautres éléments tels que les microarns on parle de réseau dinteraction pour décrire lensemble des interactions possibles entre protéines et de réseau de régulation génique pour représenter un ensemble de régulations entre gènes identifier ces interactions et ces régulations ouvre la porte à une meilleure compréhension du vivant et permet denvisager de mieux soigner par le biais du ciblage thérapeutique puisque les techniques expérimentales de mesure à grande échelle récemment développées fournissent des données dobservation de ces réseaux ce problème didentification de réseau généralement appelé inférence de réseau en biologie des systèmes sinscrit dans le cadre général de la fouille de données et plus particulièrement de lapprentissage artificiel voilà maintenant quelques années que cette problématique a été posée à notre communauté et durant lesquelles les échanges entre biologistes et informaticiens ont non seulement permis aux biologistes détoffer leurs boîtes à outils mais aussi aux informaticiens de concevoir de nouvelles méthodes de fouille de donnéesen partant des deux problématiques distinctes que sont linférence de réseau dinteraction et linférence de réseau de régulation je montrerai que ces deux tâches dapprentissage posent chacune de manière différente la problématique de la prédiction de sorties structurées linférence de réseau dinteraction entre protéines vue comme un problème transductif de prédiction de liens peut être résolue comme un problème dapprentissage dun noyau de sortie à partir dun noyau dentrée linférence de réseau de régulation impliquant la modélisation dun système dynamique peut être abordée par lapproximation parcimonieuse et structurée de fonctions à valeurs vectorielles je présenterai un ensemble de nouveaux outils de régression à sortie dans un espace de hilbert fondés sur des noyaux à valeur opérateur qui fournissent dexcellents résultats en inférence de réseaux biologiques des expériences in silico sur des données artificielles chez la levure du boulanger ou chez lhomme illustreront mes propos en fin dexposé je tracerai quelques perspectives concernant les  nouveaux  défis dans le domaine de la bioinformatique et dans celui de la prédiction de sorties structurées\n",
      "les capitalistes sociaux sur twitter  détection via des mesures de similarité\n",
      "les réseaux sociaux tels que twitter font partie du phénomène de déluge des données expression utilisée pour décrire lapparition de données de plus en plus volumineuses et complexes pour représenter ces réseaux des graphes orientés sont souvent utilisés dans cet article nous nous focalisons sur deux aspects de lanalyse du réseau social de twitter en premier lieu notre but est de trouver une méthode efficace et haut niveau pour stocker et manipuler le graphe du réseau social en utilisant des ressources informatiques raisonnables cet axe de recherche constitue un enjeu majeur puisquil est ainsi possible de traiter des graphes à échelle réelle sur des machines potentiellement accessibles par tous ensuite nous étudions les capitalistes sociaux un type particulier dutilisateurs de twitter observé par ghosh et al 2012 nous proposons une méthode pour détecter et classifier efficacement ces utilisateurs\n",
      "modèle de recherche dinformation sociale centré utilisateur\n",
      "lémergence des réseaux sociaux a révolutionné leweb en permettant notamment aux individus de prolonger leur connexion virtuelle en une relation plus réelle et de partager leurs connaissances ce nouveau contexte de diffusion de linformation sur le web peut constituer un moyen efficace pour cerner les besoins en information des utilisateurs du web et permettre à la recherche dinformation ri de mieux répondre à ces besoins en adaptant les modèles dindexation et dinterrogation lexploitation des réseaux sociaux confronte la ri à plusieurs défis dont les plus importants concernent la représentation de linformation dans ce modèle social de ri et son évaluation en labsence de collections de test et de compétitions dédiées dans cet article nous présentons un modèle de ri sociale dans lequel nous proposons de modéliser et dexploiter le contexte social de lutilisateur nous avons évalué notre modèle à laide dune collection de test de ri sociale construite à partir des annotations du réseau social de bookmarking collaboratif delicious\n",
      "nondisjoint grouping of text documents based word sequence kernel\n",
      "this paper deals with two issues in text clustering which are the detection of non disjoint groups and the representation of textual data in fact a text document can discuss several themes and then it must belong to several groups the learning algorithm must be able to produce non disjoint clusters and assigns documents to several clusters the second issue concerns the data representation textual data are often represented as a bag of features such as terms phrases or concepts this representation of text avoids correlation between terms and doesnt give importance to the order of words in the text we propose a non supervised learning method able to detect overlapping groups in text document by considering text as a sequence of words and using the word sequence kernel as similarity measure the experiments show that the proposed method outperforms existing overlapping methods using the bag of word representation in terms of clustering accuracy and detect more relevant groups in textual documents\n",
      "nouvelle approche de bipartitionnement topologique\n",
      "dans ce papier nous proposons une nouvelle approche topologique de bipartitionnement biclustering appelée bitm en utilisant les cartes autoorganisatrices lidée principale de lapproche est dutiliser une seule carte pour le partitionnement simultané des lignes observations et des colonnes variables contrairement aux approches utilisant les cartes topologiques notre modèle ne nécessite pas de prétraitement de la base de données ainsi une nouvelle fonction de coût est proposée de plus bitm fournit une visualisation topologique des blocs ou biclusters facilement interprétable les résultats obtenus sont très encourageants et prometteurs pour continuer dans cette optique\n",
      "paramétrage intelligent de lalignement dontologies par lintégrale de choquet\n",
      "le nombre croissant dontologies rend le processus dalignement une composante essentielle du web sémantique plusieurs outils ont été conçus dans le but de produire des alignements la qualité des alignements fournis par ces outils est étroitement liée à certains paramètres qui régissent leurs traitements dans ce papier nous proposons une nouvelle approche permettant ladaptation automatique des paramètres dalignement dontologies par lutilisation de lintégrale de choquet comme un opérateur dagrégation les expérimentations montrent une nette amélioration des résultats par rapport à un paramétrage statique et figé\n",
      "processus itératif dextraction de classes en non supervisée\n",
      "nous proposons dans cet article une nouvelle approche de classification non supervisée où les classes sont obtenues les unes après les autres suivant un processus itératif lapproche utilise une méthode dextraction de classes basée sur la détection de limite de classe chaque classe étant définie par son centre nous avons également défini des critères dévaluation adaptés à la méthode proposée plusieurs expérimentations ont montré lintérêt de lapproche dans divers problèmes\n",
      "réécriture de requêtes dans un système dintégration sémantique\n",
      "nous décrivons la deuxième phase de réalisation dun système dintégration qui minimise lintervention humaine habituellement nécessaire après la phase de construction semiautomatique du schéma ontologie global décrite dans de précédents articles nous présentons ici le processus de réécriture de requêtes globales en des requêtes adressées aux sources\n",
      "recherche de documents similaires sur le web par segmentations hiérarchiques et extraction de motsclés\n",
      "la recherche de documents similaires est un processus qui consiste à trouver les documents présentant des similitudes comme la copie ou la reformulation sur des bases documentaires ou sur internet elle est utilisée notamment pour protéger la propriété intellectuelle de productions issues de lenseignement de la recherche ou de lindustrie dans cet article nous définissons une approche automatique pour permettant dextraire des motsclés dun document en effectuant un bouclage sur une succession de découpage de plus en plus petit cette approche permet dobtenir des motsclés impossibles à obtenir par une approche globale notamment quand la thématique le style ou le contenu dun document varient dans le document lobjectif est de permettre la détection des documents présentant des similitudes en utilisant uniquement des motsclés\n",
      "réutiliser les connaissances dexpert pour assister lanalyse de lactivité sur simulateur pleine échelle de conduite de centrale nucléaire  approche à base de mtrace\n",
      "notre travail porte sur laide à lobservation de lactivité dans les simulateurs pleine échelle de centrale nucléaire pour assister les formateurs pendant les simulations notre approche consiste à représenter lactivité sous la forme de trace modélisée et à les transformer afin dextraire et de visualiser des informations de haut niveau permettant aux formateurs de mieux retracer et analyser les simulations afin de valider notre approche nous avons conçu le prototype d3kode que nous avons évalué avec des experts formateurs dedf\n",
      "sélection de variables non supervisée sous contraintes hiérarchiques\n",
      "la sélection des variables a un rôle très important dans la fouille de données lorsquun grand nombre de variables est disponible ainsi certaines variables peuvent être peu significatives corrélées ou non pertinentes une méthode de sélection a pour objectif de mesurer la pertinence dun ensemble utilisant principalement un critère dévaluation nous présentons dans cet article un critère non supervisé permettant de mesurer la pertinence dun sousensemble de variables ce dernier repose sur lutilisation du score laplacien auquel nous avons ajouté des contraintes hiérarchiques travailler dans le cadre non supervisé est un vrai challenge dans ce domaine dû à labsence des étiquettes de classes les résultats obtenus sur plusieurs bases de tests sont très encourageants et prometteurs\n",
      "snow un algorithme exploratoire pour le subspace clustering\n",
      "cet article propose un nouvel algorithme pour le problème de subspace clustering dénommé snow contrairement aux approches descendantes classiques il ne repose pas sur lhypothèse de localité et permet laffectation dune donnée à plusieurs clusters dans des sousespaces différents les expérimentations préliminaires montrent que notre approche obtient de meilleurs résultats que lalgorithme copac sur une base de référence et a été appliquée sur une base de données réelles\n",
      "technique de factorisation multibiais pour des recommandations dynamiques\n",
      "la factorisation de matrices offre une grande qualité de prédiction pour les systèmes de recommandation mais sa nature statique empêche de tenir compte des nouvelles notes que les utilisateurs produisent en continu ainsi la qualité des prédictions décroît entre deux factorisations lorsque de nombreuses notes ne sont pas prises en compte la quantité de notes écartées est dautant plus grande que la période entre deux factorisation est longue ce qui accentue la baisse de qualiténos travaux visent à améliorer la qualité des recommandations nous proposons une factorisation de matrices utilisant des groupes de produits et intégrant en ligne les nouvelles notes des utilisateurs nous attribuons à chaque utilisateur un biais pour chaque groupe de produits similaires que nous mettons à jour ainsi nous améliorons significativement les prédictions entre deux factorisations nos expérimentations sur des jeux de données réels montrent lefficacité de notre approche\n",
      "text2geo  des données textuelles aux informations géospatiales\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans cet article nous nous intéressons aux méthodes dextraction dinformations spatiales dans des documents textuels nous présentons la méthode hybride text2geo qui combine une approche dextraction dinformations fondée sur des patrons avec une approche de classification supervisée permettant dexplorer le contexte associé nous discutons des résultats expérimentaux obtenus sur le jeu de données de létang de thau\n",
      "totem une méthode de détection de communautés adaptées aux réseaux dinformation\n",
      "alors que les réseaux sociaux sattachaient à représenter des entités et les relations qui existaient entre elles les réseaux dinformation intègrent également des attributs décrivant ces entités  ce qui conduit à revisiter les méthodes danalyse et de fouille de ces réseaux dans cet article nous proposons une méthode de classification des sommets dun graphe qui exploite dune part leurs relations et dautre part les attributs les caractérisant cette méthode reprend le principe de la méthode de louvain en létendant de façon à permettre la manipulation dattributs continus dune manière symétrique à ce qui existe pour les relations\n",
      "towards a new science of big data analytics based on the geometry and the topology of complex hierarchic systems\n",
      "my work is concerned with pattern recognition knowledge discovery computer learning and statistics i address how geometry and topology can uncover and empower the semantics of data in addition to the semantics of data that can be explored using correspondence analysis and related multivariate data analyses hierarchy is a fundamental concept in this work i address not only low dimensional projection for display purposes but carry out search and pattern recognition whenever useful in very high dimensional spaces high dimensional spaces present very different characteristics from low dimensions i have shown that in a particular sense very high dimensional space becomes as dimensionality increases hierarchical i have also shown how in hierarchy and hence in an ultrametric topological mapping of information space we track change or anomaly or rupturein this presentation the first theme discussed is that of linear time hierarchical clustering with application to sky survey data in astronomy and to chemoinformatics the second theme discussed is computational text analysis it is interesting to note that jp benzécris original motivation was in language and linguistics in my text analysis work i have taken the dictum of mckee story  substance structure style and the principles of screenwriting methuen 1999 that text is the sensory surface of a work of art and show just how this insight can be rendered in computational terms this leads to demarcating tracking statistical modelling visualizing and pattern recognition of narrative in an application to collaborative writing i developed an interactive framework for critiquing and assessing fit and appropriateness of content on the basis of semantics leading to books that were published as ebooks having been written by school children in a few days of collaborative class work in many aspects of this work hierarchy expresses both continuity and change in the textual narrative or in the narrative of chronological events\n",
      "un critère dévaluation pour la construction de variables à base ditemsets pour lapprentissage supervisé multitables\n",
      "dans le contexte de la fouille de données multitables les données sont représentées sous un format relationnel dans lequel les individus de la table cible sont potentiellement liés à plusieurs enregistrements dans des tables secondaires en relation unàplusieurs dans cet article nous proposons un framework basé sur des itemsets pour la construction de variables à partir des tables secondaires linformativité de ces nouvelles variables est évaluée dans le cadre de la classification supervisée au moyen dun critère régularisé qui vise à éviter le surapprentissage pour ce faire nous introduisons un espace de modèles basés sur des itemsets dans la table secondaire ainsi quune estimation de la densité conditionnelle des variables construites correspondantes une distribution a priori est définie sur cet espace de modèles pour obtenir ainsi un critère sans paramètres permettant dévaluer la pertinence des variables construites des expérimentations préliminaires montrent la pertinence de lapproche\n",
      "un système hybride de recherche dinformation intégrant le raisonnement à partir de cas et la composition dontologies\n",
      "la croissance des informations disponibles sur le web nécessite des outils de recherche de plus en plus performants permettant de répondre efficacement aux besoins des utilisateurs dans ce contexte lutilisation des ontologies présente des atouts importants cependant la construction manuelle dontologies est très coûteuse ceci a poussé à proposer des approches permettant dautomatiser cette construction cet article présente un système de recherche dinformation hybride basée sur le raisonnement à partir de cas ràpc et la composition dontologies ce système vise à combiner la construction automatique dontologies modulaires et le ràpc qui a pour but daméliorer les résultats de recherche dinformation ri des expérimentations ont été menées et les résultats obtenus montrent une amélioration de la précision dans le cas dune recherche dinformation sur le web\n",
      "une approche en programmation par contraintes pour la classification non supervisée\n",
      "dans cet article nous abordons le problème de classification non supervisée sous contraintes fondé sur la programmation par contraintes ppc nous considérons comme critère doptimisation la minimisation du diamètre maximal des clusters nous proposons un modèle pour cette tâche en ppc et nous montrons aussi limportance des stratégies de recherche pour améliorer son efficacité notre modèle basé sur la distance entre les objets permet de traiter des données qualitatives et quantitatives des contraintes supplémentaires sur les clusters et les instances peuvent directement être ajoutées des expériences sur des ensembles de données classiques montrent lintérêt de notre approche\n",
      "une nouvelle mesure pour lévaluation des méthodes dextraction de thématiques  la vraisemblance généralisée\n",
      "les méthodes dédiées à lextraction automatique de thématiques sont issues de domaines variés  linguistique computationnelle tal algèbre linéaire statistique etc a ces méthodes spécifiques peuvent sajouter des méthodes adaptées dautres domaines notamment de lapprentissage automatique non supervisé les résultats produits par lensemble de ces méthodes prennent des formes hétérogènes  partitions de documents distributions de probabilités sur les mots matrices cela pose clairement un problème pour les comparer de manière uniforme dans cet article nous proposons une nouvelle mesure de qualité intitulée vraisemblance généralisée pour permettre une évaluation et ainsi la comparaison de différentes méthodes dextraction de thématiques les résultats obtenus sur un corpus de documents web autour des élections présidentielles françaises de 2012 ainsi que sur le corpus associated press montrent la pertinence de la mesure proposée\n",
      "unsupervised video tag correction system\n",
      "we present a new system for video auto tagging which aims at correcting and completing the tags provided by users for videos uploaded on the internet unlike most existing systems we do not learn any tag classifiers or use the questionable textual information to compare our videos we propose to compare directly the visual content of the videos described by different sets of features such as bagofvisualwords or frequent patterns built from them then we propagate tags between visually similar videos according to the frequency of these tags in a given video neighborhood we also propose a controlled experimental set up to evaluate such a system experiments show that with suitable features we are able to correct a reasonable amount of tags in web videos\n",
      "validation dune carte cognitive\n",
      "les cartes cognitives sont un modèle graphique représentant des influences entre des concepts malgré le fait quune carte cognitive soit relativement simple à construire certaines influences peuvent se contredire lune lautre cet article propose différents critères pour valider une carte cognitive cestàdire indiquer si la carte contient ou non des contradictions nous distinguons deux types de critères  les critères de vérification qui valident une carte cognitive en déterminant sa cohérence interne et les critères de test qui valident une carte à partir dun ensemble de contraintes choisies par le concepteur\n",
      "vers un cadre évolutif de classification non supervisée\n",
      "la classification non supervisée clustering évolutive surpasse généralement par celle statique en produisant des groupes de données clusters qui reflètent les tendances à long terme tout en étant robuste aux variations à court terme dans ce travail nous présentons un cadre différent pour le clustering évolutif dune manière incrémentale par un suivi précis des variables de proximité temporelles entre les objets suivis par un clustering statique ordinaire\n",
      "vers une architecture multicouche dontologies dédiée à la résolution mixte de problèmes\n",
      "dans cet article nous nous intéressons à la gestion dexpériences générées au sein des processus de résolution mixte individuelle etou collective de problèmes afin dassister la capitalisation et le partage des connaissances dans les environnements collaboratifs dans ce contexte nous proposons un cadre ontologique générique par rapport au domaine dédié à la modélisation formelle et consensuelle de ces expériences en adoptant une architecture multicouche basée sur quatre strates la première strate est basée sur la spécialisation dontologies fondationnelles la deuxième strate est basée sur la conception de trois patrons conceptuels ontologiques pco noyaux le pco organisationnel le pco téléologique et le pco argumentatif modélisant respectivement les acteurs le problème et les solutions proposées la troisième strate est basée sur la spécialisation des pco noyaux dans un domaine particulier et la dernière strate est basée sur linstanciation du modèle ontologique de domaine pour la représentation dune situation du monde réel\n",
      "vers une automatisation de la construction de variables pour la classification supervisée\n",
      "dans cet article nous proposons un cadre visant à automatiser la construction de variables pour lapprentissage supervisé en particulier dans le cadre multitables la connaissance du domaine est spécifiée dune part en structurant les données en variables tables et liens entre tables dautre part en choisissant des règles de construction de variables lespace de construction de variables ainsi défini est potentiellement infini ce qui pose des problèmes dexploration combinatoire et de surapprentissage nous introduisons une distribution de probabilité a priori sur lespace des variables constructibles ainsi quun algorithme performant de tirage déchantillons dans cette distribution des expérimentations intensives montrent que lapproche est robuste et performante\n",
      "vers une mesure de similarité pour les séquences complexes\n",
      "le calcul de similarité entre les séquences est dune extrême importance dans de nombreuses approches dexplorations de données il existe une multitude de mesures de similarités de séquences dans la littérature or la plupart de ces mesures sont conçues pour des séquences simples dites séquences ditems dans ce travail nous étudions dun point de vue purement combinatoire le problème de similarité entre des séquences complexes ie des séquences densembles ou itemsets nous présentons de nouveaux résultats afin de compter efficacement toutes les sousséquences communes à deux séquences ces résultats théoriques sont la base dune mesure de similarité calculée efficacement grâce à une approche de programmation dynamique\n",
      "visualisation radiale  approche parallèle entre cpu et gpu\n",
      "dans cet article nous proposons une parallélisation sur cpu et gpu dune méthode de visualisation radiale à base de points dintérêt nous montrons que cette approche peut visualiser avec des temps très courts des millions de données sur des dizaines de dimensions et nous étudions lefficacité de la parallélisation dans différentes configurations\n",
      "antipattern detection inweb ontologies an experiment using sparql queries\n",
      "ontology antipatterns are structures that reflect ontology modelling problems because they lead to inconsistencies bad reasoning performance or bad formalisation of domain knowledge we propose four methods for the detection of antipatterns using sparql queries we conduct some experiments to detect antipattern in a corpus of owl ontologies\n",
      "apprentissage densemble dopérateurs de projection orthogonale pour la détection de nouveauté\n",
      "dans ce papier nous proposons une approche de détection de nouveautéfondée sur les opérateurs de projection orthogonale et lidée de doublebootstrap bi bootstrap notre approche appelée random subspace noveltydetection filter rsndf combine une technique de rééchantillonnage etlidée dapprentissage densemble rsndf est un ensemble de filtres ndfnovelty detection filter induits à partir déchantillons bootstrap des donnéesdapprentissage en utilisant une sélection aléatoire des variables pour lapprentissagedes filtres rsndf utilise donc un double bootstrap cest à dire unrééchantillonnage avec remise sur les observations et un rééchantillonnage sansremise sur les variables la prédiction est faite par lagrégation des prédictionsde lensemble des filtres rsndf présente généralement une importante améliorationdes performances par rapport au modèle de base ndf unique grâce àson algorithme dapprentissage en ligne lapproche rsndf est également enmesure de suivre les changements dans les données au fil du temps plusieursmétriques de performance montrent que lapproche proposée est plus efficacerobuste et offre de meilleures performances pour la détection de nouveauté comparéeaux autres techniques existantes\n",
      "apprentissage par analyse linéaire discriminante des paramètres de fusion pour la recherche dinformation multimédia texteimage\n",
      "avec le développement du numérique des quantités très importantesde documents composés de texte et dimages sont échangés ce qui nécessite ledéveloppement demodèles permettant dexploiter efficacement ces informationsmultimédias dans le contexte de la recherche dinformation unmodèle possibleconsiste à représenter séparément les informations textuelles et visuelles et àcombiner linéairement les scores issus de chaque représentation cette approchenécessite le paramétrage de poids afin déquilibrer la contribution de chaquemodalité le but de cet article est de présenter une nouvelle méthode permettantdapprendre ces poids basée sur lanalyse linéaire discriminante de fisherald des expérimentations réalisées sur la collection imageclef montrentque lapprentissage des poids grâce à lald est pertinent et que la combinaisondes scores correspondante améliore significativement les résultats par rapport àlutilisation dune seule modalité\n",
      "biological event extraction using svm and composite kernel function\n",
      "with an overwhelming of experimental and computational results inmolecular biology there is an increasing interest to provide tools that will automaticallyextract structured biological information recorded in freely availabletext extraction of named entities such as protein gene or disease names andof simple relations of these entities such as statements of proteinprotein interactionshas gained certain success and now the new focus research has beenmoving to higher level of information extraction such as coreference resolutionand event extraction it is precisely the last of these tasks which will be focusedin this paper the biological event template allows detailed representations ofcomplex natural language statements which is specified by a trigger and argumentslabeled by semantic rolesin this paper we have developed a biological event extraction approach whichuses support vector machines svm and a suitable composite kernel functionto identify triggers and to assign the corresponding arguments also we makeuse of a number of features based on both syntactic and contextual informationwhich where automatically learned from the training datawe implemented our event extraction system using the stateoftheart of nlptools we achieved competitive results compared to the bionlp09 shared taskbenchmark\n",
      "caractérisation et extraction de biclusters de valeurs similaires avec lanalyse de concepts triadiques\n",
      "le biclustering de données numériques est devenu depuis le début desannées 2000 une tâche importante danalyse de données particulièrement pourlétude de données biologiques dexpression de gènes un bicluster représenteune association forte entre un ensemble dobjets et un ensemble dattributs dansune table de données numériques les biclusters de valeurs similaires peuventêtre vus comme des soustables maximales de valeurs proches seules quelquesméthodes se sont penchées sur une extraction complète ie non heuristiqueexacte et non redondante de tels motifs qui reste toujours un problème difficiletandis quaucun cadre théorique fort ne permet leur caractérisation dans le présentarticle nous introduisons des liens importants avec lanalyse formelle deconcepts plus particulièrement nous montrons de manière originale que lanalysede concepts triadiques tca propose un cadre mathématique intéressant etpuissant pour le biclustering de données numériques de cette manière les algorithmesexistants de la tca qui sappliquent habituellement à des données binairespeuvent être utilisés directement ou après quelques modifications aprèsun prétraitement des données pour lextraction désirée\n",
      "classification conceptuelle avec généralisation par intervalles\n",
      "nous nous intéressons aux méthodes de classification hiérarchique oupyramidale où chaque classe formée correspond à un concept ie une paire extensionintension considérant des données décrites par des variables quantitativesà valeurs réelles ou intervalles ordinales etou prenant la forme de distributionde probabilitésfréquences sur un ensemble de catégories les concepts sontobtenus par une correspondance de galois avec généralisation par intervalles cequi permet de traiter les données de différents types dans un cadre commun unemesure de la généralité dun concept est alors calculée sous une forme communepour les différents types de variables un exemple illustre la méthode proposée\n",
      "classification de données eeg par algorithme évolutionnaire pour létude détats de vigilance\n",
      "lobjectif de ce travail est de prédire létat de vigilance dun individuà partir de létude de son activité cérébrale signaux délectroencéphalographieeeg la variable à prédire est binaire état de vigilance normal ou relaxédes eeg de 44 participants dans les deux états 88 enregistrements ont étérecueillis via un casque à 58 électrodes après une étape de prétraitement et devalidation des données un critère nommé critère des pentes a été choisi desméthodes de classification supervisée usuelles k plus proches voisins arbresbinaires de décision cart forêts aléatoires pls et sparse pls discriminanteont été appliquées afin de fournir des prédictions de létat des participants lecritère utilisé a ensuite été raffiné grâce à un algorithme génétique ce qui apermis de construire un modèle fiable taux de bon classement moyen par cartégal à 8668 ± 187 et de sélectionner une électrode parmi les 58 initiales\n",
      "classification des données catégorielles via la maximisation spectrale de la modularité\n",
      "ce papier présente un algorithme spectrale pour maximiser le critèrede la modularité étendu à la classification des données catégorielles il met enevidence la connexion formelle entre la maximisation de la modularité et la classificationspectrale il présente en particulier le problème de maximisation de lamodularité sous forme dun problème algèbrique de maximisation de la tracenous développons ensuite un algorithme efficace pour trouver la partition optimalemaximisant le critère de modularité les résultats expérimentaux montrentlefficacité de notre approche\n",
      "classification probabiliste non supervisée et visualisation des données séquentielles\n",
      "nous proposons dans ce papier un nouvel algorithme de classificationnon supervisée à base de modèle de mélange topologique pour des donnéesnon iid non independently and identically distributed ce nouveau paradigmeprobabiliste plonge les cartes topologiques probabilistes dans une formulationsous forme de chaînes de markov cachées dans cette formulation la générationdune observation à un instant donné du temps est conditionnée par les étatsvoisins au même instant du temps ainsi une grande proximité impliquera unegrande probabilité pour la contribution à la génération lapproche proposée estévaluée en utilisant des données séquentielles réelles issues des bases de donnéesde linstitut nationale de laudiovisuel ina les résultats obtenus sonttrès encourageants et prometteurs\n",
      "classification topologique probabiliste pour des données catégorielles\n",
      "cet article présente une carte autoorganisatrice probabiliste pour lanalyseet la classification topologique des données catégorielles en considérant unmodèle de mélanges parcimonieux nous introduisons une nouvelle carte autoorganisatricesom probabiliste lestimation des paramètres de notre modèleest réalisée à laide de lalgorithme em classique contrairement à som lalgorithmedapprentissage proposé optimise une fonction objective ces performancesont été évaluées sur des données réelles et les résultats obtenus sontencourageants et prometteurs à la fois pour la classification et pour la modélisation\n",
      "clustering de séquences dactivités pour létude de procédures neurochirurgicales\n",
      "lutilisation de modèles de procédure chirurgicale surgical processmodel spm a récemment émergé dans le domaine de la conception doutilsdintervention chirurgicale assistée par ordinateur ces modèles qui sont utiliséspour analyser et évaluer les interventions représentent des procédures chirurgicalessurgical process sp qui sont formalisées comme des structures symboliquesdécrivant une chirurgie à un niveau de granularité donné un enjeu importantréside dans la définition de métriques permettant la comparaison et lévaluationde ces procédures ainsi les relations entre ces métriques et des donnéespréopératoires permettent de classer les chirurgies pour mettre en lumière desinformations sur la procédure ellemême mais également sur le comportementdu chirurgien dans ce papier nous étudions la classification automatique dunensemble de procédures chirurgicales en utilisant lalgorithme dynamic timewarping dtw pour calculer une mesure de similarité entre procédures chirurgicaleslutilisation de dtw permet de se concentrer sur les différents typesdactivité effectués pendant la procédure ainsi que sur leur séquencement touten réduisant les différences temporelles des expériences ont été menées sur 24procédures chirurgicales dhernie discale lombaire dans le but de discriminer leniveau dexpertise des chirurgiens à partir dune classification connue a laidedun algorithme de clustering hiérarchique utilisant dtw nous avons retrouvédeux groupes de chirurgiens présentant des niveaux dexpertise différents junioret senior\n",
      "clustering hiérarchique non paramétrique de données fonctionnelles\n",
      "dans cet article il est question de clustering de courbes nous proposonsune méthode non paramétrique qui segmente les courbes en clusters etdiscrétise en intervalles les variables continues décrivant les points de la courbele produit cartésien de ces partitions forme une grille de données qui est inféréeen utilisant une approche bayésienne de sélection de modèle ne faisant aucunehypothèse concernant les courbes enfin une technique de posttraitement visantà réduire le nombre de clusters dans le but daméliorer linterprétabilitédes clusters est proposée elle consiste à fusionner successivement et de façonoptimale les clusters ce qui revient à réaliser une classification hiérarchique ascendantedont la mesure de dissimilarité correspond à la variation du critèrede manière intéressante cette mesure est en fait une somme pondérée de divergencesde kullbackleibler entre les distributions des clusters avant et aprèsfusions lintérêt de lapproche dans le cadre de lanalyse exploratoire de donnéesfonctionnelles est illustré par un jeu de données artificiel et réel\n",
      "clustering multiniveaux de graphes  hiérarchique et topologique\n",
      "nan\n",
      "combinaison de classificateurs simples pour une sélection rapide de caractéristiques\n",
      "la sélection de caractéristiques est une technique permettant de choisirles caractéristiques les plus pertinentes celles adaptées à la résolution dunproblème particulier les méthodes classiques présentent certains inconvénientspar exemple elles peuvent être trop complexes elles peuvent faire dépendreles caractéristiques sélectionnées du classificateur utilisé elles risquent de sélectionnerdes caractéristiques redondantes dans le but de limiter ces inconvénientsnous proposons dans cet article une nouvelle méthode rapide de sélectionde caractéristiques basée sur la construction et la sélection de classificateurssimples associés à chacune des caractéristiques une optimisation par unalgorithme génétique est proposée afin de trouver la meilleure combinaison desclassificateurs différentes méthodes de combinaison sont considérées et adaptéesà notre problème cette méthode a été appliquée sur différents ensemblesde caractéristiques de tailles variées et construite à partir de la base de chiffresmanuscrits mnist les résultats obtenus montrent la robustesse de lapprocheainsi que lefficacité de la méthode en moyenne le nombre de caractéristiquessélectionnées a diminué de 699 tout en conservant le taux de reconnaissance\n",
      "combinaison de classification supervisée et nonsupervisée par la théorie des fonctions de croyance\n",
      "nous proposons dans cet article une nouvelle approche de classificationfondée sur la théorie des fonctions de croyance cette méthode repose surla fusion entre la classification supervisée et la classification non supervisée eneffet nous sommes face à un problème de manque de données dapprentissagepour des applications dont les résultats de classification supervisée et non superviséesont très variables selon les classificateurs employés les résultats ainsiobtenus sont par conséquent considérés comme incertainsnotre approche se propose de combiner les résultats des deux types de classificationen exploitant leur complémentarité via la théorie des fonctions de croyancecelleci permet de tenir compte de laspect dincertitude et dimprécision aprèsavoir dresser les différentes étapes de notre nouveau schéma de classificationnous détaillons la fusion de classificateurs cette nouvelle approche est appliquéesur des données génériques issues dune vingtaine de bases de donnéesles résultats obtenus ont montré lefficacité de lapproche proposée\n",
      "community detection in social networks with attribute and relationship data\n",
      "nan\n",
      "découverte de règles dassociation pour laide à la prévision des accidents maritimes\n",
      "les systèmes de surveillance maritime permettent la récupération et lafusion des informations sur les navires position vitesse etc à des fins de suividu trafic maritime sur un dispositif daffichage aujourdhui lidentification desrisques à partir de ces systèmes est difficilement automatisable comptetenu delexpertise à formaliser du nombre important de navires et de la multiplicité desrisques collision échouement etc de plus le remplacement périodique desopérateurs de surveillance complique la reconnaissance dévénements anormauxqui sont éparses et parcellaires dans le temps et lespace dans lobjectif de faireévoluer ces systèmes de surveillance maritime nous proposons dans cet articleune approche originale fondée sur le data mining pour lextraction de motifsfréquents cette approche se focalise sur des règles de prévision et de ciblagepour lidentification automatique des situations induisant ou constituant le cadredes accidents maritimes\n",
      "détection de groupes outliers en classification non supervisée\n",
      "nous proposons dans ce papier une nouvelle méthode de détection degroupes outliers notre mesure nommée gof group outlier factor est estiméepar lapprentissage nonsupervisé nous lavons intégré dans lapprentissage descartes topologiques notre approche est basée sur la densité relative de chaquegroupe de données et fournit simultanément un partitionnement des donnéeset un indicateur quantitatif gof sur la particularité de chaque cluster ougroupe les résultats obtenus sont très encourageants et prometteurs pour continuerdans cette optique\n",
      "détection non supervisée dune souspopulation par méthode densemble et changement de représentation itératif\n",
      "lapprentissage non supervisé a classiquement pour objectif la détectionde souspopulations homogènes classes considérées de manière équivalentesans information a priori sur cellesci le problème étudié dans cet articleest quelque peu distinct on se focalise ici uniquement sur une souspopulationdintérêt que lon cherche à identifier avec un rappel et une précision optimalesnous proposons pour cela une méthode sappuyant sur les principes suivants 1 travailler dans lespace de représentation fourni par des experts faibles pourcette tâche 2 confronter ces experts pour détecter des seuils de sélection pluspertinents et 3 les combiner itérativement afin de converger vers lexpert idéalcette méthode est éprouvée et comparée sur des données synthétiques\n",
      "development of a distributed recommender system using the hadoop framework\n",
      "producing high quality recommendations has become a challenge inthe recent years indeed the growth in the quantity of data involved in the recommendationprocess pose some scalability and effectiveness problems theseissues have encouraged the research of new technologies instead of developinga new recommender system we improve an already existing method a distributedframework was considered based on the known quality and simplicity ofthe mapreduce project the hadoop open source project played a fundamentalrole in this research it undoubtedly encouraged and facilitated the constructionof our application supplying all tools needed our main goal in this research wasto prove that building a distributed recommender system was not only possiblebut simple and productive\n",
      "evaluating bayesian networks by sampling with simplified assumptions\n",
      "the most common fitness evaluation for bayesian networks in the presence of data is the cooperherskovitz criterion this technique involves massive amounts of data and therefore expansive computations we propose a cheaper alternative evaluation method using simplified ssumptions which produces evaluations that are strongly correlated with the cooperherskovitz criterion\n",
      "evaluation rapide du diamètre dun graphe\n",
      "lors de lanalyse de graphes il est important de connaître leurs propriétésafin de pouvoir par exemple identifier leur structure et les comparerune des caractérisations importante de ces graphes repose sur le fait de déterminersil sagit ou non dun petit monde pour ce faire la valeur du diamètredu graphe est essentielle or la mesure du diamètre est pour un très grandgraphe une opération extrêmement longue nous proposons un algorithme endeux phases qui permet dobtenir rapidement une estimation du diamètre dungraphe avec une proportion derreur faible en réduisant cet algorithme à uneseule phase et en acceptant une marge derreur plus élevée nous obtenons uneestimation très rapide du diamètre nous testons cet algorithme sur deux grandsgraphes de terrain plus dun million de noeuds et comparons ses performancesavec celles dun algorithme de référence bfs breadthfirst search les résultatsobtenus sont décrits et commentés\n",
      "exploitation de lasymétrie entre termes pour lextraction automatique de taxonomies à partir de textes\n",
      "nous présentons dans cet article une nouvelle approche pour la générationautomatique de structures lexicales ou taxonomies à partir de textescette tâche est fondée sur lhypothèse forte selon laquelle laccumulation defaits statistiques simples sur les usages en corpus permet dapproximer des informationsde niveau sémantique sur le lexique nous utilisons la prétopologiecomme cadre de travail afin de formaliser et de combiner plusieurs hypothèsessur les usages terminologiques et enfin de structurer le lexique sous la formedune taxonomie nous considérons également le problème de lévaluation destaxonomies résultantes et proposons un nouvel indice afin de les comparer et depositionner notre approche par rapport à la littérature\n",
      "extraction dopinions appliquée à des critères\n",
      "les technologies de linformation et le succès des services associéseg blogs forums ont ouvert la voie à un mode dexpression massive dopinionssur les sujets les plus variés récemment de nouvelles techniques de détectionautomatique dopinions opinion mining ont fait leur apparition et viades analyses statistiques des avis exprimés tendent à dégager une tendance globaledes opinions exprimées par les internautes néanmoins une analyse plusfine de celleci montre que les arguments avancés par les internautes relèvent decritères de jugement distincts ici un film sera décrié pour un scénario décousulà il sera encensé pour une bande son époustouflante dans cet article nous proposonsaprès avoir caractérisé automatiquement des critères dans un documentden extraire lopinion relative a partir dun ensemble restreint de mots clésdopinions notre approche construit automatiquement une base dapprentissagede documents issus du web et en déduit un lexique de mots ou dexpressionsdopinions spécifiques au domaine dapplication des expériences menées surdes jeux de données réelles illustrent lefficacité de lapproche\n",
      "extraction de covariations entre des propriétés de sommets et leur position topologique dans un graphe attribué\n",
      "lanalyse de grands réseaux est très étudiée en fouille de donnéestoutefois les approches existantes proposent une analyse soit à un niveau macroscopiqueétude des propriétés globales comme la distribution des degréssoit à un niveau microscopique extraction de sousgraphes fréquents ou densesnous proposons une nouvelle méthode qui effectue une analyse intermédiairepermettant de découvrir des motifs regroupant des propriétés microscopiques etmacroscopiques du réseau ces motifs capturent des covariations entre des propriétésnumériques relatives aux sommets par exemple un motif mésoscopiquedans un réseau de coauteurs peut être plus le nombre de publications à egc estimportant plus la centralité des sommets correspondants dans le réseau lestégalement notre contribution est multiple dabord ce travail est le premierà exploiter conjointement des propriétés locales et des propriétés topologiquesde plus nous produisons de nouvelles avancées dans le domaine de lextractionde covariations en revisitant les motifs émergents dans ce contexte enfin nousrapportons une analyse dun réseau bibliographique réel issu de dblp\n",
      "extraction de dépendances fonctionnelles approximatives\n",
      "la découverte de dépendances fonctionnelles df à partir dune relationexistante est une technique importante pour lanalyse de bases de donnéeslensemble des df exactes ou approximatives extraites par les algorithmes existantsest valide tant que la relation nest pas modifiée ceci est insuffisant pourdes situations réelles où les relations sont constamment mises à journous proposons une approche incrémentale qui maintiens à jour lensemble desdf valides exactes ou approximatives selon une erreur donnée quand des tuplessont insérés et supprimés les résultats expérimentaux indiquent que lors de lextractionde df à partir dune relation continuellement modifiée les algorithmesexistants sont sensiblement dépassés par notre stratégie incrémentale\n",
      "extraction de liens fréquents dans les réseaux sociaux\n",
      "cet article présente flmin une nouvelle méthode dextraction de motifsfréquents dans les réseaux sociaux contrairement aux méthodes traditionnellesqui sintéressent uniquement aux régularités structurelles loriginalité denotre approche réside dans sa capacité à exploiter la structure et les attributs desnoeuds pour extraire des régularités que nous appelons “liens fréquents” dansles liens entre des noeuds partageant des caractéristiques communes\n",
      "extraction de séquences fréquentes avec intervalles dincertitude\n",
      "lors de lextraction des séquences la granularité temporelle est plusou moins importante selon les besoins des utilisateurs et les contraintes du domainedapplication nous proposons un algorithme dextraction de séquencesfréquentes par intervalles à partir de séquences à estampilles temporelles discrètesnous intégrons une relaxation des contraintes temporelles en introduisantla définition de séquences temporelles par intervalles sti ces intervalles reflètentune incertitude sur les occurrences précises des évènements nous formalisonsce nouveau concept en exhibant certaines de ses propriétés et nous menonsquelques expériences afin de comparer qualitativement nos résultats avec uneautre proposition assez proche de la nôtre\n",
      "extraction de sousparties ciblées dune ontologie généraliste pour enrichir une ontologie particulière\n",
      "différentes ressources ontologiques généralistes de très grande tailleont été développées de façon collective et sont aujourdhui disponibles sur leweb ainsi lontologie yago est une énorme base de connaissances décrivantplus de 2 millions dentités afin de tirer parti de ce gigantesque travail collectifnous montrons comment en extraire des sousparties thématiquement focaliséespour enrichir une autre ontologie dite cible de taille plus limitée mais de domainecentré sur une application particulière 1\n",
      "extraction et gestion dinformations pour la construction dune base vidéo dapprentissage\n",
      "indexer une vidéo consiste à rattacher un ou plusieurs concepts à dessegments de cette vidéo un concept étant défini comme une représentation intellectuelledune idée abstraite lindexation automatique se base sur lextractionautomatique de caractéristiques fournies par un système de traitement dimagescependant il est nécessaire de définir les index ou concepts pour cela il fautdéfinir le lien qui existe entre ces caractéristiques et ces concepts ce qui sépareles caractéristiques extraites sur lesquelles se base lindexation automatique etles concepts est appelé fossé sémantique qui est le manque de concordance entreles informations que les machines peuvent extraire depuis les documents numériqueset les interprétations que les humaines en font la définition dun conceptpeut être faite automatiquement si lon dispose dune base dapprentissage liéeau concept dans ce cas il est possible dapprendre le concept de manièrestatistique mais la construction de cette base dapprentissage nécessite de faireintervenir un utilisateur ou un expert applicatif en fait il sagit de sappuyer surses connaissances pour extraire des segments vidéo représentatifs du conceptque lon souhaite définir on peut lui demander dindexer manuellement la basedapprentissage mais cette opération est longue et fastidieuse dans cet articlenous proposons une méthode qui permet dextraire lexpertise pour que limplicationde lexpert soit la plus simple et la plus limitée possible\n",
      "extraction incrémentale de séquences fréquentes dans un flux ditemsets\n",
      "nan\n",
      "human detection by a small autonomous mobile robot\n",
      "nous proposons une méthode utilisant les histogrammes de gradientorienté hog et les séparateurs à vaste marge svm pour la détection de personnesà partir dimages prises depuis un petit robot mobile autonome les travauxantérieurs réalisés dans le domaine de la détection dêtres humains à partirdimages ne peuvent pas être employés pour ce type dapplication car ils supposentque les images sont prises à partir dune position élevée au moins lahauteur dun petit enfant alors que la taille de notre robot nest que de 15cmnous employons à la fois les hog et les svm car cette combinaison de méthodesest reconnue comme étant celle ayant le plus de succès pour la détectionde personnes pour traiter une grande variété de formes humaines principalementen raison de la distance existant entre les personnes et le robot nous avonsdéveloppé une nouvelleméthode de prédiction à deux étapes utilisant deux typesde classificateurs svm qui reposent sur une estimation de la distance lestimationest basée sur une proportion de pixels de couleur de peau dans limage cequi nous permet de clairement séparer notre problème de la détection de corpsentier et de celle de corps partiel les essais réalisés dans un bureau ont montrédes résultats prometteurs de notre méthode avec une valeur de f de 093\n",
      "identification et caractérisation de différents types de boycott par des méthodes danalyse de données\n",
      "nan\n",
      "kmoyennes contraintes par un classifieur application à la personnalisation de scores de campagnes\n",
      "lorsquon désire contacter un client pour lui proposer un produit oncalcule au préalable la probabilité quil achètera ce produit cette probabilitéest calculée à laide dun modèle prédictif pour un ensemble de clients le servicemarketing contacte ensuite ceux ayant la plus forte probabilité dacheter leproduit en parallèle et avant le contact commercial il peut être intéressant deréaliser une typologie des clients qui seront contactés lidée étant de proposerdes campagnes différenciées par groupe de clients cet article montre commentil est possible de contraindre la typologie réalisée à laide des kmoyennes àrespecter la proximité des clients visàvis de leur score dappétence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lextraction de règles de dépendance bien définies entre ensembles de variables multivaluées\n",
      "cet article étudie la faisabilité et lintérêt de lextraction de règles dedépendance entre ensembles de variables multivaluées en comparaison du problèmebien connu de lextraction des règles dassociation fréquentes une règlede dépendance correspond à une dépendance fonctionnelle approximative caractériséeprincipalement par lentropie conditionnelle associée larticle montrecomment établir une analogie formelle entre les deux familles de règles et commentadapter à laide de cette analogie lalgorithme « eclat » afin dextraire dunjeu de données les règles de dépendance dites bien définies une étude expérimentaleconclut sur les forces et inconvénients des règles de dépendance biendéfinies visàvis des règles dassociation fréquentes\n",
      "métarègles pour la génération de règles négatives\n",
      "la littérature sest beaucoup intéressée à lextraction de règles classiquesou positives et peu à lextraction des règles négatives en raison essentiellementdune part du coût de calculs et dautre part du nombre prohibitif derègles redondantes et inintéressantes extraites la démarche que nous avons retenueest de dégager les règles négatives lors de lextraction des règles positiveset pour cela nous recherchons les règles négatives que lon peut inférer ou pas àpartir de la pertinence dune règle positive ces différentes inférences vont êtreformalisées par un ensemble de métarègles\n",
      "mining genetic interactions in genomewide association study\n",
      "advanced biotechnologies have rendered feasible highthroughput data collecting in human and other model organisms the availability of such data holds promise for dissecting complex biological processes making sense of the flood of biological data poses great statistical and computational challenges i will discuss the problem of mining genegene interactions in highthroughput genetic data finding genetic interactions is an important biological problem since many common diseases are caused by joint effects of genes previously it was considered intractable to find genetic interactions in the wholegenome scale due to the enormous search space the problem was commonly addressed using heuristics which do not guarantee the optimality of the solution i will show that by utilizing the upper bound of the test statistic and effectively indexing the data we can dramatically prune the search space and reduce computational burden moreover our algorithms guarantee to find the optimal solution in addition to handling specific statistical tests our algorithms can be applied to a wide range of study types by utilizing convexity a common property of many commonly used statistics\n",
      "modèle de supervision dinteractions nonintrusif basé sur les ontologies\n",
      "lautomatisation et la supervision des systèmes pervasifs est à lheureactuelle principalement basée sur lutilisation massive de capteurs distribuésdans lenvironnement dans cet article nous proposons un modèle de supervisiondinteractions basé sur lanalyse sémantique des logs domotiques commandesémises par lutilisateur visant à limiter lutilisation de ces capteurs le principe est dutiliser des outils dinférences avancés afin de déduire les informationshabituellement captées pour cela une ontologie automatiquementdérivée dun processus dirigé par les modèles définit les interactions utilisateursystèmelutilisation dun système de règles permet ensuite dinférer des informationssur la localisation et lintention de lutilisateur dans le but de réaliserdu monitoring et de proposer des services domotiques adaptés\n",
      "pls path modeling and regularized generalized canonical correlation analysis for multiblock data analysis\n",
      "regularized generalized canonical correlation analysis rgcca is a generalization of regularizedcanonical correlation analysis to three or more sets of variables it constitutes a generalframework for many multiblock data analysis methods it combines the power of multiblockdata analysis methods maximization of well identified criteria and the flexibility of pls pathmodeling the researcher decides which blocks are connected and which are not searchingfor a fixed point of the stationary equations related to rgcca a new monotone convergentalgorithm very similar to the pls algorithm proposed by herman wold is obtained finallya practical example is discussed\n",
      "prétraitement supervisé des variables numériques pour la fouille de données multitables\n",
      "le prétraitement des variables numériques dans le contexte de lafouille de données multitables diffère de celui des données classiques individuvariablela difficulté vient principalement des relations unàplusieurs où lesindividus de la table cible sont potentiellement associés à plusieurs enregistrementsdans des tables secondaires dans cet article nous décrivons une méthodede discrétisation des variables numériques situées dans des tables secondairesnous proposons un critère qui évalue les discrétisations candidates pour ce typede variables nous décrivons un algorithme doptimisation simple qui permetdobtenir la meilleure discrétisation en intervalles de fréquence égale pour lecritère proposé lidée est de projeter dans la table cible linformation contenuedans chaque variable secondaire à laide dun vecteur dattributs un attributpar intervalle de discrétisation chaque attribut représente le nombre de valeursde la variable secondaire appartenant à lintervalle correspondant ces attributsdeffectifs sont conjointement partitionnés à laide de modèles en grille de donnéesafin dobtenir une meilleure séparation des valeurs de la classe des expérimentationssur des jeux de données réelles et artificielles révèlent que lapprochede discrétisation permet de découvrir des variables secondaires pertinentes\n",
      "raisonner sur une ontologie cartographique pour concevoir des légendes de cartes\n",
      "concevoir une carte géographique plus particulièrement sa légendeexige des compétences spécifiques lobjectif de ce papier est de présenter unebase de connaissances destinée à aider tout utilisateur à concevoir une ou plusieurslégendes adaptées à son besoin et conformes aux règles de cartographiela base de connaissances est formée dune ontologie de la cartographie nomméeontocarto dun corpus de règles  ontocartorules et dun moteur de raisonnement corese dans ce papier chaque demande de conception de légende estvue comme une instanciation particulière de lontologie associée à une sélectionde règles pertinentes dans le corpus de règles sur laquelle corese va raisonnerpour construire des légendes adaptées à la configuration spécifique traitée laconception de la légende sappuie sur la définition de deux hiérarchies dobjetsgéographiques et cartographiques les principes de fonctionnement de coresesont présentés un prototype a été implémenté et des extraits des résultats sontmontrés\n",
      "recherche dinformation agrégée dans des documents xml basée sur les réseaux bayésiens\n",
      "dans cet article nous nous intéressons à la recherche agrégée dansdes documents xml pour cela nous proposons un modèle basé sur les réseauxbayésiens les relations de dépendances entre requêtetermes dindexation ettermes dindexationéléments sont quantifiées par des mesures de probabilitédans ce modèle la requête de lutilisateur déclenche un processus de propagationpour trouver des éléments ainsi au lieu de récupérer une liste des élémentsqui sont susceptibles de répondre à la requête notre objectif est dagréger dansun agrégat des éléments pertinents nonredondants et complémentaires nousavons évalué notre approche dans le cadre de la compagne dévaluation inex2009 et avons présenté quelques résultats expérimentaux mettant en évidencelimpact de lagrégation de tels éléments\n",
      "relational learning from spatial data retrospect and prospect\n",
      "learning from spatial data is characterized by two main features first spatial objects have a locational property which implicitly defines several spatial relationships topological directional distancebased between objects second attributes of spatially related units tend to be statistically correlated these two features argue against the assumption of the independent generation of data samples iid assumption underlying classic machine learning algorithms and motivate the application of relational learning algorithms whose inferences are based on both instance properties and relations between data this relational learning approach to spatial domains has already been investigated in the last decade and important accomplishments in this direction have already been performed in this talk we retrospectively survey major achievements on relational learning from spatial data and we report open problems which still challenges researchers and prospectively suggest important topics for incorporation into a research agenda\n",
      "réorganisation hiérarchique de visualisations dans olap\n",
      "dans cet article nous proposons un nouvel algorithme pour la réorganisationhiérarchique des cubes olap online analytical processing ayantpour objectif daméliorer leur visualisation cet algorithme se caractérise par lefait quil peut traiter des dimensions organisées hiérarchiquement et optimiserconjointement les dimensions du cube contrairement aux autres approches ilutilise un algorithme génétique qui réorganise des arbres naires quelconques ila été intégré dans une interface olap puis testé en comparaison avec dautresapproches de réorganisation et fournit des résultats très positifs a ce titrenous avons également généralisé lalgorithme heuristique classique bea bondenergy algorithm au cas de hiérarchies olap enfin notre approche a été évaluéepar des utilisateurs et les résultats soulignent lintérêt de la réorganisationdans des exemples de tâches à résoudre pour olap\n",
      "représentations de services web  impact sur la découverte et la recommandation\n",
      "nan\n",
      "ricsh  recherche dinformation contextuelle par segmentation thématique de documents\n",
      "le but principal des systèmes de recherche dinformations sri classiquesest de retrouver dans un corpus de documents linformation considéréecomme pertinente pour une requête utilisateur cette pertinence est souvent liéeà la fréquence dapparition des termes dans le texte par rapport au corpus sanstenir compte du contexte de la recherche partant de ce constat nous proposonsdans cet article une approche pour la recherche dinformation contextuelle parsegmentation thématique de documents ricsh cette approche sappuie surla méthode de pondération tfidf que nous avons adaptée dans notre cas pourindexer le corpus cette adaptation se situe au niveau de limportance du termeet de son pouvoir de discrimination par rapport aux fragments de textes et nonau corpus ces fragments sont obtenus grâce à un processus didentification desunités thématiques les plus pertinentes pour chaque document\n",
      "sélection bayésienne de modèles avec prior dépendant des données\n",
      "cet article analyse la consistance asymptotique des modèles en grilleappliqués à lestimation de densité jointe de deux variables catégorielles lesmodèles en grille considèrent un partitionnement des valeurs de chacune des variablesle produit cartésien des partitions formant une grille dont les cellulespermettent de résumer la table de contingence des deux variables le meilleurmodèle de copartitionnement est recherché au moyen dune approche mapmaximum a posteriori présentant la particularité peu orthodoxe dexploiterune famille de modèles et une distribution a priori de ces modèles qui dépendentdes données ces modèles sont par nature des modèles de léchantillon dapprentissageet non de la distribution sousjacente nous démontrons la consistancede lapproche qui se comporte comme un estimateur universel de densité jointeconvergeant asymptotiquement vers la vraie distribution jointe\n",
      "solving problems with visual analytics challenges and applications\n",
      "never before in history data is generated and collected at such high volumes as it is today as the volumes of data available to business people scientists and the public increasetheir effective use becomes more challenging keeping up to date with the flood of datausing standard tools for data analysis and exploration is fraught with difficulty the field ofvisual analytics seeks to provide people with better and more effective ways to understandand analyze large datasets while also enabling them to act upon their findings immediately visual analytics integrates the analytic capabilities of the computer and the abilities of the human analyst allowing novel discoveries and empowering individuals to take control of the analytical process visual analytics enables unexpected and hidden insights which may lead to beneficial and profitable innovation the talk presents the challenges of visual analytics and exemplifies them with application examples illustrating the exiting potential of current visual analysis techniques\n",
      "structuration des décisions de jurisprudence basée sur une ontologie juridique en langue arabe\n",
      "linformatique juridique est un domaine en évolution constante lecontexte général de notre travail est lélaboration dun système de recherchede jurisprudence tunisienne en langue arabe lobjectif opérationnel de ce systèmeest de fournir une aide aux juristes pour résoudre une situation juridiquedonnée en mettant à leur disposition une collection de situations similaires cequi améliorera leur raisonnement futur une ontologie du domaine juridiqueconstruite à partir des documents des décisions juridiques est nécessaire dansnotre contextecette ontologie a pour but  i la structuration des décisions iila formulation des requêtes dinterrogation de la base des décisions et iii larecherche des décisions dans cet article nous présentons larchitecture de notresystème de recherche de jurisprudence nous nous focalisons sur lontologie dudomaine de jurisprudence que nous avons élaborée aisni que sur le module destructuration des décisions\n",
      "sweetdeki  le wiki sémantique couteau suisse du réseau social isicil\n",
      "le projet anr isicil 1 mixe les nouvelles applications virales duweb avec des représentations formelles et des processus dentreprise pour les intégrerdans les pratiques de veille en entreprise les outils développés sappuientsur les interfaces avancées des applications du web 20 blog wiki social bookmarkingextensions de navigateurs pour les interactions et sur les technologiesdu web sémantique pour linteropérabilité et le traitement de linformation leprésent article décrit plus précisément le wiki sémantique développé dans lecadre de ce projet et son intégration au coeur du framework isicil\n",
      "tmdminer  une nouvelle approche pour la détection des diffuseurs dans un système communautaire\n",
      "plusieurs méthodes ont été développées ces dernières années pour détecterdans un réseau social les membres qualifiés selon les auteurs dinfluenceursde médiateurs dambassadeurs ou encore dexperts dans cet article nousproposons un nouveau cadre méthodologique permettant didentifier des diffuseursdans le contexte où seule linformation sur lappartenance des membres duréseau à des communautés est disponible ce cadre basé sur une représentationdu réseau sous forme dhypergraphe nous a permis de formaliser la notion dediffuseur et dintroduire lalgorithme tmdminer dédié à la détection des diffuseurset basé sur les itemsets essentiels\n",
      "topological decomposition and heuristics for high speed clustering of complex networks\n",
      "with the exponential growth in the size of data and networks developmentof new and fast techniques to analyze and explore these networks isbecoming a necessity moreover the emergence of scale free and small worldproperties in real world networks has stimulated lots of activity in the field ofnetwork analysis and data mining clustering remains a fundamental techniqueto explore and organize these networks a challenging problem is to find a clusteringalgorithm that works well in terms of clustering quality and is efficient interms of time complexityin this paper we propose a fast clustering algorithm which combines someheuristics with a topological decomposition to obtain a clustering the algorithmwhich we call topological decomposition and heuristics for clusteringtdhc is highly efficient in terms of asymptotic time complexity as comparedto other existing algorithms in the literature we also introduce a number ofheuristics to complement the clustering algorithm which increases the speed ofthe clustering process maintaining the high quality of clustering we show theeffectiveness of the proposed clustering method on different real world data setsand compare its results with well known clustering algorithms\n",
      "transformation de lespace de description pour lapprentissage par transfert\n",
      "dans ce papier nous proposons une étude sur lutilisation de lapprentissagetopologique pondéré et les méthodes de factorisation matricielle pourtransformer lespace de représentation dun jeu de données sparse afin daugmenterla qualité de lapprentissage et de ladapter au cas de lapprentissagepar transfert la factorisation matricielle nous permet de trouver des variableslatentes et lapprentissage topologique pondéré est utilisé pour détecter les pluspertinentes parmi cellesci la représentation de nouvelles données est basée surleurs projections sur le modèle topologique pondérépour lapprentissage par transfert nous proposons une nouvelle méthode où lareprésentation des données est faite de la même manière que dans la premièrephase mais en utilisant un modèle topologique élaguéles expérimentations sont présentées dans le cadre dun challenge internationaloù nous avons obtenu des résultats prometteurs 5ieme rang de la compétitioninternationale1 introduction\n",
      "un algorithme de classification automatique pour des données relationnelles multivues\n",
      "classification automatique de carvalho et al 2012 capable de partitionnerdes objets en prenant en compte de manière simultanée plusieurs matricesde dissimilarité qui les décrivent ces matrices peuvent avoir été généréesen utilisant différents ensembles de variables et de fonctions de dissimilaritécette méthode basée sur lalgorithme de nuées dynamiques est conçu pour fournirune partition et un prototype pour chaque classe tout en découvrant une pondérationpertinante pour chaque matrice de dissimilarité en optimisant un critèredadéquation entre les classes et leurs représentants ces pondérations changentà chaque itération de lalgorithme et sont différentes pour chacune des classesnous présentons aussi plusieurs outils daide à linterprétation des groupes et dela partition fournie par cette nouvelle méthode deux exemples illustrent linterêtde la méthode le premier utilise des données concernant des chiffres manuscrits0 à 9 numérisés en images binaires provenant de luci le second utilise unensemble de rapports dont nous connaissons une classification experte donnée àpriori\n",
      "un assistant utilisateur pour le choix et le paramétrage des méthodes de fouille visuelle de données\n",
      "nous nous intéressons dans cet article au problème de lautomatisation du processus de choix et de paramétrage des visualisations en fouille visuelle de données pour résoudre ce problème nous avons développé un assistant utilisateur qui effectue deux étapes  à partir des objectifs annoncés par lutilisateur et des caractéristiques de ses données le système commence par proposer à lutilisateur différents appariements entre la base de données à visualiser et les visualisations quil gère ces appariements sont générés par une heuristique utilisant une base de connaissances sur les visualisations et la perception visuelle ensuite afin daffiner les différents paramétrages suggérés par le système nous utilisons un algorithme génétique interactif qui permet aux utilisateurs dévaluer et dajuster visuellement ces paramétrages nous présentons une évaluation utilisateur qui montre lintérêt de notre système pour deux tâches\n",
      "un environnement efficace pour la classification dimages à grande échelle\n",
      "la plupart des processus de classification dimages comportent troisprincipales étapes  lextraction de descripteurs de bas niveaux la création dunvocabulaire visuel par quantification et lapprentissage à laide dun algorithmede classification egsvm de nombreux problèmes se posent pour le passageà léchelle comme avec lensemble de données imagenet contenant 14 millionsdimages et 21841 classes la complexité concerne le temps dexécution dechaque tâche et les besoins en mémoire et disque eg le stockage des sifts nécessite11to nous présentons une version parallèle de libsvm pour traiter degrands ensembles de données dans un temps raisonnable de plus il y a beaucoupde perte dinformation lors de la phase de quantification et les mots visuelsobtenus ne sont pas assez discriminants pour de grands ensembles dimagesnous proposons dutiliser plusieurs descripteurs simultanément pour améliorerla précision de la classification sur de grands ensembles dimages nous présentonsnos premiers résultats sur les 10 plus grandes classes 24817 imagesdimagenet\n",
      "une approche multidimensionnelle basée sur les comportements individuels pour la prédiction de la diffusion de linformation sur twitter\n",
      "aujourdhui les réseaux sociaux en ligne sont devenus des outils trèspuissants de propagation de linformation ils favorisent la diffusion rapide àgrande échelle de contenu et les conséquences dune information inexacte voirefausse peuvent alors prendre une ampleur considérable par conséquent il devientindispensable de proposer des moyens danalyser le phénomène de diffusionde linformation dans ces réseaux de nombreuses études récentes ont traitéde la modélisation du processus de diffusion de linformation essentiellementdun point de vue topologique et dans une perspective théorique mais les facteursimpliqués sont encore méconnus nous proposons ici une solution pratiquedont lobjectif est de prédire la dynamique temporelle de la diffusion au sein detwitter basée sur des techniques dapprentissage automatique notre approcherepose sur linférence de probabilités de diffusion tirées dune analyse multidimensionnelledes comportements individuels les expérimentations menéesmontrent lintérêt de la modélisation proposée\n",
      "une distance hiérarchique basée sur la sémantique pour la comparaison dhistogrammes nominaux\n",
      "la plupart des distances entre histogrammes sont définies pour comparerdes histogrammes ordonnés dont les entités représentées sont totalementordonnées ou des histogrammes nominaux dont les entités représentées nepeuvent pas être comparées cependant il nexiste aucune distance qui permettede comparer des histogrammes nominaux dans lesquels il est possible dequantifier des valeurs de proximité sémantique entre les entités considérées cetarticle propose une nouvelle distance permettant de pallier ce problème dans unpremier temps une hiérarchie dhistogrammes obtenue par le biais dune fusionprogressive des entités considérées prenant en compte leurs proximités sémantiquesest construite pour chaque étage de cette hiérarchie une distance standardde comparaison dhistogrammes nominaux est calculée finalement pourobtenir la distance proposée ces différentes distances sont fusionnées en prenanten compte la cohérence sémantique associée aux niveaux de chaque étage de lahiérarchie cette distance a été validée dans le cadre de la classification de donnéesgéographiques les résultats obtenus sont encourageants et montrent ainsilintérêt et lutilité de cette dernière pour des processus de fouille de données\n",
      "user evaluation why\n",
      "research in information visualisation has changed significantly in the past two decadesonce it was sufficient to simply design and implement an impressive visualisation systemtoday editors and reviewers expect papers to present not only a novel system but empiricalevidence of its worth why has this change come about and what impact has it had on thoseworking in this area this talk will discuss how a field dominated by algorithms and toolsbecame infected by human participants and why this is a positive development in a maturingresearch discipline\n",
      "utilisation dinvariants pour une médiation interdomaines de modèles utilisateurs  ressources invariantes et invariants sémantiques\n",
      "les services de personnalisation du web 20 reposent sur lexploitationde modèles utilisateurs schématiquement plus la quantité dinformationssur les utilisateurs est grande meilleures sont la modélisation et la qualité du serviceen pratique nombre de services rencontrent un problème de manque dinformationssur les utilisateurs dans cet article nous y répondons par médiationinterdomaines de modèles utilisateurs cestàdire la complétion de modèles enexploitant des données dun autre domaine la médiation que nous proposonsrepose sur un transfert dinformations interdomaines ce transfert consiste enlutilisation de couples invariants ou très corrélés pouvant être des couples deressources ou de descripteurs sémantiques identifiés après enrichissement sémantiquedes modèles nous montrons que le transfert sous forme de couple deressources permet une complétion de qualité et que lexploitation de descripteurssémantiques augmente la couverture à qualité égale enrichir sémantiquementest donc bénéfique pour le transfert interdomaines\n",
      "validation et optimisation dune décomposition hiérarchique de graphes\n",
      "de nombreux algorithmes de fragmentation de graphes fonctionnentpar agrégations ou divisions successives de sousgraphes menant à une décompositionhiérarchique du réseau étudié une question importante dans ce domaineest de savoir si cette hiérarchie reflète la structure du réseau ou si elle nestquun artifice lié au déroulement de la procédure nous proposons un moyen devalider et au besoin doptimiser la décomposition multiéchelle produite parce type de méthode on applique notre approche sur lalgorithme proposé parblondel et al 2008 basé sur la maximisation de la modularité dans ce cadreune généralisation de cette mesure de qualité au cas multiniveaux est introduitenous testons notre méthode sur des graphes aléatoires ainsi que sur des exemplesréels issus de divers domaines\n",
      "vers la construction dun observatoire des pratiques agricoles  gestion et propagation de limprécision des données agronomiques\n",
      "lun des objectifs dobservox est de traiter et gérer limprécisiondes données agronomiques tant spatialement parcelles agricoles et quantitativementquantités de produits disséminées et de toujours associer une évaluationde la qualité aux données aussi nous avons choisi le cadre théorique desensembles flous a partir dun modèle conceptuel gérant limperfection nousconstruisons une base de données gérant des entités spatiotemporelles imprécisesappelées « entités agronomiques floues » cependant ce choix de représentationrend possible le chevauchement des composantes spatiales entre entitésdans ce cas nous propageons limprécision du spatial vers le quantitatif àlaide dun opérateur de caractère additif qui prend en compte à la fois linformationspatiale et quantitative et qui fournit une information quantitative localeet floue le système ainsi construit nous permet dobtenir une représentationfloue des quantités de produits phytosanitaires disséminés à chaque endroit duterritoire étudié\n",
      "vers une approche efficace dextraction de motifs spatioséquentiels\n",
      "ces dernières années laugmentation de la quantité dinformationsspatiotemporelles stockées dans les bases de données a fait naître de nouveauxbesoins notamment en matière de gestion des risques naturels sanitaires ou anthropiquesp ex compréhension de la dynamique dune épidémie de denguedans cet article nous définissons un cadre théorique pour lextraction de motifsspatioséquentiels séquences de motifs spatiaux représentant lévolution dansle temps dune localisation et de son voisinage nous proposons un algorithmedextraction efficace qui effectue un parcours en profondeur en sappuyant surdes projections successives de la base de données nous introduisons égalementune mesure dintérêt adaptée aux aspects spatiotemporels de ces motifs les expérimentationsréalisées sur des jeux de données réels soulignent la pertinencede lapproche proposée par rapport aux méthodes de la littérature\n",
      "vers une méthode automatique de construction de hiérarchies contextuelles\n",
      "dans de nombreux domaines eg fouille de données entrepôts dedonnées lexistence de hiérarchies sur certains attributs peut être extrêmementutile dans le processus analytique toutefois cette connaissance nest pas toujoursdisponible ou adaptée il est alors nécessaire de disposer dun processusde découverte automatique pour palier ce problème dans cet article nous combinonset adaptons des techniques issues de la théorie de linformation et duclustering pour proposer une technique orientée données de construction automatiquede taxonomies les deux principaux avantages dune telle approchesont son caractère totalement nonsupervisé et labsence de paramètre utilisateurà spécifier afin de valider notre approche nous lavons appliquée sur desdonnées réelles et avons conduit plusieurs types dexpérimentation dabordles hiérarchies obtenues ont été expertisées pour en examiner le pouvoir informatifensuite nous avons évalué lapport de ces taxonomies comme support àdes tâches de fouille de données nécessitant une définition hiérarchique des valeursdattributs  lextraction de séquences fréquentes multidimensionnelles etmultiniveaux ainsi que la construction de résumés de tables relationnelles lesrésultats obtenus permettent de conclure quant à lintérêt de notre approche\n",
      "webmarks  le marquage dintérêt sur le web de données\n",
      "depuis son apparition au sein du w3c la définition de la ressourceweb na cessé dévoluer au delà du simple document lieu service conceptdontologie représentation dun objet réel ou non la ressource web est complexeet il nous a semblé que les outils à disposition des internautes pour sa manipulationcomme les bookmarks par exemple nexploitaient pas pleinementces nouvelles dimensions dans cet article nous présenterons le modèle webmarksqui permet de préciser lobjet du marquage la ressource mais égalementlintérêt de lauteur de la marque limplémentation de ce modèle au sein duprojet isicil sera également présentée et nous discuterons de son apport encomparaison des technologies existantes\n",
      "krex  une méthode de construction des connaissances pour la maîtrise des activités à risques  application au domaine de la sécurité nucléaire\n",
      "dans les industries à risque comme le nucléaire les connaissances liées au savoir et à lexpérience participent à la maîtrise des activités elles sont explicites formalisables dans des documents ou tacites expression du savoir faire moins souvent prise en compte areva développe la méthode krex pour valoriser le retour dexpérience existant créer une dynamique dextraction et de capitalisation des connaissances faciliter leur partage et leur enrichissement cette communication décrit le protocole expérimental de construction des connaissances explicites et tacites du métier sécurité nucléaire\n",
      "a la recherche des tweets porteurs dinformations journalistiques\n",
      "nan\n",
      "acquisition de structures lexicosémantiques à partir de textes  un nouveau cadre de travail fondé sur une structuration prétopologique\n",
      "les structures lexicosémantiques jouent un rôle essentiel dans les processus de fouille de textes en codant les relations sémantiques entre concepts du discours elles apportent une connaissance stratégiques pour enrichir les capacités de raisonnement le développement de telles structures étant fortement limité du fait des efforts nécessaires à leur construction nous proposons un nouveau formalisme dacquisition automatique dontologies terminologiques à partir de textes nous utilisons pour cela une formalisation prétopologique de lespace des termes sur laquelle sappuie un modèle générique de structuration nous présentons une étude empirique préliminaire rendant compte du potentiel de ce modèle en terme dextraction de connaissances\n",
      "adaptation de lalgorithme cart pour la tarification des risques en assurance nonvie\n",
      "les développements récents en tarification de lassurance nonvie se concentrent majoritairement sur la maîtrise et lamélioration des modèles linéaires généralisés performants ces modèles imposent cependant à la fois des contraintes sur la structure du risque modélisé et sur les interactions entre variables explicatives du risque ces restrictions peuvent conduire dans certaines souspopulations dassurés à une estimation biaisée de la prime dassurance les arbres de régression permettent de saffranchir de ces contraintes et de plus augmentent la lisibilité des résultats de la tarification nous présentons une modification de lalgorithme cart pour prendre en compte les spécificités des données dassurance nonvie nous comparons alors notre proposition aux modèles linéaires généralisés sur un portefeuille réel de véhicules notre proposition réduit les mesures derreur entre le risque mesuré et le risque modélisé et permet ainsi une meilleure tarification\n",
      "agrégation robuste de données massives à la volée  application aux compteurs électriques communicants\n",
      "dans les années à venir plusieurs millions de compteurs électriques communicants seront déployés sur lensemble du territoire français afin dassurer la fiabilité dun réseau de cette envergure nous proposons une topologie de communication multichemins qui repose sur la duplication des données transmises toute exploitation des données collectées doit alors tenir compte de la présence déléments dupliqués dans cet article nous proposons une nouvelle méthode permettant de calculer en ligne des consommations électriques agrégées agrégation spatiale lidée est dadapter lalgorithme probabiliste summation sketch de considine et al au contexte des compteurs communicants cette approche a lavantage dêtre insensible à la duplication et permet de profiter de la structure massivement distribuée du réseau de communication des futurs compteurs électriques lexpérimentation de cette méthode sur des données réelles montre quelle donne une bonne précision sur lestimation des consommations agrégées cette approche est aussi complétée par une méthode basée sur la théorie des sondages  on obtient une meilleure réactivité de lestimateur avec rapidement et donc sur des données significativement partielles une erreur inférieure à 25\n",
      "aide à lanalyse visuelle de réseaux sociaux pour la détection de comportements suspects\n",
      "cet article traite de lanalyse visuelle de réseaux sociaux pour la détection de comportements suspects à partir de données de communications fournies à des enquêteurs suivant deux procédures  linterception légale et la rétention de données nous proposons les contributions suivantes  i un modèle de données et un ensemble dopérateurs pour interroger ces données dans le but dextraire des comportements suspects et ii une représentation visuelle conviviale pour une navigation simplifiée dans les données de communication accompagnée avec une implémentation\n",
      "algorithmes de recherche exhaustif et guidé pour la recommandation dun expert dans un réseau professionnel\n",
      "nan\n",
      "analyse comparative de méthodologies et doutils de construction automatique dontologies à partir de ressources textuelles\n",
      "plusieurs méthodologies et outils de construction automatique des ontologies à partir de ressources textuelles ont été proposés ces dernières années dans cet article nous analysons quatre approches en les comparant à une approche de référence – methontology dans leur sélection nous avons privilégié celles qui couvrent lensemble des étapes du processus de construction dontologies puis nous analysons et comparons la portée les limites et les performances des implémentations logicielles associées aux approches analysées ces outils ont été testés sur un corpus de ressources textuelles et nous avons comparé leurs résultats à ceux obtenus manuellement\n",
      "analyse du comportement limite dindices probabilistes pour une sélection discriminante\n",
      "nous étudions ici le comportement de deux types dindices probabilistes discriminants en présence de données dont le volume va en croissant a cet égard un modèle spécifique de croissance de la taille des données et de liaison entre variables est mis en œuvre et celuici va permettre de déterminer le comportement limite des différents indices quel que soit le niveau de liaison entre la prémisse et la conclusion de la règle donnée la clarté des résultats obtenus nous conduit à en chercher lexplication formelle lexpérimentation a été effectuée avec la base de données uci wages\n",
      "analyse factorielle des correspondances hiérarchique pour la fouille dimages\n",
      "nous proposons un outil graphique interactif qui permet de visualiser et dextraire des connaissances à partir des résultats de lanalyse factorielle des correspondances afc sur les images lafc est une technique descriptive développée pour analyser des tableaux de contingence lafc est originellement utilisée dans lanalyse des données textuelles adt où le corpus est représenté par un tableau de contingence croisant des documents et des mots dans la fouille dimages nous définissons dabord les « mots visuels » dans les images analogues aux mots textuels ces mots visuels sont construits à partir des descripteurs locaux sift scale invariant feature transform dans limage ensuite nous appliquons lafc sur le tableau de contingence obtenu notre outil appelé hcaviz analyse ce tableau de contingence de façon récursive et aide lutilisateur à interpréter et interagir avec les résultats de lafc dabord les résultats de la première afc sur les images sont visualisés lutilisateur sélectionne ensuite un groupe dimages et fait une deuxième afc sur le nouveau tableau de contingence ce processus peut continuer jusquà ce quun thème « pur » se dévoile ceci permet de découvrir une arborescence des thèmes dans une collection dimages une application sur la base caltech4 illustre lintérêt de hcaviz dans la fouille dimages\n",
      "analyse spatiotemporelle des vecteurs de mouvement  application au comptage des personnes\n",
      "cet article présente une nouvelle approche qui permet de compter le nombre dindividus franchissant une ligne de comptage lapproche proposée accumule dans le temps les vecteurs de mouvement pour chaque point de la ligne de comptage formant une carte spatiotemporelle une procédure de détection en ligne des blobs est ensuite utilisée afin de déterminer les régions de la carte spatiotemporelle qui correspondent à des personnes franchissant cette ligne le nombre dindividus associé à chaque blob est estimé grâce à un modèle de régression linéaire appliqué aux caractéristiques du blob lapproche proposée est validée sur la base de plusieurs ensembles de données enregistrées à laide dune caméra verticale ou dune caméra oblique\n",
      "annotation dentités nommées par extraction de règles de transduction\n",
      "la reconnaissance dentités nommées est une problématique majoritairement traitée par des modèles spécifiés à laide de règles ou par apprentissage numérique les premiers ont le désavantage dêtre coûteux à développer pour obtenir une couverture satisfaisante les seconds sont souvent difficiles à interpréter par des experts linguistes dans cet article nous présentons une approche dont lobjectif est dextraire des règles symboliques discriminantes quun humain puisse consulter a partir dun corpus de référence nous extrayons des règles de transduction dont seules les plus informatives sont retenues elles sont ensuite appliquées pour effectuer une annotation  à cet effet un algorithme recherche parmi les annotations possibles celles de meilleure qualité en termes de couverture et de probabilité nous présentons les résultats expérimentaux et discutons de lintérêt et des perspectives de notre approche\n",
      "apport de la catégorisation iconique pour la gestion coopérative des connaissances1\n",
      "nan\n",
      "apport des données thématiques dans les systèmes de recommandation  hybridation et démarrage à froid\n",
      "des travaux récents pilaszy et al 2009 suggèrent que les métadonnées sont quasiment inutiles pour les systèmes de recommandation y compris en situation de coldstart  les données de logs de notation sont beaucoup plus informatives nous étudions sur une base de référence de logs dusages pour la recommandation automatique de dvd netflix les performances de systèmes de recommandation basés sur des sources de données collaboratives thématiques et hybrides en situation de démarrage à froid coldstart nous exhibons des cas expérimentaux où les métadonnées apportent plus que les données de logs dusage collaboratives pour la performance prédictive pour gérer le coldstart dun système de recommandation nous montrons que des approches en cascade thématiques puis hybrides puis collaboratives seraient plus appropriées\n",
      "apprendre les contraintes topologiques dans les cartes autoorganisatrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la carte autoorganisatrice som  selforganizing map est une méthode populaire pour lanalyse de la structure dun ensemble de données cependant certaines contraintes topologiques de la som sont fixées avant lapprentissage et peuvent ne pas être pertinentes pour la représentation de la structure des données dans cet article nous nous proposons daméliorer les performances des som avec un nouvel algorithme qui apprend les contraintes topologiques de la carte à partir des données des expériences sur des bases de données artificielles et réelles montrent que lalgorithme proposé produit de meilleurs résultats que som classique ce nest pas le cas avec une relaxation triviale des contraintes topologiques qui résulte en une forte augmentation de lerreur topologique de la carte\n",
      "apprentissage génératif de la structure de réseaux logiques de markov à partir dun graphe des prédicats\n",
      "les réseaux logiques de markov mlns combinent lapport statistique des réseaux de markov à la logique du premier ordre dans cette approche chaque clause logique se voit affectée dun poids linstanciation des clauses permettant alors de produire un réseau demarkov lapprentissage dun mln consiste à apprendre dune part sa structure la liste de clauses logiques et dautre part les poids de cellesci nous proposons ici une méthode dapprentissage génératif de réseau logique de markov cette méthode repose sur lutilisation dun graphe des prédicats produit à partir dun ensemble de prédicats et dune base dapprentissage une méthode heuristique de variabilisation est mise en oeuvre afin de produire le jeu de clauses candidates les résultats présentés montrent lintérêt de notre approche au regard de létat de lart\n",
      "cartes cognitives  une exploitation à base déchelle vue et profil\n",
      "une carte cognitive est un réseau dinfluences entre différents concepts le modèle des cartes cognitives permet à un utilisateur de calculer linfluence entre deux concepts les cartes cognitives contenant un grand nombre de concepts et dinfluences sont difficiles à comprendre cet article introduit la notion de carte cognitive ontologique qui associe une ontologie à une carte cognitive classique pour en organiser les concepts afin de faciliter la compréhension dune carte lutilisateur peut obtenir une vue de cette carte la simplifiant selon une échelle quil aura choisie un profil peut être créé pour construire des vues correspondant aux objectifs dun type dutilisateur si une carte est manipulée par différents utilisateurs leurs profils combinés permettent de construire une vue partagée\n",
      "catégorisation des mesures dintérêt pour lextraction des connaissances\n",
      "la recherche de règles dassociation intéressantes est un domaine de recherche important et actif en fouille de données les algorithmes de la famille apriori reposent sur deux mesures pour extraire les règles le support et la confiance bien que ces deux mesures possèdent des vertus algorithmiques accélératrices elles génèrent un nombre prohibitif de règles dont la plupart sont redondantes et sans intérêt il est donc nécessaire de disposer dautres mesures filtrant les règles inintéressantes des travaux ont été réalisés pour dégager les bonnes propriétés des mesures dextraction des règles et ces propriétés ont été évaluées sur 61 mesures lobjectif de cet article est de dégager des catégories de mesures afin de répondre à une préoccupation des utilisateurs  le choix dune ou plusieurs mesures lors dun processus dextraction des connaissances dans le but déliminer les règles valides non pertinentes extraites par le couple support confiance lévaluation des propriétés sur les 61 mesures a permis de dégager 9 classes de mesures classes obtenues grâce à deux techniques  une méthode de la classification ascendante hiérarchique et une version de la méthode de classification nonhiérarchique des kmoyennes\n",
      "classificateurs aléatoires topologiques à base de graphes de voisinage\n",
      "en apprentissage supervisé les méthodes ensemble me ont montré leurs qualités lune des méthodes de référence dans ce domaine est les forêts aléatoires fa cette dernière repose sur des partitionnements de lespace de représentation selon des frontières parallèles aux axes ou obliques les conséquences de cette façon de partitionner lespace de représentation peuvent affecter la qualité de chaque prédicteur il nous a semblé que cette approche pouvait être améliorée si on se libérait de cette contrainte de manière à mieux coller à la structure topologique de lensemble dapprentissage dans cet article nous proposons une nouvelle me basée sur des graphes de voisinage dont les performances sur nos premières expérimentations sont aussi bonnes que celles des fa\n",
      "classification des aéronefs par estimation de la pose\n",
      "dans le présent travail nous proposons un outil daide à la reconnaissance de cibles radar basé sur la signature de forme et de la pose de la cible la tâche principale dans le cadre de cet article consiste à établir la fonction de recherche dimages isar par lexemple en exploitant linformation de pose estimée depuis les images isar lobjectif est dintroduire linformation de pose dans lindexation des images notamment dans la phase de sélection des images candidates nous proposons une nouvelle méthode destimation de la pose basée sur laxe le plus symétrique de la cible la méthode proposée est ensuite comparée avec dautres techniques connues telles que la transformée de hough et la transformée en ondelette enfin la tâche de classification est réalisée en utilisant les kplus proches voisins incluant linformation de la pose\n",
      "closedsetbased discovery of representative association rules revisited\n",
      "the output of an association rule miner is often huge in practice this is why several concise lossless representations have been proposed such as the “essential” or “representative” rules we revisit the algorithm given by kryszkiewicz int symp intelligent data analysis 2001 springerverlag lncs 2189 350–359 for mining representative rules we show that its output is sometimes incomplete due to an oversight in its mathematical validation and we propose an alternative complete generator that works within only slightly larger running times\n",
      "comparaison entre deux indices pour lévaluation probabiliste discriminante des règles dassociation\n",
      "lélaboration dune échelle de probabilité discriminante pour la comparaison mutuelle entre plusieurs attributs observés sur un échantillon dobjets de grosse taille nécessite une normalisation préalable lobjet de cet article est lanalyse comparée entre deux approches la première dérive de l analyse de la vraisemblance des liens relationnels normalisée la seconde est fondée sur la notion de valeur test sur un échantillon virtuel de taille 100 synthétisant léchantillon initial\n",
      "complex information processing\n",
      "it is commonplace nowadays to claim that information is everywhere and that as a result finding the right information mathematically  according to a set of criteria optimizing a specific goal is very difficult defence applications have to cope with similar problems  communication networks surveillance and information systems transmit and generate significant amounts of complex information which cannot be processed with low level algorithms the challenge is to build highlevel processing units which demand a lot of computing power so as process video streams and communication packets with little possibility of a false alarm as automatically as possible methods for processing aligning merging lowlevel and highlevel information from syntactic to semantic information extracted from still images videos speech text and the internet are being considered the framework includes theoretical approaches algorithms as well as evaluation methods topics of interest are data fusion learning techniques data mining hci even artificial intelligence defence applications are numerous from scene understanding to weak signal detection\n",
      "conception et implémentation dune nouvelle technique cellulaire de discrétisation  intégration dans tanagra\n",
      "nan\n",
      "construction dune ontologie daide au renforcement de la sécurité des systèmes de transport automatisés\n",
      "nan\n",
      "construction ontologique à partir de séquences dexpression de champignons\n",
      "nan\n",
      "data stream summarization by online histograms clustering\n",
      "nan\n",
      "découverte de motifs dévolution significatifs dans les séries temporelles dimages satellites\n",
      "les séries temporelles dimages satellites ou satellite image time series – sits sont dimportantes sources dinformations sur lévolution du territoire étudier ces images permet de comprendre les changements sur des zones précises mais aussi de découvrir des schémas dévolution à grande échelle toutefois découvrir ces phénomènes impose de répondre à plusieurs défis qui sont liés aux caractéristiques des sits et à leurs contraintes premièrement chaque pixel dune image satellite est décrit par plusieurs valeurs les niveaux radiométriques sur différentes longueurs dondes deuxièmement ces motifs dévolution portent sur des périodes très longues et ne sont pas forcément synchrones selon les régions troisièmement les régions qui ne sont pas concernées par des évolutions significatives sont majoritaires et leur domination rend difficile lextraction des motifs dévolution dans cet article nous proposons une méthode qui répond à ces difficultés et nous la validons sur une série dimages satellites acquises sur une période de 20 ans\n",
      "des graphes de documents aux réseaux sociaux\n",
      "nan\n",
      "détection de changements de distribution dans un flux de données  une approche supervisée\n",
      "lanalyse de flux de données traite des données massives grâce à des algorithmes en ligne qui évitent le stockage exhaustif des données la détection de changements dans la distribution dun flux est une question importante dont les applications potentielles sont nombreuses dans cet article la détection de changement est transposée en un problème dapprentissage supervisé nous avons choisi dutiliser la méthode de discrétisation supervisée modl car celleci présente des propriétés intéressantes notre approche est comparée favorablement à une méthode de létatdelart sur des flux de données artificiels\n",
      "détection de redondances dans les tableaux guidée par une ontologie\n",
      "nous nous intéressons dans cet article à la réconciliation dannotations floues associées à des tableaux de données par une méthode dannotation sémantique qui est guidée par une ontologie de domaine etant donnés deux tableaux la méthode consiste à détecter leurs instances de relation redondantes elle sappuie sur les connaissances déclarées dans lontologie ainsi que sur des scores de similarité entre les annotations floues représentées par des sousensembles flous numériques ou par des sousensembles flous symboliques\n",
      "détection des profils à long terme et à court terme dans les réseaux sociaux\n",
      "la conception des profils et contextes utilisateurs se situe au coeur de létude et de la mise en oeuvre des mécanismes de personnalisation ou dadaptation de contenus recherche dinformation systèmes de recommandation etc plusieurs modèles et dimensions de profils et contextes sont décrits dans la littérature dans la vie réelle tout comme dans les systèmes dinformation le comportement de lutilisateur est très souvent influencé par son environnement social cependant la dimension sociale des profils et contextes utilisateurs reste très peu étudiée et évaluée dans cet article nous présentons une méthode de visualisation des profils utilisateurs permettant dévaluer la pertinence du réseau social de lutilisateur dans lévolution de son profil lexpérimentation de la méthode à partir de facebook permet didentifier dune part les centres dintérêts à courtterme et à longterme des profils utilisateurs et dautre part linfluence réelle à courtterme et à longterme du réseau social de chaque utilisateur ces résultats démontrent lintérêt de modéliser et dintégrer une dimension sociale dans les profils et contextes utilisateurs afin de tenter daméliorer les mécanismes de personnalisation ou dadaptation de contenus\n",
      "early classification on temporal sequences\n",
      "early classification of temporal sequences has applications in for example health informatics intrusion detection anomaly detection and scientific and engineering sequence data monitoring in early classification instead of optimizing accuracy our goal is to produce classification as early as possible provided that the accuracy meets some expectation in this talk i will advocate early classification as an exciting and challenging research problem which has not been systematically studied in the literature i will discuss several interesting formulations of the problem which provide complimentary features possibly desirable in different application scenarios i will also review some of our recent progress on this aspect\n",
      "entropicgenetic clustering\n",
      "this paper addresses the clustering problem given the similarity matrix of a dataset we define two distinct criteria with the aim of simultaneously minimizing the cut size and obtaining balanced clusters the first criterion minimizes the similarity between objects belonging to different clusters and is an objective generally met in clustering the second criterion is formulated with the aid of generalized entropy the tradeoff between these two objectives is explored using a multiobjective genetic algorithm with enhanced operators\n",
      "equilibrer lanalyse des motifs fréquents\n",
      "cet article propose une méthode originale dévaluation de la qualité des motifs en anticipant la manière qui sera utilisée pour les analyser nous commençons par introduire le modèle de lanalyse aléatoire dun ensemble de motifs selon une mesure dintérêt avec ce modèle nous constatons que létude des motifs fréquents avec le support conduit à une analyse déséquilibrée du jeu de données afin que chaque transaction reçoive la même attention nous définissons le support équilibré qui corrige le support classique en pondérant les transactions nous proposons alors un algorithme qui calcule ces poids et nous validons expérimentalement son efficacité\n",
      "equivalence topologique entre mesures de proximité\n",
      "le choix dune mesure de proximité entre objets a un impact direct sur les résultats de toute opération de classification de comparaison dévaluation ou de structuration dun ensemble dobjets pour un problème donné lutilisateur est amené à choisir une parmi les nombreuses mesures de proximité existantes or selon la notion déquivalence choisie comme celle basée sur les préordonnances certaines sont plus ou moins équivalentes dans cet article nous proposons une nouvelle approche pour comparer les mesures de proximité celleci est basée sur léquivalence topologique a cet effet nous introduisons un nouveau concept baptisé équivalence topologique ce dernier fait appel à la structure de voisinage local nous proposons alors de définir léquivalence topologique entre deux mesures de proximité à travers la structure topologique induite par chaque mesure nous établissons ensuite des liens formels avec léquivalence en préordonnance les deux approches sont comparées sur le plan théorique et sur le plan empirique nous illustrons le principe de cette comparaison sur un exemple simple pour une quinzaine de mesures de proximités de la littérature\n",
      "estimation de la densité darcs dans les graphes de grande taille une alternative à la détection de clusters\n",
      "la recherche de structures dans les graphes est un sujet étudié depuis longtemps qui a bénéficié dun regain dintérêt avec la mise à disposition de graphes de grande taille sur le web tels les réseaux sociaux de nombreuses méthodes de recherche de clusters “naturels” dans les graphes ont été proposées fondées notamment sur la modularité de newman on introduit dans cet article une nouvelle façon de résumer la structure des graphes de grande taille en utilisant des estimateurs de densité des arcs exploitant des modèles en grille basés sur un copartitionnent des noeuds source et cible des arcs les structures identifiées par cette méthode vont au delà de la “classique” détection de clusters dans les graphes et permettent destimer asymptotiquement la densité des arcs les expérimentations confirment le potentiel de lapproche qui permet didentifier des structures fortement informatives dans les graphes sans faire lhypothèse dune décomposition en clusters denses\n",
      "être ou ne pas être usager dinternet telle est la question \n",
      "nan\n",
      "evaluation des outils dextraction terminologique quezao et acabit\n",
      "larticle décrit lévaluation de deux outils dextraction terminologique acabit et quezao si acabit est plus connu car librement disponible quezao est issu des travaux dorange labs sur la recherche dinformations après une comparaison sur les approches théoriques des deux systèmes une évaluation concrète va porter sur un corpus dactualité 2424actu pour laspect qualitatif et sur un corpus de presse pour laspect quantitatif\n",
      "extraction de motifs séquentiels contextuels\n",
      "les motifs séquentiels traditionnels ne tiennent généralement pas compte des informations contextuelles fréquemment associées aux données séquentielles dans le cas des séquences dachats de clients dans un magasin lextraction classique de motifs se focalise sur les achats des clients sans considérer leur catégorie socioprofessionnelle leur sexe leur âge or en considérant le fait quun motif séquentiel est spécifique à un contexte donné un expert pourra adapter sa stratégie au type du client et prendre les décisions adéquates dans cet article nous proposons dextraire des motifs de la forme «lachat des produits a et b suivi de lachat du produit c est spécifique aux jeunes clients» en mettant en valeur les propriétés formelles de tels contextes nous développons un algorithme efficace dextraction de motifs séquentiels contextuels les expérimentations effectuées sur un jeu de données réelles montrent les apports et lefficacité de lapproche proposée\n",
      "extraction de motifs temporels à partir de séquences dévénements avec intervalles temporels\n",
      "la fouille de base de données séquentielles a pour objet lextraction de motifs séquentiels représentatifs la plupart des méthodes concernent des motifs composés dévénements liés par des relations temporelles basées sur la précédence des instants pourtant dans de nombreuses situations réelles une information quantitative sur la durée des événements ou le délai interévénements est nécessaire pour discriminer les phénomènes nous proposons deux algorithmes qtiapriori et qtiprefixspan pour extraire des motifs temporels composés dévénements associés à des intervalles décrivant leur position dans le temps et leur durée chacun deux ajoute aux algorithmes gsp et prefixspan une étape de catégorisation dintervalles multidimensionnels pour extraire les intervalles temporelles représentatifs les expérimentations sur des données simulées montrent la capacité des algorithmes à extraire des motifs précis en présence de bruit et montrent lamélioration des performances en temps de calcul\n",
      "extraction et analyse de réseaux sociaux issus de bases de données relationnelles\n",
      "dans un contexte dentreprise beaucoup dinformations importantes restent stockées dans des bases de données relationnelles constituant une source riche pour construire des réseaux sociaux le réseau ainsi extrait a souvent une taille importante ce qui rend son analyse et sa visualisation difficiles dans ce travail nous proposons une étape dextraction suivie dune étape dagrégation des réseaux sociaux à partir des bases de données relationnelles létape dextraction ou de construction transforme une base de données relationnelle en base de données graphe puis le réseau social est extrait létape dagrégation qui est basée sur lalgorithme ksnap produit un graphe résumé\n",
      "extraction sous contraintes densembles de cliques homogènes\n",
      "nous proposons une méthode de fouille de données sur des graphes ayant un ensemble détiquettes associé à chaque sommet une application est par exemple danalyser un réseau social de chercheurs coauteurs lorsque des étiquettes précisent les conférences dans lesquelles ils publientnous définissons lextraction sous contraintes densembles de cliques tel que chaque sommet des cliques impliquées partage suffisamment détiquettes nous proposons une méthode pour calculer tous les ensembles maximaux de cliques dits homogènes qui satisfont une conjonction de contraintes fixée par lanalyste et concernant le nombre de cliques séparées la taille des cliques ainsi que le nombre détiquettes partagées les expérimentations montrent que lapproche fonctionne sur de grands graphes construits à partir de données réelles et permet la mise en évidence de structures intéressantes\n",
      "heuristique pour lextraction de motifs ensemblistes bruités\n",
      "la recherche de motifs ensemblistes dans des matrices de données booléennes est une problématique importante dans un processus dextraction de connaissances elle consiste à rechercher tous les rectangles de 1 dans une matrice de données à valeurs dans 01 dans lesquelles lordre des lignes et colonnes nest pas important plusieurs algorithmes ont été développés pour répondre à ce problème mais sadaptent difficilement à des données réelles susceptibles de contenir du bruit un des effets du bruit est de pulvériser un motif pertinent en un ensemble de sousmotifs recouvrants et peu pertinents entraînant une explosion du nombre de motifs résultats dans le cadre de ce travail nous proposons une nouvelle approche heuristique basée sur les algorithmes de graphes pour la recherche de motifs ensemblistes dans des contextes binaires bruités pour évaluer notre approche différents tests ont été réalisés sur des données synthétiques et des données réelles issues dapplications bioinformatiques\n",
      "import automatique et interactif de données dans les systèmes de visualisations\n",
      "la première étape du processus de visualisation dinformation consiste à transformer les données dun format brut vers une structure de données utilisable par les différents composants de visualisation dans les applications réelles cette première étape représente une barrière empêchant laccès des utilisateurs novices à une riche variété de techniques de visualisation par exemple il peut être techniquement impossible pour un utilisateur lambda de transformer des données arborescentes en un modèle de graphe pouvant utiliser une représentation à base de treemap une autre barrière est aussi la multitude de transformations possible des données brutes il faut pouvoir explorer cet ensemble de combinaisons basé sur nos retours dexpériences avec des utilisateurs finaux dans cet article nous considérons que le format brut est sous forme tabulaire ce format est le plus couramment utilisé et est facilement accessible par nos utilisateurs nous proposons une méthode novatrice permettant de générer automatiquement des graphes valués à partir de nimporte quelle table en analysant le contenu de chaque dimension nous identifions les interconnexions entre cellesci puis nous caractérisons les entités les attributs et les relations possibles au sein des tables finalement nous intégrons lutilisateur dans le processus de transformation en lui proposant un ensemble de transformations valides\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intégration de données haptiques brutes dans des systèmes experts de diagnostic des connaissances\n",
      "cet article a pour cadre un environnement informatique pour lapprentissage humain eiah dédié à la chirurgie orthopédique et plus précisément sur le diagnostic des connaissances des apprenants pour ce faire un réseau bayésien infère à partir dexercices que les étudiants réalisent sur un simulateur avec bras articulé ce réseau résulte dune approche centrée expert du domaine comme très souvent dans les eiah pourtant dans un domaine comme la chirurgie où les connaissances sont tacites le geste de lapprenant semble intéressant à considérer le but de nos travaux est donc dadopter une démarche plus centrée sur les données en incorporant au réseau bayésien les données haptiques continues issues du simulateur divers problèmes se posent néanmoins dune part sur le besoin détudier la nature des données pour conserver la généricité du système et dautre part pour trouver des méthodes de validation pertinentes concernant leur traitement\n",
      "interprétation graphique de la courbe roc\n",
      "nan\n",
      "interprétation spectrale de la classification relationnelle\n",
      "ce papier présente une vue spectrale sur lapproche de lanalyse relationnelle pour la classification des données catégorielles il établit dabord le lien théorique entre lapproche de lanalyse relationnelle et le problème de classification spectrale en particulier le problème de classification relationnelle est présenté comme un problème de maximisation de trace ce problème est donc transformé par la relaxation spectrale en un problème doptimisation sous contraintes qui peut être résolu par des multiplicateurs de lagrange la solution est donnée par un problème de valeurs propres\n",
      "introduction de lingénierie ontologique dans la méthodologie de développement des progiciels de gestion des collectivités territoriales\n",
      "nan\n",
      "isicil  intégration sémantique dinformations à travers des communautés dintelligence en ligne\n",
      "nan\n",
      "les moteurs de wikis sémantiques  un état de lart\n",
      "cet article est un état de lart sur les moteurs de wiki sémantique en particulier sur leur utilisation des technologies du web sémantique les principales notions liées aux wikis sémantiques sont dabord présentées ensuite plusieurs projets actifs de moteurs de wiki sont comparés selon différents points de vue finalement des recommandations sont données pour le choix dun moteur de wiki en conclusion les auteurs sinterrogent sur les perspectives des wikis sémantiques telles que la faible interopérabilité de certains moteurs\n",
      "m3a  une plateforme dingénierie de maintenance assistée par apprentissage automatique\n",
      "nan\n",
      "mesure de concordance pour les bases de données évidentielles\n",
      "dans cet article nous proposons une mesure de concordance dune source avec les autres sources cette mesure pourra servir à réduire limportance de ses fonctions de masse avant de les combiner afin de trouver un compromis et donc réduire le conflit cette mesure sera illustrée par des données réelles\n",
      "mesures dhétérogénéité sémantique des systèmes p2p nonstructurés\n",
      "lautonomie des participants dans les systèmes p2p pour le partage de données peut conduire à une situation dhétérogénéité sémantique dans le cas où les participants utilisent leurs propres ontologies pour représenter leurs données dans cet article nous commençons par définir des mesures de disparité entre participants en considérant leurs contextes sémantiques en considérant la topologie du système et les disparités entre participants nous proposons des mesures dhétérogénéité sémantique dun système p2p nonstructuré\n",
      "mixer les moyens pour extraire les gloses\n",
      "nous proposons dextraire des connaissances lexicales en exploitant les « gloses » de mot ces descriptions spontanées de sens repérables par des marqueurs lexicaux et des configurations morphosyntaxiques spécifiques ainsi dans lextrait suivant le mot testing est suivi dune glose en cestà dire  « 10  de ces embauches vont porter sur un métier qui monte  le «testing» cestàdire la maîtrise des méthodologies rigoureuses de test des logiciels» cette approche ouvre des perspectives pour lacquisition lexicale et terminologique fondamentale pour de nombreuses tâches dans cet article nous comparons deux façons dextraire les unités en relation de glose  patrons et statistiques dassociations dunités sur le web en les évaluant sur des données réelles\n",
      "mobility data mining and privacy mining human movement patterns from trajectory data\n",
      "the technologies of mobile communications and ubiquitous computing pervade our society and wireless networks sense the movement of people and vehicles generating large volumes of mobility data such as mobile phone call records and gps tracks this is a scenario of great opportunities and risks  on one side mining this data can produce useful knowledge supporting sustainable mobility and intelligent transportation systems  on the other side individual privacy is at risk as the mobility data contain sensitive personal information a new multidisciplinary research area is emerging at this crossroads of mobility data mining and privacy the talk assesses this research frontier from a data mining perspective and illustrates the results of a europeanwide research project called geopkdd geographic privacyaware knowledge discovery and delivery geopkdd has created an integrated platform named matlas for complex analysis of mobility data which combines spatiotemporal querying capabilities with data mining visual analytics and semantic technologies thus providing a full support for the mobility knowledge discovery process in this talk we focus on the key data mining models  trajectory patterns and trajectory clustering and illustrate the analytical power of our system in unvealing the complexity of urban mobility in a large metropolitan area by means of a large scale experiment based on a massive real life gps dataset obtained from 17000 vehicles with onboard gps receivers tracked during one week of ordinary mobile activity in the urban area of the city of milan italy\n",
      "modèle pour une analyse du phénomène de linéarité de catégories sémantiques dans les énoncés en français\n",
      "nan\n",
      "modélisation dune ressource terminoontologique de domaine pour lannotation sémantique de tableaux\n",
      "nous proposons dans cet article une modélisation dune ressource terminoontologique rto de domaine guidée par la tâche dannotation sémantique de tableaux lannotation dun tableau consiste à annoter ses cellules pour pouvoir ensuite identifier les concepts représentés par ses colonnes et enfin identifier la ou les relations naires quil représente la rto proposée permet dune part de modéliser dans sa composante lexicale les termes utilisés pour lannotation des cellules en intégrant la gestion des synonymes et du multilingue et dautre part de modéliser dans sa composante conceptuelle les concepts symboliques les concepts numériques et les relations naires qui sont propres au domaine étudié\n",
      "modélisation de la dynamique de phénomènes spatiotemporels par des séquences de motifs\n",
      "dans ce papier nous proposons un nouveau cadre théorique permettant de modéliser la dynamique de phénomènes spatiotemporels nous définissons le concept de séquences spatiotemporelles de motifs afin de capturer les interactions entre des ensembles de propriétés et un phénomène à observer un algorithme incrémental est proposé pour extraire des séquences spatiotemporelles de motifs sous contraintes et une nouvelle structure de données est mise en place afin daméliorer ses performances un prototype a été développé et testé sur des données réelles\n",
      "modélisation de la propagation de linformation sur le web  de lextraction des données à la simulation\n",
      "nous proposons un modèle de la propagation de linformation dans un réseau en détaillant toutes les étapes de sa réalisation et de son utilisation dans un cadre de simulation a partir de données réelles extraites du web nous identifions parmi les sources des catégories de comportements de publication distincts nous proposons ensuite une extension dun modèle de diffusion de linformation existant afin daugmenter son pouvoir dexpression en particulier pour reproduire ces comportements de publication puis nous le validons sur un exemple de simulation\n",
      "moteur de questions réponses à partir de données du web sémantique\n",
      "nan\n",
      "moteur de questionsréponses dune base de connaissances\n",
      "cet article présente comment la gestion et lexploitation de connaissances issues du site web wikipedia ont permis de développer une telle fonction qui a été intégrée depuis février 2010 dans un moteur de recherche internet français pour le grand public aujourdhui cette fonction est capable de répondre à des questions formulées en langage naturelle sur environs 170 000 lieux ou personnes la formalisation des données extraites de wikipedia en connaissances au format owl ou rdfs a permis de déduire de nouvelles informations manquantes de typer les entités nommées trouvées et de traiter de nouvelles formes de questions qui étaient non traitées\n",
      "motifs séquentiels deltalibres\n",
      "bien que largement étudiée lextraction de motifs séquentiels reste une tâche très difficile et pose aussi le défi du grand nombre de motifs produits dans cet article nous proposons une nouvelle approche extrayant les motifs séquentiels les plus généraux à fréquence similaire nous montrons en quoi lextension de cette notion déjà connue pour les motifs ensemblistes est un problème particulièrement difficile pour les séquences les motifs deltalibres ainsi produits sont en nombre réduit et facilitent les usages dun processus de fouille et nous montrons leur apport comme descripteurs dans un contexte de classification de séquences\n",
      "mumie une approche automatique pour linteropérabilité des métadonnées\n",
      "avec lexplosion du multimedia lutilisation des métadonnées est devenue cruciale pour assurer une bonne gestion des contenus cependant il est nécessaire d assurer un accès uniforme aux métadonnées plusieurs techniques ont ainsi été développées afin de réaliser cette interopérabilité la plupart dentre elles sont spécifiques à un seul langage de description les systèmes de matching existants présentent certaines limites en particulier dans le traitement des informations structurelles nous présentons dans cet article un nouveau système dintégration qui supporte des schémas provenant de langages descriptifs différents de plus la méthode de matching proposée a recours à plusieurs types dinformation de façon à augmenter la précision de matching\n",
      "nomao  la recherche géolocalisée personnalisée\n",
      "nan\n",
      "nouvelle approche de fouille de graphes acréduits fréquents\n",
      "la fouille de graphes est devenue une piste de recherche intéressante et un défi réel en matière de fouille de données parmi les différentes familles de motifs de graphes les graphes fréquents permettent une caractérisation intéressante des groupes de graphes ainsi quune discrimination des différents graphes lors de la classification ou de la segmentation a cause de la npcomplétude du test disomorphisme de sousgraphes et de limmensité de lespace de recherche les algorithmes de fouille de graphes sont exponentiels en temps dexécution etou occupation mémoire dans cet article nous étudions un nouvel opérateur de projection polynomial nommé acprojection basé sur une propriété clé du domaine de la programmation par contraintes à savoir larc consistance cet opérateur est censé remplacer lutilisation de lisomorphisme de sousgraphes en établissant un biais sur la projection cette étude est suivie dune évaluation expérimentale du pouvoir discriminant des patterns acréduits découverts\n",
      "optimisation de lextraction de lalignement des ontologies avec la contrainte de différence\n",
      "dans ce papier nous proposons une approche basée sur la programmation par contraintes pour aborder efficacement le problème de lalignement des ontologies et plus particulièrement lextraction des correspondances à partir des mesures de similarités la complexité de ce problème est accentuée dans les applications à caractère dynamique où laspect performance est capital plus précisément nous exploitons la contrainte globale de différence développée dans le domaine de la programmation par contraintes pour extraire un alignement total et injectif nous montrons que cette approche est efficace et se prête à une mise en oeuvre à la fois interactive et automatique\n",
      "optimisation directe des poids de modèles dans un prédicteur bayésien naïf moyenné\n",
      "le classifieur bayésien naïf est un outil de classification efficace en pratique pour de nombreux problèmes réels en dépit de lhypothèse restrictive dindépendance des variables conditionnellement à la classe récemment de nouvelles méthodes permettant daméliorer la performance de ce classifieur ont vu le jour sur la base à la fois de sélection de variables et de moyennage de modèles dans cet article nous proposons une extension de la sélection de variables pour le classifieur bayésien naïf en considérant un modèle de pondération des variables utilisées et des algorithmes doptimisation directe de ces poids les expérimentations confirment la pertinence de notre approche en permettant une diminution significative du nombre de variables utilisées sans perte de performance prédictive\n",
      "parameterfree association rule mining with yacaree\n",
      "nan\n",
      "point of view based clustering of sociosemantic networks\n",
      "nan\n",
      "pondération et classification simultanée de données binaires et continues\n",
      "dans cet article nous proposons une nouvelle approche de classification topologique et de pondération des variables mixtes qualitatives et quantitatives codées en binaire durant un processus dapprentissage non supervisé cette approche est basée sur le modèle des cartes autoorganisatrices lapprentissage est combiné à un mécanisme de pondération des différentes variables sous forme de poids dinfluence sur la pertinence des variables lapprentissage des pondérations et des prototypes est réalisé dune manière simultanée en favorisant une classification optimisée des données lapproche proposée a été validée sur des données qualitatives codées en binaire et plusieurs bases de données mixtes\n",
      "ppmi  étude formelle dune variante à valeurs positives de la pmi\n",
      "nan\n",
      "prévision de trajectoires de cyclones à laide de forêts aléatoires avec arbres de régression\n",
      "nous présentons une étude pour la prédiction des trajectoires de cyclones dans locéan atlantique nord à partir de données issues dimages satellites on y extrait des mesures de vitesses de vent de vorticité dhumidité base jra25 et des mesures de latitude de longitude et de vitesse de vent instantanée des cyclones toutes les 6 heures base ibtracs les modèles de référence à ce jour ne tiennent pas compte des corrélations entre les données et les prévisions ce qui limite leur intérêt pour certains utilisateurs nous proposons ainsi de prédire le déplacement en latitude et le déplacement en longitude au même instant à un horizon de 120 h toutes les 6 h à laide de forêts aléatoires avec arbres de régression sur le long terme à partir de 18 h la méthode proposée donne de meilleurs résultats que les méthodes existantes\n",
      "prise en compte du réseau de sources pour la fusion dinformations\n",
      "nan\n",
      "propositionaliser des attributs numériques sans les discrétiser ni les agréger\n",
      "la fouille de données relationnelles considère des données contenues dans au moins deux tables reliées par une association unàplusieurs par exemple des clients et leurs achats ou des molécules et leurs atomes une façon de fouiller ces données consiste à transformer les données en une seule table attributvaleur cette transformation est appelée propositionalisation les approches existantes gèrent principalement les attributs catégoriels une première solution est donc de discrétiser les attributs numériques pour les transformer en attributs catégoriels les approches alternatives qui gèrent les attributs numériques consistent à les agréger nous proposons une approche duale de la discrétisation qui inverse lordre de traitement du nombre dobjets et du seuil et dont la discrétisation généralise les quartiles nous pouvons ainsi construire des attributs que les approches existantes de propositionalisation ne peuvent pas construire et qui ne peuvent pas non plus être obtenus par les systèmes complets de fouille de données\n",
      "reasoning about the learning process\n",
      "data mining is faced with new challenges in emerging applications like financial data traffic tcpip sensor networks etc data continuously flow eventually at high speed the processes generating data evolve over time and the concepts we are learning change in this talk we present a onepass classification algorithm able to detect and react to changes we present a framework that identify contexts using drift detection characterize contexts using metalearning and select the most appropriate base model for the incoming data using unlabeled examples evolving data requires that learning algorithms must be able to monitor the learning process and the ability of predictive selfdiagnosis a significant and useful characteristic is diagnostics  not only after failure has occurred but also predictive before failure these aspects require monitoring the evolution of the learning process taking into account the available resources and the ability of reasoning and learning about it\n",
      "reconnaissance dactions par modélisation du mouvement\n",
      "cet article propose une approche utilisant les modèles de direction et de magnitude de mouvement pour détecter les actions qui sont effectuées par des êtres humains dans des séquences vidéo des mélanges gaussiens et de lois de von mises sont estimés à partir des orientations et des magnitudes des vecteurs du flux optique calculés pour chaque bloc de la scène les paramètres de ces modèles sont estimés grâce à un algorithme dapprentissage en ligne les actions sont reconnues grâce à une mesure qui se base sur la distance de bhattacharyya et qui permet de comparer le modèle dune séquence donnée avec les modèles créés à partir de séquences dapprentissage lapproche proposée est évaluée sur deux ensembles de vidéos contenant des actions variées exécutées aussi bien dans des environnements intérieur quextérieur\n",
      "résumés et interrogations de logs de requêtes olap\n",
      "une façon dassister lanalyse dentrepôt de données repose sur lexploitation et la fouille de fichiers logs de requêtes olap mais à notre connaissance il nexiste pas de méthode permettant dobtenir une représentation dun tel log qui soit à la fois concise et exploitable dans ce papier nous proposons une méthode pour résumer et interroger des logs de requêtes olap lidée de base est quune requête résume une autre requête et quun log qui est une séquence de requêtes résume un autre log notre cadre formel est composé dune algèbre simple destinée à résumer des requêtes olap et dune mesure évaluant la qualité du résumé obtenu nous proposons également plusieurs stratégies pour calculer automatiquement des résumés de logs de bonne qualité et nous montrons comment des propriétés simples sur les résumés peuvent être utilisées pour interroger un log efficacement des tests sur des logs de requêtes mdx ont montré lintérêt de notre approche\n",
      "sélection des variables informatives pour lapprentissage supervisé multitables\n",
      "dans la fouille de données multitables les données sont représentées sous un format relationnel dans lequel les individus de la table cible sont potentiellement associés à plusieurs enregistrements dans des tables secondaires en relation unàplusieurs la plupart des approches existantes opèrent en transformant la représentation multitables notamment par mise à plat par conséquent on perd la représentation initiale naturellement compacte mais également on risque dintroduire des biais statistiques notre approche a pour objectif dévaluer linformativité des variables explicatives originelles par rapport à la variable cible dans le contexte des relations unàplusieurs elle consiste à résumer linformation contenue dans chaque variable par un tuple dattributs représentant les effectifs des modalités de celleci des modèles en grilles multivariées sont alors employés pour qualifier linformation apportée conjointement par les nouveaux attributs ce qui revient à une estimation de densité conditionnelle de la variable cible connaissant la variable explicative en relation unàplusieurs les premières expérimentations sur des bases de données artificielles et réelles montrent quon arrive à identifier les variables explicatives potentiellement pertinentes sur tout le domaine relationnel\n",
      "service de recherche web30 de contenus audiovisuels\n",
      "nan\n",
      "structuration automatique des flux télévisuels par apprentissage non supervisé des répétitions\n",
      "nan\n",
      "système de recherche de musique adaptable à la perception de chaque utilisateur\n",
      "dans le cadre de nos travaux sur le portage linguistique des systèmes de gestion de contenu traitant des énoncés spontanés en langue naturelle nous présentons ici une évaluation du portage dimrs système de recherche de morceau de musique en langue naturelle kumamoto 2007 du japonais vers le français cette évaluation peut se faire au niveau des représentations internes en les comparant ou au niveau de la tâche ici nous nous intéressons à une évaluation liée à la tâche en proposant un service web qui permet de mesurer la performance globale de la nouvelle version obtenue nous avons par la suite cherché à améliorer et ajouter de nouvelles fonctionnalités en proposant un service de recherche de musique adaptable à la perception de chaque utilisateur en effet un même morceau de musique peut être jugé calme pour un premier auditeur très calme pour un deuxième et assez calme pour un troisième etc on se demande limpression finale que porte ce dernier morceau de musique cest naturel que les utilisateurs évaluent différemment un même morceau de musique car ils ont des perceptions différentes devant cette situation nous proposons un service de recherche de musique basé des méthodes simples et automatisées et qui sont adaptables à la perception de chaque utilisateur\n",
      "système pour la catégorisation automatique des offres demploi en une typologie de fonctions\n",
      "depuis les deux dernières décennies laugmentation du nombre de sites demploi sur internet a accentué la nécessité de proposer des outils daide à la décision adaptés aux besoins des recruteurs cet article présente un système pour la catégorisation des textes doffres demploi destinées à être diffusées sur internet après un prétraitement adapté des offres les termes descripteurs sont choisis en fonction de leur pouvoir discriminant visàvis des différentes classes ce qui permet de réduire leur nombre de manière significative les offres sont ensuite représentées par leurs coordonnées dans lespace factoriel obtenu par analyse des correspondances et la classification réalisée dans un cadre supervisé à laide de svm\n",
      "towards a distributedweb search engine\n",
      "in the ocean of web data web search engines are the primary way to access content as the data is on the order of petabytes current search engines are very large centralized systems based on replicated clusters web data however is always evolving the number of web sites continues to grow rapidly 230 millions at the end of 2009 and there are currently more than 20 billion indexed pages on the other hand internet users are above one billion and hundreds of million of queries are issued each day in the near future centralized systems are likely to become less effective against such a dataquery load thus suggesting the need of fully distributed search engines such engines need to maintain high quality answers fast response time high query throughput high availability and scalability  in spite of network latency and scattered data in this talk we present the main challenges behind the design of a distributed web retrieval system and our research in all the components of a search engine  crawling indexing and query processing\n",
      "treillis des concepts skylines  analyse multidimensionnelle des skylines fondée sur les ensembles en accord\n",
      "le concept de skyline a été introduit pour mettre en évidence les objets « les meilleurs » selon différents critères une généralisation multidimensionnelle du skyline a été proposée à travers le skycube qui réunit tous les skylines possibles selon toutes les combinaisons de critères et permet danalyser les liens entre objets skylines comme le data cube le skycube savère extrêmement volumineux si bien que des approches de réduction sont incontournables dans cet article nous définissons une approche de matérialisation partielle du skycube lidée sousjacente est déliminer de la représentation les skycuboïdes facilement recalculables pour atteindre cet objectif de réduction nous caractérisons un cadre formel  le treillis des concepts accords cette structure combine la notion densemble en accord et le treillis des concepts à partir de cette structure nous dérivons le treillis des concepts skylines qui en est une instance contrainte le point fort de notre approche est dêtre orientée attribut ce qui permet de borner le nombre de noeuds du treillis et dobtenir une navigation efficace à travers les skycuboïdes\n",
      "un critère bayésien pour évaluer la robustesse des règles de classification\n",
      "lutilisation de règles de classification dans les modèles prédictifs a été très étudiée ces dernières années la forme simple et interprétable des règles en font des motifs très populaires les classifieurs combinant des règles de classification intéressantes selon une mesure dintérêt offrent de bonnes performances de prédictions cependant les performances de ces classifieurs dépendent de la mesure dintérêt eg confiance taux daccroissement   et du seuillage nontrivial de cette mesure pour déterminer les règles pertinentes de plus il est facile de montrer que les règles extraites ne sont pas individuellement robustes dans cet article nous proposons un nouveau critère pour évaluer la robustesse des règles de classification dans les données booléennes notre critère est issu dune approche bayésienne  nous proposons une expression analytique de la probabilité dune règle connaissant les données ainsi les règles les plus probables sont robustes le critère bayésien nous permet alors didentifier sans paramètre les règles robustes parmi un ensemble de règles données\n",
      "un cycle de vie complet pour lenrichissement sémantique des folksonomies\n",
      "les tags fournis par les utilisateurs des plateformes de tagging social ne sont pas explicitement liés sémantiquement et ceci limite considérablement les possibilités dexploitation de ces données nous présentons dans cet article notre approche pour lenrichissement sémantiques des folksonomies qui intègre une combinaison de traitements automatiques ainsi que la capture des contributions de structuration des utilisateurs via une interface ergonomique de plus notre modèle supporte les points de vue qui divergent tout en permettant de les combiner en respectant leur cohérence locale cette approche sadresse aux communautés de connaissances collaborant en ligne et en intégrant leurs usages nous sommes en mesure de proposer un cycle de vie complet pour le processus de structuration sémantique des folksonomies la navigation dans les données de tagging est ainsi améliorée et les folksonomies peuvent alors être directement intégrées dans la construction de thesauri\n",
      "un outil de géolocalisation et de résumé automatique pour faciliter laccès à linformation dans des corpus dactualité\n",
      "nan\n",
      "un outil de navigation dans un espace sémantique\n",
      "nan\n",
      "un système cellulaire neurosymbolique pour lextraction et la gestion des connaissances\n",
      "le cnss – cellular neurosymbolic system – est un système hybride ralliant conjointement le neurosymbolique et le cellulaire cnss permet à partir dune base de cas pratique de faire coopérer un réseau de neurones un graphe dinduction et un automate cellulaire pour la construction dun modèle de prédiction en détectant et en éliminant les individus non applicables et les variables non pertinentes le réseau de neurones optimise la base dapprentissage le résultat ainsi obtenu est affiné par un processus dapprentissage symbolique à base de graphe dinduction ce raffinement se fait par une modélisation booléenne qui va assister lapprentissage symbolique à optimiser le graphe dinduction et va assurer par la suite la représentation et la génération des règles de classification sous forme conjonctives avant dentamer la phase de déduction par un moteur dinférence cellulaire cnss a été testé sur plusieurs applications en utilisant des problèmes académiques et réels les résultats montrent que le système cnss a des performances supérieures et de nombreux avantages\n",
      "une approche à base de règles floues pour les requêtes à préférences contextuelles\n",
      "nan\n",
      "une mesure de distance dans lespace des alignements entre parties potentiellement homologues de deux ontologies légères\n",
      "nous proposons dans cet article une méthode qui calcule la distance entre ontologies dans un but daide à la décision sur la pertinence ou non de leur fusion cette méthode calcule la distance entre parties homologues de deux ontologies par rapport à leurs niveaux de détail et leurs structures taxonomiques et ce en exploitant les correspondances produites par un alignement préalablement effectué entre ces ontologies et en adaptant la méthode de la distance dédition entre arbres ordonnés nous limitons notre étude ici aux ontologies légères cest à dire des taxonomies représentées en langages owl le langage dontologies pour le web notre méthode a été implémentée et testée sur des ontologies réelles et les résultats obtenus semblent prometteurs\n",
      "une méthodologie de recommandations produits fondée sur lactionnabilité et lintérêt économique des clients\n",
      "dans un contexte économique difficile la fidélisation des clients figure au premier rang des préoccupations des entreprises en effet selon le gartner fidéliser des clients existants coûterait beaucoup moins cher que prospecter de nouveaux clients pour y parvenir les entreprises optimisent la marge et le cycle de vie des clients en développant une relation personnalisée aboutissant à de meilleures recommandations dans cet article nous proposons une méthodologie pour les systèmes de recommandations fondée sur lanalyse des chiffres daffaires des clients sur des familles de produits plus précisément la méthodologie consiste à extraire des comportements de référence sous la forme de règles dassociation et à en évaluer lintérêt économique et lactionnabilité les recommandations sont réalisées en ciblant les contreexemples les plus actionnables sur les règles les plus rentables notre méthodologie est appliquée sur 12 000 clients et 100 000 produits de vmmatériaux afin dorienter les commerciaux sur les possibilités daccroissement de la valeur client\n",
      "une nouvelle approche pour lextraction non supervisée de critères\n",
      "récemment de nouvelles techniques regroupées sous le vocable de détection automatique dopinions opinion mining ont fait leur apparition et proposent une évaluation globale dun document ainsi elles ne permettent pas de mettre en avant le fait que les personnes expriment une opinion très positive du scénario dun film alors quelles trouvent que les acteurs sont médiocres dans cet article nous proposons de caractériser automatiquement les segments de textes relevant dun critère donné sur un corpus de critiques\n",
      "une nouvelle approche visuelle pour la classification hiérarchique et topologique\n",
      "nous proposons dans cet article une nouvelle méthode de classification hiérarchique et topologique notre approche consiste à construire de manière autoorganisée une partition de données représentées par un ensemble forêt darbres répartis sur une grille 2d chaque cellule de la grille est modélisée par un arbre dont les noeuds représentent les données la partition globale obtenue est visualisée à laide dune carte de treemap dans laquelle chaque treemap représente un arbre de données nous évaluerons les capacités et les performances de notre approche sur des données aux difficultés variables des résultats numériques et visuels seront présentés et discutés\n",
      "utilisation dune ontologie du domaine pour la découverte du contenu de bases de données géographiques\n",
      "lessor récent des technologies associées à la géomatique a permis la production rapide de nombreuses données géographiques or pour tirer profit de ces données il convient de pouvoir évaluer leur pertinence et leur complexité vis à vis de lapplication à laquelle on les destine dans cet article nous présentons une application permettant à un utilisateur de découvrir le contenu de bases de données géographiques à savoir quels types dentités géographiques sont représentés au sein de chaque base et comment pour accéder à ces informations lutilisateur interroge le système via une ontologie globale du domaine qui décrit les types dentités topographiques du monde réel des ontologies locales ou dapplication sont utilisées pour formaliser les spécifications de chaque base de données décrite elles sont annotées à laide de concepts issus de lontologie globale ce système est implémenté sous la forme dune interface web et inclut un affichage cartographique déchantillons de données\n",
      "utilisation de la machine cellulaire pour la détection des courriels indésirables\n",
      "nan\n",
      "utiliser des résultats dalignement pour enrichir une ontologie\n",
      "en établissant des relations entre des concepts issus de deux ontologies distinctes les outils dalignement peuvent être utilisés pour enrichir une des deux ontologies avec les concepts de lautre a partir dune expérience menée dans le cadre du projet anr geonto 1 dans le domaine de la topographie cet article identifie des traitements complémentaires à lalignement pour lenrichissement et montre leur mise en oeuvre dans taxomap framework\n",
      "vers la fusion dinformations hétérogènes et partielles pour laide au codage diagnostique\n",
      "nan\n",
      "visualisation de lintra et inter structure des groupes en classification non supervisée\n",
      "la croissance exponentielle des données engendre des volumétries de bases de données très importantes une solution couramment envisagée est lutilisation dune description condensée des propriétés et de la structure des données de ce fait il devient crucial de disposer doutils de visualisation capables de représenter la structure des données non pas à partir des données elles mêmes mais à partir de ces descriptions condensées nous proposons une méthode de description des données à partir de prototypes enrichis puis segmentés à laide dun algorithme adapté de classification non supervisée nous introduisons ensuite un procédé de visualisation capable de mettre en valeur la structure intra et intergroupes des données\n",
      "abstopk 945 un algorithme dextraction de paires abstraites hautement corrélées pour mieux recommander dans la ”longue traine\n",
      "de nombreux systèmes de recommandation se focalisent sur les articlesque nous appellerons ”items” les plus ”populaires” et ignorent souventla ”longue traîne” des produits qui le sont moins nous proposons lalgorithmeabstopk945 qui améliore les recommandations en se basant sur la combinaisonpondérée par 945 de paires hautement corrélées entre des abstractions ditems etentre des paires ditems concrets classiquement recherchées\n",
      "action rules and metaactions\n",
      "nan\n",
      "affichage de publicités sur des portails web\n",
      "nous nous intéressons au problème de laffichage de publicités surle web de plus en plus dannonceurs souhaitent maintenant payer uniquementlorsque quelquun clique sur leurs publicités dans ce modèle lopérateur duportail a intérêt à identifier les publicités les plus cliquées selon ses catégoriesde visiteurs comme les probabilités de clic sont inconnues a priori il sagit dundilemme explorationexploitation ce problème a souvent été traité en ne tenantpas compte de contraintes provenant du monde réel  les campagnes de publicitésont une durée de vie et possèdent un nombre de clics à assurer et ne pas dépasserpour cela nous introduisons une approche hybride mablp entre la programmationlinéaire et les bandits nos algorithmes sont testés sur des modèles créésavec un important acteur du web commercial ces expériences montrent que cesapproches atteignent une performance très proche de loptimum et mettent enévidence des aspects clés du problème\n",
      "agrégation de systèmes de fermetures cas des hiérarchies topologies et géométries convexes\n",
      "nan\n",
      "aide à la décision pour la maintenance ferroviaire préventive\n",
      "la maintenance de trains est un problème particulièrement délicat liéà de nombreux enjeux à la fois financiers sécuritaires et énergétiques nous nousintéressons à la mise en place dune maintenance préventive basée sur la détectionet la correction de tout comportement anormal susceptible de provoquer unproblème majeur dans un futur proche nous proposons ainsi un outil daide à ladécision afin de i dégager des connaissances utiles sur lhistorique des trainset ii détecter et étudier les anomalies comportementales dans le but de prendredes décisions optimales en termes de maintenance ferroviaire\n",
      "allier csps et motifs locaux pour la découverte de motifs sous contraintes naires\n",
      "dans cet article nous étudions la relation entre la découverte de motifssous contraintes et les csps constraint satisfaction problems afin de définirdes contraintes de plus haut niveau qui sont précieuses pour mener à bien destâches de fouille de données pour cela nous proposons une approche de modélisationet dextraction de motifs sous contraintes naires exploitant les motifslocaux lutilisateur définit un ensemble de contraintes naires et un solveur decsp génère lensemble des solutions notre approche profite des progrès récentssur lextraction de motifs locaux et permet de modéliser de manière concise etélégante tout ensemble de contraintes combinant plusieurs motifs locaux permettantainsi la découverte de motifs répondant mieux aux buts finaux de lutilisateurles expériences menées montrent la faisabilité de notre approche\n",
      "analyse de documents pédagogiques en vue de leur annotation\n",
      "lutilisation des documents pédagogiques disponibles sur le webdevient de plus en plus large tant pour lenseignant qui a besoin de préparerson support de cours que pour létudiant qui désire par exemple sautoformerla description dun document pédagogique en lalimentant par desmétadonnées savère une solution qui confère une valeur ajoutée au documentafin dexpliciter des informations placées dans ce document dans cetteoptique nous proposons une méthode dannotation de documentspédagogiques selon différents points de vue qui est basée sur lanalysesémantique des éléments discursifs du texte\n",
      "analyse de séquences dévénements avec traminer\n",
      "nan\n",
      "analyse en ligne dobjets complexes avec lanalyse factorielle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les entrepôts de données et lanalyse en ligne olap online analysisprocessing présentent des solutions reconnues et efficaces pour le processusdaide à la décision notamment lanalyse en ligne grâce aux opérateurs olappermet de naviguer et de visualiser des données représentées dans un cube multidimensionnelmais lorsque les données ou les objets à analyser sont complexesil est nécessaire de redéfinir et denrichir ces opérateurs olap dans cet articlenous proposons de combiner lanalyse olap et la fouille de données data miningafin de créer un nouvel opérateur de visualisation dobjets complexes cetopérateur utilise lanalyse factorielle des correspondances\n",
      "analyse globale du flux optique pour la détection dévènements dans une scène de foule\n",
      "les systèmes de vidéosurveillance sont de plus en plus autonomesdans la détection des événements anormaux cet article présente une méthode dedétection des flux majeurs et des évènements qui surviennent dans une scène defoule ces détections sont effectuées en utilisant un modèle directionnel construità partir dun mélange de lois de von mises appliqué à lorientation des vecteursde mouvement les flux majeurs sont alors calculés en récupérant les orientationsles plus importantes des mélanges divers évènements se produisant dansune foule sont aussi détectés en utilisant en plus du modèle dorientation unmodèle probabiliste de magnitude des vecteurs de mouvement les résultats delexpérimentation sur un échantillon de vidéos dévénements sont présentés\n",
      "analyse incrémentale des usages pour le routage des requêtes dans les systèmes pairs à pairs\n",
      "nan\n",
      "applying markov logic to document annotation and citation deduplication\n",
      "structured learning approaches are able to take into account the relationalstructure of data thus promising an enhancement over nonrelationalapproaches in this paper we explore two documentrelated tasks in relationaldomains setting the annotation of semistructured documents and the citationdeduplication for both tasks we report results of comparing relational learningapproach namely markov logic to nonrelational one namely support vectormachines svm we discover that increased complexity due to the relationalsetting is difficult to manage in large scale cases where nonrelational modelsmight perform better moreover our experiments show that in markov logicthe contribution of its probabilistic component decreases in large scale domainsand it tends to act like firstorder logic fol\n",
      "apport de la technique de fouille de données spatiales dans la prédiction des risques engendrés par les changements climatiques\n",
      "nan\n",
      "apprentissage de patrons lexicosyntaxiques à partir de textes\n",
      "ce papier présente une approche dapprentissage de patrons lexicosyntaxiquesà partir de textes annotés les patrons lexicosyntaxiques sont utiliséspour identifier des relations lexicales dans les corpus textuels leur constructionmanuelle est une tâche fastidieuse et des solutions permettant lapprentissagesont souhaitables nous proposons une approche dapprentissage qui reposesur lutilisation des chemins de dépendance pour représenter les patrons et limplémentationdun algorithme de classification lapproche a été appliquée dansle domaine biomédical pour identifier des patrons lexicosyntaxiques exprimantdes relations fonctionnelles\n",
      "apprentissage de spécifications de csp\n",
      "nan\n",
      "apprentissage supervisé adaptatif de concepts formels à partir des données nominales\n",
      "nan\n",
      "approche biomimétique coopérative pour la visualisation de grands graphes multidimensionels\n",
      "face à la quantité sans cesse grandissante de données stockées les algorithmes de fouille etde visualisation de données doivent pouvoir être capable de traiter de grandes quantités de donnéesune des solutions est deffectuer un prétraitement des données permettant la réductionde la dimension des données sans perte significative dinformations lidée est donc de réduirelensemble de descripteurs avant de faire appel à la méthode de visualisation sous forme dungraphe\n",
      "approche complexe de lanalyse de documents anciens\n",
      "cet article présente une méthode complexe pour la caractérisation etlindexation dimages graphiques de documents anciens a partir dun bref étatde lart une méthode pour décrire ces images en tenant compte de leur complexitéest proposée trois étapes principales de ce traitement sont détailléesdont une méthode novatrice danalyse de segmentation et de description destraits les résultats sont issus de travaux en cours et sont encourageants\n",
      "approche sémantique pour la préservation de la vie privée dans les médias sociaux\n",
      "nan\n",
      "bien cube les données textuelles peuvent sagréger \n",
      "la masse des données aujourdhui disponibles engendre des besoinscroissants de méthodes décisionnelles adaptées aux données traitées ainsi récemmentde nouvelles approches fondées sur des cubes de textes sont apparuespour pouvoir analyser et extraire de la connaissance à partir de documents loriginalitéde ces cubes est détendre les approches traditionnelles des entrepôts etdes technologies olap à des contenus textuels dans cet article nous nous intéressonsà deux nouvelles fonctions dagrégation la première propose une nouvellemesure de tfidf adaptative permettant de tenir compte des hiérarchiesassociées aux dimensions la seconde est une agrégation dynamique permettantde faire émerger des groupements correspondant à une situation réelle lesexpériences menées sur des données issues du serveur hal dune universitéconfirment lintérêt de nos propositions\n",
      "caractériser la terminologie des usagers de santé dans le domaine du cancer du sein\n",
      "internet est devenu une source importante dinformations médicalespour les patients et leurs proches  recherche dinformations sur leurs maladieset les dernières recherches cliniques ainsi que pour y constituer des communautés“numériques” de dialogue et de partage cependant accès à internet nesignifie pas nécessairement accès à linformation le manque de familiarité avecle langage médical constitue un problème majeur pour les usagers de santé danslaccès à linformation et son interprétation ce papier sinscrit dans la problématiquedétude et de caractérisation de la terminologie des usagers de santépour pouvoir proposer des services adaptés à leur langage et à leur niveau deconnaissances le travail réalisé est une ontologie dans le domaine du cancerdu sein orientée vers les usagers de santé cette ontologie est construite à partirdun ensemble de corpus de textes représentant deux catégories  les médiateurset les usagers de santé les éléments de cette ontologie ont été analysés en utilisantdes méthodes quantitatives et qualitatives sur plusieurs niveaux  termesconcepts et relations\n",
      "cartocel  un outil de cartographie des connaissances guidée par la machine cellulaire casi\n",
      "nous présentons dans ce papier loutil cartocel cartographiescellulaires permettant une visualisation automatique et dynamique desdomaines de connaissances le fonctionnement de cartocel est basé surune approche originale de modélisation booléenne de la cartographie des domainesde connaissances métiersstratégiques inspirée du principe de la machinecellulaire casi cellular automata for symbolic induction le butaprès une modélisation booléenne de la cartographie des domaines de connaissancesest double  dune part affiner la cartographie par une fouille de donnéeorchestrée par casi et dautre part réduire la complexité de stockage ainsique le temps de calcul\n",
      "chorml  résumés visuels de bases des données géographiques\n",
      "nan\n",
      "classer discriminer et visualiser des séquences dévénements\n",
      "cet article 1 présente un ensemble doutils destiné à analyser des séquencesdévénements en sciences sociales et à visualiser les résultats obtenusnous commençons par formaliser la notion de séquence dévénements avant dedéfinir une mesure de dissimilarité entre ces séquences afin de construire destypologies et de tester les liens entre ces séquences et dautres variables dintérêtsinitialement définie par moen 2000 cette mesure se base sur la notion dedistance dédition entre séquences et permet didentifier les différences dordonnancementet de temporalité des événements nous proposons une extension decelleci afin de pouvoir prendre en compte la simultanéité des événements ainsiquune méthode de normalisation qui garantit le respect de linégalité triangulairedans un deuxième temps nous présentons un ensemble doutils destinésà interpréter les résultats nous proposons ainsi deux méthodes de visualisationdun ensemble de séquences et nous introduisons la notion de sousséquencediscriminante qui permet didentifier les différences dordonnancement des événementsles plus significatives entre groupes lensemble des outils présentés estdisponible au sein de la librairie r traminer\n",
      "classification de documents  calcul dune distance structurelle\n",
      "la classification des documents numériques garantit un accès rapideet ciblé à linformation si nous considérons quun document est représenté parsa ou ses structures définir des classes de documents revient à définir desclasses de structures une classe structurelle représente donc des structures« proches » ainsi associer la structure dun document à sa classe structurellerevient à calculer une distance dite « structurelle » elle tiendra compte à lafois de lorganisation des éléments position des noeuds chemin du coûtdadaptation des représentants des classes ainsi que de la représentativité dessousgraphes sur un corpus de documents représentant des notices de livresissus de la bibliothèque de luniversité nous discuterons de la construction decette distance de lintérêt de chacun des trois paramètres utilisés\n",
      "classification et selection de caracteristique basees sur les concepts semantiques pour la recherche dinformation multimedia\n",
      "le besoin récent de nombreuses applications multimédia basées sur le contenu a engendré une demande croissante de technologies dans le domaine de la recherche dinformation multimédia basée sur létat de lart des techniques existantes nous proposons dans cet article une approche de recherche dinformation multimédia qui prend en compte les informations de scène et exploite un modèle de sélection de caractéristiques les principaux avantages de notre modèle de recherche par rapport aux modèles existants sont  i une méthode de classification basée sur des catégories de concept sémantique ii un modèle de recherche par rapport aux modèles existants sont  i une méthode de classification basée sur des catégories de concept sémantique ii un modèle de sélection de caractéristiques iii un index multidimensionnel notre framework propose un bon compromis entre précision et rapidité de la recherche\n",
      "classification supervisée pour de grands nombres de classes à prédire  une approche par copartitionnement des variables explicatives et à expliquer\n",
      "dans la phase de préparation des données du data mining les méthodesde discrétisation et de groupement de valeurs supervisé possèdent denombreuses applications  interprétation estimation de densité conditionnellesélection de type filtre des variables recodage des variables en amont des classifieursces méthodes supposent habituellement un faible nombre de valeur àexpliquer classes typiquement moins dune dizaine et trouvent leur limitequand leur nombre augmente dans cet article nous introduisons une extensiondes méthodes de discrétisation et groupement de valeurs consistant à partitionnerdune part la variable explicative dautre part la variable à expliquerle meilleur copartitionnement est recherché au moyen dune approche bayesiennede la sélection de modèle nous présentons ensuite comment utiliser cetteméthode de prétraitement en préparation pour le classifieur bayesien naïf desexpérimentations intensives démontrent lapport de la méthode dans le cas decentaines de classes\n",
      "cndcube  nouvelle représentation concise sans perte dinformation dun cube de données\n",
      "le calcul des cubes de données est excessivement coûteux aussi bienen temps dexécution quen mémoire et son stockage sur disque peut savérerprohibitif plusieurs efforts ont été consacrés à ce problème à travers les cubesfermés où les cellules préservant la sémantique dagrégation sont réduites à unecellule sans perte dinformation dans cet article nous introduisons le conceptdu cube de données nondérivable fermé nommé cndcube qui généralisela notion des modèles nondérivables fermés fréquents bidimensionnels à uncontexte multidimensionnel nous proposons un nouvel algorithme pour extrairele cndcube à partir des bases de données multidimensionnelles en se basantsur trois contraintes antimonotones à savoir “être fréquent” “être non dérivable”et “être un générateur minimal” les expériences montrent que notreproposition fournit la représentation la plus concise dun cube de données et elleest ainsi la plus efficace pour réduire lespace de stockage\n",
      "codage et classification non supervisée dun corpus maya  extraire des contextes pour situer linconnu par rapport au connu\n",
      "lécriture logosyllabique des anciens mayas comprend plus de 500signes et est en bonne partie déchiffrée avec des degrés de certitude diversnous avons appliqué au codex de dresde lun des trois seuls manuscrits quinous soient parvenus codé sous latexavec le systèmemayatex notre méthodede représentation graduée par apprentissage non supervisé hybride entre clusteringet analyse factorielle oblique sous la métrique de hellinger afin dobtenirune image nuancée des thèmes traités  les individus statistiques sont les 212segments de folio du codex et leurs attributs sont les 1687 bigrammes de signesextraits pour comparaison nous avons introduit dans cette approche endogèneun élément exogène la décomposition en éléments des signes composites pourpréciser plus finement les contenus la rétrovisualisation dans le texte originaldes résultats et expressions dégagées éclaire la signification de certains glyphespeu compris en les situant dans des contextes clairement interprétables\n",
      "combiner approche logique et numérique pour la réconciliation de données et lalignement dontologies\n",
      "nan\n",
      "combinerweb 20 et web sémantique pour réduire les disparités dexpertise au sein de blogs dentreprise\n",
      "avec lavènement dapplications sociales en entreprise blogs wikisetc il est fréquent que des individus aux niveaux dexpertise relativement distantsse réunissent au sein de communautés en ligne ces disparités dexpertisese traduisent entre autres par des comportements différents dans la manière detagguer les contenus créés notamment en ce qui concerne les termes utilisésrendant ainsi complexe la découverte dinformations pourtant publiées dans cetarticle nous mettons en avant la possibilité offerte par les technologies du websémantique combinées avec les paradigmes du web social de résoudre cetteproblématique nous proposons ainsi une chaine de traitement combinant ontologieswikis sémantiques et indexation de contenus permettant la production degraphes sémantiques interconnectés et facilitant de cette manière la découvertede contenus créés au sein de tels systèmes\n",
      "comparaison de critères de pureté pour lintégration de connaissances en clustering semisupervisé\n",
      "lutilisation de connaissances pour améliorer les processus de fouillede données a mobilisé un important effort de recherche ces dernières années ilest cependant souvent difficile de formaliser ce type de connaissances commecellesci sont souvent dépendantes du domaine dans cet article nous nous intéressonsà lintégration de connaissances sous la forme dobjets étiquetés dansles algorithmes de clustering plusieurs critères permettant dévaluer la puretédes clusters sont présentés et leur comportement est comparé sur des jeux dedonnées artificiels les avantages et les inconvénients de chaque critère sontanalysés pour aider lutilisateur à faire un choix\n",
      "comparaisons structurelles de grandes bases de données par apprentissage nonsupervisé\n",
      "dans le domaine de la fouille de données mesurer les similitudesentre différents sousensembles est une question importante qui a été peu étudiéejusquà présent dans cet article nous proposons une nouvelle méthodebasée sur lapprentissage nonsupervisé les différents sousensembles à comparersont caractérisés au moyen dun modèle à base de prototypes ensuite lesdifférences entre les modèles sont détectées en utilisant une mesure de similarité\n",
      "composition de servicesweb basée sur les réseau sociaux\n",
      "nous proposons dans cet article une première approche qui consisteà exploiter les réseaux sociaux afin de faciliter la composition de services parles utilisateurs finaux nous introduisons un framework nommé social composersoco qui implémente cette approche soco fournit à lutilisateur desrecommandations dynamiques de services basées entre autre sur le réseau socialde lutilisateur qui est construit implicitement à partir des interactions entre lesutilisateurs les services les différentes compositions opérées par les membresdu réseau social ainsi que le réseau social global\n",
      "construction de noyaux pour lapprentissage supervisé à partir darbres aléatoires\n",
      "nous montrons quun ensemble darbres de décision avec une composantealéatoire permet de construire un noyau efficace destiné à lapprentissagesupervisé nous étudions théoriquement les propriétés dun tel noyau et montronsque sous des conditions très souvent rencontrées en pratique il existe uneséparabilité linéaire entre exemples de classes distinctes dans lespace induit parceluici parallèlement nous observons également que le classique vote à la majoritédun ensemble darbres est un hyperplan sans garantie doptimalité danslespace induit par le noyau enfin comme le montrent nos expérimentationslutilisation conjointe dun ensemble darbres et dun séparateur à vaste margesvm aboutit à des résultats extrêmement encourageants\n",
      "cubes fermés  quotients émergents\n",
      "le concept de cube émergent a été introduit afin de comparer deuxdata cubes dans cet article nous introduisons deux nouvelles représentationsréduites du cube émergent sans perte des mesures  le cube fermé émergent etle cube quotient émergent la première représentation est basée sur le conceptde fermeture cubique cest la plus petite représentation possible du cube dedonnées émergent à partir du cube fermé émergent et donc en stockant le minimumdinformations il est possible de répondre efficacement aux requêtes quipeuvent être exécutées sur le cube émergent luimême la seconde représentationsappuie sur la structure du cube quotient qui a été proposé pour résumer uncube de données le cube quotient est revisité afin de le doter dune sémantiquebasée sur la fermeture cubique et donc adapté au contexte du cube émergent lecube quotient émergent résultant est moins réduit que le cube fermé émergentmais il préserve la propriété de  spécialisationgénéralisation  du data cube quipermet la navigation au sein du cube émergent nous établissons également lelien entre les deux représentations introduites et celle basée sur les bordures classiquesen fouille de données des expérimentations effectuées sur divers jeux dedonnées visent à comparer la taille des différentes représentations\n",
      "dafoe une plateforme pour construire des ontologies à partir de textes et de thésaurus\n",
      "nan\n",
      "découverte ditemsets fréquents fermés sur architectures multicoeurs\n",
      "dans ce papier nous proposons plcm un algorithme parallèle dedécouverte ditemsets fréquents fermés basé sur lalgorithme lcm reconnucomme lalgorithme séquentiel le plus efficace pour cette tâche nous présentonsaussi une interface de parallélisme à la fois simple et puissante basée sur lanotion de tuple space qui permet davoir une bonne répartition dynamique dutravailgrâce à une étude expérimentale détaillée nous montrons que plcm est le seulalgorithme qui soit suffisamment générique pour calculer efficacement des itemsetsfréquents fermés à la fois sur des bases creuses et sur des bases densesaméliorant ainsi létat de lart\n",
      "découverte des dépendances fonctionnelles conditionnelles fréquentes\n",
      "les dépendances fonctionnelles conditionnelles dfc ont été introduitesen 2007 pour le nettoyage des données elles peuvent être considéréescomme une unification de dépendances fonctionnelles df classiques et derègles dassociation ra puisquelles permettent de spécifier des dépendancesmixant des attributs et des couples de la forme attributvaleurdans cet article nous traitons le problème de la découverte des dfc ie déterminerune couverture de lensemble des dfc satisfaites par une relation r nousmontrons comment une technique connue pour la découverte des df exacteset approximatives peut être étendue aux dfc cette technique a été implémentéeet des expériences ont été menées pour montrer la faisabilité et le passage àléchelle de notre proposition\n",
      "density estimation on data streams  an application to change detection\n",
      "in recent years the amount of data to process has increased in manyapplication areas such as network monitoring web click and sensor data analysis data stream mining answers to the challenge of massive data processing this paradigm allows for treating pieces of data on the fly and overcoming data storage the detection of changes in a data stream distribution is an important issue this article proposes a new schema of change detection i the summarization of the input data stream by a set of microclustersii the estimate of the data stream distribution exploiting microclustersiii the estimate of the divergence between the current estimated distribution and a reference distributioniv diagnostic step through the contribution of each predictive variable to the overall divergence between both distributionsour schema of change detection is applied and evaluated on artificial data streams\n",
      "detecting anomalies in data streams using statecharts\n",
      "the environment around us is progressively equipped withvarious sensors producing data continuously the applications usingthese data face many challenges such as data stream integration over anattribute such as time and knowledge extraction from raw data in thispaper we propose one approach to face those two challenges first datastreams integration is performed using statecharts which represents aresume of data produced by the corresponding data producer secondwe detect anomalous events over temporal relations among statechartswe describe our approach in a demonstration scenario that is using avisual tool called patternator\n",
      "détection des mouvements anormaux dans des vidéos\n",
      "nan\n",
      "développement de méthodes de classification basées sur lanalyse de concepts formels sous la plateforme weka\n",
      "nan\n",
      "differentes variantes gmmsmos pour lidentification du locuteur\n",
      "dans cet article nous présentons différentes variantes gmmsmos pour lidentification du locuteur en mode indépendant du texte pour mettre en oeuvre les différents systèmes nous avons opté une représentation multigaussienne de lespace des caractéristiques basées sur lalgorithme expectation maximisation em ces nouvelles représentations constituent les vecteurs dentrés pour entraîner les supports vecteurs machines svms par lalgorithme de type optimisation par minimisation séquentielle smo\n",
      "etude comparative des langages de requêtes sémantiques pour lextraction des liens complexes dans une base de connaissances\n",
      "nan\n",
      "etude de stabilité de méthodes de sélection de motifs à partir des séquences protéiques\n",
      "nan\n",
      "expansion de requêtes sql par une ontologie de domaine\n",
      "cet article traite un problème dans le domaine de la gestion des basesde données classiques il sagit dexploiter une ontologie de domaine pour aiderlutilisateur dune base de données relationnelle dans sa recherche et de luipermettre une interrogation transparente de la base de données pour cela nousproposons une approche dexpansion automatique de requêtes sql lorsquecellesci nont pas de réponses notre approche est décrite par un algorithmedéfini de manière générique afin dêtre utilisé pour une base de données quelconque\n",
      "explication de décisions de réconciliation  approche fondée sur les réseaux de petri colorés\n",
      "lobjectif des systèmes dintégration de données est de faciliter lexploitationet linterprétation dinformations hétérogènes provenant de différentessources lorsque lon doit intégrer de grands volumes de données le recours àun expert nest pas envisageable mais lexploitation de processus dintégrationautomatiques peut introduire des approximations ou des erreurs nous nous focalisonssur les résultats fournis par les méthodes de réconciliation de donnéesces dernières comparent les données entre elles et détectent celles qui réfèrent àla même entité du monde réel pour renforcer la confiance des utilisateurs dansles résultats retournés par ces méthodes nous proposons dans cet article une approchedexplication graphique fondée sur les réseaux de petri colorés qui estparticulièrement adaptée aux approches de réconciliation globales numériqueset guidées par une ontologie\n",
      "exploration de dépendances fonctionnelles et de règles dassociation avec olap\n",
      "nan\n",
      "extraction ditemsets distinctifs dans les flux de données\n",
      "lextraction ditemsets distinctifs est un sujet de recherche récent quiconnait plusieurs algorithmes pour les données statiques knobbe et ho 2006heikinheimo et al 2007 ces solutions ne sont toutefois pas conçues pour lecas des flux de données pour lesquels les temps de réponse doivent être aussifaibles que possible nous considérons le problème de lextraction ditemsetsdistinctifs dans les flux qui peut avoir de nombreuses applications dans la sélectionde variables la classification ou encore la recherche dinformation nousproposons lheuristique idkf itemsets distinctifs dans les flux et des résultatsdexpérimentations en comparaison dune technique de la littérature\n",
      "extraction de la région dintérêt dune personne sur un obstacle\n",
      "nan\n",
      "extraction de motifs graduels clos\n",
      "la découverte automatique de règles et motifs graduels “plus lâgedune personne est élevé plus son salaire est élevé” trouve de très nombreusesapplications sur des bases de données réelles eg biologie flots de données decapteurs si des algorithmes de plus en plus efficaces sont proposés dans desarticles récents il nen reste pas moins que ces méthodes génèrent un nombrede motifs tellement important que les experts peinent à les exploiter dans cetarticle nous proposons donc une représentation condensée des motifs graduelsen introduisant les concepts théoriques associés aux opérateurs de fermeture surde tels motifs\n",
      "extraction de règles dassociation séquentielle à laide de modèles semiparamétriques à risques proportionnels\n",
      "la recherche de liens entre objets fréquents a été popularisée par lesméthodes dextraction de règles dassociation dans le cas de séquences dévénementsles méthodes de fouille permettent dextraire des sousséquences quipeuvent ensuite être exprimées sous la forme de règles dassociation séquentielleentre événements cette utilisation de la fouille de séquences pour la recherchede liens entre des événements pose deux problèmes premièrement lecritère principal utilisé pour sélectionner les sousséquences dévénements estla fréquence or les occurrences de certains événements peuvent être fortementliées entre elles même lorsquelles sont peu fréquentes deuxièmement les mesuresactuelles utilisées pour caractériser les règles dassociation ne tiennent pascompte du caractère temporel des données comme limportance du timing desévénements ou le problème des données censurées dans cet article nous proposonsune méthode pour rechercher des liens significatifs entre des événementsà laide de modèles de durée les règles dassociation sont construites à partirdes motifs séquentiels observés dans un ensemble de séquences linfluence surle risque que lévénement « conclusion » se produise après le ou les événements« prémisse » est estimée à laide dun modèle semiparamétrique à risques proportionnelsoutre la présentation de la méthode larticle propose une comparaisonavec dautres mesures dassociation\n",
      "extraction des séquences fermées fréquentes à partir de corpus parallèles  application à la traduction automatique\n",
      "dans cet article nous abordons la problématique dextraction de séquencesfréquentes à partir de corpus de textes parallèles en prenant en comptelordre dapparition des mots dans une phrase notre finalité est dexploiter cesséquences dans la traduction automatique ta nous introduisons ainsi la notionde règles associatives interlangues rail et nous définissons notre modèlede traduction à base de ces associations nous décrivons également les différentesexpérimentations conduites sur le corpus europarl afin de construire àpartir des rail une table de traduction bilingue qui est intégrée par la suite dansun processus complet de ta\n",
      "fouille visuelle de données en 3d et réalité virtuelle  état de lart\n",
      "la fouille visuelle de données ou visual data mining vdm a pourobjectif de faciliter linterprétation des résultats issus dune fouille de donnéesgrâce à lusage de représentations graphiques au cours de la dernière décennieun grand nombre de techniques de visualisation dinformation ont été mises aupoint permettant la visualisation de données multidimensionnelles dans des environnementsvirtuels lors des travaux antérieurs les chercheurs ont proposédes taxonomies pour classer les techniques de vdm chi 2000 herman et al2000 toutefois ces taxonomies ne prennent en compte que partiellement lestechniques récentes relatives à lutilisation de la 3d et de la réalité virtuelle lebut de cet article est de faire un état de lart récent et spécifique à ces techniquescellesci sont détaillées classées et comparées selon différents critères  les applicationslencodage graphique les techniques dinteraction les avantages etles inconvénients de chaque approche ces techniques sont présentées dans destableaux accompagnées dillustrations graphiques\n",
      "gestion sémantique des droits daccès au contenu lontologie amo\n",
      "dans cet article nous proposons une approche de la gestion des droitsdaccès pour les systèmes de gestion de contenu qui reposent sur les modèles ettechniques du web sémantique nous présentons lontologie amo qui consiste1 en un ensemble de classes et propriétés permettant dannoter les ressourcesdont il sagit de contrôler laccès et 2 en une base de règles dinférence modélisantla stratégie de gestion des droits à mettre en oeuvre appliquées sur la basedannotations des ressources ces règles permettent de gérer les ressources selonune stratégie donnée cette modélisation garantit ainsi ladaptabilité de lontologieà différentes stratégies de gestion des droits daccès nous illustrons lutilisationde lontologie amo sur les documents du projet anr isicil produitspar le wiki sémantique sweetwiki nous montrons comment les documents sontannotés avec amo quelles règles sont mises en oeuvre et quelles requêtes permettentle contrôle de laccès aux documents\n",
      "identifying the presence of communities in complex networks through topological decomposition and component densities\n",
      "the exponential growth of data in various fields such as social networksand internet has stimulated lots of activity in the field of network analysisand data mining identifying communities remains a fundamental technique toexplore and organize these networks few metrics are widely used to discoverthe presence of communities in a network we argue that these metrics do nottruly reflect the presence of communities by presenting counter examples thisis because these metrics concentrate on local cohesiveness among nodes wherethe goal is to judge whether two nodes belong to the same community or viseversa thus loosing the overall perspective of the presence of communities in theentire network in this paper we propose a new metric to identify the presenceof communities in real world networks this metric is based on the topologicaldecomposition of networks taking into account two important ingredients of realworld networks the degree distribution and the density of nodes we show theeffectiveness of the proposed metric by testing it on various real world data sets\n",
      "incfds un nouvel algorithme dinférence incrémentale des dépendances fonctionnelles\n",
      "linférence des dépendances fonctionnelles est lune des problématiquesles plus étudiées en bases de données elle a fait lobjet de plusieurstravaux qui ont proposé des algorithmes afin dinférer efficacement les dépendancesfonctionnelles pour les utiliser dans différents domaines  administrationde bases de données réingénierie optimisation des requêtesetc toutefoispour les application réelles les bases de données sont évolutives et les relationssont fréquemment augmentées ou diminuées de tuples par conséquent afin desadapter à ce cadre dynamique une solution consiste à appliquer lun des algorithmesdisponibles dans la littérature pour inférer les dépendances fonctionnellesaprès chaque mise à jour cette solution étant coûteuse nous proposonsdans cet article dinférer les dépendances fonctionnelles dune manière incrémentaleà cet effet nous introduisons un nouvel algorithme appelé incfds etnous évaluons ses performances par rapport à lapproche classique dinférencedes dépendances fonctionnelles à partir dune relation dynamique\n",
      "indexation et recherche dimages à très grande échelle avec une afc incrémentale et parallèle sur gpu\n",
      "nous présentons un nouvel algorithme incrémental et parallèledanalyse factorielle des correspondances afc pour la recherche dimages àgrande échelle en utilisant le processeur de la carte graphique gpu lafcest adaptée à la recherche dimages par le contenu en utilisant des descripteurslocaux des images sift lafc permet de réduire le nombre de dimensionset de découvrir des thèmes qui permettent de diminuer le nombre dimages àparcourir et donc le temps de réponse dune requête pour traiter de trèsgrandes bases dimages nous présentons une version incrémentale et parallèledafc puis nous utilisons ses indicateurs pour construire des fichiers inverséspour retrouver les images contenant les mêmes thèmes que limage requêtecette étape est elle aussi parallélisée sur gpu pour obtenir des réponsesrapides les résultats numériques sur la base de données dimages nistérstewénius plongée dans 1 million dimages de flickr montrent que notrealgorithme incrémental et parallèle est très significativement plus rapide que saversion standard\n",
      "indice de complexité pour le tri et la comparaison de séquences catégorielles\n",
      "cet article1 propose un nouvel indice de la complexité de séquencescatégorielles bien que conçu pour des séquences représentant des trajectoiresbiographiques telles que celles rencontrées dans les sciences sociales il sappliqueà tous types de listes ordonnées détats lindice prend en compte deuxaspects distincts soit la complexité induite par lordonnancement des états successifsqui est mesurée par le nombre de transitions changements détat et lacomplexité liée à la distribution des états dont rend compte lentropie\n",
      "inférence bayesienne du maximum dentropie pour le diagnostic du cancer\n",
      "nan\n",
      "intégration de connaissances a priori dans le principe du maximum dentropie\n",
      "cet article montre que si lon dispose dune connaissance a priori surle problème en main lintégration de cette dernière dans le processus dapprentissagedune machine intelligente pour des tâches de classification peut améliorerla performance de cette machine nous étudions leffet de lintégration de laconnaissance a priori de convexité sur le processus dapprentissage du principedu maximum dentropie maxent en utilisant des exemples virtuels nous testonsles idées proposées sur un problème benchmark bien connu dans la littératuredes machines dapprentissage le problème de formes dondes de breimannous avons abouti à un taux derreur de généralisation de 1557 qui est trèsproche du taux derreur théorique estimé par breiman 14\n",
      "intégration interactive de contraintes pour la réduction de dimensions et la visualisation\n",
      "il existe aujourdhui de nombreuses méthodes de réduction de dimensionsque ce soit dans un cadre supervisé ou non supervisé lun des intérêts deces méthodes est de pouvoir visualiser les données avec pour objectif que lesobjets qui apparaissent visuellement proches soient similaires dans un sensqui correspond aux connaissances dun expert du domaine ou qui soit conformeaux informations de supervision nous nous plaçons ici dans un contexte semisuperviséoù des connaissances sont ajoutées de façon interactive  ces informationsseront apportées sous forme de contraintes exprimant les écarts entrela représentation observée et les connaissances dun expert nous pourrons parexemple spécifier que deux objets proches dans lespace dobservation sont enfait peu similaires ou inversement la méthode utilisée ici dérive de lanalyseen composantes principales acp à laquelle nous proposons dintégrer deuxtypes de contraintes nous présentons une méthode de résolution qui a été implémentéedans un logiciel offrant une représentation 3d des données et grâceauquel lutilisateur peut ajouter des contraintes de manière interactive puis visualiserles modifications induites par ces contraintes deux types dexpérimentationsont présentés reposant respectivement sur un jeu de données synthétiqueet sur des jeux standards  ces tests montrent quune représentation de bonnequalité peut être obtenue avec un nombre limité de contraintes ajoutées\n",
      "interrogation des résumés de flux de données\n",
      "les systèmes de gestion de flux de données sgfd ont été conçusafin de traiter une masse importante de données produites en ligne de façoncontinue etant donné que les ressources matérielles ne permettent pas de conservertoute cette volumétrie seule la partie récente du flux est mémorisée dans lamémoire du sgfd ainsi les requêtes évaluées par ces systèmes ne peuvent porterque sur les données les plus récentes du flux par conséquent les sgfd actuelsne peuvent pas traiter des requêtes qui portent sur des périodes très longuesnous proposons dans cet article une approche permettant dévaluer des requêtesqui portent sur une période plus longue que la mémoire du sgfd ces fenêtresfont appels à des données récentes et des données historisées nous présentonsle niveau logique de cette approche ainsi que son implantation sous le sgfd esperune technique déchantillonnage associée à une technique de fenêtre pointde repère est appliquée pour conserver une représentation compacte des donnéesdu flux\n",
      "kwords lab  un outil danalyse des mots clés permettant dexplorer les dynamiques dun domaine scientifique\n",
      "nan\n",
      "kgram une machine abstraite de graphes de connaissance\n",
      "cet article présente la machine abstraite de graphes de connaissancekgram qui unifie les notions dhomomorphisme de graphe et de calcul de requêtestelles que celles du langage sparql sur des données rdf kgramimplémente un ensemble extensible dexpressions qui définissent une famille delangages abstraits dinterrogation de graphes graal nous décrivons la sémantiquedynamique de graal en sémantique naturelle et nous présentons lamachine abstraite kgram conçue comme linterprète de graal qui implémenteles règles de sémantique naturelle du langage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le conflit dans la théorie des fonctions de croyance\n",
      "le conflit apparaît naturellement lorsque plusieurs sources dinformationsimparfaites sont en jeu la théorie des fonctions de croyance offre unformalisme adapté à la fusion dinformations dans lequel la considération duconflit est centrale ce travail propose de revenir sur les différentes définitionsdu conflit dans cette théorie tentant de les synthétiser et de montrer commentsupprimer ce conflit ou bien comment en tenir compte lors de la combinaisondes informations\n",
      "modèle de langue à base de concepts pour la recherche dinformation\n",
      "la majorité des modèles de langue appliqués à la recherchedinformation repose sur lhypothèse dindépendance des motsplus précisément ces modèles sont estimés à partir des mots simplesapparaissant dans les documents sans considérer les éventuelles relationssémantiques et conceptuelles pour pallier ce problème deux grandesapproches ont été explorées  la première intègre des dépendances dordresurfacique entre les mots et la seconde repose sur lutilisation des ressourcessémantiques pour capturer les dépendances entre les mots le modèle delangue que nous présentons dans cet article sinscrit dans la seconde approchenous proposons dintégrer les dépendances entre les mots en représentant lesdocuments et les requêtes par les concepts\n",
      "modélisation et interrogation de données xml multidimensionnelles\n",
      "xml étant devenu omniprésent et ses techniques de stockage et dinterrogationde plus en plus efficaces le nombre de cas dutilisations de ces technologiesaugmente tous les jours un sujet prometteur est lintégration dxml etdes entrepôts de données dans laquelle une base de données xml native stockeles données multidimensionnelles et exécute des requêtes olap écrites à laidedu langage dinterrogation xml xquery ce papier explore les questions quipeuvent survenir lors de limplémentation dun tel entrepôt de données xml\n",
      "mysins  make your semantic information system\n",
      "nan\n",
      "objective novelty of association rules measuring the confidence boost1\n",
      "on sait bien que la confiance des régles dassociation nest pas vraimentsatisfaisant comme mésure dinterêt nous proposons au lieu de la substituerpar des autres mésures soit en lemployant de façon conjointe a desautres mésures évaluer la nouveauté de chaque régle par comparaison de saconfiance par rapport á des régles plus fortes quon trouve au même ensemblede données cest á dire on considère un seuil “relative” de confiance au lieu duseuil absolute habituel cette idée se précise avec la magnitude du “confidenceboost” mésurant lincrement rélative de confiance prés des régles plus fortesnous prouvons que nôtre proposte peut remplacer la “confidence width” et leblockage de régles employés a des publications précedentes\n",
      "osom  un algorithme de construction de cartes topologiques recouvrantes\n",
      "les modèles de classification recouvrante ont montré leur capacité àgénérer une organisation plus fidèle aux données tout en conservant la simplificationattendue par une structuration en classes strictes par ailleurs les modèlesneuronaux nonsupervisés sont plébiscités lorsquil sagit de visualiser la structurede classesnous proposons dans cette étude détendre les cartes autoorganisatrices traditionnellesaux cartes autoorganisatrices recouvrantes nous montrons que cettenouvelle structure apporte des solutions à certaines problématiques spécifiquesen classification recouvrante nombre de classes complexité cohérence des recouvrementslalgorithme osom sinspire de la version recouvrante des nuées dynamiqueset de lapproche de kohonen pour générer de telles cartes recouvrantes nousdiscutons du modèle proposé dun point de vue théorique fonction dénergieassociée complexité  enfin nous présentons un cadre dévaluation généraleque nous utilisons pour valider les résultats obtenus sur des données réelles\n",
      "pattern mining the past present and future\n",
      "pattern mining is one of the fundamental techniques in data mining as one increases thecomplexity of the pattern types from subsets to subsequences subtrees and subgraphs onediscovers potentially more informative patterns in this talk i will offer a tour of the past andthe present research landscape in this area and ill conclude with some thoughts on directionsfor the future\n",
      "pcar  nouvelle approche de génération de règles dassociation cycliques\n",
      "les règles dassociation cycliques vise la découverte de nouvelles relationsentre des produits qui varient dune façon régulièrement cyclique dans letemps dans ce cadre nous introduisons un nouvel algorithme nommé pcarcaractérisé par sa performance et son aspect incrémental létude empirique quenous avons menée montre la robustesse et lefficacité de notre algorithme proposévs ceux de la littérature\n",
      "pgpmc  extraction parallèle efficace de motifs graduels\n",
      "initialement utilisés pour les systèmes de commande les règles et motifsgraduels de la forme “plus une personne est âgée plus son salaire est élevé”trouvent de très nombreuses applications par exemple dans les domainesde la biologie des données en flots eg issues de réseaux de capteurs etc trèsrécemment des algorithmes ont été proposés pour extraire automatiquementde tels motifs cependant même si certains dentre eux ont permis des gainsde performance importants les algorithmes restent coûteux et ne permettentpas de traiter efficacement les bases de données réelles souvent très volumineusesen nombre de lignes etou nombre dattributs nous proposons doncdans cet article une méthode originale de recherche de ces motifs utilisant lemultithreading pour exploiter au mieux les multiples coeurs présents dans laplupart des ordinateurs et serveurs actuels lefficacité de cette approche est validéepar une étude expérimentale\n",
      "prédiction de séries temporelles et applications à lanalyse de séquences vidéo\n",
      "nan\n",
      "pretopolib la librairie java de la prétopologie\n",
      "pretopolib est une librairie java implémentant les concepts de laprétopologie son intérêt réside dans la représentation de structures de donnéespermettant la manipulation des données par des opérations ensemblistescelleci offre un cadre de développement dalgorithmes efficaces pour la fouillede données lapprentissage topologique et la modélisation des systèmes complexes\n",
      "proposition dopérateurs olap pour un modèle multidimensionnel à base dobjets complexes\n",
      "nan\n",
      "proposition dune méthode de classification associative adaptative\n",
      "la classification associative est une méthode de prédiction à base derègles issue de la fouille de règles dassociation cette méthode est particulièrementintéressante car elle recherche de façon exhaustive les règles dassociationpertinentes quelle filtre pour ne garder que les règles dassociation de classecelles admettant pour conséquent une modalité de classe qui sont utiliséescomme classifieur les connaissances produites sont ainsi directement interprétablesdes études antérieures montrent les inconvénients de cette approchequil sagisse de la génération massive de règles non utilisées ou de la mauvaiseprédiction de la classe minoritaire lorsque les classes sont déséquilibréesnous proposons une approche originale du type boosting de règles dassociationde classes qui utilise comme classifieur faible une base de règles significativesconstruites par un algorithme de génération ditemsets fréquents qui se limiteà lextraction des seules règles de classe significatives et qui prend en comptele déséquilibre des données des comparaisons avec dautres méthodes de classificationassociative montrent que notre approche améliore la précision et lerappel\n",
      "protein graph repository\n",
      "protein graph repository pgr est i outil bioinformatique sur le web permettant dobtenir une nouvelle representation de protéines sous la forme de graphes dacides aminés une représentation plus simple et plus facile à étudier par les moyens informatiques et statistiques dédiés aux graphes la génération des graphes est faite à partir dun parseur appliqué sur des fichiers des protéines pdb extraits de la base protein data bank et en precisant les parametres et la methode a utiliser les graphes generes sont ensuite enregistres dans un entrepot doté de moyens de recherche de filtrage et de telechargement pgr peut etre provisoirement consulte à ladresse httpwwwenodeeditioncompgr il est spécialement dédié aux recherches intéressées à létude de données protéiques sous la forme de graphes et permettra donc de fournir des échantillons pour des travaux expérimentaux\n",
      "recent advances in partitioning clustering algorithms for intervalvalued data\n",
      "nan\n",
      "recherche sémantique sur le web basée sur lontologie modulaire et le raisonnement à base de cas\n",
      "dans ce papier nous présentons une approche de recherche sémantiquebasée sur les ontologies modulaires et le raisonnement à base de casrapc un cas représente lensemble des requêtes similaires associées à leursrésultats pertinents les ontologies modulaires sont utilisées pour représenteret indexer les cas qui sont construits sur la base des requêtes antérieures et lesrésultats pertinents sélectionnés par les utilisateurs la similarité à basedontologies est utilisée pour retrouver les cas similaires à la requête utilisateuret pour fournir à celuici des propositions de reformulation de requêtes correspondantsà son besoin la principale contribution de ce travail réside dans lutilisationdun mécanisme de rapc et une représentation ontologique à deuxfins lamélioration de la recherche sémantique et lenrichissement dontologiesà partir de cas lexpérimentation de lapproche proposée montre que la précisionet le rappel des résultats se sont nettement améliorés\n",
      "reconnaissance de concepts basée sur lapprentissage\n",
      "nan\n",
      "réduction bidirectionnelle dimages  vers une méthode dextraction de caractéristiques multiniveaux\n",
      "inspiré des performances du cerveau humain à identifier les élémentspar la vue le problème de la réduction de la dimension dans le domaine de laperception visuelle consiste à extraire une quantité réduite des caractéristiquesdun ensemble dimages afin de les identifierce papier présente une approche innovante bidirectionnelle dextraction de caractéristiquesdimages fondée sur lutilisation partielle dune méthode spatiotemporelleles expériences numériques appliquées sur 70000 images représentantdes chiffres écrits à la main ainsi que sur 698 images illustrant un visagesous différentes postures démontrent lefficacité de notre approche à fortementréduire la dimension tout en conservant les relations intelligibles entre les objetsdes données permettant même dobtenir une meilleure classification à partir desversions réduites des images quà partir des versions originales\n",
      "reglo  une nouvelle stratégie pour résumer un flux de séries temporelles\n",
      "les flux de séries temporelles sont aujourdhui produits dans de nombreuxdomaines comme la finance zhu et shasha 2002 la surveillance deréseaux borgne et al 2007 airoldi et faloutsos 2004 la gestion de lhistoriquedes usages fréquents giannella et al 2003 teng et al 2003 etcrésumer de tels flux est devenu un domaine important qui permet de surveilleret denregistrer des informations fiables sur les séries observées à ce jour lamajorité des algorithmes de ce domaine sest concentrée sur des résumés séparéset indépendants giannella et al 2003 zhu et shasha 2002 chen et al2002 en accordant à chaque série le même espace en mémoire toutefois lagestion de cet espace mémoire est un sujet important pour les flux de donnéeset une stratégie accordant la même quantité de mémoire à chaque série nest pasforcément appropriée dans cet article nous considérons que les séries doiventêtre en compétition vis à vis de lespace mémoire selon leur besoin de précisionainsi nous proposons  1 une stratégie de gestion de lespace mémoireoptimisée et 2 une nouvelle méthode de résumé des séries temporelles par approximationdans ce but nous observons à la fois lerreur globale et les erreurslocales la répartition de la mémoire suit les étapes suivantes  1 recherchede la séquence la mieux représentée et 2 recherche de la partie à compresseren minimisant lerreur nos expérimentations sur des données réelles montrentlefficacité et la pertinence de notre approche\n",
      "regrouper les données textuelles et nommer les groupes à laide de classes recouvrantes\n",
      "organiser les données textuelles et en tirer du sens est un défi majeuraujourdhui ainsi lorsque lon souhaite analyser un débat en ligne ou unforum de discussion on voudrait pouvoir rapidement voir quels sont les principauxthèmes abordés et la manière dont la discussion se structure autour deuxpour cela et parce que un même texte peut être associé à plusieurs thèmes nousproposons une méthode originale pour regrouper les données textuelles en autorisantles chevauchements et pour nommer chaque groupe de manière lisiblela contribution principale de cet article est une méthode globale qui permet deréaliser toute la chaîne partant des données textuelles brutes jusquà la caractérisationdes groupes à un niveau sémantique qui dépasse le simple ensemble demots\n",
      "requêtes skyline avec prise en compte des préférences utilisateurs pour des données volumineuses\n",
      "appréhender parcourir des données ou des connaissances reste unetâche difficile en particulier lorsque les utilisateurs sont confrontés à de gros volumesde données de nombreux travaux se sont intéressés à extraire des pointsskylines comme outil de restitution la prise en compte des préférences a retenulattention des travaux les plus récents mais les solutions existantes restenttrès consommatrices en terme de stockage dinformations additionnelles afindobtenir des délais raisonnables de réponse aux requêtes notre propositionec2sky efficient computation of compromises se focalise sur deux points 1 comment répondre efficacement à des requêtes de type skyline en présencede préférences utilisateurs malgré de gros volumes de données aussi bien enterme de dimensions que de préférences  2 comment restituer les connaissancesles plus pertinentes en soulignant les compromis associés aux préférencesspécifiées\n",
      "résumé généraliste de flux de données\n",
      "lorsque le volume des données est trop important pour quelles soient stockéesdans une base de données ou lorsque leur fréquence de production est élevée les systèmesde gestion de flux de données sgfd permettent de capturer des flux denregistrementsstructurés et de les interroger à la volée par des requêtes permanentes exécutées de façoncontinue mais les sgfd ne conservent pas lhistorique des flux qui est perdu à jamaiscette communication propose une définition formelle de ce que devrait être un résumé généralistede flux de données la notion de résumé généraliste est liée à la capacité de répondreà des requêtes variées et de réaliser des tâches variées de fouille de données en utilisant lerésumé à la place du flux dorigine une revue de plusieurs approches de résumés est ensuiteréalisée dans le cadre de cette définition\n",
      "rss merger\n",
      "nan\n",
      "salines  un automate au service de lextraction de motifs séquentiels multidimensionnels\n",
      "les entrepôts de données occupent aujourdhui une place centrale dans le processus décisionneloutre leur consultation une des finalités des entrepôts est de servir de socle aux techniquesde fouilles de données malheureusement les approches existantes exploitent peu les particularitésdes entrepôts multidimensionnalité hiérarchies et données historiques parmi ces méthodes lextractionde motifs séquentiels multidimensionnels a récemment été étudiée nous montrons dans cetarticle que ces dernières ne tirent pas pleinement profit des hiérarchies et ne découvrent par conséquentquune partie seulement des motifs qualitativement intéressants nous proposons alors uneméthode dextraction de motifs séquentiels multidimensionnels basée sur un automate et extrayantde nouveaux motifs les différentes expérimentations menées sur des jeux de données synthétiquesattestent des bonnes performances de notre proposition\n",
      "sélection par entropie de descripteurs textuels pour la catégorisation de documents\n",
      "nan\n",
      "selfclustering for identification of customer purchase behaviours\n",
      "la segmentation dune base client peut avoir différents objectifs etplusieurs segmentation peuvent être utiles pour décrire les clients ou pour sadapteravec les stratégies commerciales dune entreprise dans ce papier nous présentonsun schéma expérimental visant à proposer un ensemble de segmentationsalternatives ces segmentations sont produites sur des données réelles par latransformation des données initiales la génération et la sélection de différentessegmentations\n",
      "sequencesviewer  comment rendre accessible des motifs séquentiels de gènes trop nombreux\n",
      "les techniques dextraction de connaissances appliquées aux gros volumesde données issus de lanalyse de puces adn permettent de découvrirdes connaissances jusqualors inconnues or ces techniques produisent de trèsnombreux résultats difficilement exploitables par les experts nous proposonsun outil dédié à laccompagnement de ces experts dans lappropriation et lexploitationde ces résultats cet outil est basé sur trois techniques de visualisationnuages systèmes solaire et treemap qui permettent aux biologistes dappréhenderde grandes quantités de motifs séquentiels séquences ordonnées de gènes\n",
      "siam système dindexation des articles médicaux\n",
      "nan\n",
      "simplification de données de vol pour un stockage optimal et une visualisation accélérée\n",
      "le projet records collaboration entre industriels et université apour objectif de développer une infrastructure de service sécurisée pour assurerle suivi et lanalyse des conditions dutilisation daéronefs chaque aéronefest muni de capteurs au cours de chaque mission vol les données mesuréessont enregistrées localement ces dernières sont par la suite transférées dansune base de données centralisée à des fins danalyse le problème rencontré estla grande quantité de données ainsi enregistrées ce qui en rend lexploitationdifficile dans cet article nous proposons des techniques de compression et desimplification de données avec un taux de perte contrôlé nos expérimentationsmontrent des gains drastiques en volumétrie avec de très faibles pertes dinformationsceci représente une première étape avant dappliquer des techniquesdextraction de connaissances\n",
      "simtole\n",
      "la plateforme simtole est dédiee a levaluation dalgorithmes dalignement dontologies heterogenes et reparties a travers un reseau pair a pair p2p cette plateforme permet de simuler un réseau p2p dans lequel chaque pair dispose de sa propre ontologie ainsi que des outils permettant lalignement entre lontologie locale et une ontologie stockée sur un pair distant le developpement de cette plateforme sinscrit dans le cadre de travaux de recherche étudiant limpact de la topologie du réseau p2p dans le processus dinférence de correspondances sémantiques durant cette démonstration la plateforme simtole est présentée puis testée pour illustrer des scénarii montrant comment affiner le processus dalignement dontologies dans un réseau p2p\n",
      "sotree  autoorganisation topologique et hiérarchique des données\n",
      "nous proposons dans cet article dintroduire une nouvelle approche pour la classification non supervisée hiérarchique notre méthode nommée sotree consiste à construire dune manière autonome et simultanée une partition topologique et hiérarchique des données chaque ”cluster” de la partition est associé à une cellule dune grille 2d et est modélisé par un arbre dont chaque noeud représente une donnée nous évaluerons les capacités et les performances de notre approche sur des données aux difficultés variables les résultats préliminaires obtenus sont encourageants et prometteurs pour continuer dans cette direction\n",
      "souséchantillonnage topographique par apprentissage semisupervisé\n",
      "plusieurs aspects pourraient influencer les systèmes dapprentissage existantsun de ces aspects est lié au déséquilibre des classes dans lequel le nombre dobservationsappartenant à une classe dépasse fortement celui des observations dans les autresclasses dans ce type de cas assez fréquent le système dapprentissage a des difficultésau cours de la phase dentraînement liées au déséquilibre interclasse nous proposonsune méthode de souséchantillonnage adaptatif pour traiter ce type de bases déséquilibréesle processus procède par le souséchantillonnage des données majoritaires guidépar les données minoritaires tout au long de la phase dun apprentissage semisuperviséenous utilisons comme modèle dapprentissage les cartes autoorganisatrices lapprocheproposée a été validée sur plusieurs bases de données en utilisant les arbres de décisioncomme classificateur avec une validation croisée les résultats expérimentaux ont montrédes performances très prometteuses\n",
      "suivi dautomobiles par classification hiérarchique ascendante\n",
      "nan\n",
      "système dextraction des connaissances à partir des données temporelles basé sur les réseaux bayésiens dynamiques\n",
      "un grand nombre dinformations qui ont une structure complexeproviennent de diverses sources ces informations contiennent des connaissancestrès utiles pour laide à la décision lextraction des connaissances àpartir des données ecd permet dacquérir des informations pertinentes pourles systèmes interactifs daide à la décision siad mais dans plusieurs domainesles données évoluent dune manière dynamique et finissent par dépendrede plusieurs dimensions les réseaux bayésiens dynamiques rbdsont des modèles représentant des connaissances incertaines sur des phénomènescomplexes de processus dynamiques notre objectif revient à fixer lesmeilleures modèles de connaissances extraites par les rbd et à les utiliserpour la prise de décision dynamique ainsi nous proposons dans cet articleune démarche pour la mise en place dun processus dextraction des connaissancesà partir des données multidimensionnelles et temporelles\n",
      "tulip a scalable graph visualization framework\n",
      "the graph visualization framework tulip now enjoys 10 years ofuser experience and has matured its architecture and development cycle originallydesigned to interactively navigate large graphs the framework integratesstateoftheart software engineering concepts and good practices it offers alarge panel of graphical representations traditional graph drawing as well asalternate representations tulip is most useful in a data mining and knowledgediscovery context allowing users to easily add their own data analysis and computingroutines through its plugin architecture\n",
      "un modèle dextraction de masses de croyance à partir de probabilités a posteriori pour une amélioration des performances en classification supervisée\n",
      "lobjectif de cet article est de montrer que lutilisation de la règle dedécision du maximum de masse de croyance en lieu et place de celle du maximumde probabilité a posteriori peut permettre de réduire le taux derreur en classificationsupervisée nous proposons une technique efficace pour extraire à partirdun vecteur de probabilités a posteriori un vecteur de masses de croyance surlequel baser la décision par le maximum de masse de croyance lapplicationde notre méthode dans le domaine de la classification automatique en stades desommeil montre une amélioration des performances pouvant atteindre 80 deréduction du taux derreur de classification\n",
      "un système daide à lextraction de relations sémantiques pour la construction dontologies à partir de textes\n",
      "cet article présente une méthode dextraction de relations sémantiquespour la construction dontologies à partir de corpus de textes notre objectif estde proposer une méthode générique qui soit indépendante du domaine et de lalangue elle repose sur une analyse distributionnelle des unités sémantiques ducorpus pour faire émerger des relations sémantiques candidates cette méthodene fait aucune hypothèse sur les types de relations recherchées ni sur leur formelinguistique il sagit de regrouper les associations de termes dans des classesqui représentent des relations sémantiques candidates lhypothèse sousjacenteest que les occurrences de ces associations réunies sur la base des éléments decontexte quelles partagent ont des chances de relever dune même relation sémantiqueet que les relations candidates ainsi proposées peuvent aider le travailde conceptualisation de lontologue\n",
      "une approche fondée sur la corrélation entre prédicats pour le traitement des réponses pléthoriques\n",
      "linterrogation de bases de données dont les dimensions ne cessentde croître se heurte fréquemment au problème de la gestion des réponses pléthoriquesune des approches envisageables pour réduire lensemble des résultatsretournés et le rendre exploitable est de contraindre la requête initiale parlajout de nouvelles conditions lapproche présentée dans cet article sappuiesur lidentification de liens de corrélation entre prédicats associés aux attributsde la relation concernée la requête initiale peut ainsi être intensifiée automatiquementou par validation de lutilisateur à travers lajout de prédicats prochessémantiquement de ceux spécifiés\n",
      "une approche probabiliste pour lidentification de structures de communautés\n",
      "dans cet article nous valorisons et défendons lidée que les modèles génératifs sont une approche prometteuse pour lidentification de structure de communautés isc nous proposons un nouveau modèle probabiliste pour lidenditification de structures de communautés qui utilise le lissage afin de pallier le petit nombre de liens entre les noeuds notre modèle étant très sensible aux paramètres de lissage nous proposons également une méthode basée sur la modularité pour leur estimation les résultats expérimentaux obtenus sur 3 jeux de données montrent que notre modèle spce est largement meilleur que le modèle phits\n",
      "une méthode daide au management de connaissances pour améliorer le processus de suivi et dévaluation de la prise en charge précoce des enfants imc  application de lashms\n",
      "nan\n",
      "une nouvelle approche de découverte des correspondances complexes entre ontologies\n",
      "les correspondances complexes ont été étudiées à plusieurs reprisesdans le domaine dalignement de schémas de bases de données par contredans le domaine dalignement des ontologies elles ont été peu étudiées nousproposons dans ce papier une nouvelle approche de découverte de correspondancescomplexes entre deux ontologies lapproche proposée est extensionnelleterminologique et implicative dans cette approche nous utilisons le modèledes règles dassociation afin de découvrir des correspondances de typex 8658 y1 8743  8743 yn entre deux ontologies\n",
      "une nouvelle stratégie dapprentissage bayésienne\n",
      "dans cet article une nouvelle stratégie dapprentissage actif est proposée cette stratégie est fondée sur une méthode de discrétisation bayésienne semisupervisée des expériences comparatives sont menées sur des données unidimensionnelles lobjectif étant destimer la position dun échelon à partir de données bruitées\n",
      "une ontologie pour lacquisition et lexploitation des connaissances en conception inventive\n",
      "lacquisition des connaissances en vue de résoudre des problèmesconcernant lévolution des artefacts comme elle se doit dêtre pratiquée enconception inventive a des caractéristiques spécifiques elle nécessite lasélection de certaines des connaissances qui peuvent induire des évolutionselle amène à reformuler le problème initial afin de construire un modèleabstrait de lartefact concerné la méthode de conception inventive induite parla théorie de la résolution des problèmes inventifs aussi connue souslacronyme triz na pas encore fait lobjet dune véritable formalisationnous proposons ici une ontologie des notions principales des concepts liés àlacquisition des connaissances dans ce cadre cette ontologie outre laclarification des notions en jeu est utilisée comme support dun environnementinformatique daide à la mise en oeuvre dune méthode pour acquérir lesconnaissances et formuler les problèmes\n",
      "une structure basée sur les hiérarchies pour synthétiser les itemsets fréquents extraits dans des fenêtres temporelles\n",
      "le paradigme des flots de données rend impossible la conservation de lintégralitéde lhistorique dun flot quil faut alors résumer lextraction ditemsets fréquentssur des fenêtres temporelles semble tout à fait adaptée mais lamoncellement des résultatsindépendants rend impossible lexploitation de ces résultats nous proposons une structurebasée sur les hiérarchies des données afin dunifiant ces résultats de plus puisque laplupart des données dun flot présentent un caractère multidimensionnel nous intégronsla prise en compte ditemsets multidimensionnels enfin nous pallions une faiblesse majeuredes tilted timewindows ttw en prenant en compte la distribution des données\n",
      "utilisation de graphes sémantiques pour lextraction et la traduction des idées essentielles dun texte\n",
      "nan\n",
      "vers une extraction et une visualisation des colocalisations adaptées aux experts\n",
      "une des tâches classiques en fouille de données spatiales est lextractionde colocalisations intéressantes dans des données géoréférencées lobjectifest de trouver des sousensembles de caractéristiques booléennes apparaissantfréquemment dans des objets spatiaux voisins toutefois les relations découvertespeuvent ne pas être pertinentes pour les experts et leur interprétation sousforme textuelle peut être difficile nous proposons dans ce contexte une nouvelleapproche pour intégrer la connaissance des experts dans la découverte descolocalisations ainsi quune nouvelle représentation visuelle de ces motifs unprototype a été développé et intégré dans un sig des expérimentations on étémenées sur des données géologiques réelles et les résultats validés par un expertdu domaine\n",
      "visual sentencephrasebased document representation for effective and efficient contentbased image retrieval\n",
      "having effective and efficient methods to get access to desired imagesis essential nowadays with the huge amount of digital images this paperpresents an analogy between contentbased image retrieval and text retrievalwe make this analogy from pixels to letters patches to words sets of patchesto phrases and groups of sets of patches to sentences to achieve a more accuratedocument matching more informative features including phrases and sentencesare needed to improve these scenarios the proposed approach is basedfirst on constructing different visual words using local patch extraction and descriptionafter that we study different association rules between frequent visualwords in the context of local regions in the image to construct visual phraseswhich will be grouped to different sentences\n",
      "visualisation de mesures agrégées pour lestimation de la qualité des articleswikipedia\n",
      "wikipedia devenue lune des bases de connaissances les plus populairespose le problème de la fiabilité de linformation quelle dissémine nousproposons wikipediaviz un ensemble de visualisations basé sur un mecanismede collecte et dagrégation de données dédition wikipedia pour aider le lecteurà appréhender la maturité dun article nous listons cinq métriques importantesdéterminées lors de sessions de conception participative avec des experts wikipediapour juger de la qualité que nous présentons au lecteur sous forme devisualisations compactes et expressives dépeignant le profil dévolution dun articlenos études utilisateur ont montré quewikipediaviz réduisait significativementle temps requis pour évaluer la qualité en maintenant une bonne précision\n",
      "wcum pour lanalyse dun site web\n",
      "dans ce papier nous proposons une approche wcum web contentand usage based approach permettant de relier lanalyse du contenu dun siteweb à lanalyse de lusage afin de mieux comprendre les comportements de navigationsur le site lapport de ce travail réside dune part dans la propositiondune approche reliant lanalyse du contenu à lanalyse de lusage et dautre partdans lextension de lapplication des méthodes de block clustering appliquéesgénéralement en bioinformatique au contexte web mining afin de profiter deleur pouvoir classificatoire dans la découverte de biclasses homogènes à partirdune partition des instances et une partition des attributs recherchées simultanément\n",
      "a contextualization service for a personalized access model\n",
      "personalization paradigm aims at providing users with the most relevant content and services according to many factors such as interest center orlocation at the querying time all this knowledge and requirements are organized into user profiles and contexts a user profile encompasses metadata describing the user whereas a context groups information about the environmentof interaction between the user and the system an interesting problem is therefore to identify which part of the profile is significant in a given context thispaper proposes a contextualization service which allows defining relationshipsbetween user preferences and contexts further we propose an approach forthe automatic discovery of these mappings by analyzing user behavior extractedfrom log files\n",
      "accompagner au début du 21ème siècle les organisations dans la mise en place dune gestion des connaissances  retour dexpérience\n",
      "cet article présente succinctement le retour dexpérience dardansdans limplantation de systèmes de gestion de connaissances dans des organisationstrès variées au début de ce 21ème siècle\n",
      "acquisition de la théorie ontologique dun système dextraction dinformation\n",
      "la conception de systèmes dextraction dinformation ei destinésà extraire les réseaux dinteractions géniques décrits dans la littérature scientifiqueest un enjeu important de tels systèmes nécessitent des représentationssophistiquées sappuyant sur des ontologies afin de définir différentes relationsbiologiques ainsi que les dépendances récursives quelles présentent entre ellescependant lacquisition de ces dépendances nest pas possible avec les techniquesdapprentissage automatique actuellement employées en ei car ces dernièresne gèrent pas la récursivité afin de palier ces limitations nous présentonsune application à lei de la programmation logique inductive en mode multipredicatsnos expérimentations effectuées sur un corpus bactérien conduisentà un rappel global de 677 pour une précision de 755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquisition annotation et exploration interactive dimages stéréoscopiques en réalité virtuelle  application en dermatologie\n",
      "nous présentons dans cet article le système skin3d qui implémentetous les composants matériels et logiciels nécessaires pour extraire desinformations dans des images 3d de peau il sagit à la fois du matérieldéclairage et dacquisition à base dappareils photographiquesstéréoscopiques dune méthode de calibration de caméras utilisant lesalgorithmes génétiques de matériel de réalité virtuelle pour restituer lesimages en stéréoscopie et interagir avec elles et enfin dun ensemble defonctionnalités interactives pour annoter les images partager ces annotations etconstruire un hypermédia 3d nous présentons une étude comparativeconcernant la calibration et une application réelle de skin3d sur des images devisages\n",
      "aggregative and neighboring approximations to query semistructured documents\n",
      "structures heterogeneity in web resources is a constant concern inelement retrieval ie tag retrieval in semistructured documents in this paperwe present the shiri 1 querying approach which allows to reach more or lessstructured document parts without an a priori knowledge on their structuring\n",
      "an approach for handling risk and uncertainty in multiarmed bandit problems\n",
      "an approach is presented to deal with risk in multiarmed bandit problems specifically the well known explorationexploitation dilemma is solvedfrom the point of view of maximizing an utility function which measures thedecision makers attitude towards risk and uncertain outcomes a link withthe preference theory is thus established simulations results are provided forin order to support the main ideas and to compare the approach with existingmethods with emphasis on the short term small sample size behavior of theproposed method\n",
      "analyse de dissimilarités par arbre dinduction\n",
      "dans cet article1 nous considérons des objets pour lesquels nous disposons dune matrice des dissimilarités et nous nous intéressons à leurs liensavec des attributs nous nous centrons sur lanalyse de séquences détats pourlesquelles les dissimilarités sont données par la distance dédition toutefois lesméthodes développées peuvent être étendues à tout type dobjets et de mesurede dissimilarités nous présentons dans un premier temps une généralisation delanalyse de variance anova pour évaluer le lien entre des objets non mesurables p ex des séquences avec une variable catégorielle la clef de lapprocheest dexprimer la variabilité en termes des seules dissimilarités ce qui nous permet didentifier les facteurs qui réduisent le plus la variabilité nous présentonsun test statistique général qui peut en être déduit et introduisons une méthodeoriginale de visualisation des résultats pour les séquences détats nous présentons ensuite une généralisation de cette analyse au cas de facteurs multiples et endiscutons les apports et les limites notamment en terme dinterprétation finalement nous introduisons une nouvelle méthode de type arbre dinduction quiutilise le test précédent comme critère déclatement la portée des méthodesprésentées est illustrée à laide dune analyse des facteurs discriminant le plusles trajectoires occupationnelles \n",
      "analyse de données pour la construction de modèles de procédures neurochirurgicales\n",
      "dans cet article nous appliquons une méthode danalyse sur desdescriptions de procédures de neurochirurgie dans le but den améliorer lacompréhension la base de données xml utilisée dans cette étude estconstituée de la description de 157 chirurgies de tumeurs trois cent vingtdeux variables ont été identifiées et décomposées en variables prédictivesconnues avant lopération et variables à prédire décrivant des gesteschirurgicaux une analyse factorielle des correspondances afc a étéréalisée sur les variables prédictives ainsi quun arbre de décision basé sur undendrogramme préalablement établi six classes principales de variablesprédictives ont ainsi été identifiées puis pour chacune de ces classes uneanalyse afc a été réalisée sur les variables à prédire ainsi quun arbre dedécision bien que le nombre de cas et le choix des variables constituent unelimite à cette étude nous avons réussi à prédire certaines caractéristiques liéesaux procédures en partant de données prédictives\n",
      "analyse et application de modèles de régression pour optimiser le retour sur investissement dopérations commerciales\n",
      "nan\n",
      "analyse et application de modèles de régression pour optimiser le retour sur investissement dopérations commerciales\n",
      "les activités de négoce de matériaux sont un marché extrêmementcompétitif pour les acteurs de ce marché les méthodes de fouille de donnéespeuvent savérer intéressantes en permettant de dégager des gains de rentabilitéimportants dans cet article nous présenterons le retour dexpérience du projetde fouille de données mené chez vm matériaux pour améliorer le retour surinvestissement dopérations commerciales la synergie des informaticiens dumarketing et des experts métier a permis daméliorer lextraction des connaissances à partir des données de manière à aboutir à la connaissance actionnable laplus pertinente possible et ainsi aider les experts métier à prendre des décisions\n",
      "analyse multigraduelle olap\n",
      "les systèmes décisionnels reposent sur des bases de données multidimensionnellesqui offrent un cadre adéquat aux analyses olap larticleprésente un nouvel opérateur olap nommé « blend » rendant possible desanalyses multigraduelles il sagit de transformer la structuration multidimensionnellelors des interrogations pour analyser les mesures selon des niveauxde granularité différents recombinées comme un même paramètre nous menonsune étude des combinaisons valides de lopération dans le contexte deshiérarchies strictes enfin une première série dexpérimentations implantelopération dans le contexte rolap en montrant le faible coût de lopération\n",
      "analyse sémantique spatiotemporelle pour les ontologies owldl\n",
      "lanalyse sémantique est un nouveau paradigmedinterrogation du web sémantique qui a pour objectif didentifier lesassociations sémantiques reliant des individus décrits dans desontologies owldl pour déduire davantage dassociationssémantiques et augmenter la précision de lanalyse linformationspatiotemporelle attachée aux ressources doit être prise en compte aces fins  et pour combler labsence actuelle de raisonneurs spatiotemporeldéfini pour les ontologies rdfs et owl nous proposonsle système de représentation et dinterrogation dontologies spatiotemporellesontoast compatible avec le langage owldl nousprésentons les principes de base de lalgorithme de découvertedassociations sémantiques entre individus intégré dans ontoastcet algorithme utilise deux contextes lun spatial et lautre temporelqui permettent daffiner la recherche nous décrivons enfin lapprochemise en oeuvre pour la déduction de connexions spatiales entreindividus\n",
      "assessing the uncertainty in knn data fusion\n",
      "nan\n",
      "binary sequences and association graphs for fast detection of sequential patterns\n",
      "we develop an efficient algorithm for detecting frequent patterns thatoccur in sequence databases under certain constraints by combining the useof bit vector representations of sequence databases with association graphs weachieve superior time and low memory usage based on a considerable reductionof the number of candidate patterns\n",
      "caractérisation automatique des classes découvertes en classification non supervisée\n",
      "dans cet article nous proposons une nouvelle approche de classifi cation et de pondération des variables durant un processus dapprentissage non supervisé cette approche est basée sur le modèle des cartes autoorganisatrices lapprentissage de ces cartes topologiques est combiné à un mécanisme desti mation de pertinences des différentes variables sous forme de poids dinfluence sur la qualité de la classification nous proposons deux types de pondérations adaptatives  une pondération des observations et une pondération des distances entre observations lapprentissage simultané des pondérations et des prototypes utilisés pour la partition des observations permet dobtenir une classification op timisée des données un test statistique est ensuite utilisé sur ces pondérations pour élaguer les variables non pertinentes ce processus de sélection de variables permet enfin grâce à la localité des pondérations dexhiber un sous ensemble de variables propre à chaque groupe cluster offrant ainsi sa caractérisation lapproche proposée a été validé sur plusieurs bases de données et les résultats expérimentaux ont montré des performances très prometteuses\n",
      "ciblage des règles dassociation intéressantes guidé par les connaissances du décideur\n",
      "lusage du modèle des règles dassociation en fouille de données estlimité par la quantité prohibitive de règles quil fournit et nécessite la mise enplace dune phase de posttraitement efficace afin de cibler les règles les plusutiles cet article propose une nouvelle approche intégrant explicitement lesconnaissances du décideur afin de filtrer et cibler les règles intéressantes\n",
      "cisna un système hybride ldrègles pour gérer des connaissances\n",
      "nan\n",
      "classification des images de télédétection avec envi fx\n",
      "dimportants volumes dimages satellites et aériennes de tout typepanchromatiques multispectrales hyperspectrales sont généréesquotidiennement et leur classification par des méthodes semiautomatiquesdevient nécessaire le logiciel envi feature extractiontm envi fxtm sebase sur une approche « objet » par opposition à une approche pixelsclassique et sur des algorithmes innovants pour la segmentation et laclassification des images de télédétection avec un haut niveau de précision\n",
      "collaborative outlier mining for intrusion detection\n",
      "intrusion detection is an important topic dealing with security of information systems most successful intrusion detection systems ids rely onsignature detection and need to update their signature as fast as new attacks areemerging on the other hand anomaly detection may be utilized for this purposebut it suffers from a high number of false alarms actually any behaviour whichis significantly different from the usual ones will be considered as dangerousby an anomaly based ids therefore isolating true intrusions in a set of alarmsis a very challenging task for anomaly based intrusion detection in this paperwe consider to add a new feature to such isolated behaviours before they can beconsidered as malicious this feature is based on their possible repetition fromone information system to another we propose a new outlier mining principleand validate it through a set of experiments\n",
      "comment valider automatiquement des relations syntaxiques induites\n",
      "nous présentons dans cet article des approches visant à valider desrelations syntaxiques induites de type verbeobjet ainsi nous proposons dutiliser dans un premier temps une approche sappuyant sur des vecteurs sémantiques déterminés à laide dun thésaurus la seconde approche emploie unevalidation web nous effectuons des requêtes sur un moteur de recherche associées à des mesures statistiques afin de déterminer la pertinence dune relationsyntaxique nous proposons enfin de combiner ces deux méthodes la qualitéde nos approches de validation de relations syntaxiques a été évaluée en utilisantdes courbes roc\n",
      "comparaison de distances et noyaux classiques par degré déquivalence des ordres induits\n",
      "le choix dune mesure pour comparer les données est au coeur destâches de recherche dinformation et dapprentissage automatique nous considéronsici ce problème dans le cas où seul lordre induit par la mesure importeet non les valeurs numériques quelle fournit  cette situation est caractéristiquedes moteurs de recherche de documents par exemple nous étudions dans cecadre les mesures de comparaison classiques pour données numériques tellesque les distances et les noyaux les plus courants nous identifions les mesureséquivalentes qui induisent toujours le même ordre  pour les mesures non équivalentesnous quantifions leur désaccord par des degrés déquivalence basés surle coefficient de kendall généralisé nous étudions les équivalences et quasiéquivalencesà la fois sur les plans théorique et expérimental\n",
      "constraint programming for data mining\n",
      "nan\n",
      "construction de descripteurs pour classer à partir dexemples bruités\n",
      "en classification supervisée la présence de bruit sur les valeurs desdescripteurs peut avoir des effets désastreux sur la performance des classifieurset donc sur la pertinence des décisions prises au moyen de ces modèles traiterce problème lorsque le bruit affecte un attribut classe a été très étudié il estplus rare de sintéresser au bruit sur les autres attributs cest notre contextede travail et nous proposons la construction de nouveaux descripteurs robusteslorsque ceux des exemples originaux sont bruités les résultats expérimentauxmontrent la valeur ajoutée de cette construction par la comparaison des qualitésobtenues eg précision lorsque lon utilise les méthodes de classification àpartir de différentes collections de descripteurs\n",
      "contrôle des observations pour la gestion des systèmes de flux de données\n",
      "les systèmes danalyse de flux de données prennent de plus en plusdimportance dans un contexte où les données circulant sur les réseaux sont deplus en plus volumineuses et où la volonté de réagir au plus vite en temps réeldevient un besoin nécessaire afin de permettre des analyses aussi rapides etefficaces que possible il convient de pouvoir contrôler les flots de données et defocaliser les traitements sur les données pertinentes le protocole présenté dansce papier donne au module de traitement des capacités daction et de contrôle surles observations remontantes en fonction de létat de lanalyse la diminutiondes flux résultant de telles focalisations permet des traitements beaucoup plusefficaces plus pertinents et moins consommateurs de ressources les premiersrésultats montrent un réel gain de performances sur nos applications facteur100\n",
      "correspondances de galois pour la manipulation de contextes flous multivalués\n",
      "lanalyse formelle de concepts est une méthode fondée sur la correspondancede galois et qui permet de construire des hiérarchies de conceptsformels à partir de tableaux de données binaires cependant de nombreux problèmesréels abordés en fouille de données comportent des données plus complexesafin de traiter de tels problèmes nous proposons une conversion de donnéesfloues multivaluées en attributs histogrammes et une correspondance degalois adaptée à ce format notre propos est illustré avec un jeu de donnéessimples enfin nous évaluons brièvement les résultats et les apports de cettecorrespondance de galois par rapport à lapproche classique\n",
      "dbfrequentqueries  extraction de requêtes fréquentes\n",
      "nan\n",
      "de lutilisation de lanalyse de données symboliques dans les systèmes multiagents\n",
      "lexploitation en temps réel de connaissances complexes est un défidans de nombreux domaines tels que le web sémantique la simulation ou lessystèmes multiagents sma dans le paradigme multiagents des travaux récents montrent que les communications multiparties cmp offrent des opportunités intéressantes en termes de réalisme des communications diffusion desconnaissances et sémantique des actes de langage cependant ces travaux seheurtent à la difficulté de mise en oeuvre des cmp pour lesquelles les supportsde communications classiques sont insuffisants dans cet article nous proposons dutiliser le formalisme de lanalyse de données symboliques ads pourmodéliser les informations et les besoins des agents nous appuyons le routagedes messages sur cette modélisation dans le cadre dun environnement de communication pour les systèmes multiagents afin dillustrer notre propos nousutiliserons lexemple de la gestion des communications dans un poste dappelsdurgence nous présentons ensuite notre retour dexpérience et discutons lesperspectives ouvertes par la fertilisation croisée de lads et des sma\n",
      "définition dune stratégie de résolution de problèmes pour un robot humanoïde\n",
      "nous avons développé un système dont le but est dobtenir le logicielde commande dun robot capable de simuler le comportement dun humainplacé en situation de résolution de problèmes nous avons résolu ce problèmedans un environnement psychologique particulier où les comportements humainspeuvent être interprétés comme des ‘observables de leurs stratégies derésolution de problèmes notre solution contient de plus celle dun autre problèmecelui de construire une boucle complète commençant avec le comportementdun groupe dhumains son analyse et son interprétation en termesdobservables humaines la définition des stratégies utilisées par les humains ycompris celles qui sont inefficaces linterprétation des observables humainesen terme de mouvements du robot la définition de ce quest une “stratégie derobot ” en terme de stratégies humaines la boucle est bouclée avec un langagede programmation capable de programmer ces stratégies robotiques qui deviennentainsi à leur tour des observables tout comme lont été les stratégieshumaines du début de la boucle nous expliquons comment nous avons été capablesdéfinir de façon objective ce que nous appelons une stratégie de robotnotre solution assemble deux facteurs différents lun permet déviter lescomportements ‘inhumains et se fonde sur la moyenne des comportementsdes humains que nous avons observés lautre fournit une sorte ‘dhumanitéau robot en lui permettant de dévier de cette moyenne par n fois lécart typeobservé chez les humains quil doit simuler il devient alors possible de programmerdes comportements complètements humains\n",
      "demon  découverte de motifs séquentiels pour les puces adn\n",
      "prometteuses en terme de prévention de dépistage de diagnostic etdactions thérapeutiques les puces à adn mesurent lintensité des expressionsde plusieurs milliers de gènes dans cet article nous proposons une nouvelleapproche appelée demon pour extraire des motifs séquentiels à partir de données issues des puces adn et qui utilise des connaissances du domaine\n",
      "demonvisualisation  un outil pour la visualisation des motifs séquentiels extraits à partir de données biologiques\n",
      "nan\n",
      "desesper un logiciel de prétraitement de flux appliqué à la surveillance des centrales hydrauliques\n",
      "nan\n",
      "détection dintrusions dans un environnement collaboratif sécurisé\n",
      "pour pallier le problème des attaques sur les réseaux de nouvelles approches de détection danomalies ou dabus ont été proposées ces dernières années et utilisent des signatures dattaques pour comparer une nouvelle requêteet ainsi déterminer sil sagit dune attaque ou pas cependant ces systèmes sontmis à défaut quand la requête nexiste pas dans la base de signature généralement ce problème est résolu via une expertise humaine afin de mettre à jourla base de signatures toutefois il arrive fréquemment quune attaque ait déjàété détectée dans une autre organisation et il serait utile de pouvoir bénéficier decette connaissance pour enrichir la base de signatures mais cette information estdifficile à obtenir car les organisations ne souhaitent pas forcément indiquer lesattaques qui ont eu lieu sur le site dans cet article nous proposons une nouvelleapproche de détection dintrusion dans un environnement collaboratif sécurisénotre approche permet de considérer toute signature décrite sous la forme dexpressions régulières et de garantir quaucune information nest divulguée sur lecontenu des différents sites\n",
      "détection dobjets atypiques dans un flot de données  une approche multirésolution\n",
      "nan\n",
      "détection de séquences atypiques basée sur un modèle de markov dordre variable\n",
      "récemment le nombre et le volume des bases de données séquentiellesbiologiques ont augmenté de manière considérable dans ce contexte lidentificationdes anomalies est essentielle la plupart des approches pour lesextraire se fondent sur une base dapprentissage ne contenant pas doutlier ordans de très nombreuses applications les experts ne disposent pas dune tellebase de plus les méthodes existantes demeurent exigeantes en mémoire cequi les rend souvent impossibles à utiliser nous présentons dans cet article unenouvelle approche basée sur un modèle de markov dordre variable et sur unemesure de similarité entre objets séquentiels nous ajoutons aux méthodes existantesun critère délagage pour contrôler la taille de lespace de rechercheet sa qualité ainsi quune inégalité de concentration précise pour la mesure desimilarité conduisant à une meilleure détection des outliers nous démontronsexpérimentalement la validité de notre approche\n",
      "détermination du nombre des classes dans lalgorithme croki2 de classification croisée\n",
      "un des problèmes majeurs de la classification non supervisée est ladétermination ou la validation du nombre de classes dans la population ce problèmesétend aux méthodes de bipartitionnement ou block clustering dans cepapier nous nous intéressons à lalgorithme croki2 de classification croiséedes tableaux de contingence proposé par govaert 1983 notre objectif est dedéterminer le nombre de classes optimal sur les lignes et les colonnes à traversun ensemble de techniques de validation de classes proposés dans la littératurepour les méthodes classiques de classification\n",
      "diagnostic multisources adaptatif application à la détection dintrusion dans des serveursweb\n",
      "le but dun système adaptatif de diagnostic est de surveiller et diagnostiquerun système tout en sadaptant à son évolution ceci passe par ladaptationdes diagnostiqueurs qui précisent ou enrichissent leur propre modèle poursuivre au mieux le système au fil du temps pour détecter les besoins dadaptationnous proposons un cadre de diagnostic multisources sinspirant de lafusion dinformation des connaissances fournies par le concepteur sur des relationsattendues entre les diagnostiqueurs monosource forment un métamodèledu diagnostic la compatibilité des résultats du diagnostic avec le métamodèleest vérifiée en ligne lorsquune de ces relations nest pas vérifiée les diagnostiqueursconcernés sont modifiésnous appliquons cette approche à la conception dun système adaptatif de détectiondintrusion à partir dun flux de connexions à un serveur web les évaluationsdu système mettent en évidence sa capacité à améliorer la détection desintrusions connues et à découvrir de nouveaux types dattaque\n",
      "empreintes conceptuelles et spatiales pour la caractérisation des réseaux sociaux\n",
      "cet article propose une méthode reposant sur lutilisation delanalyse formelle de concepts et des treillis de galois pour lanalyse desystèmes complexes des statistiques reposant sur ces treillis permettent decalculer la distribution conceptuelle des objets classifiés par le treillislexpérimentation sur des échantillons de trois réseaux sociaux en ligneillustre lutilisation de ces statistiques pour la caractérisation globale et pour lefiltrage automatique de ces systèmes\n",
      "exploration de données de traçabilité issues de la rfid par apprentissage nonsupervisé\n",
      "la rfid radio frequency identification est une technologie avancée denregistrementde données spatiotemporelles de traçabilité lobjectif de ce travail est de transformer cesdonnées spatiotemporelles en connaissances exploitables par les utilisateurs par lintermédiaire dune méthode de classification automatique des données les systèmes rfid peuventêtre utilisés pour étudier les sociétés animales qui sont des systèmes dynamiques complexescaractérisés par beaucoup dinteractions entre les individus fresneau et al 1989 le cadreapplicatif choisi pour ce travail est létude de la structure dun groupe dindividus en interactionsociale et en particulier la division du travail au sein dune colonie de fourmis1la rfid générant dimportants volumes de données il est nécessaire de développer desméthodes appropriées afin den comprendre le sens nous proposons pour cela un algorithmede classification topographique nonsupervisée pour lexploration de ce type de données capable de détecter les groupes dindividus exprimant le même comportement lalgorithmeds2lsom densitybased simultaneous twolevel  som cabanes et bennani 2008 estcapable de détecter non seulement les groupes définis par une zone vide de donnée grâce àune estimation de la pertinence des connexions entre référents mais aussi les groupes définis seulement par une diminution de densité grâce à une estimation de la densité autour desréférents pendant lapprentissage\n",
      "exploration des corrélations dans un classifieur application au placement doffres commerciales\n",
      "cet article présente une nouvelle méthode permettant dexplorer lesprobabilités délivrées par un modèle prédictif de classification laugmentationde la probabilité doccurrence de lune des classes du problème étudié est analyséeen fonction des variables explicatives prises isolément la méthode proposéeest posée et illustrée dans un cadre général puis explicitement dédiée au classifieurbayesien naïf son illustration sur les données du challenge pakdd 2007montre que ce type dexploration permet de créer des indicateurs performantsdaide à la vente\n",
      "explorer3d  classification et visualisation de données\n",
      "nan\n",
      "extraction de motifs fermés dans des relations naires bruitées\n",
      "lextraction de motifs fermés dans des relations binaires a été trèsétudiée cependant de nombreuses relations intéressantes sont naires avec n 2 et bruitées nécessité dune tolérance aux exceptions récemment ces deuxproblèmes ont été traités indépendamment nous introduisons notre propositionpour combiner de telles fonctionnalités au sein dun même algorithme\n",
      "extraction de règles de corrélation décisionnelles\n",
      "dans cet article nous introduisons deux nouveaux concepts  les règlesde corrélation décisionnelles et les vecteurs de contingence le premier résultedun couplage entre les règles de corrélation et les règles de décision il permetde mettre en évidence des liens pertinents entre certains ensembles de motifsdune relation binaire et les valeurs dun attribut cible appartenant à cette mêmerelation en se basant à la fois sur la mesure du khicarré et sur le support desmotifs extraits de par la nature du problème les algorithmes par niveaux fontque lextraction des résultats a lieu avec des temps de réponse élevés et uneoccupation mémoire importante afin de palier à ces deux inconvénients nousproposons un algorithme basé sur lordre lectique et les vecteurs de contingence\n",
      "extraction efficace de règles graduelles\n",
      "les règles graduelles suscitent depuis quelques années un intérêt croissantde telles règles de la forme “plus moins a1 et  plus moins an alorsplus moins b1 et  plus moins bn” trouvent application dans de nombreuxdomaines tels que la bioinformatique les contrôleurs flous les relevés de capteursou encore les flots de données ces bases souvent composées dun grandnombre dattributs restent un verrou pour lextraction automatique de connaissancescar elles rendent inefficaces les techniques de fouille habituelles règlesdassociation clustering dans cet article nous proposons un algorithme efficacedextraction ditemset graduels basé sur lutilisation des treillis nous définissonsformellement les notions de gradualité ainsi que les algorithmes associésdes expérimentations menées sur jeux de données synthétiques et réelsmontrent lintérêt de notre méthode\n",
      "fcpgrowth une adaptation de fpgrowth pour générer des règles dassociation de classe\n",
      "nan\n",
      "fouille de données dans les bases relationnelles pour lacquisition dontologies riches en hiérarchies de classes\n",
      "de par leur caractère structuré les bases de données relationnellessont des sources précieuses pour la construction automatisée dontologies cependant une limite persistante des approches existantes est la production dontologies de structure calquée sur celles des schémas relationnels sources dans cetarticle nous décrivons la méthode rtaxon dont la particularité est didentifierdes motifs de catégorisation dans les données afin de produire des ontologiesplus structurées riches en hiérarchies la méthode formalisée combine analyseclassique du schéma relationnel et fouille des données pour lidentification destructures hiérarchiques\n",
      "fusion symbolique pour la recommandation de programmes télévisées\n",
      "nous proposons une approche générique pour la fusion dinformations qui repose sur lutilisation du modèle des graphes conceptuels et lopération de jointure maximale nous validons notre approche par le biais dexpérimentations ces expérimentations soulignent limportance des heuristiquesmises en place\n",
      "générer des règles de classification par dopage de concepts formels\n",
      "la classification supervisée est une tâche de fouille de données datamining qui consiste à construire un classifieur à partir dun ensemble dexemplesétiquetés par des classes phase dapprentissage et ensuite prédire les classesdes nouveaux exemples avec ce classifieur phase de classification en classification supervisée plusieurs approches ont été proposées dont lapproche basée sur lanalyse de concepts formels lapprentissage de concepts formelsest basé généralement sur la structure mathématique du treillis de galois outreillis de concepts cependant la complexité exponentielle de génération duntreillis de galois a limité les champs dapplication de ces systèmes dans cetarticle nous présentons plusieurs méthodes de classification supervisée baséessur lanalyse de concepts formels nous présentons aussi le boosting dopagede classifieurs une technique de classification innovante enfin nous proposonsle boosting de concepts formels une nouvelle méthode adaptative qui construitseulement une partie du treillis englobant les meilleurs concepts ces conceptssont utilisés comme étant des règles de classification les résultats expérimentaux réalisés ont prouvé lintérêt de la méthode proposée par rapport à cellesexistantes\n",
      "graphes des liens et anti liens statistiquement valides entre les mots dun corpus textuel  test de randomisation tournebool sur le corpus reuters\n",
      "la définition du voisinage est un élément central en fouille de données et de nombreuses définitions ont été avancées nous en proposons ici une version statistique issue de notre test de randomisation tournebool qui permet à partir dun tableau de relations binaires objets décritsdescripteurs détablir quelles relations entre descripteurs sont dues au hasard et lesquelles ne le sont pas sans faire dhypothèse sur les lois de répartitions sousjacentes cest à dire en tenant compte de lois de tous types sans avoir besoin de les spécifier ce test est basé sur la génération et lexploitation dun ensemble de matrices randomisées ayant les mêmes sommes marginales en lignes et colonnes que la matrice dorigine après une première application encourageante à un corpus textuel réduit nous avons opéré le passage à léchelle adéquat pour traiter des corpus textuels de taille réelle comme celui des dépêches reuters nous caractérisons le graphe des mots de ce corpus au moyen dindicateurs classiques comme le coefficient de clustering la distribution des degrés et de la taille des communautés etc une autre caractéristique de tournebool est quil permet aussi de dégager les anti liens entre mots à savoir les mots qui sévitent plus quattendu du fait du hasard le graphe des liens et celui des antiliens seront caractérisés de la même façon\n",
      "handling texts  a challenge for data mining\n",
      "the amount of data in free form by far surpasses the structured records in databases in theirnumber however standard learning algorithms require observations in the form of vectorsgiven a fixed set of attributes for texts there is no such fixed set of attributes the bag ofwords representation yields vectors with as many components as there are words in a languagehence the classification of documents represented as bag of word vectors demands efficientlearning algorithms the tcat model for the support vector machine joachims 2002 offers asound performance estimation for text classificationthe huge mass of documents in principle offers answers to many questions and is oneof the most important sources of knowledge however information retrieval and text classification deliver merely the document in which the answer can be found by a human reader not the answer itself hence information extraction has become an important topic if we canextract information from text we can apply standard machine learning to the extracted factscraven et al 1998 first information extraction has to recognize named entities see egroessler morik 2005 second relations between these become the nucleus of events extracting events from a complex web site with long documents allows to automatically discoverregularities which are otherwise hidden in the mass of sentences see eg jungermann morik2008\n",
      "lanalyse formelle de concepts pour lextraction de connaissances dans les données dexpression de gènes\n",
      "lanalyse formelle de concepts afc ganter etwille 1999 est uneméthode pertinente dextraction de connaissances à partir de données complexesdexpression de gènes blachon et al 2007 motameny et al 2008 dans cepapier nous proposons dextraire des groupes de gènes partageant un comportement similaire montrant des changements “significatifs” à travers divers environnements biologiques servant dhypothèses à la fonction des gènes\n",
      "la carte ghsom comme alternative à la som pour lanalyse exploratoire de données\n",
      "lobjecif de cet article est de faire de la carte autoorganisatrice hiérarchiqueghsom un outil utilisable dans le cadre dune démarche danalyseexploratoire de données la visualisation globale est un outil indispensable pourrendre les résultats dune segmentation intelligibles pour un utilisateur nousproposons donc différents outils de visualisation pour la ghsom équivalents àceux de la som\n",
      "la « créativité calculatoire » et les heuristiques créatives en synthèse de prédicats multiples\n",
      "nous présentons une approche à ce que nous appelons la « créativitécalculatoire » cestàdire les procédés par lesquels une machine peut fairemontre dune certaine créativité dans cet article nous montronsessentiellement que la synthèse de prédicats multiples en programmationlogique inductive ilp et la synthèse de programmes à partir de spécificationsformelles spsf deux domaines de linformatique qui sattaquent à desproblèmes où la notion de créativité est centrale ont été amenés à ajouter àleur formalisme de base lilp pour lun les tableaux de beth pour lautretoute une série dheuristiques cet article présente une collectiondheuristiques qui sont destinées à fournir au programme une forme decréativité calculatoire dans cette présentation laccent est plutôt mis sur lesheuristiques de lilp mais lorsque cela était possible sans de trop longsdéveloppements nous avons aussi présenté quelques heuristiques de la spsfloutil indispensable de la créativité calculatoire est ce que nous appelons un‘générateur datouts dont une spécification forcément informelle commenous le verrons est fournie comme première conclusion aux exemples décritsdans le corps de larticle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le logiciel syr pour lanalyse de données symboliques\n",
      "nan\n",
      "logiciel « dtmvic » data and text mining visualisation inférence classification\n",
      "nan\n",
      "management des connaissances dans le domaine du patrimoine culturel\n",
      "nan\n",
      "méthode de regroupement par graphe de voisinage\n",
      "ce travail sinscrit dans la problématique de lapprentissage non supervisé dans ce cadre se retrouvent les méthodes de classification automatiquenon paramétriques qui reposent sur lhypothèse que plus des individus sontproches dans lespace de représentation plus ils ont de chances de faire partie de la même classe cet article propose une nouvelle méthode de ce type quiconsidère la proximité à travers la structure fournie par un graphe de voisinage\n",
      "modèle de préférences contextuelles pour les analyses olap\n",
      "cet article présente un environnement pour la personnalisation desanalyses olap afin de réduire la charge de navigation de lutilisateur nousproposons un modèle de préférences contextuelles qui permet de restituer lesdonnées en fonction des préférences de lutilisateur et de son contextedanalyse\n",
      "modélisation des connaissances dans le cadre de bibliothèques numériques spécialisées\n",
      "nous présentons une application innovante de la modélisation desconnaissances au domaine des bibliothèques numériques spécialisées nous utilisonsla spécification experte de la tei text encoding initiative pour modéliserla connaissance apportée par les chercheurs qui travaillent sur des archivesmanuscrites nous montrons les limites de la tei dans le cas dune approchediachronique du document cette dernière impliquant la construction simultanéede structures de données concurrentes nous décrivons un modèle qui présentele problème et permet denvisager des solutions enfin nous justifions les structuresarborescentes sur lesquelles se base ce modèle\n",
      "okmed et wokm\n",
      "cet article traite de la problématique de la classification recouvranteoverlapping clustering et propose deux variantes de lapproche okm  okmedet wokm okmed généralise kmédoïdes au cas recouvrant il permet dorganiserun ensemble dindividus en classes nondisjointes à partir dune matricede distances la méthode wokm weightedokm étend okm par une pondérationlocale des classes  cette variante autorise chaque individu à appartenir àplusieurs classes sur la base de critères différents des expérimentations sont réaliséessur une application cible  la classification de textes nous montrons alorsque okmed présente un comportement similaire à okm pour la métrique euclidienneet offre la possibilité dutiliser des métriques plus adaptées et dobtenirde meilleures performances enfin les résultats obtenus avec wokm montrentun apport significatif de la pondération locale des classes\n",
      "online and adaptive anomaly detection detecting intrusions in unlabelled audit data streams\n",
      "nan\n",
      "partitionnement dontologies pour le passage à léchelle des techniques dalignement\n",
      "lalignement dontologies est une tâche importante dans les systèmesdintégration puisquelle autorise la prise en compte conjointe de ressourcesdécrites par des ontologies différentes en identifiant des appariements entreconcepts avec lapparition de très grandes ontologies dans des domaines commela médecine ou lagronomie les techniques dalignement qui mettent souventen oeuvre des calculs complexes se trouvent face à un défi  passer à léchellepour relever ce défi nous proposons dans cet article deux méthodes de partitionnement conçues pour prendre en compte le plus tôt possible lobjectif dalignement ces méthodes permettent de décomposer les deux ontologies à aligneren deux ensembles de blocs de taille limitée et tels que les éléments susceptiblesdêtre appariés se retrouvent concentrés dans un ensemble minimal de blocs quiseront effectivement comparés les résultats des tests effectuées avec nos deuxméthodes sur différents couples dontologies montrent leur efficacité\n",
      "privacy and data mining new developments and challenges\n",
      "there is little doubt that data mining technologies create new challenges in the area of dataprivacy in this talk we will review some of the new developments in privacypreserving datamining in particular we will discuss techniques in which data mining results can reveal personal data and how this can be prevented we will look at the practically interesting situationswhere data to be mined is distributed among several parties we will mention new applications in which mining spatiotemporal data can lead to identification of personal informationwe will argue that methods that effectively protect personal data while at the same time preserve the quality of the data from the data analysis perspective are some of the principal newchallenges before the field\n",
      "probabilistic multiclassifier by svms from voting rule to voting features\n",
      "nan\n",
      "rdbtoonto  un logiciel dédié à lapprentissage dontologies à partir de bases de données relationnelles\n",
      "rdbtoonto1 est un logiciel extensible qui permet délaborer des ontologies précises à partir de bases de données relationnelles le processus supporté est largement automatisé de lextraction des données à la génération dumodèle de lontologie et son instanciation pour affiner le résultat le processuspeut être orienté par des contraintes locales définies interactivement cest aussiun cadre facilitant la mise en oeuvre de nouvelles méthodes dapprentissage\n",
      "regroupement des définitions de sigles biomédicaux\n",
      "lapplication présentée permet de regrouper les définitions de siglesissues des sciences du vivant par des mesures de proximité lexicale approcheautomatique et une intervention de lexpert approche manuelle\n",
      "résumé hybride de flux de données par échantillonnage et classification automatique\n",
      "face à la grande volumétrie des données générées par les systèmes informatiqueslhypothèse de les stocker en totalité avant leur interrogation nestplus possible une solution consiste à conserver un résumé de lhistorique duflux pour répondre à des requêtes et pour effectuer de la fouille de donnéesplusieurs techniques de résumé de flux de données ont été développées tellesque léchantillonnage le clustering etc selon le champ de requête ces résuméspeuvent être classés en deux catégories résumés spécialisés et résumés généralistesdans ce papier nous nous intéressons aux résumés généralistes notreobjectif est de créer un résumé de bonne qualité sur toute la période temporellequi nous permet de traiter une large panoplie de requêtes nous utilisons deuxalgorithmes  clustream et streamsamp lidée consiste à les combiner afin detirer profit des avantages de chaque algorithme pour tester cette approche nousutilisons un benchmark de données réelles kdd99 les résultats obtenussont comparés à ceux obtenus séparément par les deux algorithmes\n",
      "softjaccard  une mesure de similarité entre ensembles de chaînes de caractères pour lunification dentités nommées\n",
      "parmi lesmesures de similarité classiques utilisables sur des ensemblesfigure lindice de jaccard dans le cadre de cet article nous en proposons uneextension pour comparer des ensembles de chaînes de caractères cette mesurehybride permet de combiner une distance entre chaînes de caractères telle que ladistance de levenstein et lindice de jaccard elle est particulièrement adaptéepourmettre en correspondance des champs composés de plusieurs chaînes de caractèrescomme par exemple lorsquon se propose dunifier des noms dentitésnommées\n",
      "spams une nouvelle approche incrémentale pour lextraction de motifs séquentiels fréquents dans les data streams\n",
      "lextraction de motifs séquentiels fréquents dans les datastreams est un enjeu important traité par la communauté des chercheursen fouille de données plus encore que pour les bases de données denombreuses contraintes supplémentaires sont à considérer de par la nature intrinsèque des streams dans cet article nous proposons un nouvelalgorithme en une passe  spams basé sur la construction incrémentaleavec une granularité très fine par transaction dun automate appelé spapermettant lextraction des motifs séquentiels dans les streams linformation du stream est apprise à la volée au fur et à mesure de linsertionde nouvelles transactions sans prétraitement a priori les résultats expérimentaux obtenus montrent la pertinence de la structure utilisée ainsique lefficience de notre algorithme appliqué à différents jeux de données\n",
      "svm incrémental et parallèle sur gpu\n",
      "nous présentons un nouvel algorithme incrémental et parallèle deséparateur à vaste marge svm ou support vector machine pour laclassification de très grands ensembles de données en utilisant le processeur dela carte graphique gpus graphics processing units les svms et lesméthodes de noyaux permettent de construire des modèles avec une bonneprécision mais ils nécessitent habituellement la résolution dun programmequadratique ce qui requiert une grande quantité de mémoire et un long tempsdexécution pour les ensembles de données de taille importante nousprésentons une extension de lalgorithme de least squares svm lssvmproposé par suykens et vandewalle pour obtenir un algorithme incrémental etparallèle le nouvel algorithme est exécuté sur le processeur graphique pourobtenir une bonne performance à faible coût les résultats numériques sur lesensembles de données de luci et delve montrent que notre algorithmeincrémental et parallèle est environ 70 fois plus rapide sur gpu que sur cpuet significativement plus rapide plus de 1000 fois que les algorithmesstandards tels que libsvm svmperf et cbsvm\n",
      "taaable  système de recherche et de création par adaptation de recettes de cuisine\n",
      "taaable is a textual casebased reasoning system that according to requestedforbiddeningredients dish types andor dish origins retrieves cooking recipes if no recipe satisifies theconstraints taaable adapts existing recipes by replacing some ingredients by other ones\n",
      "traminer une librairie r pour lanalyse de données séquentielles\n",
      "nan\n",
      "un algorithme stable de décomposition pour lanalyse des réseaux sociaux dynamiques\n",
      "les réseaux dynamiques soulèvent de nouveaux problèmes danalysesun outils efficace danalyse doit non seulement permettre de décomposerces réseaux en groupes déléments similaires mais il doit aussi permettre la détectionde changements dans le réseau nous présentons dans cet article une nouvelleapproche pour lanalyse de tels réseaux cette technique est basée sur unalgorithme de décomposition de graphe en groupes chevauchants ou chevauchementla complexité de notre algorithme est oe · deg2max v  · logv la faible sensibilité de cet algorithme aux changements structuraux du réseaupermet den détecter les modifications majeures au cours du temps\n",
      "un critère dévaluation bayésienne pour la construction darbres de décision\n",
      "nous présentons dans cet article un nouvel algorithme automatiquepour lapprentissage darbres de décision nous abordons le problème selon uneapproche bayésienne en proposant sans aucun paramètre une expression analytique de la probabilité dun arbre connaissant les données nous transformonsle problème de construction de larbre en un problème doptimisation  nousrecherchons dans lespace des arbres de décision larbre optimum au sens ducritère bayésien ainsi défini cest à dire larbre maximum a posteriori maploptimisation est effectuée en exploitant une heuristique de préélagage desexpérimentations comparatives sur trente bases de luci montrent que notreméthode obtient des performances prédictives proches de celles de létat de larttout en étant beaucoup moins complexes\n",
      "un nouvel algorithme de forêts aléatoires darbres obliques particulièrement adapté à la classification de données en grandes dimensions\n",
      "lalgorithme des forêts aléatoires proposé par breiman permet dobtenir de bons résultats en fouille de données comparativement à de nombreusesapproches cependant en nutilisant quun seul attribut parmi un sousensembledattributs tiré aléatoirement pour séparer les individus à chaque niveau de larbrecet algorithme perd de linformation ceci est particulièrement pénalisant avecles ensembles de données en grandes dimensions où il peut exister de nombreuses dépendances entre attributs nous présentons un nouvel algorithme deforêts aléatoires darbres obliques obtenus par des séparateurs à vaste margesvm la comparaison des performances de notre algorithme avec celles delalgorithme de forêts aléatoires des arbres de décision c45 et de lalgorithmesvm montre un avantage significatif de notre proposition\n",
      "un prototype crosslingue multimétiers  vers la gestion sémantique de contenu dentreprise au service du collaboratif opérationnel\n",
      "le domaine « qualité hygiène sécurité et environnement »qhse représente à lheure actuelle un vecteur de progrès majeur pourlindustrie européenne le prototype « semantic quality environment » sqeintroduit dans cet article vise à démontrer la validité dune architecturesémantique crosslingue vouée à la collaboration multimétiers et multilinguedans le cadre dun système banalisé de gestion de contenu dentreprise dédié àlindustrie navale européenne\n",
      "un système pour lextraction de corrélations linéaires dans des données de génomique médicale\n",
      "nan\n",
      "une méthode de classification supervisée sans paramètre pour lapprentissage sur les grandes bases de données\n",
      "dans ce papier nous présentons une méthode de classification supervisée sans paramètre permettant dattaquer les grandes volumétries la méthodeest basée sur des estimateurs de densités univariés optimaux au sens de bayessur un classifieur bayesien naïf amélioré par une sélection de variables et unmoyennage de modèles exploitant un lissage logarithmique de la distribution aposteriori des modèles nous analysons en particulier la complexité algorithmique de la méthode et montrons comment elle permet danalyser des bases dedonnées nettement plus volumineuses que la mémoire vive disponible nous présentons enfin les résultats obtenu lors du récent pascal large scale learningchallenge où notre méthode a obtenu des performances prédictives de premierplan avec des temps de calcul raisonnables\n",
      "une nouvelle approche pour la classification non supervisée en segmentation dimage\n",
      "la segmentation des images en régions est un problème crucial pourlanalyse et la compréhension des images parmi les approches existantes pourrésoudre ce problème la classification non supervisée est fréquemment employée lors dune première étape pour réaliser un partitionnement de lespacedes intensités des pixels quil sagisse de niveaux de gris de couleurs ou de réponses spectrales puisquelle ignore complètement les notions de voisinagedes pixels une seconde étape danalyse spatiale étiquetage en composantesconnexes par exemple est ensuite nécessaire pour identifier les régions issuesde la segmentation la non prise en compte de linformation spatiale est une limite majeure de ce type dapproche ce qui a motivé de nombreux travaux où laclassification est couplée à dautres techniques pour saffranchir de ce problèmedans cet article nous proposons une nouvelle formulation de la classificationnon supervisée permettant deffectuer la segmentation des images sans faire appel à des techniques supplémentaires plus précisément nous élaborons une méthode itérative de type kmeans où les données à partitionner sont les pixels euxmêmes et non plus leurs intensités et où les distances des points aux centresdes classes ne sont plus euclidiennes mais topographiques la segmentation estalors un processus itératif et à chaque itération les classes obtenues peuvent êtreassimilées à des zones dinfluence dans le contexte de la morphologie mathématique ce parallèle nous permet de bénéficier des algorithmes efficaces proposésdans ce domaine tels que ceux basés sur les files dattente tout en y ajoutantle caractère itératif des méthodes de classification non supervisée considéréesici nous illustrons finalement le potentiel de lapproche proposée par quelquesrésultats préliminaires de segmentation sur des images artificielles\n",
      "utilisation de lanalyse factorielle des correspondances pour la recherche dimages à grande échelle\n",
      "nous nous intéressons à lutilisation de lanalyse factorielle des correspondances afc pour la recherche dimages par le contenu dans une base dedonnées dimages volumineuse nous adaptons lafc méthode originellementdéveloppée pour lanalyse des données textuelles adt aux images en utilisant des descripteurs locaux sift en adt lafc permet de réduire le nombrede dimensions et de trouver des thèmes ici lafc nous permettra de limiter lenombre dimages à examiner au cours de la recherche afin daccélérer le tempsde réponse pour une requête pour traiter de grandes bases dimages nous proposons une version incrémentale de lalgorithme afc ce nouvel algorithmedécoupe une base dimages en blocs et les charge dans la mémoire lun aprèslautre nous présentons aussi lintégration des informations contextuelles egla mesure de dissimilarité contextuelle jegou et al 2007 dans notre structurede recherche dimages cela améliore considérablement la précision nous exploitons cette intégration dans deux axes i hors ligne la structure de voisinageest corrigée hors ligne et ii à la volée la structure de voisinage des images estcorrigée au cours de la recherche sur un petit ensemble dimages\n",
      "vers la simulation et la détection des changements des données évolutives dusage du web\n",
      "dans le domaine des flux des données la prise en compte du tempssavère nécessaire pour lanalyse de ces données car leur distribution sousjacentepeut changer au cours du temps un exemple typique concerne les modèles desprofils de navigation des internautes notre objectif est danalyser lévolutionde ces profils celleci peut être liée au changement deffectifs ou aux déplacementde clusters au cours du temps afin danalyser la validité de notre approchenous mettons en place uneméthodologie pour la simulation des données dusageà partir de laquelle il est possible de contrôler loccurrence des changements\n",
      "vers le traitement à grande échelle de données symboliques\n",
      "nan\n",
      "vers une utilisation améliorée de relations spatiales pour lapprentissage de données dans les modèles graphiques\n",
      "nous nous intéressons dans cet article aux représentations des relationsspatiales pour lextraction dinformation et la modélisation des donnéesvisuelles en particulier dans le contexte de la catégorisation dimages nousmontrons comment la prise en compte dune relation spatiale entre deux élémentsentraîne lapparition dune information supplémentaire entre ces élémentset le reste de lensemble à modéliser ce qui est rarement exploité explicitementune représentation floue des relations dans unmodèle graphique est bien adaptéepour les algorithmes dapprentissage utilisés actuellement et permet dintégrerce type dinformation complémentaire qui concerne labsence dune interactionplutôt que sa présence nous tentons dévaluer les bénéfices de cette approchesur un problème de traitement dimages\n",
      "a spatial rough set for extracting the periurban fringe\n",
      "to date the availability of spatial data is increasing together withtechniques and methods adopted in geographical analysis despite this tendencyclassifying in a sharp way every part of the city is more and more complicatedthis is due to the growth of city complexity rough set theory maybe a useful method to employ in combining great amounts of data in order tobuild complex knowledge about territory it represents a different mathematicalapproach to uncertainty by capturing the indiscernibility two differentphenomena can be indiscernible in some contexts and classified in the sameway when combining available information about them several experiencesexist in the use of rough set theory in data mining knowledge analysis andapproximate pattern classification but the spatial component lacks in all theseresearch streamsthis paper aims to the use of rough set methods in geographical analysesthis approach has been applied in a case of study comparing the resultsachieved by means of both map algebra technique and spatial rough set thestudy case area potenza province is particularly suitable for the application ofthis theory because it includes 100 municipalities with a different number ofinhabitants and morphologic features\n",
      "algorithmes rapides de boosting de svm\n",
      "les algorithmes de boosting de newton support vector machine nsvm proximal support vector machine psvm et leastsquares support vector machine lssvm que nous présentons visent à la classification de très grands ensembles de données sur des machines standard nous présentons une extension des algorithmes de nsvm psvm et lssvm pour construire des algorithmes de boosting a cette fin nous avons utilisé un terme de régularisation de tikhonov et le théorème shermanmorrison woodbury pour adapter ces algorithmes au traitement densembles de données ayant un grand nombre de dimensions nous les avons ensuite étendus par construction dalgorithmes de boosting de nsvm psvm et lssvm afin de traiter des données ayant simultanément un grand nombre dindividus et de dimensions les performances des algorithmes sont évaluées sur des grands ensembles de données de luci comme adult kddcup 1999 forest covertype reuters21578 et rcv1binary sur une machine standard pcp4 24 ghz 1024 mo ram\n",
      "analyse exploratoire dopinions cinématographiques  coclustering de corpus textuels communautaires\n",
      "les sites communautaires sont un endroit privilégié pour sexprimer et publier des opinions le site wwwflixstercom est un exemple de site participatif sur lequel se rassemblent plus de 20 millions de cinéphiles qui partagent des commentaires sur les films quils ont ou non aimés explorer les contenus autoproduits est un challenge pour qui veut comprendre les attentes des internautes par une méthode dapprentissage non supervisée nous montrerons quil est possible de mieux comprendre le vocabulaire utilisé pour décrire des opinions en particulier grâce à une méthode de coclustering nous montrerons quun rapprochement peut être fait entre des films particuliers sur la base de lusage dun vocabulaire particulier lanalyse des résultats peut conduire à retrouver une certaine typologie de films ou encore des rapprochements entre films cette étude peut être complémentaire avec des analyses linguistiques des corpus ou encore être exploitée dans un contexte applicatif de recommandation de contenus multimédias\n",
      "apport des traitements morphosyntaxiques pour lalignement des définitions par une classification svm\n",
      "cet article propose une méthode dalignement automatique de définitions destinée à améliorer la fusion entre des terminologies spécialisées et un vocabulaire médical généraliste par un classifieur de type svm support vecteur machine et une représentation compacte et pertinente dun couple de définitions par concaténation dun ensemble de mesures de similarité afin de tenir compte de leur complémentarité auquelle nous ajoutons les longueurs de chacune des définitions trois niveaux syntaxiques ont été investigués le modèle fondé sur un apprentissage à partir des groupes nominaux de type nomsadjectifs aboutit aux meilleures performances\n",
      "approche dannotation automatique des événements\n",
      "quotidiennement plusieurs agences de presse publient des milliers darticles contenant plusieurs événements de toutes sortes politiques économiques culturels etc les preneurs de décision se trouvent face à ce grand nombre dévénements dont seulement quelques uns les concernent le traitement automatique de tels événements devient de plus en plus nécessaires pour cela nous proposons une approche qui se base sur lapprentissage automatique et qui permet dannoter les articles de presse pour générer un résumé automatique contenant les principaux événements nous avons validé notre approche par le développement du système annotev\n",
      "approche hybride de classification à base de treillis de galois application à la reconnaissance de visages\n",
      "la recherche dans le domaine de la reconnaissance de visages profite des solutions obtenues dans le domaine de lapprentissage automatique le problème de classification de visages peut être considéré comme un problème dapprentissage supervisé où les exemples dapprentissage sont les visages étiquetés notre article introduit dans ce contexte une nouvelle approche hybride de classification qui utilise le paradigme dapprentissage automatique supervisé ainsi en se basant sur le fondement mathématique des treillis de galois et leur utilisation pour la classification supervisée nous proposons un nouvel algorithme de classification baptisé citrec ainsi que son application pour la reconnaissance de visages loriginalité de notre approche provient de la combinaison de lanalyse formelle de concepts avec les approches de classification supervisée à inférence bayésienne ou à plus proches voisins une validation expérimentale est décrite sur un benchmark du domaine de la reconnaissance de visages\n",
      "approches de type ngrammes pour lanalyse de parcours de vie familiaux\n",
      "cet article porte sur lanalyse de parcours de vie représentés sous forme de séquences dévénements plus spécifiquement on examine les possibilités dexploiter des codages de type ngrammes de ces séquences pour en extraire des connaissances en fait compte tenu de la simultanéité de certains événements une procédure stricte de ngrammes comme on peut par exemple lappliquer sur des textes nest pas applicable ici nous discutons diverses alternatives qui savèrent finalement plus proches de la fouille de séquences fréquentes les concepts discutés sont illustrés sur des données de lenquête biographique rétrospective réalisée par le panel suisse de ménages en 2002 enfin on précisera sur quels aspects lapproche proposée peut apporter un éclairage complémentaire utile par rapport à dautres techniques plus classiques danalyse exploratoire de parcours de vie\n",
      "assignation automatique de solutions à des classes de plaintes liées aux ambiances intérieures polluées\n",
      "nous présentons dans cet article un système informatique pour le traitement des plaintes en lien avec des situations de pollution domestique écrites en français après la construction automatique dune base de scenarii de plaintes un module de recherche apparie la plainte à traiter à la thématique de la plainte la plus similaire enfin il sagit dassigner au problème courant la solution correspondante au scénario de pollution auquel est affectée la plainte pertinente nous montrons ici lintérêt de lintroduction dans lappariement des textes de laspect sémantique géré par un dictionnaire généraliste de synonymes et en quoi il nest pas réalisable pour notre problème particulier de construire une ontologie\n",
      "binary block gtm  carte autoorganisatrice probabiliste pour les grands tableaux binaires\n",
      "ce papier présente un modèle génératif et son estimation permettant la visualisation de données binaires notre approche est basée sur un modèle de mélange de lois de bernoulli par blocs et les cartes de kohonen probabilistes la méthode obtenue se montre à la fois parcimonieuse et pertinente en pratique\n",
      "cas dutilisation réelle de nautilus  calculs dindicateurs chez un opérateur télécom\n",
      "nautilus est un logiciel danalyse de bases de données le but de cette application est de généraliser lutilisation de données clients au sein des entreprises elle facilite laccès aux données en permettant de visualiser et manipuler les données du sgbd sous forme de concepts métiers elle inclut un générateur de requêtes sql et un outil de gestion de tâches désignées pour lagrégation de grands volumes de données le principe de fonctionnement est basé sur lenchaînement de phases permettant la création des données danalyse  importation des métadonnées du sgbd  construction dun dictionnaire de des concepts métiers  spécification des champs à calculer les différents traitements tels que les jointures et lalimentation des tables sont optimisés afin de rendre lapplication utilisable sur des sgbd dentreprise\n",
      "classification adaptative de séries temporelles  application à lidentification des gènes exprimés au cours du cycle cellulaire\n",
      "ce travail sinscrit dans le cadre de létude de la division cellulaire assurant la prolifération des cellules une meilleure compréhension de ce phénomène biologique nécessite lidentification des gènes caractérisant chaque phase du cycle cellulaire le procédé didentification est généralement basé sur un ensemble de gènes dits gènes de référence sélectionnés expérimentalement et considérés comme caractérisant les phases du cycle cellulaire les niveaux dexpression des gènes étudiés sont mesurés durant le cycle de la division cellulaire et permettent de construire des profils dexpression chaque gène étudié est affecté à la phase du cycle cellulaire correspondant au groupe de gènes de référence le plus similaire cette approche classique souffre de deux limites dune part les mesures de proximité les plus couramment utilisés entre profils dexpression de gènes sont basées sur les écarts en valeurs sans tenir compte de la forme des profils dautre part dans la littérature il ny a pas consensus quant à lensemble des gènes de référence à considérer dans cet article notre but est de proposer une classification adaptative basée sur un indice de dissimilarité incluant les proximités en valeurs et en forme des profils dexpression de gènes permettant didentifier les phases dexpression des gènes étudiés et de présenter un nouvel ensemble de gènes de référence validé par une connaissance biologique\n",
      "classification de documents en réseaux petits mondes en vue dapprentissage\n",
      "nan\n",
      "clustering en haute dimension par accumulation de clusterings locaux\n",
      "le clustering est une tâche fondamentale de la fouille de données ces dernières années les méthodes de type cluster ensembles ont été lobjet dune attention soutenue il sagit dagréger plusieurs clusterings dun jeu de données afin dobtenir un clustering moyen les clusterings individuels peuvent être le résultat de différents algorithmes ces méthodes sont particulièrement utiles lorsque la dimensionalité des données ne permet pas aux méthodes classiques basées sur la distance etou la densité de fonctionner correctement dans cet article nous proposons une méthode pour obtenir des clusterings individuels à faible coût à partir de projections partielles du jeu de données nous évaluons empiriquement notre méthode et la comparons à trois méthodes de différents types nous constatons quelle donne des résultats sensiblement supérieurs aux autres\n",
      "clustering visuel semisupervisé pour des systèmes en coordonnées en étoiles 3d\n",
      "dans cet article nous proposons une approche qui combine les méthodes statistiques avancées et la flexibilité des approches interactives manuelles en clustering visuel nous présentons linterface semisupervised visual clustering ssvc sa contribution principale est lapprentissage dune métrique de projection optimale pour la visualisation en coordonnées en étoiles ainsi que pour lextension 3d que nous avons développée la métrique de distance de projection est apprise à partir des retours de lutilisateur soit en termes de similarité dissimilarité entre les items soit par lannotation directe linterface ssvc permet de plus une utilisation hybride dans laquelle un ensemble de paramètres sont manuellement fixés par lutilisateur tandis que les autres paramètres sont déterminés par un algorithme de distance optimale\n",
      "coclassification sous contraintes par la somme des résidus quadratiques\n",
      "dans de nombreuses applications une coclassification est plus facile à interpréter quune classification monodimensionnelle il sagit de calculer une bipartition ou collection de coclusters  chaque cocluster est un groupe dobjets associé à un groupe dattributs et les interprétations peuvent sappuyer naturellement sur ces associations pour exploiter la connaissance du domaine et ainsi améliorer la pertinence des partitions plusieurs méthodes de classification sous contraintes ont été proposées pour le cas monodimensionnel eg lexploitation de contraintes mustlink et cannotlink nous considérons ici la coclassification sous contraintes avec la gestion de telles contraintes étendues aux dimensions des objets et des attributs mais aussi lexpression de contraintes de contiguité dans le cas de domaines ordonnés nous proposons un algorithme itératif qui minimise la somme des résidus quadratiques et permet lexploitation active des contraintes spécifiées par les analystes nous montrons la valeur ajoutée de ce type dextraction sur deux applications en analyse du transcriptome\n",
      "conception de systèmes dinformation spatiotemporelle adaptatifs avec astis\n",
      "les avancées technologiques récentes du web et du sans filconjuguées au succès des applications spatialisées grand public sont àlorigine dun accès accru aux systèmes dinformation spatiotemporellesist par une grande diversité dutilisateurs munis des dispositifs daccèset dans des contextes dutilisation variés adapter ces systèmes à lutilisateurdevient donc une nécessité un gage dutilisabilité et de pérennité cet articleprésente une approche générique pour la conception et la génération desystèmes dinformation spatiotemporelle adaptés à lutilisateur appeléastis astis offre des modalités générales de mise en oeuvre deladaptation à lutilisateur visant tant le contenu que la présentation desapplications elle permet aux concepteurs dintégrer ces modalitésdadaptation dans des applications traitant des données spatiotemporellesafin de définir les besoins et types dadaptation propres à leur application ilsuffit aux concepteurs de créer des modèles conceptuels par spécialisation etinstanciation des modèles offerts par notre architecture\n",
      "data mining for activity extraction in video data\n",
      "the exploration of large video data is a task which is now possible because of the advances made on object detection and tracking data mining techniques such as clustering are typically employed such techniques have mainly been applied for segmentationindexation of video but knowledge extraction of the activity contained in the video has been only partially addressed in this paper we present how video information is processed with the ultimate aim to achieve knowledge discovery of people activity in the video first objects of interest are detected in real time then in an offline process we aim to perform knowledge discovery at two stages 1 finding the main trajectory patterns of people in the video 2 finding patterns of interaction between people and contextual objects in the scene an agglomerative hierarchical clustering is employed at each stage we present results obtained on real videos of the torino metro italy\n",
      "découverte de motifs séquentiels et de règles inattendus\n",
      "les travaux autour de lextraction de motifs séquentiels se sont particulièrement focalisés sur la définition dapproches efficaces pour extraire en fonction dune fréquence dapparition des corrélations entre des éléments dans des séquences même si ce critère de fréquence est déterminant le décideur est également de plus en plus intéressé par des connaissances qui sont représentatives dun comportement inattendu dans ces données erreurs dans les données fraudes nouvelles niches   dans cet article nous introduisons le problème de la détection de motifs séquentiels inattendus par rapport aux croyances du domaine nous proposons lapproche user dont lobjectif est dextraire les motifs séquentiels et les règles inattendues dans une base de séquences\n",
      "délestage pour lanalyse multidimensionnelle de flux de données\n",
      "dans le contexte de la gestion de flux de données les données entrent dans le système à leur rythme des mécanismes de délestage sont à mettre en place pour quun tel système puisse faire face aux situations où le débit des données dépasse ses capacités de traitement le lien entre réduction de la charge et dégradation de la qualité des résultats doit alors être quantifié dans cet article nous nous plaçons dans le cas où le système est un cube de données dont la structure est connue a priori alimenté par un flux de données nous proposons un mécanisme de délestage pour les situations de surcharge et quantifions la dégradation de la qualité des résultats dans les cellules du cube nous exploitons linégalité de hoeffding pour obtenir une borne probabiliste sur lécart entre la valeur attendue et la valeur estimée\n",
      "détection de groupes atypiques pour une variable cible quantitative\n",
      "une tâche importante en analyse des données est la compréhension de comportements inattendus ou atypiques de groupes dindividus quelles sont les catégories dindividus qui gagnent de particulièrement forts salaires ou au contraire quelles sont celles qui ont de très faibles salaires  nous présentons le problème dextraction de tels groupes atypiques visàvis dune variable cible quantitative comme par exemple la variable salaire et plus particulièrement pour les faibles et fortes valeurs dun intervalle déterminé par lutilisateur il sagit donc de rechercher des conjonctions de variables dont la distribution diffère significativement de celle de lensemble dapprentissage pour les faibles et fortes valeurs de lintervalle de cette variable cible une adaptation dune mesure statistique existante lintensité dinclination nous permet de découvrir de tels groupes atypiques cette mesure nous libère de létape de transformation des variables quantitatives à savoir létape de discrétisation suivie dun codage disjonctif complet nous proposons donc un algorithme dextraction de tels groupes avec des règles délagage pour réduire la complexité du problème cet algorithme a été développé et intégré au logiciel dextraction de connaissances weka nous terminons par un exemple dextraction sur la base de données ipums du bureau de recensement américain\n",
      "discretization of continuous features by resampling\n",
      "les arbres de décision sont largement utilisés pour générer des classificateurs à partir dun ensemble de données le processus de construction est une partitionnement récursif de lensemble dapprentissage dans ce contexte les attributs continus sont discrétisés il sagit alors pour chaque variable à discrétiser de trouver lensemble des points de coupure dans ce papier nous montrons que la recherche des ces points de coupure par une méthode de rééchantillonnage comme le bootstrap conduit à des meilleurs résultats nous avons testé cette approche avec les méthodes principales de discrétisation comme mdlpc fusbin fusinter contrast chimerge et les résultats sont systématiquement meilleurs en utilisant le bootstrap nous exposons ces principaux résultats et ouvrons de nouvelles pistes pour la construction darbres de décision\n",
      "echantillonnage adaptatif de jeux de données déséquilibrés pour les forêts aléatoires\n",
      "dans nombre dapplications les données présentent un déséquilibre entre les classes la prédiction est alors souvent détériorée pour la classe minoritaire pour contourner cela nous proposons un échantillonnage guidé lors des itérations successives dune forêt aléatoire par les besoins de lutilisateur\n",
      "echantillonnage pour lextraction de motifs séquentiels  des bases de données statiques aux flots de données\n",
      "depuis quelques années la communauté fouille de données sest intéressée à la problématique de lextraction de motifs séquentiels à partir de grandes bases de données en considérant comme hypothèse que les données pouvaient être chargées en mémoire centrale cependant cette hypothèse est mise en défaut lorsque les bases manipulées sont trop volumineuses dans cet article nous étudions une technique déchantillonnage basée sur des réservoirs et montrons comment cette dernière est particulièrement bien adaptée pour résumer de gros volumes de données nous nous intéressons ensuite à la problématique plus récente de la fouille sur des données disponibles sous la forme dun flot continu et éventuellement infini data stream nous étendons lapproche déchantillonnage à ce nouveau contexte et montrons que nous sommes à même dextraire des motifs séquentiels de flots tout en garantissant les taux derreurs sur les résultats les différentes expérimentations menées confirment nos résultats théoriques\n",
      "echantillonnage spatiotemporel de flux de données distribués\n",
      "ces dernières années sont apparues de nombreuses applications utilisant des données potentiellement infinies provenant de façon continue de capteurs distribués on retrouve ces capteurs dans des domaines aussi divers que la météorologie établir des prévisions le domaine militaire surveiller des zones sensibles lanalyse des consommations électriques transmettre des alertes en cas de consommation anormale pour faire face à la volumétrie et au taux darrivée des flux de données des traitements sont effectués à la volée sur les flux en particulier si le système nest pas assez rapide pour traiter toutes les données dun flux il est possible de construire des résumés de linformation cette communication a pour objectif de faire un premier point sur nos travaux déchantillonnage dans un environnement de flux de données fortement distribués notre approche est basée sur la théorie des sondages lanalyse des données fonctionnelles et la gestion de flux de données cette approche sera illustrée par un cas réel  celui des mesures de consommations électriques\n",
      "enhancing personal file retrieval in semantic file systems with tagbased context\n",
      "recently tagging systems are widely used on the internet on desktops tags are also supported by some semantic file systems and desktop search tools in this paper we focus on personal tag organization to enhance personal file retrieval our approach is based on the notion of context a context is a set of tags assigned to a file by a user based on tag popularity and relationships between tags our proposed algorithm creates a hierarchy of contexts on which a user can navigate to retrieve files in an effective manner\n",
      "étude comparative de deux approches de classification recouvrante  moc vs okm\n",
      "la classification recouvrante désigne les techniques de regroupements de données en classes pouvant sintersecter particulièrement adaptés à des domaines dapplication actuels eg recherche dinformation bioinformatique quelques modèles théoriques de classification recouvrante ont été proposés très récemment parmi lesquels le modèle moc banerjee et al 2005a utilisant les modèles de mélanges et lapproche okm cleuziou 2007 consistant à généraliser lalgorithme des kmoyennes la présente étude vise dune part à étudier les limites théoriques et pratiques de ces deux modèles et dautre part à proposer une formulation de lapproche okm en terme de modèles de mélanges gaussiens laissant ainsi entrevoir des perspectives intéressantes quant à la variabilité des schémas de recouvrements envisageables\n",
      "étude de linteraction entre variables pour lextraction des règles dinfluence\n",
      "cet article présente une méthode efficace pour lextraction de règles dinfluence quantitatives positives et négatives ces règles dinfluence introduisent une nouvelle sémantique qui vise à faciliter lanalyse dun volume important de données cette sémantique fixe la direction de la règle entre deux variables en positionnant au préalable lune comme étant linfluent et lautre comme étant linflué elle permet de ce fait dexprimer la nature de linfluence  positive en maximisant le nombre déléments en commun ou négative en maximisant le nombre déléments qui violent linflué notre approche sappuie sur une stratégie qui comporte cinq étapes dont deux exécutées en parallèle ces deux étapes constituent les étapes clé de notre approche la première combine une méthode délagage et de regroupement tabulaire basée sur les tableaux de contingence cette dernière construit et classe les zones potentiellement intéressantes la seconde injecte la sémantique et évalue le degré dinfluence que produirait lintroduction dune nouvelle variable sur un ensemble de variables en utilisant une nouvelle mesure dintérêt linfluence cette étape vient affiner les résultats de la première étape et permet de se focaliser sur des zones valides par rapport aux contraintes spécifiées enfin un système de règles dinfluence jugées intéressantes est construit basé sur la juxtaposition des résultats des deux étapes clé de notre approche\n",
      "évaluation des critères asymétriques pour les arbres de décision\n",
      "pour construire des arbres de décision sur des données déséquilibrées des auteurs ont proposés des mesures dentropie asymétriques le problème de lévaluation de ces arbres se pose ensuite cet article propose dévaluer la qualité darbres de décision basés sur une mesure dentropie asymétrique\n",
      "explsa  utilisation dinformations syntaxicosémantiques associées à lsa pour améliorer les méthodes de classification conceptuelle\n",
      "lanalyse sémantique latente lsa  latent semantic analysis est aujourdhui utilisée dans de nombreux domaines comme la modélisation cognitive les applications éducatives mais aussi pour la classification lapproche présentée dans cet article consiste à ajouter des informations grammaticales à lsa différentes méthodes pour exploiter ces informations grammaticales sont étudiées dans le cadre dune tâche de classification conceptuelle\n",
      "extraction ditemsets compacts\n",
      "lextraction ditemsets fréquents est un sujet majeur de lecd et son but est de découvrir des corrélations entre les enregistrements dun ensemble de données cependant le support est calculé en fonction de la taille de la base dans son intégralité dans cet article nous montrons quil est possible de prendre en compte des périodes difficiles à déceler dans lorganisation des données et qui contiennent des itemsets fréquents sur ces périodes nous proposons ainsi la définition des itemsets compacts qui représentent un comportement cohérent sur une période spécifique et nous présentons lalgorithme deico qui permet leur découverte\n",
      "extraction dun modèle numérique de terrain à partir de photographies par drone\n",
      "dans le suivi et la modélisation de lérosion en montagne lareprésentation fine du relief est une composante importante en effet laconnaissance des zones de concentration des eaux notamment à traverslapparition de rigoles élémentaires est fondamentale pour bien décrire lesconnectivités entre les zones de mobilisation des sédiments sur le versant et leréseau hydrographique stabilisé la résolution au sol permise par lesphotographies aériennes classiques ne permet pas daccéder à unereprésentation 3d suffisamment fine des ravines élémentaires nous testonslutilisation de photographies stéréoscopiques à résolution centimétrique prisesà basse altitude par un drone pour obtenir un mnt précis la question majeureconcerne les règles à suivre pour un meilleur compromis entre précision etfacilité délaboration et lévaluation de limportance relative de chaque étapesur la qualité finale de la restitution la zone détude est située dans lesbadlands de draix alpes de haute provence\n",
      "extraction de motifs séquentiels multidimensionnels clos sans gestion densemble de candidats\n",
      "lextraction de motifs séquentiels permet de découvrir des corrélations entre événements au cours du temps introduisant plusieurs dimensions danalyse les motifs séquentiels multidimensionnels permettent de découvrir des motifs plus pertinents mais le nombre de motifs obtenus peut devenir très important cest pourquoi nous proposons dans cet article de définir une représentation condensée garantie sans perte dinformation  les motifs séquentiels multidimensionnels clos extraits ici sans gestion densemble de candidats\n",
      "extraction et exploitation des annotations contextuelles\n",
      "dans la perspective doffrir un web sémantique des travaux ont cherché à automatiser lextraction des annotations sémantiques à partir de textes pour représenter au mieux la sémantique que vise à transmettre une page web dans cet article nous proposons une approche dextraction des annotations qui représentent le plus précisément possible le contenu dun document nous proposons de prendre en compte la notion de contexte modélisé par des relations contextuelles émanant à la fois de la structure et de la sémantique du texte\n",
      "extraction et validation par croisement des relations dune ontologie de domaine\n",
      "nan\n",
      "fiasco  un nouvel algorithme dextraction ditemsets fréquents dans les flots de données\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nous présentons dans cet article un nouvel algorithme permettant la construction et la mise à jour incrémentale du fia  fiasco notre algorithme effectue un seul passage sur les données et permet de prendre en compte les nouveaux batches itemset par itemset et pour chaque itemset item par item\n",
      "fouille de données audio pour la classification automatique de mots homophones\n",
      "cet article présente une contribution à la modélisation acoustique des mots à partir de grands corpus oraux faisant appel aux techniques de fouilles de données en transcription automatique de nombreuses erreurs concernent des mots fréquents homophones deux paires de mots quasihomophones àa et etest sont sélectionnées dans les corpus pour lesquels sont définis et examinés 41 descripteurs acoustiques permettant potentiellement de les distinguer 17 algorithmes de classification mis à lépreuve pour la discrimination automatique de ces deux paires de mots donnent en moyenne 77 de classification correcte sur les 5 meilleurs algorithmes en réduisant le nombre de descripteurs à 10 sélectionnés par lalgorithme le plus performant les résultats de classification restent proches du résultat obtenu avec 41 attributs cette comparaison met en évidence le caractère discriminant de certains attributs qui pourront venir enrichir à la fois la modélisation acoustique et nos connaissances des prononciations de loral\n",
      "from mining the web to inventing the new sciences underlying the internet\n",
      "as the internet continues to change the way we live find information communicate and do business it has also been taking on a dramatically increasing role in marketing and advertising unlike any prior mass medium the internet is a unique medium when it comes to interactivity and offers ability to target and program messaging at the individual level coupled with its uniqueness in the richness of the data that is available for measurability in the variety of ways to utilize the data and in the great dependence of effective marketing on applications that are heavily datadriven makes data mining and statistical data analysis modeling and reporting an essential missioncritical part of running the online business however because of its novelty and the scale of data sets involved few companies have figured out how to properly make use of this data in this talk i will review some of the challenges and opportunities in the utilization of data to drive this new generation of marketing systems i will provide several examples of how data is utilized in critical ways to drive some of these capabilities the discussion will be framed with themore general framework of grand challenges for data mining  pragmatic and technical i will conclude this presentation with a consideration of the larger issues surrounding the internet as a technology that is ubiquitous in our lives yet one where very little is understood at the scientific level in defining and understanding many of the basics the internet enables  community personalization and the new microeconomics of the web this leads to an overview of the new yahoo  research organization and its aims  inventing the new sciences underlying what we do on the internet focusing on areas that have received little attention in the traditional academic circles some illustrative examples will be reviewed to make the ultimate goals more concrete\n",
      "génération de séquence résumé par une nouvelle approche basée sur le soft computing\n",
      "cet article propose une approche dabstraction des séquences vidéo basée sur le soft computing etant donné une longueur cible du condensé vidéo on cherche les segments vidéo qui couvrent le maximum du visuel de la vidéo originale en respectant la longueur du condensé\n",
      "gradients de prototypicalité conceptuelle et lexicale\n",
      "longtemps les ontologies ont été limitées à des domaines scientifiques et techniques favorisant au passage lessor du concept de « connaissances universelles et objectives » avec lémergence et lengouement actuel pour les sciences cognitives couplés à lapplication des ontologies à des domaines relatifs aux sciences humaines et sociales shs la subjectivité des connaissances devient une dimension incontournable qui se doit dêtre intégrée et prise en compte dans le processus dingénierie ontologique io lobjectif de nos travaux est de développer la notion dontologie pragmatisée vernaculaire de domaine opvd le principe sousjacent à de telles ressources consiste à considérer que chaque ontologie est non seulement propre à un domaine mais également à un endogroupe donné doté dune pragmatique qui est fonction tant de la culture que de lapprentissage et de létat émotionnel du dit endogroupe cette pragmatique qui traduit un processus dappropriation et de personnalisation de lontologie considérée est qualifiée à laide de deux mesures  un gradient de prototypicalité conceptuelle et un gradient de prototypicalité lexicale\n",
      "hypersmooth  calcul et visualisation de cartes de potentiel interactives\n",
      "le groupe de recherche hypercarte propose hypersmoothun nouvel outil cartographique pour lanalyse spatiale de phénomènessociaux économiques mettant en oeuvre une méthode de calcul depotentiel lobjectif est de pouvoir représenter de façon continue et enchangeant déchelle danalyse une information statistiqueéchantillonnée sur toutes sortes de maillages réguliers ou non le défitechnologique est de fournir un outil accessible sur le web interactifet rapide ceci malgré le coût élevé du calcul et qui assure laconfidentialité des données nous présentons notre solution basée surune architecture client serveur  le serveur calcule les cartes depotentiel en utilisant des techniques doptimisation particulières alorsque le client est en charge de la visualisation et du paramétrage delanalyse et les deux parties communiquent via un protocole web\n",
      "industrialiser le data mining  enjeux et perspectives\n",
      "linformatique décisionnelle est un secteur en forte croissance dans toutes les entreprises les techniques classiques reporting simple  olap qui sintéressent essentiellement à présenter les données sont aujourdhui très largement déployées le data mining commence à se répandre apportant des capacités de prévision à forte valeur ajoutée pour les entreprises les plus compétitives ce développement est rendu possible par la disponibilité croissante de masses de données importantes et la puissance de calcul dorénavant disponible cependant la mise en ijuvre industrielle des projets de data mining pose des contraintes tant théoriques quels algorithmes utiliser pour produire des modèles danalyses exploitant des milliers de variables pour des millions dexemples quopérationnelles comment mettre en production et contrôler le bon fonctionnement de centaines de modèles je présenterai ces contraintes issues des besoins des entreprises  je montrerai comment exploiter des résultats théoriques provenant des travaux de vladimir vapnik pour produire des modèles robustes  je donnerai des exemples dapplications réelles en gestion de la relation client et en analyse de qualité je conclurai en présentant quelques perspectives utilisation du texte et des réseaux sociaux\n",
      "intégration de contraintes dans les cartes autoorganisatrices\n",
      "le travail présenté dans cet article décrit une nouvelle version des cartes topologiques que nous appelons crtm cette version consiste à modifier lalgorithme de kohonen de telle façon à ce quil contrôle les violations des contraintes lors de la construction de la topologie de la carte nous validons notre approche sur des données connues de la littérature en utilisant des contraintes artificielles une validation supplémentaire sera faite sur des données réelles issues dimages médicales pour la classification des mélanomes chez lhumain sous contraintes médicales\n",
      "intégration de la structure dans un modèle probabiliste de document\n",
      "en fouille de textes comme en recherche dinformation différents modèles de type probabiliste vectoriel ou booléen se sont révélés bien adaptés pour représenter des documents textuels mais ces modèles présentent linconvénient de ne pas tenir compte de la structure du document or la plupart des informations disponibles aujourdhui sur internet ou dans des bases documentaires sont fortement structurées dans cet article nous proposons détendre le modèle probabiliste de représentation des documents de façon à tenir compte du poids dune certaine catégorie déléments structurels  les balises représentant la structure logique et la structure de mise en forme ce modèle a été évalué à laide de la collection de la campagne dévaluation inex 2006\n",
      "interprétation automatique ditinéraires à partir dun corpus de récits de voyages pilotée par un usage pédagogique\n",
      "de larges corpus à fort ancrage territorial deviennent disponibles sousforme numérique dans les médiathèques et plus particulièrement dans les médiathèquesde dimension régionale les défis quoffrent ces gigas octets de documentsbruts sont énormes en terme de traitement automatique des contenusnous proposons dans cet article deux modèles computationnels et une méthodecomplète permettant de réaliser un traitement automatique afin dextraire des itinérairesdans des textes relatant des récits de voyage le premier modèle est unmodèle des attendus il sintéresse au concept ditinéraire et adopte le point devue du pédagogue et fait intervenir très tôt les usages envisagés le deuxièmemodèle est un modèle dextraction il permet de modéliser lexpression du déplacementdans des textes du genre récit de voyage nous proposons alors uneméthode automatique pour  dune part extraire et interpréter automatiquementles déplacements dun récit et dautre part passer des déplacements à litinérairecestàdire alimenter de manière automatique le modèle des attendus à partir dumodèle dextraction nous montrons également comment les itinéraires extraitsinterviennent soit dans la phase de construction dactivités pédagogiques soitdirectement comme matériau dans une activité dapprentissage nous présentonsenfin ¼r un prototype pour linterprétation ditinéraires dans des récitsde voyages qui implémente notre approche il prend en entrée un texte brut etfournit linterprétation de litinéraire décrit dans le texte il permet également devisualiser sur un fond cartographique litinéraire extrait\n",
      "interprétation dimages basée sur une approche évolutive guidée par une ontologie\n",
      "les approches de fouille et dinterprétation dimages consistant à considérer les pixels de façon indépendante ont montré leurs limites pour lanalyse dimages complexes pour résoudre ce problème de nouvelles méthodes sappuient sur une segmentation préalable de limage qui consiste en une agrégation des pixels connexes afin de former des régions homogènes au sens dun certain critère cependant le lien est souvent complexe entre la connaissance de lexpert sur les objets quil souhaite identifier dans limage et les paramètres nécessaires à létape segmentation permettant de les identifier dans cet article la connaissance de lexpert est modélisée dans une ontologie qui est ensuite utilisée pour guider un processus de segmentation par une approche évolutive cette méthode trouve automatiquement des paramètres de segmentation permettant didentifier les objets décrits par lexpert dans lontologie\n",
      "khiops outil de préparation et modélisation des données pour la fouille des grandes bases de données\n",
      "khiops est un outil de préparation des données et de modélisation pour lapprentissage supervisé et non supervisé loutil permet dévaluer de façon non paramétrique la corrélation entre tous types de variables dans le cas non supervisé et limportance prédictive des variables et paires de variables dans le cas de la classification supervisée ces évaluations sont effectuées au moyen de modèles de discrétisation dans le cas numérique et de groupement de valeurs dans le cas catégoriel ce qui permet de rechercher une représentation des données efficace au moyen dun recodage des variables loutil produit également un modèle de scoring pour les tâches dapprentissage supervisé selon un classifieur bayesien naif avec sélection de variables et moyennage de modèles loutil est adapté à lanalyse des grandes bases de données avec des centaines de milliers dindividus et des dizaines de milliers de variables et a permis de participer avec succès à plusieurs challenges internationaux récents\n",
      "lintelligence collective géospatiale au service du diagnostic de territoire  geodoc\n",
      "le diagnostic de territoire constitue une étape obligatoire dans toutprojet daménagement ou dans toute volonté politique de modifier durablementlespace les décideurs politiques doivent avoir une vision objective des actionsà mener en fondant leurs réflexions sur des études et des documents quils soient à caractère géographique ou non il est donc fondamentaldaméliorer laccès et la consultation par les décideurs stratégiques de ce quelon peut appeler des documents géographiques le but de cet article est deprésenter certains concepts et solutions technologiques qui peuvent être utilisésafin de mieux organiser de naviguer dans et de visualiser ces documents ilpropose une mise en perspective commune de certaines de ces approches surlaquelle est fondée la conception dune première maquette dun outil de visualisationet de navigation de documents géographiques nommé geodoc\n",
      "la prise en compte de la dimension temporelle dans la classification de données\n",
      "dans un contexte dingénierie de la connaissance lanalyse des données relationnelles évolutives est une question centrale la représentation de ce type de données sous forme de graphe optimisé en facilite lanalyse et linterprétation par lutilisateur non expert cependant ces graphes peuvent rapidement devenir trop complexes pour être étudiés dans leur globalité il faut alors les décomposer de manière à en faciliter la lecture et lanalyse pour cela une solution est de les simplifier dans un premier temps en un graphe réduit dont les sommets représentent chacun un groupe distinct de sommets  acteurs ou termes du domaine étudié dans un second temps il faut les décomposer en instances un graphe par période afin de prendre en compte la dimension temporellela plateforme de veille stratégique tétralogie développée dans notre laboratoire permet de synthétiser les données relationnelles évolutives sous forme de matrices de cooccurrence 3d et visugraph son module de visualisation permet de les représenter sous forme de graphes évolutifsvisugraph assimile les différentes périodes à des repères temporels et chaque sommet est placé en fonction de son degré dappartenance aux différentes périodes ce prototype est aussi doté dun module de la classification interactive de données relationnelles basé sur une technique de markov clustering qui conduit à une visualisation sous forme de graphe réduit nous proposons ici de prendre en compte la dimension temporelle dans notre processus de classification des données ainsi par la visualisation successive des différentes instances il devient plus facile danalyser lévolution des classes au niveau intra mais aussi au niveau inter classes\n",
      "le fia un nouvel automate permettant lextraction efficace ditemsets fréquents dans les flots de données\n",
      "le fia frequent itemset automaton est un nouvel automate qui permet de traiter de façon efficace la problématique de lextraction des itemsets fréquents dans les flots de données cette structure de données est très compacte et informative et elle présente également des propriétés incrémentales intéressantes pour les mises à jour avec une granularité très fine lalgorithme développé pour la mise à jour du fia effectue un unique passage sur les données qui sont prises en compte tout dabord par batch ie itemset par itemset puis pour chaque itemset item par item nous montrons que dans le cadre dune approche prédictive et par lintermédiaire de la bordure statistique le fia permet dindexer les itemsets véritablement fréquents du flot en maximisant le rappel et en fournissant à tout moment une information sur la pertinence statistique des itemsets indexés avec la pvaleur\n",
      "le forage de réseaux sociaux\n",
      "lexploitation des réseaux sociaux pour lextraction de connaissances nest pas nouvelle les anthropologues sociologues et épidémiologies se sont déjà penchés sur la question cest probablement le succès du moteur de recherche google qui a vulgarisé lutilisation des parcours aléatoires des réseaux sociaux pour lordonnancement par pertinence plusieurs applications ont depuis vu naissance la découverte des communautés dans les réseaux sociaux est aussi une nouvelle tendance de recherche très prisée durant cet exposé nous parlerons de lanalyse des réseaux sociaux la découverte de communautés et présenterons quelques applications dont lordonnancement dans les bases de données\n",
      "le logiciel sodas  avancées récentes un outil pour analyser et visualiser des données symboliques\n",
      "nan\n",
      "les cartes cognitives hiérarchiques\n",
      "une carte cognitive fournit une représentation graphique dun réseau dinfluence entre des concepts les cartes cognitives de dimensions importantes ont linconvénient dêtre difficiles à appréhender interpréter et exploiter cet article présente un modèle de cartes cognitives hiérarchiques permettant au concepteur deffectuer des regroupements de concepts qui sont ensuite utilisés dans un mécanisme permettant à lutilisateur dobtenir des vues partielles et synthétiques dune carte\n",
      "mesures hiérarchiques pondérées pour lévaluation dun système semiautomatique dannotation de génomes utilisant des arbres de décision\n",
      "lannotation dune protéine consiste entre autres à lui attribuer une classe dans une hiérarchie fonctionnelle celleci permet dorganiser les connaissances biologiques et dutiliser un vocabulaire contrôlé pour estimer la pertinence des annotations des mesures telles que la précision le rappel la spécificité et le fscore sont utilisées cependant ces mesures ne sont pas toujours bien adaptées à lévaluation de données hiérarchiques car elles ne permettent pas de distinguer les erreurs faites aux différents niveaux de la hiérarchie nous proposons ici une représentation formelle pour les différents types derreurs adaptés à notre problème\n",
      "méthodologie devaluation intelligente des concepts ontologiques\n",
      "un des problèmes majeurs dans la gestion des ontologies est son évaluation cet article traite lévaluation des concepts ontologiques qui sont extraits de pages web pour cela nous avons proposé une méthodologie dévaluation des concepts basée trois critères révélateurs  le degré de crédibilité le degré de cohésion et le degré déligibilité chaque critère correspond à un apport de connaissance pour la tâche dévaluation notre méthode dévaluation assure une évaluation qualitative grâce aux associations de mots ainsi quune évaluation quantitative par le biais des trois degrés nos résultats et discussions avec les experts et les utilisateurs ont montré que notre méthode facilite la tâche dévaluation\n",
      "méthodologie de définition de eservices pour la gestion des connaissances à partir dun plateau de créativité  application au elearning instrumental\n",
      "en sappuyant sur la théorie de lactivité nous avons mis au point une méthodologie de gestion des connaissances à base de eservices sur un plateau de créativité visant à faire piloter le processus de fabrication métier par celui des usages nous lavons testé avec la réalisation dun eservice dapprentissage instrumental de pièces de musique à la guitare eguitare\n",
      "mining implications from lattices of closed trees\n",
      "we propose a way of extracting highconfidence association rules from datasets consisting of unlabeled trees the antecedents are obtained through a computation akin to a hypergraph transversal whereas the consequents follow from an application of the closure operators on unlabeled trees developed in previous recent works of the authors we discuss in more detail the case of rules that always hold independently of the dataset since these are more complex than in itemsets due to the fact that we are no longer working on a lattice\n",
      "modélisation conceptuelle des trajectoires\n",
      "une perception intelligente du mouvement dobjets mobilespersonnes voitures colis etc est à la base de nombreuses applications parexemple le suivi dune distribution postale à travers le monde loptimisation dutrafic routier ou létude de la migration danimaux les systèmes de gestion debases de données actuels noffrent ni les concepts ni les fonctions nécessaires àune analyse sémantique du mouvement se limitant au stockage et àlinterrogation de positions spatiales individuelles hors contexte temporel destravaux de recherche précédents ont introduit et développé le concept dobjetmobile ou spatiotemporel dans cet article nous allons plus loin en proposantle concept de trajectoire comme unité sémantique de mouvement sur laquellese construit la vision applicative nous proposons de décrire les trajectoires auniveau conceptuel avec leurs aspects géométriques temporels et sémantiqueset leurs composants structurels  point de départ point darrivée arrêts etdéplacements intermédiaires chaque élément trajectoire arrêt déplacementvoire partie de déplacement peut recevoir des annotations sémantiques sousforme de valeurs dattributs ou de liens vers des objets de la base lapprochede modélisation décrite dans cet article est basée sur les patrons demodélisation qui permettent une solution générique pour modéliser lescaractéristiques standard des trajectoires tout en étant ouverte auxcaractéristiques spécifiques à lapplication envisagée enfin limplémentationdans une base de données relationnelle étendue est présentée\n",
      "nouvelle approche pour la recherche dimages par le contenu\n",
      "on utilise lanalyse factorielle des correspondances afc pour la recherche dimages par le contenu en sinspirant directement de son utilisation en analyse des données textuelles adt lafc permet ici de réduire les dimensions du problème et de sélectionner des indicateurs pertinents pour la recherche par le contenu en adt lafc est appliquée à un tableau de contingence croisant mots et documents la première étape consiste donc à définir des « mots visuels » dans les images analogue des mots dans les textes ces mots sont construits à partir des descripteurs locaux sift des images la méthode a été testée sur la base caltech4 sivic et al 2005 sur laquelle elle fournit de meilleurs résultats qualité des résultats de recherche et temps dexécution que des méthodes plus classiques comme tfidfrocchio rocchio 1971 ou plsa hofmann 1999a 1999b enfin pour passer à léchelle et améliorer la qualité de recherche nous proposons un nouveau prototype de recherche qui utilise des fichiers inversés basés sur la qualité de représentation des images sur les axes après avoir fait une afc chaque fichier inversé est associé à une partie dun axe positive ou négative et contient des images ayant une bonne qualité de représentation sur cet axe les tests réalisés montrent que ce nouveau prototype réduit le temps de recherche sans perte de qualité de résultat et dans certains cas améliore le taux de précision par rapport à la méthode exhaustive\n",
      "ontologies et raisonnement à partir de cas  application à lanalyse des risques industriels\n",
      "lanalyse de risques est un processus visant à décrire les scénarios conduisant à des phénomènes dangereux et à des accidents potentiels sur une installation industrielle pour réaliser une analyse de risques un expert dispose de nombreuses ressources  rapports études de dangers bases daccidents etc ces ressources sont cependant souvent difficiles à exploiter parce quelles ne sont pas suffisamment structurées ni formalisées dans le cadre du projet kmgr knowledge management pour la gestion des risques mené en partenariat avec linstitut national de lenvironnement industriel et des risques ineris nous proposons de traiter ce problème en développant un système de recherche dinformation basé sur des ontologies et de le compléter par un système de raisonnement à partir de cas ràpc pour tenir compte des expériences passées\n",
      "optimisation du primal pour les svm\n",
      "lapprentissage de svm par optimisation directe du primal est très étudié depuis quelques temps car il ouvre de nouvelles perspectives notamment pour le traitement de données structurées nous proposons un nouvel algorithme de ce type qui combine de façon originale un certain nombre de techniques et idées comme la méthode du sousgradient loptimisation de fonctions continues non partout différentiables et une heuristique de shrinking\n",
      "optimisation incrémentale de réseaux de neurones rbf pour la régression via un algorithme évolutionnaire  rbfgene\n",
      "les réseaux de neurones rbf sont dexcellents régresseurs ils sont cependant difficiles à utiliser en raison du nombre de paramètres libres  nombre de neurones poids des connexions  des algorithmes évolutionnaires permettent de les optimiser mais ils sont peu nombreux et complexesnous proposons ici un nouvel algorithme rbfgene qui permet doptimiser la structure et les poids du réseau grâce à une inspiration biologique il est compétitif avec les autres techniques de régression mais surtout lévolution peut choisir dynamiquement le nombre de neurones et la précision des différents paramètres\n",
      "pondération locale des variables en apprentissage numérique nonsupervisé\n",
      "dans cet article nous proposons une nouvelle approche de pondérations des variables durant un processus dapprentissage non supervisé cette méthode se base sur lalgorithme « batch » des cartes autoorganisatrices lestimation des coefficients de pondération se fait en parallèle avec la classification automatique ces pondérations sont locales et associées à chaque référent de la carte autoorganisatrice elles reflètent limportance locale de chaque variable pour la classification les pondérations locales sont utilisées pour la segmentation de la carte topologique permettant ainsi un découpage plus riche tenant compte des pertinences des variables les résultats de lévaluation montrent que lapproche proposée comparée à dautres méthodes de classification offre une segmentation plus fine de la carte et de meilleure qualité\n",
      "prétraitement des bases de données de réactions chimiques pour la fouille de schémas de réactions\n",
      "un grand nombre de réactions chimiques sont aujourdhui répertoriées dans des bases de données les chimistes aimeraient pouvoir fouiller les graphes moléculaires contenus dans ces données pour en extraire des schémas de réactions fréquents deux obstacles sopposent à cela  dune part la manière dont les chimistes représentent les réactions par des graphes ne permet pas aux techniques de fouille de graphes dextraire les schémas de réactions fréquents dautre part les bases de données contiennent des descriptions de réactions souvent incomplètes ambiguës ou erronées le présent article décrit un processus de prétraitement opérationnel qui permet de filtrer compléter puis transformer le contenu dune base de réactions en des données fiables constituées de graphes abstraits répondant au problème de la fouille de schémas de réactions le processus place ainsi les bases de réactions à portée des techniques de fouille de graphes comme en attestent les résultats expérimentaux\n",
      "principes danalyse des données symboliques et application à la détection danomalies sur des ouvrages publics\n",
      "lanalyse des données symboliques a pour objectif de fournir des résultatscomplémentaires à ceux fournis par la fouille de données classique encréant des concepts issus de données simples ou complexes puis en analysantces concepts par des descriptions symboliques où les variables expriment lavariation des instances de ces concepts en prenant des valeurs intervalle histogrammesuites munies de règles et de taxonomies etc\n",
      "processus dacquisition dun dictionnaire de sigles et de leurs définitions à partir dun corpus\n",
      "le logiciel présenté dans cet article sappuie sur une approche dacquisition de sigles à partir de données textuelles\n",
      "proposition dune nouvelle approche de détection dintrusions basée sur les règles associatives génériques de classification\n",
      "les systèmes de détection dintrusions sdis ont pour objectif la sécurité des réseaux informatiques dans ce papier nous proposons une nouvelle approche de détection dintrusions basée sur des règles associatives génériques de classification pour améliorer la qualité de la détection dintrusions\n",
      "proposition pour lintégration de lanalyse spatiale et de lanalyse multidimensionnelle\n",
      "lintroduction de linformation spatiale dans les modèlesmultidimensionnels a donné naissance au concept de spatial olap solapdans cet article nous montrons en quoi les spécificités de linformationgéographique et de lanalyse spatiale ne sont pas entièrement prises en comptedans lanalyse et les modèles multidimensionnels solap pour pallier ceslimites nous proposons le concept de dimension géographique et décrivons lesdifférents types de hiérarchies associées nous proposons lintroduction denouveaux opérateurs qui permettent dadapter les opérateurs danalyse spatialeau paradigme multidimensionnel enfin nous présentons notre prototype quioffre une interface web de navigation spatiale et multidimensionnelle etpermet lintégration de ces nouveaux concepts\n",
      "recherche adaptative de structures de régulation génétique\n",
      "nous avons proposé un algorithme original de fouille de données licorn afin dinférer des relations de régulation coopérative à partir de données dexpression licorn donne de bons résultats sil est appliqué à des données de levure mais le passage à léchelle sur des données plus complexes eg humaines est difficile dans cet article nous proposons une extension de licorn afin quil puisse gérer une contrainte de corégulation adaptative une évaluation préliminaire sur des données de transcriptome de tumeurs de vessie montre que les réseaux significatifs sont obtenus à laide dune contrainte de corégulation adaptative de manière beaucoup plus efficace et quils ont des performances de prédiction équivalentes voire meilleures que celles obtenues par licorn\n",
      "recherche dimages par noyaux sur graphes de régions\n",
      "dans le cadre de la recherche interactive dimages dans une base de données nous nous intéressons à des mesures de similarité dimage qui permettent daméliorer lapprentissage et utilisables en temps réel lors de la recherche les images sont représentées sous la forme de graphes dadjacence de régions floues pour comparer des graphes valués nous employons des noyaux de graphes sappuyant sur des ensembles de chaînes extraites des graphes comparés nous proposons un cadre général permettant lemploi de différents noyaux et différents types de chaînessans cycle avec boucles autorisant des appariements inexacts nous avons effectué des comparaisons sur deux bases issues de columbia et caltech et montré que des chaînes de très faible dimension longueur inférieur à 3 sont les plus efficaces pour retrouver des classes dobjets\n",
      "recherche dinformation personnalisée dans les bibliothèques numériques scientifiques\n",
      "dans cet article nous présentons nos travaux sur la recherche dinformation personnalisée dans les bibliothèques numériques nous utilisons des profils utilisateurs qui représentent des intérêts et des préférences des utilisateurs les résultats de recherche peuvent être retriés en tenant compte des besoins dinformations spécifiques de différentes personnes ce qui donne une meilleure précision nous étudions différentes méthodes basées sur les citations sur le contenu textuel des documents et des approches hybrides les résultats des expérimentations montrent que nos approches sont efficaces et applicables dans le cadre des bibliothèques numériques\n",
      "recherche de motifs spatiotemporels de cas atypiques pour le trafic routier urbain\n",
      "un large panel de domaines dapplication utilise des réseaux de capteurs géoréférencés pour mesurer divers évènements les séries temporelles fournies par ces réseaux peuvent être utilisées dans le but de dégager des connaissances sur les relations spatiotemporelles de lactivité mesurée dans cet article nous proposons une méthode permettant dabord de détecter des situations atypiques au sens de loccurrence puis de construire des motifs spatiotemporels relatant leur propagation sur un réseau le cas étudié est celui du trafic routier urbain notre raisonnement se fonde sur lapplication de la méthode spacetime principal component analysis stpca et de la combinaison entre linformation mutuelle et lalgorithme isomap les résultats expérimentaux exécutés sur des données réelles de trafic routier démontrent lefficacité de la méthode introduite à identifier la propagation de cas atypiques fournissant ainsi un outil performant de prédiction de la circulation intraday à court et moyen terme\n",
      "requêtes alternatives dans le contexte dun entrepôt de données génomiques\n",
      "afin daider les biologistes à annoter des génomes ce qui nécessite lanalyse le croisement et la comparaison de données provenant de sources diverses nous avons conçu un entrepôt de données de génomique microbienne nous présentons la structure globale flexible de lentrepôt et son architecture multiniveaux et définissons des correspondances entre ces niveaux nous introduisons ensuite la notion de requête alternative et montrons comment le système peut construire lensemble des requêtes alternatives à une requête initiale pour cela nous introduisons un mécanisme dinterrogation qui repose sur larchitecture multiniveaux et donnons un algorithme de calcul des requêtes alternatives\n",
      "segmentation hiérarchique des cartes topologiques\n",
      "dans ce papier nous présentons une nouvelle mesure de similarité pour la classification des référents de la carte autoorganisatrice qui sera réalisée à laide dune nouvelle approche de classification hiérarchique 1 la mesure de similarité est composée de deux termes  la distance de ward pondérée et la distance euclidienne pondérée par la fonction de voisinage sur la carte topologique 2 un algorithme à base de fourmis artificielles nommé anttree sera utilisé pour segmenter la carte autoorganisatricecet algorithme a lavantage de prendre en compte le voisinage entre les référents et de fournir une hiérarchie des référents avec une complexité proche du nlogn la segmentation incluant la nouvelle mesure est validée sur plusieurs bases de données publiques\n",
      "semantics of spatial window over spatiotemporal data stream\n",
      "dans les systèmes dsms data stream management systems les données en entrée sont infinies et les requêtes sur cellesci sont actives tout le temps dans le but de satisfaire ces caractéristiques le fenêtrage temporel est largement utilisée pour convertir le flux infini de données sous forme de relations finies mais cette technique est inadaptée pour de nombreuses applications émergentes en particulier les services de localisation de nombreuses requêtes ne peuvent pas être traitées en utilisant le fenêtrage temporel ou seraient traitées plus e\u000ecacement à laide dun fenêtrage basé sur lespace fenêtrage spatial dans cet article nous analysons la nécessité dun fenêtrage spatial sur des flux de données spatiotemporels et proposons sur la base du langage de requêtes cql continuous query language une syntaxe et une sémantique associées au fenêtrage spatial\n",
      "sémantique et réutilisation dontologie générique\n",
      "dans ce papier nous enrichissons la méthode terminae de construction dontologie à partir de textes en proposant une semiautomatisation de la construction du modèle conceptuel nous présentons un algorithme permettant la conceptualisation dun terme en sappuyant sur les informations linguistiques contenues dans lontologie générique de référence\n",
      "som pour la classification automatique non supervisée de documents textuels basés sur wordnet\n",
      "dans cet article nous proposons la méthode des som cartes autoorganisatrices de kohonen pour la classification non supervisée de documents textuels basés sur les ngrammes la même méthode basée sur les synsets de wordnet comme termes pour la représentation des documents est étudiée par la suite ces combinaisons sont évaluées et comparées\n",
      "stratégies de classification non supervisée basées sur fenêtres superposées  application aux données dusage du web\n",
      "un problème majeur se pose dans le domaine des flux de données  la distribution sousjacente des données peut changer sur le temps dans cet article nous proposons trois stratégies de classification non supervisée basée sur des fenêtres superposées notre objectif est de pouvoir repérer ces changements dans le temps notre approche est appliquée sur un benchmark de données réelles et les conclusions obtenues sont basées sur deux indices de comparaison de partitions\n",
      "structure inference of bayesian networks from data a new approach based on generalized conditional entropy\n",
      "we propose a novel algorithm for extracting the structure of a bayesian network from a dataset our approach is based on generalized conditional entropies a parametric family of entropies that extends the usual shannon conditional entropy our results indicate that with an appropriate choice of a generalized conditional entropy we obtain bayesian networks that have superior scores compared to similar structures obtained by classical inference methods\n",
      "suppression des itemsets clés non essentiels en classification basée sur les règles dassociation\n",
      "en classification basée sur les règles dassociation les itemsets clés sont essentiels  la suppression des itemsets non clés naffecte pas la précision du classifieur en construction ce travail montre que parmi ces itemsets clés on peut sintéresser seulement à ceux de petites tailles plus loin encore il étudie une généralisation dune propriété importante des itemsets non clés et montre que parmi les itemsets clés de petites tailles il y a ceux qui ne sont pas significatifs pour la classification ces itemsets clés sont dits non essentiels ils sont définis via un test de \u001f2 les expériences menées sur les grands jeux de données montrent que loptimisation par la suppression de ces itemsets est correcte et efficace\n",
      "système multiagent argumentatif pour la classification des connaissances cruciales\n",
      "dans cet article nous proposons une approche multiagent argumentative permettant dautomatiser la résolution des conflits entre décideurs dans un système daide à lidentification des connaissances cruciales nommé kdss en effet des divergences concernant la crucialité des connaissances peuvent apparaître entre les décideurs et aboutir ainsi à des incohérences dans la base commune de connaissances la rendant inexploitable notre objectif à travers ce travail est de proposer une approche argumentative permettant de résoudre les conflits entre décideurs afin de concevoir cette approche nous nous appuyons sur la théorie multiagents pour représenter les acteurs humains par des agents logiciels connaissant leurs préférences et leurs règles de décision et pouvant ainsi argumenter leurs choix ou mettre à jour leurs croyances en fonction des arguments quils reçoivent des autres agents décideurs\n",
      "un algorithme de classification topographique non supervisée à deux niveaux simultanés\n",
      "une des questions les plus importantes pour la plupart des applications réelles de la classification est de déterminer un nombre approprié de groupes clusters déterminer le nombre optimal de groupes est un problème difficile puisquil ny a pas de moyen simple pour connaître ce nombre sans connaissance a priori dans cet article nous proposons un nouvel algorithme de classification non supervisée à deux niveaux appelé s2lsom simultaneous twolevel clustering  self organizing map qui permet de déterminer automatiquement le nombre optimal de groupes pendant lapprentissage dune carte autoorganisatrice lestimation du nombre correct de groupes est en relation avec la stabilité de la segmentation et la validité des groupes générés pour mesurer cette stabilité nous utilisons une méthode de souséchantillonnage le principal avantage de lalgorithme proposé comparé aux méthodes classiques de classification est quil nest pas limité à la détection de groupes convexes mais est capable de détecter des groupes de formes arbitraires la validation expérimentale de cet algorithme sur un ensemble de problèmes fondamentaux pour la classification montre sa supériorité sur les méthodes standards de classification à deux niveaux comme somkmoyennes et somhierarchical agglomerativeclustering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un cyber cartogramme gravitationnel pour lanalyse visuelle de données spatiotemporelles complexes\n",
      "le cartogramme présenté dans cet article est destiné à faciliterlanalyse visuelle de données spatiotemporelles complexes pour cela il offrela possibilité de représenter simultanément les trois dimensions nécessaires àtoute forme danalyse géographique que sont les dimensions spatiale oùthématique quoi et temporelle quand à partir de trois composantes principales 1 une représentation unidimensionnelle 1d de lespace géographiquede forme semicirculaire centrée sur une origine ex le canada  2 desentités géographiques ex pays qui viennent graviter autour de cette origineen fonction de valeurs attributaires  et 3 une ligne de temps interactive permettantdexplorer la dimension temporelle de linformation représentée lacombinaison de ces trois composantes offre de multiples potentialités pourlanalyse spatiotemporelle de différentes formes de proximités quelles soientéconomiques culturelles sociales ou démographiques les fonctionnalités etpotentialités de ce cartogramme développé en source ouverte sont illustrées àpartir dexemples issus de latlas cybercartographique du commerce canadiencet article reprend les grandes lignes dune communication présentée lors de laconférence sageo 2007\n",
      "un modèle despace vectoriel de concepts pour noyaux sémantiques\n",
      "les noyaux ont été largement utilisés pour le traitement de données textuelles comme mesure de similarité pour des algorithmes tels que les séparateurs à vastemarge svm le modèle de lespace vectoriel vsm a été amplement utilisé pour la représentation spatiale des documents cependant le vsm est une représentation purement statistique dans ce papier nous présentons un modèle despace vectoriel de concepts cvsm qui se base sur des connaissances linguistiques a priori pour capturer le sens des documents nous proposons aussi un noyau linéaire et un noyau latent pour cet espace le noyau linéaire exploite les concepts linguistiques pour lextraction du sens alors que le noyau latent combine les concepts statistiques et linguistiques en effet le noyau latent utilise des concepts latents extraits par lanalyse sémantique latente lsa dans le cvsm les noyaux sont évalués sur une tâche de catégorisation de texte dans le domaine biomédical le corpus ohsumed bien connu pour sa difficulté de catégorisation a été utilisé les résultats ont montré que les performances de catégorisation sont améliorées dans le csvm\n",
      "un modèle et une algèbre pour les systèmes de gestion dontologies\n",
      "nous présentons ici une approche pour la gestion de bases dontologies basée sur un modèle comprenant outre la définition formelle des concepts sous forme daxiomes de logique de description dautres éléments descriptifs termes commentaires et arguments ainsi que leurs liens dalignement avec des concepts dautres ontologies ladaptation ou la combinaison dontologies se font grâce à une algèbre comprenant des opérations telles que la sélection la projection lunion ou la jointure dontologies ces opérations agissent au niveau des axiomes des éléments descriptifs et des liens dalignement\n",
      "un nouveau système immunitaire artificiel pour lapprentissage non supervisé\n",
      "nous proposons dans ce papier un nouveau système immunitaire artificiel sia appelé système nk pour la détection de comportement du soi non soi avec une approche non supervisée basée sur le mécanisme de cellule nk naturel killer dans ce papier le système nk est appliqué à la détection de fraude en téléphonie mobile\n",
      "un processus dacquisition dinformation pour les besoins de lenrichissement des bdg\n",
      "les données constituent lélément central dun système dinformation géographiques sig et leur coût est souvent élevé en raison de linvestissement substantiel qui permet leur production cependant ces données sont souvent restreintes à un service ou pour une catégorie dutilisateurs ce qui a fait ressortir la nécessité de proposer des moyens denrichissement en informations pertinentes pour un nombre plus important dutilisateurs nous présentons dans ce papier notre approche denrichissement de données qui se déroule selon trois étapes  une identification de segments et de thèmes associés une délégation et enfin un filtrage textuel un processus de raffinement est également offert notre approche globale a été intégrée à un sig son évaluation a été accomplie montrant ainsi sa performance\n",
      "un système de vote pour la classification de textes dopinion\n",
      "les tâches de classification textuelle ont souvent pour objectif de regrouper thématiquement différents textes dans cet article nous nous sommes intéressés à la classification de documents en fonction des opinions et jugements de valeurs quils contiennent lapproche proposée est fondée sur un système de vote utilisant plusieurs méthodes de classification\n",
      "une aide à la découverte de mappings dans somerdfs\n",
      "dans cet article nous nous intéressons à la découverte de mises en correspondance entre ontologies distribuées modélisant les connaissances de pairs du système de gestion de données p2p somerdfs plus précisément nous montrons comment exploiter les mécanismes de raisonnement mis en oeuvre dans somerdfs pour aider à découvrir des mappings entre ontologies ce travail est réalisé dans le cadre du projet mediad en partenariat avec france telecom rd\n",
      "une approche ensembliste inspirée du boosting en classification non supervisée\n",
      "en classification supervisée de nombreuses méthodes ensemblistes peuvent combiner plusieurs hypothèses de base afin de créer une règle de décision finale plus performante ainsi il a été montré que des méthodes comme le bagging ou le boosting pouvaient se révéler intéressantes tant dans la phase dapprentissage quen généralisation dès lors il est tentant de vouloir sinspirer des grands principes dune méthode comme le boosting en classification non supervisée or il convient préalablement de se confronter aux difficultés connues de la thématique des ensembles de regroupeurs correspondance des classes agrégation des résultats qualité puis dintroduire lidée du boosting dans un processus itératif cet article propose une méthode ensembliste inspirée du boosting qui à partir dun partitionnement flou obtenu par les cmoyennes floues fuzzycmeans va insister itérativement sur les exemples difficiles pour former une partition dure finale plus pertinente\n",
      "une approche ontologique pour automatiser le contrôle de conformité dans le domaine du bâtiment\n",
      "cet article présente la méthode et le système c3r pour vérifier de façon semiautomatique la conformité dun projet de construction par rapport à des normes du bâtiment les projets de construction sont représentés par des graphes rdf et les normes par des requêtes sparql  le processus de contrôle consiste en lappariement des requêtes et des graphes son efficacité repose sur lacquisition de connaissances ontologiques et sur un processus dextraction de connaissances guidé par ce but spécifique de contrôle de conformité qui prend en compte les connaissances ontologiques acquises elle repose ensuite sur des métaconnaissances acquises auprès des experts du cstb qui permettent de guider le contrôle luimême  les requêtes représentant les normes sont annotées et organisées selon ces annotations ces annotations sont également utilisées dans les interactions avec lutilisateur de c3r pour expliquer les résultats du processus de validation en particulier en cas déchec\n",
      "une jmesure orientée pour élaguer des modèles de chroniques\n",
      "nan\n",
      "une mesure de similarité contextuelle pour laide à la navigation dans un treillis\n",
      "la recherche dinformation et la navigation dans les pages web savèrent complexes du fait du volume croissant des données et de leur manque de structure la formalisation conceptuelle dun contexte associé à une ontologie rend possible lamélioration de ce processus nous définissons un contexte conceptuel comme étant lassociation dun treillis de concepts construit à partir de pages web avec des ontologies la recherche et la navigation peuvent alors seffectuer à plusieurs niveaux dabstraction  le niveau des données le niveau conceptuel et le niveau sémantique cet article sintéresse essentiellement au niveau conceptuel grâce à une représentation par les treillis de concepts des documents selon les termes quils ont en commun notre objectif est de proposer une mesure de similarité permettant à lutilisateur de mieux naviguer dans le treillis en effet une bonne interprétation du treillis devrait passer par un choix rigoureux des concepts objets relations et propriétés les plus intéressants pour faciliter la navigation il faut pouvoir indiquer à lutilisateur les concepts les plus pertinents par rapport au concept correspondant à sa requête ou pouvoir lui proposer un point de départ loriginalité de notre proposition réside dans le fait de considérer un lien sémantique entre les concepts du treillis basé sur une extension des mesures de similarité utilisées dans le cadre des ontologies afin de permettre une meilleure exploitation de ce treillis nous présentons les résultats expérimentaux de lapplication de cette mesure sur des treillis construits à partir de pages web dans le domaine du tourisme\n",
      "une nouvelle approche du boosting face aux données bruitées\n",
      "la réduction de lerreur en généralisation est lune des principales motivations de la recherche en apprentissage automatique de ce fait un grand nombre de travaux ont été menés sur les méthodes dagrégation de classifieurs afin daméliorer par des techniques de vote les performances dun classifieur unique parmi ces méthodes dagrégation le boosting est sans doute le plus performant grâce à la mise à jour adaptative de la distribution des exemples visant à augmenter de façon exponentielle le poids des exemples mal classés cependant en cas de données fortement bruitées cette méthode est sensible au surapprentissage et sa vitesse de convergence est affectée dans cet article nous proposons une nouvelle approche basée sur des modifications de la mise à jour des exemples et du calcul de lerreur apparente effectuées au sein de lalgorithme classique dadaboost une étude expérimentale montre lintérêt de cette nouvelle approche appelée approche hybride face à adaboost et à brownboost une version dadaboost adaptée aux données bruitées\n",
      "une nouvelle méthode divisive en classification non supervisée pour des données symboliques intervalles\n",
      "dans cet article nous présentons une nouvelle méthode de classification non supervisée pour des données symboliques intervalles il sagit de lextension dune méthode de classification non supervisée classique à des données intervalles la méthode classique suppose que les points observés sont la réalisation dun processus de poisson homogène dans k domaines convexes disjoints de rp la première partie de la nouvelle méthode est une procédure monothétique divisive la règle de coupure est basée sur une extension à des données intervalles du critère de classification des hypervolumes létape délagage utilise un test statistique basé sur le processus de poisson homogène le résultat est un arbre de décision la seconde partie de la méthode consiste en une étape de recollement qui permet dans certains cas daméliorer la classification obtenue à la fin de la première partie de lalgorithme la méthode est évaluée sur un ensemble de données réelles\n",
      "une proposition pour lextraction de relations non prédicatives\n",
      "les relations sémantiques généralement reconnues par les méthodes dextraction sont portées par des structures de type prédicatsarguments or linformation recherchée est souvent répartie sur plusieurs phrases pour détecter ces relations dites complexes nous proposons un modèle de représentation des connaissances basé sur les graphes conceptuels\n",
      "utilisation du web sémantique pour la gestion dune liste de diffusion dune cop\n",
      "cet article décrit une approche de création semiautomatique dontologies et dannotations sémantiques à partir de messages électroniques échangés dans une liste de diffusion dédiée au support informatique les ressources sémantiques générées permettront didentifier les questions fréquemment posées faq à travers une recherche guidée par cette ontologie\n",
      "vers des machines à vecteurs de support “actionnables”  une approche fondée sur le classement\n",
      "une des principales critiques que lon puisse faire aux séparateurs à vaste marge svm est le manque dintelligibilité des résultats en effet il sagit dune technique boite noire qui ne fournit pas dexplications ni dindices quant aux raisons dune classification les résultats doivent être pris tels quels en faisant confiance au système qui les a produits pourtant selon notre expérience pratique les experts du domaine préfèrent largement une méthode dapprentissage avec explications et recommandation dactions plutôt quune boite noire aussi performante et prédictive soitelle dans cette thématique nous proposons une nouvelle approche qui consiste a rendre les svm plus actionnables ce but est atteint en couplant des modèles de classement des résultats des svm à des méthodes dapprentissage de concepts nous présentons une application de notre méthode sur diverses données dont des données médicales concernant des patients de lathérosclérose nos résultats empiriques semblent très prometteurs et montrent lutilité de notre approche quant à lintelligibilité et lactionnabilité des résultats produits par svm\n",
      "vers lexploitation de grandes masses de données\n",
      "une tendance lourde depuis la fin du siècle dernier est laugmentation exponentielle du volume des données stockées cette augmentation ne se traduit pas nécessairement par une information plus riche puisque la capacité à traiter ces données ne progresse pas aussi rapidement avec les technologies actuelles un difficile compromis doit être trouvé entre le coût de mise en oeuvre et la qualité de linformation produite nous proposons une approche industrielle permettant daugmenter considérablement notre capacité à transformer des données en information grâce à lautomatisation des traitements et à la focalisation sur les seules données pertinentes\n",
      "vers lintégration de la prédiction dans les cubes olap\n",
      "nan\n",
      "vers une fouille sémantique des brevets  application au domaine biomédical\n",
      "les brevets sont une source dinformation très riche puisque ce sont des documents qui servent à décrire les inventions laccès aux documents de brevets en ligne est possible grâce aux efforts des offices nationaux de la propriété intellectuelle par ailleurs ayant des objectifs différents la présentation de ces documents a pris des formes variées loin dêtre unifiées ce papier présente une méthode et un système permettant lanalyse de brevets patent mining pour générer des annotations sémantiques lidée principale est de pouvoir prendre en considération la structure des brevets pour pouvoir trouver un lien entre le contenu du brevet et les concepts des différentes ontologies\n",
      "visualisation des motifs séquentiels extraits à partir dun corpus en ancien français\n",
      "cet article présente une interface permettant de visualiser des motifs séquentiels extraits à partir de données textuelles en ancien français\n",
      "visualisation et classification des parcours de vie\n",
      "cet article propose une méthodologie pour la visualisation et la classification des parcours de vie plus spécifiquement nous considérons les parcours de vie dindividus suisses nés durant la première moitié du xxème siècle en utilisant les données provenant de lenquête biographique rétrospective menée en 2002 par le panel suisse de ménages nous nous sommes concentrés sur ces événements du parcours de vie  le départ du foyer parental la naissance du premier enfant le premier mariage et le premier divorce a partir des données de base sur ces événements nous discutons de leur transformation en séquences détats nous présentons ensuite notre méthodologie pour extraire de la connaissance des parcours de vie cette méthodologie repose sur des distances calculées par un algorithme doptimal matching ces distances sont ensuite utilisées pour la classification des parcours de vie et leur visualisation à laide de techniques de « multi dimensional scaling » cet article sintéresse en particulier aux problématiques entourant lapplication de ces méthodes aux données de parcours de vie\n",
      "web content data mining  la classification croisée pour lanalyse textuelle dun site web\n",
      "notre objectif dans cet article est lanalyse textuelle dun site web indépendamment de son usage notre approche se déroule en trois étapes la première étape consiste au typage des pages afin de distinguer les pages de navigation ou pages « auxiliaires » des pages de contenu la deuxième étape consiste au prétraitement du contenu des pages de contenu afin de représenter chaque page par un vecteur de descripteurs la dernière étape consiste au block clustering ou la classification simultanée des lignes et des colonnes de la matrice croisant les pages aux descripteurs de pages afin de découvrir des biclasses de pages et de descripteurs lapplication de cette approche au site de tourisme de metz prouve son efficacité et son applicabilité lensemble de classes de pages groupés en thèmes facilitera lanalyse ultérieure de lusage du site\n",
      "alignement de ressources sémantiques à partir de règles\n",
      "ce papier présente une approche automatique pour aligner des ressources sémantiques lalignement se traduit par la mise en correspondance des entités termes concepts rôles appartenant à des ressources dun même domaine qui peuvent avoir des niveaux de formalisation différents les entités correspondantes sont de même nature et un coefficient caractérise leur degré de ressemblancelapproche proposée est fondée sur des règles dappariement entre les entités des deux ressources dans une première phase ces règles dappariement sont identifiées empiriquement des algorithmes combinant les différentes règles identifiées sont ensuite définis afin détablir des correspondances entre les entités des ressources considéréesce papier présente un ensemble de règles dappariement exploitant des éléments situés à différents niveaux conceptuels cet ensemble constitue un cadre pour lalignement automatique des ressources sémantiques les résultats dune première expérimentation qui a porté sur lalignement de deux ressources du domaine de laccidentologie sont également présentés\n",
      "annotation et navigation de données archéologiques\n",
      "dans cet article nous proposons un cadre et un outil pour lannotation et la navigation de données archéologiques lobjectif principal est de structurer les annotations de façon à permettre une navigation incrémentale où lutilisateur peut à partir dun ensemble dobjets initialement retournés par une requête découvrir des liens approximatifs avec dautres objets de la base lapproche a été implémentée et est en cours de validation\n",
      "annotation sémantique floue de tableaux guidée par une ontologie\n",
      "nous présentons dans cet article différentes étapes de lannotation de tableaux de données à laide dune ontologie tout dabord nous distinguons les colonnes de données numériques et symboliques les données symboliques sont ensuite annotées de manière floue à laide des termes de lontologie cette annotation nous permet de déduire le type des colonnes de données symboliques pour trouver le type des colonnes de données numériques nous utilisons à la fois le titre de la colonne et les valeurs numériques et unités présentes dans la colonne chaque étape de notre annotation est validée expérimentalement\n",
      "application des réseaux bayésiens à lanalyse des facteurs impliqués dans le cancer du nasopharynx\n",
      "lapprentissage de la structure des réseaux bayésien à partir de données est un problème npdifficile une nouvelle heuristique de complexité polynômiale intitulée polynomial maxmin skeleton pmms a été proposée en 2005 par tsamardinos et al et validée avec succès sur de nombreux bancs dessai pmms présente en outre lavantage dêtre performant avec des jeux de données réduits néanmoins comme tous les algorithmes sous contraintes celuici échoue lorsque des dépendances fonctionnelles déterministes existent entre des groupes de variables il ne sapplique par ailleurs quaux données complètes aussi dans cet article nous apportons quelques modifications pour remédier à ces deux problèmes après validation sur le banc dessai asia nous lappliquons aux données dune étude épidémiologique castémoins du cancer du nasopharynx npc de 1289 observations 61 variables et 5 de données manquantes issues dun questionnaire lobjectif est de dresser un profil statistique type de la population étudiée et dapporter un éclairage utile sur les différents facteurs impliqués dans le npc\n",
      "apport du web sémantique dans la réalisation dun moteur de recherche géolocalisé à usage des entreprises\n",
      "la recherche dune entreprise sur le web relative à un savoirfaire particulier nest pas une tâche toujours facile à mener les outils mis à la disposition de linternaute ne donnent pas entièrement satisfaction dun côté les moteurs de recherche éprouvent des difficultés à faire ressortir clairement le résultat escompté de lautre côté les annuaires spécialisés type pages jaunes sont tributaires dune organisation figée nuisant à leur efficacité face à ce constat nous nous proposons de créer un nouveau moteur spécialisé dans la recherche dentreprise associant web sémantique et géolocalisation cette approche novatrice nécessite limplémentation dune ontologie ayant pour objectif la formalisation des connaissances du domaine cette tâche a mis en évidence lintérêt des structures économiques maintenues par linsee et leur utilisation au sein de lontologie les nomenclatures économiques ont été retenues pour gérer la classification des activités et produits pouvant être dispensés par les entreprises la structure des unités administratives telle que gérée au sein du fichier sirene sest avérée judicieuse pour répondre à la problématique de géolocalisation des entreprises une opération de désambiguïsation est réalisée en associant à chaque noeud dactivité les mots clés et synonymes lui correspondant enfin nous comparons les résultats obtenus par notre moteur à ceux obtenu par le principal moteur de recherche dactivités géolocalisées en france  les pages jaunes que ce soit au niveau de la précision et du rappel notre moteur obtient des résultats significativement meilleurs\n",
      "apprentissage actif démotions dans les dialogues hommemachine\n",
      "la prise en compte des émotions dans les interactions hommemachine permet de concevoir des systèmes intelligents capables de sadapter aux utilisateurs les techniques de redirection dappels dans les centres téléphoniques automatisés se basent sur la détection des émotions dans la parole les principales difficultés pour mettre en oeuvre de tels systèmes sont lacquisition et létiquetage des données dapprentissage cet article propose lapplication de deux stratégies dapprentissage actif à la détection démotions dans des dialogues en interaction hommemachine létude porte sur des données réelles issues de lutilisation dun serveur vocal et propose des outils adaptés à la conception de systèmes automatisés de redirection dappels\n",
      "apprentissage semisupervisé de fonctions dordonnancement\n",
      "nous présentons dans cet article un algorithme inductif semisupervisé pour la tâche dordonnancement bipartite les algorithmes semi–supervisés proposés jusquà maintenant ont été étudiés dans le cadre strict de la classification récemment des travaux ont été réalisés dans le cadre transductif pour étendre les modèles existants en classification au cadre dordonnancement loriginalité de notre approche est quelle est capable dinférer un ordre sur une base test non– utilisée pendant la phase dapprentissage ce qui la rend plus générique quune méthode transductive pure les résultats empiriques sur la base cacm contenant les titres et les résumés du journal communications of the association for computer machinery montrent que les données non–étiquetées sont bénéfiques pour lapprentissage de fonctions dordonnancement\n",
      "apprentissage statistique de la topologie dun ensemble de données étiquetées\n",
      "découvrir la topologie dun ensemble de données étiquetées dans un espace euclidien peut aider à construire un meilleur système de décision dans ce papier nous proposons un modèle génératif basé sur le graphe de delaunay de plusieurs prototypes représentant les données étiquetées dans le but dextraire de ce graphe la topologie des classes\n",
      "approche connexionniste pour lextraction de profils castémoins du cancer du nasopharynx à partir des données issues dune étude épidémiologique\n",
      "dans cet article nous présentons un système de découverte de connaissances à partir de données issues dune étude épidémiologique castémoins du cancer du nasopharynx npc ces données étant obtenues par une collecte de questionnaires elles ont dune part la particularité dêtre qualitatives et dautre part de présenter des valeurs manquantes prenant en compte ces deux dernières contraintes le système que nous proposons suit une démarche dexploration de données qui consiste à 1 définir une procédure de codage des données qualitatives en présence de valeurs manquantes  2 étudier les propriétés de lalgorithme des cartes autoorganisatrices de kohonen et son adaptation à ce type de données dans un cadre de découverte et de visualisation de groupes homogènes des cas cancer  noncancer  3 posttraiter le resultat de cet algorithme par une classification automatique pour optimiser le nombre de groupes ainsi trouvés et 4 donner une interprétation sémantique des profils extraits de chaque groupe lobjectif général de cette étude est déclater le profil statistique global de la population étudiée en un ensemble de profils types cancer ou noncancer et dextraire pour chaque profil lensemble de variables explicatives du npc à partir dune cartographie bidimensionnelle\n",
      "approche logique pour la réconciliation de références\n",
      "le problème de réconciliation de références consiste à décider si deux descriptions provenant de sources distinctes réfèrent ou non à la même entité du monde réel dans cet article nous étudions ce problème quand le schéma des données est décrit en rdfs étendu par certaines primitives de owldl nous décrivons et montrons lintérêt dune approche logique basée sur des règles de réconciliation qui peuvent être générées automatiquement à partir des axiomes du schéma ces règles traduisent de façon déclarative les dépendances entre réconciliations qui découlent de la sémantique du schéma les premiers résultats ont été obtenus sur des données réelles dans le cadre du projet picsel 3 en collaboration avec france telecom rd\n",
      "calcul et représentation efficace de cubes de données pour une visualisation orientée pixel\n",
      "les cubes de données fournissent une aide non négligeable lorsquil sagit dinterroger des entrepôts de données un cube de données représente un précalcul de toutes les requêtes olap et ainsi améliore leur temps de réponses les approches proposées jusquà présent réduisent les temps de calcul et dentrée sortie mais leur utilisation reste très coûteuse dautres travaux de recherche se sont intéressés à la visualisation de données pour les exploiter de façon interactivenous proposons une adaptation de la représentation condensée des cubes de données basée sur le modèle partitionnel cette technique nous permet de calculer efficacement un cube de données et de représenter les liens entre les données pour la visualisation la visualisation proposée dans cet article est basée sur des techniques de visualisation orientée pixel et sur des techniques de diagramme de liens entre noeuds pour offrir à la fois une vision globale et locale pour lexploitation cette nouvelle approche utilise dune part les calculs efficaces de cubes de données et dautre part les techniques avancées de visualisation\n",
      "caractérisation des transitions temporisées dans les logs de conversation de services web\n",
      "la connaissance du protocole de conversation dun service web est importante pour les utilisateurs et les fournisseurs car il en modélise le comportement externe  mais il nest souvent pas spécifié lors de la conception notre travail sinscrit dans une thématique dextraction du protocole de conversation dun service existant à partir de ses données dexécution nous en étudions un sousproblème important qui est la découverte des transitions temporisées ie les changements détat liés à des contraintes temporelles nous proposons un cadre formel aboutissant à la définition des expirations propres qui représentent un équivalent dans les logs des transitions temporisées a notre connaissance ceci représente la première contribution à la résolution de ce problème\n",
      "cartographie de lorganisation  une approche topologique des connaissances\n",
      "la gestion des connaissances est devenue aujourdhui un enjeu majeur pour toute organisation celleci a pour but de capitaliser et de rendre accessible à ses acteurs la connaissance détenue par lorganisation cet article sintéresse particulièrement à la visualisation à deux niveaux de ces connaissances macroscopique  relatif aux connaissances globales détenues par lorganisation  et microscopique – relatif aux connaissances locales détenues par chaque membre organisationnel la caractérisation des connaissances détenues par les acteurs repose sur quatre dimensions complémentaires formelle conative cognitive et sociocognitive les deux types de visualisation proposés sappuient sur les cartes autoorganisatrices et permettent une navigation dans différentes représentations des connaissances de lorganisation\n",
      "choix des conclusions et validation des règles issues darbres de classification\n",
      "cet article traite de la validation de règles dans un contexte de ciblage où il sagit de déterminer les profils type des différentes valeurs de la variable à prédire les concepts de lanalyse statistique implicative fondée sur la différence entre nombre observé de contreexemples et nombre moyen que produirait le hasard savèrent particulièrement bien adaptés à ce contexte le papier montre comment les notions dindice et dintensité dimplication de gras sappliquent aux règles produites par les arbres de décision et présente des alternatives inspirées de résidus utilisés en modélisation de tables de contingence nous discutons ensuite sur un jeu de données réelles deux usages de ces indicateurs de force dimplication pour les règles issues darbres il sagit dune part de lévaluation individuelle des règles et dautre part de leur utilisation comme critère pour le choix de la conclusion de la règle\n",
      "classement des fragments de documents xml par une méthode daide à la décision\n",
      "vu laccroissement constant du volume dinformation accessible en ligne sous format xml il devient primordial de proposer des modèles adaptés à la recherche dinformation dans les documents xml tandis que la recherche dinformation classique repose sur lindexation du contenu des documents la recherche dinformation dans les documents xml tente daméliorer la qualité des résultats en tirant profit de la sémantique véhiculée par la structure des documents dans cet article nous présentons une méthode de classement des items éléments xml retournés lors dune recherche dans une collection de documents xml le classement repose sur la prise en compte dun ensemble de critères discriminants la particularité de notre approche réside dans la façon dont nous les utilisons  nous employons une méthode décisionnelle pour classer les items en les comparant deuxàdeux là où en général une fonction de scoring globale est utilisée\n",
      "classification de fonctions continues à laide dune distribution et dune densité définies dans un espace de dimension infinie\n",
      "il nest pas rare que des données individu soient caractérisées par une distribution continue et non une seule valeur ces données fonctionnelles peuvent être utilisées pour classer les individus une solution élémentaire est de réduire les distributions à leurs moyennes et variances une solution plus riche a été proposée par diday 2002 et mise en oeuvre par vrac et al 2001 et cuvelier et noirhommefraiture 2005 elle utilise des points de coupures dans les distributions et modélise ces valeurs conjointes par une distribution multidimensionnelle construite à laide dune copule nous avons montré dans un précédent travail que si cette technique apporte de bons résultats la qualité de la classification dépend néanmoins du nombre et de lemplacement des coupures les questions du choix du nombre et de lemplacement des coupures restaient des questions ouvertes nous proposons une solution à ces questions lorsque le nombre de coupures tend vers linfini en proposant une nouvelle distribution de probabilité adaptée à lespace de dimension infinie que forment les données fonctionnelles nous proposons aussi une densité de probabilité adaptée à la nature de cette distribution en utilisant la dérivée directionnelle de gâteaux la direction choisie pour cette dérivée est celle de la dispersion des fonctions à classer les résultats sont encourageants et offrent des perspectives multiples dans tous les domaines où une distribution de données fonctionnelles est nécessaire\n",
      "classification de grands ensembles de données avec un nouvel algorithme de svm\n",
      "le nouvel algorithme de boosting de leastsquares support vector machine lssvm que nous présentons vise à la classification de très grands ensembles de données sur des machines standard les méthodes de svm et de noyaux permettent dobtenir de bons résultats en ce qui concerne la précision mais la tâche dapprentissage pour de grands ensembles de données demande une grande capacité mémoire et un temps relativement long nous présentons une extension de lalgorithme de lssvm proposé par suykens et vandewalle pour le boosting de lssvm a cette fin nous avons ajouté un terme de régularisation de tikhonov et utilisé la formule de shermanmorrisonwoodbury pour traiter des ensembles de données ayant un grand nombre de dimensions nous lavons ensuite étendu par application du boosting de lssvm afin de traiter des données ayant simultanément un grand nombre dindividus et de dimensions les performances de lalgorithme sont évaluées sur les ensembles de données de luci twonorm ringnorm reuters21578 et ndc sur une machine standard pcp4 3ghz 512 mo ram\n",
      "classification supervisée de séquences biologiques basée sur les motifs et les matrices de substitution\n",
      "la classification des séquences biologiques est lun des importants défis ouverts dans la bioinformatique tant pour les séquences protéiques que pour les séquences nucléiques cependant la présence de ces données sous la forme de chaînes de caractères ne permet pas de les traiter par les outils standards de classification supervisée qui utilisent souvent le format relationnel pour remédier à ce problème de codage plusieurs travaux se sont basés sur lextraction des motifs pour construire une nouvelle représentation des séquences biologiques sous la forme dun tableau binaire nous décrivons une nouvelle approche qui étend les méthodes précédents par lutilisation de matrices de substitution dans les cas des séquences protéiques nous présentons ensuite une étude comparative qui prend en compte leffet de chaque méthode sur la précision de la classification mais aussi le nombre dattributs générés et le temps de calcul\n",
      "clustering  from modelbased approaches to heuristic algorithms\n",
      "les méthodes du clustering ont pour but de diviser un ensemble large dobjets dans un petit nombre de groupes homogènes clusters basé sur des données relevées ou observées qui décrivent les dissimilarités qui existent entre les objets – en espérant que ces clusters soient utiles pour lapplication concernée il existe une multitude dapproches et cette contribution présente quelquesunes qui sont les plus importantes ou actuelles\n",
      "combinaison des cartes topologiques mixtes et des machines à vecteurs de support  une application pour la prédiction de perte de poids chez les obèses\n",
      "cet article présente un modèle pour aborder les problèmes de classement difficiles en particulier dans le domaine médical ces problèmes ont souvent la particularité davoir des taux derreurs en généralisations très élevés et ce quelles que soient les méthodes utilisées pour ce genre de problèmes nous proposons dutiliser un modèle de classement combinant le modèle de partitionnement des cartes topologiques mixtes et les machines à vecteurs de support svm le modèle non supervisé est dédié à la visualisation et au partitionnement des données composées de variables quantitatives etou qualitatives le deuxième modèle supervisé est dédié au classement la combinaison de ces deux modèles permet non seulement daméliorer la visualisation des données mais aussi en les performances en généralisation ce modèle ctsvm consiste à entraîner des cartes autoorganisatrices pour construire une partition organisée des données constituée de plusieurs sousensembles qui vont servir à reformuler le problème de classement initial en sousproblème de classement pour chaque sousensemble on entraîne un classeur svm spécifique pour la validation expérimentale de notre modèle ctsvm nous avons utilisé quatre jeux de données la première base est un extrait dune grande base médicale sur létude de lobésité réalisée à lhôpital hôteldieu de paris et les trois dernières bases sont issues de la littérature\n",
      "construction coopérative de carte de thèmes  vers une modélisation de lactivité sociosémantique\n",
      "nous présentons dans cette contribution un cadre de modélisation recourant conjointement au modèle hypertopic cahier et al 2004 pour la représentation des connaissances de domaine et au modèle seeme herrmann et al 1999 pour la représentation de lactivité ces deux approches apparaissent complémentaires et nous montrons comment elles peuvent être combinées pour mieux ancrer sur les plans formel et méthodologique les approches de cartographie collective des connaissances\n",
      "construction dontologie à partir de corpus de textes\n",
      "cet article présente une méthode semiautomatique de construction dontologie à partir de corpus de textes sur un domaine spécifique cette méthode repose en premier lieu sur un analyseur syntaxique partiel et robuste des textes et en second lieu sur lutilisation de lanalyse formelle de concepts fca pour la construction de classes dobjets en un treillis de galois la construction de lontologie cest à dire dune hiérarchie de concepts et dinstances est réalisée par une transformation formelle de la structure du treillis cette méthode sapplique dans le domaine de lastronomie\n",
      "construction et analyse de résumés de données évolutives  application aux données dusage du web\n",
      "la manière dont une visite est réalisée sur un site web peut changer en raison de modifications liées à la structure et au contenu du site luimême ou bien en raison du changement de comportement de certains groupes dutilisateurs ou de lémergence de nouveaux comportements ainsi les modèles associés à ces comportements dans la fouille dusage du web doivent être mis à jour continuellement afin de mieux refléter le comportement actuel des internautes une solution proposée dans cet article est de mettre à jour ces modèles à laide des résumés obtenus par une approche évolutive des méthodes de classification\n",
      "construction incrémentale et visualisation de graphes de voisinage par des fourmis artificielles\n",
      "cet article décrit un nouvel algorithme incrémental nommé antgraph pour la construction de graphes de voisinage il sinspire du comportement dautoassemblage observé chez des fourmis réelles où ces dernières se fixent progressivement à un support fixe puis successivement aux fourmis déjà fixées afin de créer une structure vivante nous utilisons ainsi une approche à base de fourmis artificielles où chaque fourmi représente une donnée nous indiquons comment ce comportement peut être utilisé pour construire de manière incrémentale un graphe à partir dune mesure de similarité entre les données nous montrons finalement que notre algorithme obtient de meilleurs résultats en comparaison avec le graphe de voisins relatifs notamment en terme de temps de calcul\n",
      "découverte de chroniques à partir de séquences dévénements pour la supervision de processus dynamiques\n",
      "ce papier adresse le problème de la découverte de connaissances temporelles à partir des données datées générées par le système de supervision dun processus de fabrication par rapport aux approches existantes qui sappliquent directement aux données notre méthode dextraction des connaissances se base sur un modèle global construit à partir des données lapproche de modélisation adoptée dite stochastique considère les données datées comme une séquence doccurrences de classes dévénements discrets cette séquence est représentée sous les formes duales dune chaîne de markov homogène et dune superposition de processus de poisson lalgorithme proposé appelé bjt4r permet didentifier les motifs séquentiels les plus probables entre deux classes dévénements discrets et les représentent sous la forme de modèles de chroniques ce papier présente les premiers résultats de lapplication de cet algorithme sur des données générées par un processus de fabrication de semiconducteur dun site de production du groupe stmicroelectronics\n",
      "des fonctions doubli intelligentes dans les entrepôts de données\n",
      "les entrepôts de données stockent des quantités de données de plus en plus massives et arrivent vite à saturation un langage de spécifications de fonctions doubli est défini pour résoudre ce problème dans le but doffrir la possibilité deffectuer des analyses sur lhistorique des données les spécifications définissent des résumés par agrégation et par échantillonnage à conserver parmi les données à oublier cette communication présente le langage de spécifications ainsi que les principes et les algorithmes pour assurer de façon mécanique la gestion des fonctions doubli\n",
      "détermination du niveau de consommation des abonnés en téléphonie mobile par la théorie des ensembles flous\n",
      "la détermination du niveau de consommation chez les clients est essentielle pour tout objectif de segmentation stratégique et de churn nous présentons sur un cas réel lutilisation de la théorie des ensembles flous pour la définition dune fonction dappartenance permettant dévaluer de manière précise le niveau de consommation des abonnés en téléphonie mobile\n",
      "ensemble prédicteur fondé sur les cartes autoorganisatrices adapté aux données volumineuses\n",
      "le stockage massif des données noie linformation pertinente et engendre des problèmes théoriques liés à la volumétrie des données disponibles ces problèmes dégradent la capacité prédictive des algorithmes dextraction des connaissances à partir des données dans cet article nous proposons une méthodologie adaptée à la représentation et à la prédiction des données volumineuses a cette fin suite à un partitionnement des attributs des groupes dattributs noncorrélés sont créés qui permettent de contourner les problèmes liés aux espaces de grandes dimensions un ensemble est alors mis en place apprenant chaque groupe par une carte autoorganisatrice outre la prédiction ces cartes ont pour objectif une représentation pertinente des données enfin la prédiction est réalisée par un vote des différentes cartes une expérimentation est menée qui confirme le bienfondé de cette approche\n",
      "evaluation dune approche de classification conceptuelle\n",
      "lobjectif de ce travail est dévaluer la perte dinformation au sens de linertie entre des méthodes de partitionnement ou de classification hiérarchiques et une approche de classification conceptuelle nous voulons répondre à la question suivante  laspect simpliste du processus monothétique dune méthode conceptuelle impliquetil des partitions de moins bonne qualité au sens du critère de linertie  nous proposons de réaliser cette expérience sur 6 bases de luci trois de ces bases sont des tableaux de données quantitatives les trois autres sont des tableaux de données qualitatives\n",
      "evaluation supervisée de métrique  application à la préparation de données séquentielles\n",
      "de nos jours le statisticien na plus nécessairement le contrôle sur la récolte des données le besoin dune analyse statistique vient dans un second temps une fois les données récoltées par conséquent un travail est à fournir lors de la phase de préparation des données afin de passer dune représentation informatique à une représentation statistique adaptée au problème considéré dans cet article nous étudions un procédé de sélection dune bonne représentation en nous basant sur des travaux antérieurs nous proposons un protocole dévaluation de la pertinence dune représentation par lintermédiaire dune métrique dans le cas de la classification supervisée ce protocole exploite une méthode de classification non paramétrique régularisée garantissant lautomaticité et la fiabilité de lévaluation nous illustrons le fonctionnement et les apports de ce protocole par un problème réel de préparation de données de consommation téléphonique nous montrons également la fiabilité et linterprétabilité des décisions qui en résultent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evolution de lontologie et gestion des annotations sémantiques inconsistantes\n",
      "les ontologies et les annotations sémantiques sont deux composants importants dans un système de gestion des connaissances basé sur le web sémantique dans lenvironement dynamique et distribué du web sémantique les ontologies et les annotations pourraient être changées pour sadapter à lévolution de lorganisation concernée ces changements peuvent donc entraîner des inconsistances à détecter et traiter dans cet article nous nous focalisons principalement sur lévolution des annotations sémantiques en soulignant le contexte où les modifications de lontologie entraînent des inconsistances sur ces annotations nous présentons une approche basée sur des règles permettant de détecter les inconsistances dans les annotations sémantiques devenues obsolètes par rapport à lontologie modifiée nous décrivons aussi les stratégies dévolution nécessaires pour guider le processus de résolution de ces inconsistances grâce à des règles correctives\n",
      "extension sémantique du modèle de similarité basé sur la proximité floue des termes\n",
      "le modèle flou de proximité repose sur lhypothèse que plus les occurrences des termes dune requête se trouvent proches dans un document plus ce dernier est pertinent cette mesure floue est très avantageuse dans le traitement des documents à textes courts toutefois elle ne tient pas compte de la sémantique des termes nous présentons dans cet article lintégration dune métrique conceptuelle au modèle de proximité floue des termes pour la formalisation de notre propre modèle\n",
      "extraction dentités dans des collections évolutives\n",
      "nous nous intéressons à lextraction dentités nommées avec comme but dexploiter un ensemble de rapports pour en extraire une liste de partenaires à partir dune liste initiale nous utilisons un premier ensemble de documents pour identifier des schémas de phrase qui sont ensuite validés par apprentissage supervisé sur des documents annotés pour en mesurer lefficacité avant dêtre utilisés sur lensemble des documents à explorer cette approche est inspirée de celle utilisée pour lextraction de données dans les documents semistructurés wrappers et ne nécessite pas de ressources linguistiques particulières ni de larges collections de tests notre collection de documents évoluant annuellement nous espérons de plus une amélioration de notre extraction dans le temps\n",
      "extraction de connaissances dadaptation par analyse de la base de cas\n",
      "en raisonnement à partir de cas ladaptation dun cas source pour résoudre un problème cible est une étape à la fois cruciale et difficile à réaliser une des raisons de cette difficulté tient au fait que les connaissances dadaptation sont généralement dépendantes du domaine dapplication cest ce qui motive la recherche sur lacquisition de connaissances dadaptation aca cet article propose une approche originale de laca fondée sur des techniques dextraction de connaissances dans des bases de données ecbd nous présentons cabamaka une application qui réalise laca par analyse de la base de cas en utilisant comme technique dapprentissage lextraction de motifs fermés fréquents lensemble du processus dextraction des connaissances est détaillé puis nous examinons comment organiser les résultats obtenus de façon à faciliter la validation des connaissances extraites par lanalyste\n",
      "extraction de données sur internet avec retroweb\n",
      "ce document décrit retroweb une boite à outils qui permet lextraction de données structurées à partir de pages web notre solution est semiautomatique car les données à extraire sont préalablement dé\u0002nies par lutilisateur lintérêt de cette approche est quelle permet lextraction de données ciblées et conformes aux besoins de lapplication utilisatrice migrateur moteur de recherche outil de veille retroweb se caractérise aussi par une grande facilité dutilisation car il ne nécessite aucune connaissance de langage particulier la définition des règles dextraction se faisant directement de manière interactive dans le navigateur internet ce document décrit les trois principaux processus de notre méthode\n",
      "extraction de séquences multidimensionnelles convergentes et divergentes\n",
      "les motifs séquentiels sont un domaine de la fouille de données très étudié depuis leur introduction par agrawal et srikantmême sil existe de nombreux travaux algorithmes domaines dapplication peu dentre eux se situent dans un contexte multidimensionnel avec la prise en compte de ses spécificités  plusieurs dimensions relations hiérarchiques entre les éléments de chaque dimension etc dans cet article nous proposons une méthode originale pour extraire des connaissances multidimensionnelles définies sur plusieurs niveaux de hiérarchies mais selon un certain point de vue  du général au particulier ou vice et versa nous définissons ainsi le concept de séquences multidimensionnelles convergentes ou divergentes ainsi que lalgorithme associé m2scd basé sur le paradigme pattern growth des expérimentations sur des jeux de données synthétiques et réelles montrent lintérêt de notre approche aussi bien en terme de robustesse des algorithmes que de pertinence des motifs extraits\n",
      "extraction des topk motifs par approximeretpousser\n",
      "cet article porte sur lextraction de motifs sous contraintes globales contrairement aux contraintes usuelles comme celle de fréquence minimale leur vérification est problématique car elle entraine de multiples comparaisons entre les motifs typiquement la localisation des k motifs maximisant une mesure dintérêt ie satisfaisant la contrainte topk est difficile pourtant cette contrainte globale se révèle très utile pour trouver les motifs les plus significatifs au regard dun critère choisi par lutilisateur dans cet article nous proposons une méthode générale dextraction de motifs sous contraintes globales appelée approximeretpousser cette méthode peut être vue comme une méthode de relaxation dune contrainte globale en une contrainte locale évolutive nous appliquons alors cette approche à lextraction des topk motifs selon une mesure dintérêt les expérimentations montrent lefficacité de lapproche approximeretpousser\n",
      "filtrage des sites web à caractère violent par analyse du contenu textuel et structurel\n",
      "dans cet article nous proposons une solution pour la classification et le filtrage des sites web à caractère violent a la différence de la majorité de systèmes commerciaux basés essentiellement sur la détection de mots indicatifs ou lutilisation dune liste noire manuellement collectée notre solution baptisée webangels filter sappuie sur un apprentissage automatique par des techniques de data mining et une analyse conjointe du contenu textuel et structurel de la page web les résultats expérimentaux obtenus lors de lévaluation de notre approche sur une base de test sont assez bons comparé avec des logiciels parmi les plus populaires webangels filter montre sa performance en terme de classification\n",
      "finding interesting queries in relational databases\n",
      "la découverte de motifs dans des bases de données relationnelles quelconques est un problème intéressant pour lequel il existe très peu de méthodes efficaces nous présentons un cadre dans lequel des paires de requêtes sur les données sont utilisées comme des motifs et nous discutons du problème de la découverte dassociations utiles entre elles plus spécifiquement nous considérons des petites sousclasses de requêtes conjonctives qui nous permettent de découvrir des motifs intéressants de manière efficace\n",
      "fusion des approches visuelles et contextuelles pour lannotation des images médicales\n",
      "dans le contexte de la recherche dinformation sur internet nous proposons une architecture dannotation automatique des images médicales extraites à partir des documents de santé en ligne notre système est conçu pour extraire des informations médicales spécifiques ie modalité médicale région anatomique à partir du contenu et du contexte des images nous proposons une architecture de fusion des approches contenucontexte adaptée aux images médicales lapproche orientée sur le contenu des images consiste à annoter des images inconnues par la catégorisation des représentations visuelles compactes nous utilisons en même temps le contexte des images les régions textuelles ainsi que des ontologies médicales spécialement adaptées aux informations recherchées finalement nous démontrons quen fusionnant les décisions des deux approches nous améliorons les performances globales du système dannotation\n",
      "génération et enrichissement automatique de listes de patrons de phrases pour les moteurs de questionsréponses\n",
      "nous utilisons un algorithme damorce mutuelle riloff et jones 99 entre des couples de termes dune relation et des patrons de phrase à partir de couples damorce le système génère des listes de patrons qui sont ensuite enrichies de façon semisupervisée puis utilisées pour trouver de nouveaux couples ces couples sont à leur tour réutilisés pour générer par itérations successives de nouveaux patrons loriginalité de létude réside dans linterprétation du rappel estimé comme la couverture dun patron sur lensemble des exemples auxquels il sapplique\n",
      "intégration des connaissances utilisateurs pour des analyses personnalisées dans les entrepôts de données évolutifs\n",
      "dans cet article nous proposons une approche dévolution de schéma dans les entrepôts de données qui permet aux utilisateurs dintégrer leurs propres connaissances du domaine afin denrichir les possibilités danalyse de lentrepôt nous représentons cette connaissance sous la forme de règles de type sialors ces règles sont utilisées pour créer de nouveaux axes danalyse en générant de nouveaux niveaux de granularité dans les hiérarchies de dimension notre approche est fondée sur un modèle formel dentrepôts de données évolutif qui permet de gérer la mise à jour des hiérarchies de dimension\n",
      "interestingness in data mining\n",
      "interestingness measures play an important role in data mining regardless of the kind of patterns being mined these measures are intended for selecting and ranking patterns according to their potential interest to the user good measures also allow the time and space cost of the mining process to be reduced measuring the interestingness of discovered patterns is an active and important area of data mining research although much work has been conducted in this area so far there is no widespread agreement on a formal definition of interestingness in this context based on the diversity of definitions presented to date interestingness is perhaps best treated as a broad concept which emphasizes conciseness coverage reliability peculiarity diversity novelty surprisingness utility and actionability this presentation reviews interestingness measures for rules and summaries classifies them from several perspectives compares their properties identifies their roles in the data mining process gives strategies for selecting appropriate measures for applications and identifies opportunities for future research in this area\n",
      "lémergence de connaissances dans les communautés de pratique\n",
      "cet article est le résultat dune recherche sur le processus peu explicité dans la littérature de création de connaissances dans les communautés de pratique nous commençons par établir une définition de travail pour ce concept de communauté de pratique qui permet léchange et le partage de connaissances au sein de groupes de plus en plus virtuels nous analysons ensuite les communautés de pratique sous langle de la théorie de lémergence nous proposons alors la modélisation dun outil de support pour ces communautés qui améliore les échanges entre les membres et favorise lémergence de nouvelles connaissances cet outil manipule les connaissances implicites ainsi quexplicites et propose des possibilités pour la publication et la recherche dinformations de plus il sadapte à chaque membre de la communauté par un processus de personnalisation\n",
      "loutil sdet pour le complètement des données descriptives liées aux bases de données géographiques\n",
      "lenrichissement des bases de données est un moyen visant à offrir un supplément informationnel aux utilisateurs dans le cas des données géographiques cette activité représente de nos jours un problème crucial sa résolution permettrait de meilleures prises de décisions ne reposant pas uniquement sur les informations limitées notre outil sdet semantic data enrichment tool vient proposer une solution denrichissement faisant du système dinformation géographiques sig initial une source riche dinformations\n",
      "les itemsets essentiels fermés  une nouvelle représentation concise\n",
      "devant laccroissement constant des grandes bases de données plusieurs travaux de recherche en fouille de données sorientent vers le développement de techniques de représentation compacte ces recherches se développent suivant deux axes complémentaires  lextraction de bases génériques de règles dassociation et lextraction de représentations concises ditemsets fréquentsdans ce papier nous introduisons une nouvelle représentation concise exacte des itemsets fréquents elle se situe au croisement de chemins de deux autres représentations concises à savoir les itemsets fermés et ceux dits essentiels lidée intuitive est de profiter du fait que tout opérateur de fermeture induit une fonction surjective dans ce contexte nous introduisons un nouvel opérateur de fermeture permettant de calculer les fermetures des itemsets essentiels ceci a pour but davoir une représentation concise de taille réduite tout en permettant lextraction des supports négatif et disjonctif dun itemset en plus de son support conjonctif un nouvel algorithme appelé dclosure permettant dextraire les itemsets essentiels fermés est aussi présenté létude expérimentale que nous avons menée a permis de confirmer que la nouvelle approche présente un bon taux de compacité comparativement aux autres représentations concises exactes\n",
      "logiciel daide à lévaluation des catégorisations\n",
      "les méthodes de classification automatique sont employées dans des domaines variés et de nombreux algorithmes ont été proposés dans la littérature au milieu de cette jungle il semble parfois difficile à un simple utilisateur de choisir quel algorithme est le plus adapté à ses besoins depuis le milieu des années 90 une nouvelle thématique de recherches appelée clustering validity tente de répondre à ce genre dinterrogation en proposant des indices pour juger de la qualité des catégorisations obtenues mais le choix est parfois difficile entre ces indices et il peut savérer délicat de prendre la bonne décision cest pourquoi nous proposons un logiciel adapté à cette problématique dévaluation\n",
      "mesure dentropie asymétrique et consistante\n",
      "les mesures dentropie dont la plus connue est celle de shannon ont été proposées dans un contexte de codage et de transmission dinformation néanmoins dès le milieu des années soixante elles ont été utilisées dans dautres domaines comme lapprentissage et plus particulièrement pour construire des graphes dinduction et des arbres de décision lusage brut de ces mesures nest cependant pas toujours bien approprié pour engendrer des modèles de prédiction ou dexplication pertinents cette faiblesse résulte des propriétés des entropies en particulier le maximum nécessairement atteint pour la distribution uniforme et linsensibilité à la taille de léchantillon nous commençons par rappeler ces propriétés classiques nous définissons ensuite une nouvelle axiomatique mieux adaptée à nos besoins et proposons une mesure empirique dentropie plus flexible vérifiant ces axiomes\n",
      "mesure non symétrique pour lévaluation de modèles utilisation pour les jeux de données déséquilibrés\n",
      "les critères servant à lévaluation de modèles dapprentissage supervisé ainsi que ceux utilisés pour bâtir des arbres de décision sont pour la plupart symétriques de manière pragmatique cela signifie que chacune des modalités de la variable endogène se voit assigner une importance identique or dans nombre de cas pratiques cela nest pas le cas ainsi on peut notamment prendre lexemple de jeux de données fortement déséquilibrés pour lesquels lobjectif principal est lidentification des objets représentatifs de la modalité minoritaire aide au diagnostic identification de phénomènes inhabituels  fraudes pannes dans ce type de situation il apparaît clairement quassigner une importance identique aux erreurs de prédiction ne constitue pas la meilleure des solutions nous proposons dans cet article un critère pouvant servir à la fois pour lévaluation de modèles dapprentissage supervisé ou encore de critère utilisé pour bâtir des arbres de décision prenant en compte cet aspect non symétrique de limportance associée à chacune des modalités de la variable endogène nous proposons ensuite une évolution des modèles de type forêts aléatoires utilisant ce critère pour les jeux de données fortement déséquilibrés\n",
      "méthodes statistiques et modèles thermiques compacts\n",
      "dans le domaine thermique la plupart des études reposent sur des modèles à éléments finis cependant le coût en calcul et donc en temps de ces méthodes ont renforcé le besoin de modèles plus compacts le réseau rc équivalent est la solution la plus souvent utilisée toutefois ses paramètres doivent souvent être ajustés à laide de mesures ou de simulation dans ce contexte didentification de système les méthodes statistiques seront comparées aux méthodes classiquement utilisées pour la prédiction thermique\n",
      "navigation et appariement dobjets géographiques dans une ontologie\n",
      "laci fodomust se propose délaborer un processus de fouille de données multistratégies pour la reconnaissance automatique dobjets géographiques sur des images satellitaires ou aériennes ces dernières sont segmentées afin disoler des polygones définis par un ensemble de descripteurs de bas niveaux afin de leur affecter une sémantique on applique dans un premier temps une classification si aucun objet géographique nest identifié on tente alors un appariement du polygone avec les concepts dune ontologie dobjets géographiques un algorithme de navigation dans lontologie et une mesure de comparaison sémantique ont ainsi été développés paramétrables selon le contexte dappariement cette mesure évalue la pertinence dun appariement et comprend une composante locale comparaison au niveau du concept et une composante globale combinaison linéaire de mesures locales la méthode proposée a été développée en java et intégrée à la plateforme fodomust les premières expérimentations et évaluations humaines sont très encourageantes\n",
      "notion de conversation dans les communications interpersonnelles instantanées sur ip\n",
      "dans cet article nous étudions la contribution des techniques de fouille de données à lamélioration des services de communications instantanées sur ip tel que la messagerie instantanée im et la téléphonie sur ip toip\n",
      "okm  une extension des kmoyennes pour la recherche de classes recouvrantes\n",
      "dans cet article nous abordons le problème de la classification ou clustering dans le but de découvrir des classes avec recouvrements malgré quelques avancées récentes dans ce domaines motivées par des besoins applicatifs importants traitements des données multimédia par exemple nous constatons labsence de solutions théoriques à ce problème notre étude consiste alors à proposer une nouvelle formulation du problème de classification par partitionnement adaptée à la recherche dun recouvrement des données en classes dobjets similaires cette approche se fonde sur la dé\u0002nition dun critère objectif de qualité dun recouvrement et dune solution algorithmique visant à optimiser ce critère nous proposons deux évaluations de ce travail permettant dune part dappréhender le fonctionnement global de lalgorithme sur des données simples vitesse de convergence visualisation des résultats et dautre part dévaluer quantitativement le bénéfice dune telle approche sur une application de classification de documents textuels\n",
      "optimal histogram representation of large data sets fisher vs piecewise linear approximation\n",
      "histogram representation of a large set of data is a good way to summarize and visualize data and is frequently performed in order to optimize query estimation in dbms in this paper we show the performance and the properties of two strategies for an optimal construction of histograms on a single real valued descriptor on the base of a prior choice of the number of buckets the first one is based on the fisher algorithm while the second one is based on a geometrical procedure for the interpolation of the empirical distribution function by a piecewise linear function the goodness of fit is computed using the wasserstein metric between distributions we compare the proposed method performances against some existing ones on artificial and real datasets\n",
      "partitionnement dun réseau de sociabilité à fort coefficient de clustering\n",
      "afin de comparer lorganisation sociale dune paysannerie médiévale avant et après la guerre de cent ans nous étudions la structure de réseaux sociaux construits à partir dun corpus de contrats agraires faibles diamètres et fort clustering révèlent des graphes en petit monde comme beaucoup de grands réseaux dinteraction étudiés ces dernières années ces graphes sont sans échelle typique les distributions des degrés de leurs sommets sont bien ajustées par une loi de puissance tronquée par une coupure exponentielle ils possèdent en outre un clubhuppé cest à dire un noyau dense et de faible diamètre regroupant les individus à forts degrés la forme particulière des éléments propres du laplacien permet dextraire des communautés qui se répartissent en étoile autour du club huppé\n",
      "peuton capturer la sémantique à travers la syntaxe   découverte des règles dexception simultanée\n",
      "lobjectif de la fouille de données est la découverte sophistiquée de connaissances lisibles surprenantes et possiblement utiles les aspects surprenant et utile font partie de la sémantique et nécessitent lutilisation des connaissances du domaine ce qui cause souvent le problème dacquisition de la connaissance notre découverte des règles dexception simultanée peut être une réponse à ce problème nous envisageons de trouver les connaissances surprenantes et possiblement utiles à travers notre forme de paire de règles dexception les autres méthodes inventées concernent lindex dévaluation et la recherche exhaustive plusieurs applications médicales seront présentées sur lesquelles nos propositions ont été appliquées\n",
      "préservation de lintimité dans les protocoles de conversations\n",
      "le travail présenté dans cet article rentre dans le cadre de la gestion des données privées en vue de la substitution appelée remplaçabilité dynamique des services web trois contributions sont apportées 1 modélisation des politiques privées spécifiant les règles dutilisation des données privées prenant en compte des aspects se rapportant aux services web 2 étendre les protocoles de conversations des services web par le modèle proposé afin dapporter les primitives nécessaires pour lanalyse des protocoles en présence de ces règles 3 définition dun mécanisme danalyse de la remplaçabilité dun service par un autre en vue de ses politiques privées\n",
      "ras  un outil pour lannotation de documents basée sur les liens de citation\n",
      "ras reference annotation system est un outil dannotation de documents cet outil est le résultat de limplémentation de notre approche dannotation basée sur le contexte de citation lapproche est indépendante du contenu et utilise un regroupement thématique des références construit à partir dune classification floue nonsupervisée loutil présenté dans cet article a été expérimentée et évaluée avec la base de documents scientifiques citeseer\n",
      "réordonnancement pour lapprentissage de transformations de documents html\n",
      "notre objectif est de transformer les documents web vers un schéma médiateur xml défini a priori cest une étape nécessaire pour de nombreuses tâches de recherche dinformation concernant le web sémantique les documents semistructurés le traitement de sources hétérogènes etc elle permet dassocier une structure sémantiquement riche à des documents dont le formats ne contient que des informations de présentation nous proposons de traiter ce problème comme un problème dapprentissage structuré en le formalisant comme une transformation darbre en arbrenotre méthode de transformation comporte deux étapes dans une première étape une grammaire horscontexte probabiliste permet de générer un ensemble de solutions candidates dans une deuxième étape ces solutions candidates sont ordonnées grâce à un algorithme de réordonnancement à base de perceptron à noyau cette étape dordonnancement nous permet dutiliser de manière efficace des caractéristiques complexes définies à partir du document dentrée et de la solution candidate\n",
      "réduction de dimension pour lanalyse de données vidéo\n",
      "les données vidéo ont la particularité dêtre très volumineuses alors quelles contiennent peu dinformation sémantique pour les analyser il faut réduire la quantité dinformation dans lespace de recherche les données vidéo sont souvent considérées comme lensemble des pixels dune succession dimages analysées séquentiellement dans cet article nous proposons dutiliser une analyse en composantes principales acp pour réduire la dimensionnalité des informations sans perdre la nature tridimensionnelle des données initiales nous commençons par considérer des sousséquences dont le nombre de trames est le nombre de dimensions dans lespace de représentation nous appliquons une acp pour obtenir un espace de faible dimension où les points similaires sémantiquement sont proches la sousséquence est ensuite divisée en blocs tridimensionnels dont on projette lellipsoïde dinertie dans le premier plan factoriel nous déduisons enfin le mouvement présent dans les blocs à partir des ellipses ainsi obtenues nous présenterons les résultats obtenus pour un problème de vidéosurveillance\n",
      "régression floue et crédibiliste par svm pour la classification des images sonar\n",
      "la classification des images sonar est dune grande importance par exemple pour la navigation sousmarine ou pour la cartographie des fonds marins en effet le sonar offre des capacités dimagerie plus performantes que les capteurs optiques en milieu sousmarin la classification de ce type de données rencontre plusieurs difficultés en raison des imprécisions et incertitudes liées au capteur et au milieu de nombreuses approches ont été proposées sans donner de bons résultats cellesci ne tenant pas compte des imperfections des données pour modéliser ce type de données il est judicieux dutiliser les théories de lincertain comme la théorie des sousensembles flous ou la théorie des fonctions de croyance les machines à vecteurs de supports sont de plus en plus utilisées pour la classification automatique aux vues leur simplicité et leurs capacités de généralisation il est ainsi possible de proposer une approche qui tient compte de ces imprécisions et de ces incertitudes au coeur même de lalgorithme de classification lapproche de la régression par svm que nous avons introduite permet cette modélisation des imperfections nous proposons ici une application de cette nouvelle approche sur des données réelles particulièrement complexes dans le cadre de la classification des images sonar\n",
      "segmentation thématique par calcul de distance thématique\n",
      "dans cet article nous présentons une approche de la segmentation thématique fondée sur une représentation en vecteurs sémantiques des phrases et des calculs de distance entre ces vecteurs les vecteurs sémantiques sont générés par le système sygfran un analyseur morphosyntaxique et conceptuel de la langue française la segmentation thématique seffectue elle en recherchant des zones de transition au sein du texte grâce aux vecteurs sémantiques lévaluation de cette méthode sest faite sur les données du défi deft06\n",
      "sémantique et contextes conceptuels pour la recherche dinformation\n",
      "cet article propose une méthodologie de recherche dinformation qui utilise lanalyse conceptuelle conjointement avec la sémantique dans le but de fournir des réponses contextuelles à des requêtes sur le web le contexte conceptuel défini dans cet article peut être global – cestàdire stable – ou instantané – cestàdire borné par le contexte global notre méthodologie consiste en une première phase de pré traitement permettant de construire le contexte global et une seconde phase de traitement en ligne des requêtes des utilisateurs associées au contexte instantané notre processus de recherche dinformation est illustré à travers une expérimentation dans le domaine du tourisme\n",
      "sousbases kfaibles pour des règles dassociation valides au sens de la confiance\n",
      "nous introduisons la notion de sousbase kfaible pour les règles dassociation valides au sens de la confiance ces sousbases kfaibles sont caractérisées en termes dopérateurs de fermeture correspondant à des familles de moore kfaiblement hiérarchiques\n",
      "spoid  extraction de motifs séquentiels pour les bases de données incomplètes\n",
      "les bases de données issues du monde réel contiennent souvent de nombreuses informations non renseignées durant le processus dextraction de connaissances dans les bases de données une phase de traitement spécifique de ces données est souvent nécessaire permettant de les supprimer ou de les compléter lors de lextraction de séquences fréquentes ces données incomplètes sont la plupart du temps occultées ceci conduit parfois à lélimination de plus de la moitié de la base et linformation extraite nest plus représentative nous proposons donc de ne plus éliminer les enregistrements incomplets mais dutiliser linformation partielle quils contiennent la méthode proposée ignore en fait temporairement certaines données incomplètes pour les séquences recherchées les expérimentations sur jeux de données synthétiques montrent la validité de notre proposition aussi bien en terme de qualité des motifs extraits que de robustesse aux valeurs manquantes\n",
      "syrqus  recherche par combinaison de graphes rdf\n",
      "nous nous intéressons à un mécanisme permettant la construction de réponses combinés à partir de plusieurs graphes rdf nous imposons par souci de cohérence que cette combinaison soit réalisée uniquement si les graphes rdf ne se contredisent pas pour déterminer la noncontradiction entre deux graphes rdf nous utilisons une mesure de similarité calculée au moment de lajout de documents rdf dans la base de documents\n",
      "traitement de données de consommation électrique par un système de gestion de flux de données\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avec le développement de compteurs communicants les consommations dénergie électrique pourront à terme être télérelevées par les fournisseurs délectricité à des pas de temps pouvant aller jusquà la seconde ceci générera des informations en continu à un rythme rapide et en quantité importante les systèmes de gestion de flux de données sgfd aujourdhui disponibles sous forme de prototypes ont vocation à faciliter la gestion de tels flux cette communication décrit une étude expérimentale pour analyser les avantages et limites de lutilisation de deux prototypes de sgfd stream et telegraphcq pour la gestion de données de consommation électrique\n",
      "traitement et exploration du fichier log du serveur web pour lextraction des connaissances  web usage mining\n",
      "le but dans ce travail consiste à concevoir et réaliser un outil logiciel en utilisant les concepts du web usage mining pour offrir aux web masters lensemble des connaissances y inclut les statistiques sur leurs sites afin de prendre les décisions adéquates il sagit en fait dextraire de linformation à partir du fichier log du serveur web hébergeant le site web et de prendre les décisions pour découvrir les habitudes des internautes et de répondre à leurs besoins en adaptant le contenu la forme et lagencement des pages web\n",
      "un algorithme multiagent de classification pour la construction dontologies dynamiques\n",
      "la construction dontologies à partir de textes reste une tâche coûteuse en temps qui justifie lémergence de lontology learning notre système dynamo sinscrit dans cette mouvance en apportant une approche originale basée sur une architecture multiagent adaptative en particulier larticle présente le coeur de notre approche un algorithme distribué de classification hiérarchique qui sapplique sur les résultats dun analyseur syntaxique cet algorithme est évalué et comparé à un algorithme centralisé plus conventionnel forts de ces résultats nous discutons ses limites et dressons en perspective les aménagements à effectuer pour aller vers une solution complète de construction dontologies\n",
      "un cadre théorique pour la gestion de grandes bases de motifs\n",
      "les algorithmes de fouille de données sont maintenant capables de traiter de grands volumes de données mais les utilisateurs sont souvent submergés par la quantité de motifs générés en outre dans certains cas que ce soit pour des raisons de confidentialité ou de coûts les utilisateurs peuvent ne pas avoir accès directement aux données et ne disposer que des motifs les utilisateurs nont plus alors la possibilité dapprofondir à partir des données initiales le processus de fouille de façon à extraire des motifs plus spécifiques pour remédier à cette situation une solution consiste à gérer les motifs ainsi dans cet article nous présentons un cadre théorique permettant à un utilisateur de manipuler en posttraitement une collection de motifs préalablement extraite nous proposons de représenter la collection sous la forme dun graphe quun utilisateur pourra ensuite exploiter à laide dopérateurs algébriques pour y retrouver des motifs ou en chercher de nouveaux\n",
      "un outil pour la visualisation de relations entre gènes\n",
      "la reconstruction de réseaux de gènes est un des défis majeurs de la postgénomique a partir de données dexpression issues de puces à adn différentes techniques existent pour inférer des réseaux de gènes nous proposons dans ce papier une approche pour la visualisation de réseaux dinteractions entre gènes à partir de données dexpression loriginalité de notre approche est de superposer des règles avec des sémantiques différentes au sein dun même support visuel et de ne générer que les règles qui impliquent des gènes dits centraux ceuxci sont spécifiés en amont par les experts et permettent de limiter la génération des règles aux seuls gènes qui intéressent les spécialistes une implémentation a été réalisée dans le logiciel libre mev de linstitut tigr\n",
      "un segmenteur de texte en phrases guidé par lutilisateur\n",
      "ce programme effectue une segmentation en phrases dun texte contrairement aux procédures classiques nous nutilisons pas dannotations préliminaires et tirons parti dun apprentissage guidé par lutilisateur\n",
      "une approche de classification non supervisée basée sur la détection de singularités et la corrélation de séries temporelles pour la recherche détats  application à un bioprocédé fedbatch\n",
      "nous proposons dans cet article une méthode de clustering qui combine lanalyse dynamique et lanalyse statistique pour caractériser des états il sagit dune méthode de fouille de données qui travaille sur des ensembles de séries temporelles pour détecter des états ces états représentent les informations les plus significatives du système lobjectif de cette méthode non supervisée est dextraire de la connaissance à partir de lanalyse des séries temporelles multiples elle sappuie sur la détection de singularités dans les séries temporelles et sur lanalyse des corrélations des séries entre les intervalles définis par ces singularités pour lapplication présentée les séries temporelles sont des signaux biochimiques mesurés durant un bioprocédé cette approche est donc utilisée pour confirmer et enrichir la connaissance des experts du domaine des bioprocédés sans utiliser la connaissance a priori de ces experts elle est appliquée à la recherche détats physiologiques dans un bioprocédé de type fedbatch\n",
      "une approche non paramétrique bayésienne pour lestimation de densité conditionnelle sur les rangs\n",
      "nous nous intéressons à lestimation de la distribution des rangs dune variable cible numérique conditionnellement à un ensemble de prédicteurs numériques pour cela nous proposons une nouvelle approche non paramétrique bayesienne pour effectuer une partition rectangulaire optimale de chaque couple cible prédicteur uniquement à partir des rangs des individus nous montrons ensuite comment les effectifs de ces grilles nous permettent de construire un estimateur univarié de la densité conditionnelle sur les rangs et un estimateur multivarié utilisant lhypothèse bayesienne naïve ces estimateurs sont comparés aux meilleures méthodes évaluées lors dun récent challenge sur lestimation dune densité prédictive si lestimateur bayésien naïf utilisant lensemble des prédicteurs se révèle peu performant lestimateur univarié et lestimateur combinant deux prédicteurs donne de très bons résultats malgré leur simplicité\n",
      "une approche sociotechnique pour le knowledge management km\n",
      "cet article présente un cadre sociotechnique pour le km cette vision sociotechnique du km permet  1 décarter le km dun souci commercial  2 faire le clivage des différentes technologies du km  et 3 de sinterroger sur les paradigmes associés aux composants social et technique du km cest précisément ce dernier point que cet article développe afin didentifier les mécanismes génériques du km plus précisément laspect social est décrit à travers lapproche organisationnelle du km lapproche managériale du km et lapproche biologique du km alors que laspect technique est décrit à travers lapproche ingénierie des connaissances et compétences du km ces approches nous conduisent aussi à donner un tableau comparatif entre ces visions organisationnelles managériales et biologiques du km\n",
      "une étude des algorithmes de construction darchitecture des réseaux de neurones multicouches\n",
      "le problème de choix darchitecture dun réseau de neurones multicouches reste toujours très difficile à résoudre dans un processus de fouille de données ce papier recense quelques algorithmes de recherche darchitectures dun réseau de neurones pour les tâches de classification il présente également une analyse théorique et expérimentale de ces algorithmes ce travail confirme les difficultés de choix des paramètres dapprentissage modèle nombre de couches nombre de neurones par couches taux dapprentissage algorithme dapprentissage communs à tout processus de construction de réseaux de neurones et les difficultés de choix de paramètres propres à certains algorithmes\n",
      "une extension de xquery pour la recherche textuelle dinformation dans des documents xml\n",
      "nous présentons dans cet article une extension de xquery que nous avons développée pour interroger le contenu et la structure de documents xml cette extension consiste à intégrer dans xquery le langage nexi un sousensemble de xpath défini dans le cadre de linitiative inex notre proposition est double  i équiper nexi dune sémantique floue ii intégrer nexi dans xquery au moyen dune métafonction appelée nexi ayant une requête nexi comme paramètre et dune extension de la clause for de lopérateur flwor de xquery de plus nous décrivons le prototype paramétrable que nous avons développé au dessus de deux moteurs xquery classiques  galax et saxon\n",
      "une méthode dinterprétation de scores\n",
      "cet article présente une méthode permettant dinterpréter la sortie dun modèle de classification ou de régression linterprétation se base sur limportance de la variable et limportance de la valeur de la variable cette approche permet dinterpréter la sortie du modèle pour chaque instance\n",
      "une méthode optimale dévaluation bivariée pour la classification supervisée\n",
      "en préparation des données pour la classification supervisée les méthodes filtres usuellement utilisées pour la sélection de variables sont efficaces en temps de calcul néanmoins leur nature univariée ne permet pas de détecter les redondances ou les interactions constructives entre variables cet article présente une nouvelle méthode permettant dévaluer limportance prédictive jointe dune paire de variables de façon automatique rapide et fiable elle est basée sur un partitionnement de chaque variable exogène en intervalles dans le cas numérique et groupes de valeurs dans le cas catégoriel la grille de données exogène résultante permet alors dévaluer la corrélation entre la paire de variables exogènes et la variable endogène le meilleur partitionnement bivarié est recherché au moyen dune approche bayésienne de la sélection de modèle les expérimentations démontrent les apports de la méthode notamment une amélioration significative des performances en classification\n",
      "une nouvelle approche de la programmation dc et dca pour la classification floue\n",
      "dans cet article nous nous intéressons à fuzzy cmeans fcm une technique très connue pour la classification floue nous proposons un algorithme efficace basé sur la programmation dc difference of convexe functions et dca dc algorithm pour résoudre ce problème les expériences numériques comparatives avec lalgorithme standard fcm sur les données réelles montrent la robustesse la performance de cet nouvel algorithme dca et sa supériorité par rapport à fcm\n",
      "une nouvelle méthode dalignement et de visualisation dontologies owllite\n",
      "dans ce papier une nouvelle plateforme dalignement et de visualisation des ontologies appelée pova prototype owllite visual alignment est décrite le module dalignement implémente une nouvelle approche dalignement dontologies remédiant au problème de la circularité et de lintervention de lutilisateur\n",
      "une règle dexception en analyse statistique implicative\n",
      "en fouille de règles certaines situations exceptionnelles défient le bon sens cest le cas de la règle r  a  c et b  c et a et b  non c une telle règle que nous étudions dans larticle est appelée règle dexception a la suite des travaux précurseurs de e suzuki et y kodratoff 1999 qui ont étudié un autre type de règle dexception nous cherchons ici à caractériser les conditions dapparition de la règle r dans le cadre de lanalyse statistique implicative\n",
      "utilisation de wordnet dans la catégorisation de textes multilingues\n",
      "cet article est consacré au problème de la catégorisation multilingue qui consiste à catégoriser des documents de différentes langues en utilisant le même classifieur lapproche que nous proposons est basée sur lidée détendre lutilisation de wordnet dans la catégorisation monolingue vers la catégorisation multilingue\n",
      "validation des visualisations par axes principaux de données numériques et textuelles\n",
      "parmi les outils de visualisation de données multidimensionnelles figurent dune part les méthodes fondées sur la décomposition aux valeurs singulières et dautre part les méthodes de classification incluant les cartes autoorganisées de kohonen comment valider ces visualisations  on présente sept procédures de validation par bootstrap qui dépendent des données des hypothèses des outils  a le bootstrap partiel qui considère les réplications comme des variables supplémentaires b le bootstrap total de type 1 qui réanalyse les réplications avec changements éventuels de signes des axes c le bootstrap total de type 2 qui corrige aussi les interversions daxes d le bootstrap total de type 3 sur lequel on insistera qui corrige les réplications par rotations procrustéenne e le bootstrap spécifique cas des hiérarchies dindividus statistiques et des données textuelles f le bootstrap sur variables g les extensions des procédures précédentes à certaines cartes autoorganisées\n",
      "vers un algorithme multiagents de clustering dynamique\n",
      "dans cet article nous présentons un algorithme multiagents de clustering dynamique ce type de clustering doit permettre de gérer des données évolutives et donc être capable dadapter en permanence les clusters construits\n",
      "vers un système hybride pour lannotation sémantique dimages irm du cerveau\n",
      "cet article montre lintérêt de combiner des méthodes numériques et symboliques pour obtenir une annotation sémantique des images irm du cerveau humain il sagit didentifier des structures anatomiques du cortex cérébral humain en utilisant conjointement des connaissances a priori de nature numérique et une ontologie des structures corticales du cerveau représentée en owl dl étendue par des règles swrl ces connaissances symboliques a priori représentées dans des langages standards du web deviennent non seulement partageables mais permettent aussi un raisonnement automatique qui aide lutilisateur à la labellisation des structures anatomiques mises en évidence dans des images irm du cerveau dun individu donné\n",
      "vers une base de connaissances biographique  extraction dinformation et ontologie\n",
      "le projet bontology a pour but lextraction lorganisation et lexploitation de connaissances biographiques à partir de dépêches de presse sa réalisation requiert lintégration de diverses technologies principalement lextraction dinformation les ontologies et bases de connaissances les techniques de data mining cet article propose un aperçu des choix réalisés dans le cadre du projet cette démarche permet également de définir un environnement doutils utiles pour les applications dextraction et de gestion de connaissances\n",
      "vers une nouvelle approche dextraction des motifs séquentiels nondérivables\n",
      "lextraction de motifs séquentiels est un défi important pour la communauté fouille de données même si les représentations condensées ont montré leur intérêt dans le domaine des itemsets à lheure actuelle peu de travaux considèrent ce type de représentation pour extraire des motifs cet article propose détablir les premières bases formelles pour obtenir les bornes inférieures et supérieures du support dune séquence s nous démontrons que ces bornes peuvent être dérivées à partir des sousséquences de s et prouvons que ces règles de dérivation permettent la construction dune nouvelle représentation condensée de lensemble des motifs fréquents les différentes expérimentations menées montrent que notre approche offre une meilleure représentation condensée que celles des motifs clos et cela sans perte dinformation\n",
      "vers une plateforme interactive pour la visualisation de grands ensembles de règles dassociation\n",
      "la recherche de règles dassociation est une question centrale en extraction de connaissances dans les données ecd dans cet article nous nous intéressons plus particulièrement à la restitution visuelle de règles pertinentes dans un corpus très important nous proposons ainsi un prototype basé sur une approche de type wrapper par intégration des phases dextraction et de visualisation de lecd tout dabord le processus dextraction génère une base générique de règles et dans un second temps la tâche de visualisation sappuie sur un processus de regroupement clustering permettant de grouper et de visualiser un sousensemble de règles dassociation génériques le rendu visuel à lécran exploite une représentation de type fisheye view de manière à obtenir simultanément une représentation globale des différents groupes de règles et une vue détaillée du groupe sélectionné\n",
      "visualisation de graphes avec tulip  exploration interactive de grandes masses de données en appui à la fouille de données et à lextraction de connaissances\n",
      "cet article décrit une étude de cas exhibant les qualités de la plateforme de visualisation de graphes tulip démontrant lapport de la visualisation à la fouille de données interactive et à lextraction de connaissances le calcul dun graphe à partir dindices de similarité est un exemple typique où lexploration visuelle et interactive de graphes vient en appui au travail de fouille de données nous penchons sur le cas où lon souhaite étudier une collection de documents afin davoir une idée des thématiques abordées dans la collection\n",
      "visualisation exploratoire des résultats dalgorithmes darbre de décision\n",
      "nous présentons une méthode dexploration des résultats des algorithmes dapprentissage par arbre de décision comme c45 la méthode présentée utilise simultanément une visualisation radiale focuscontext fisheye et hiérarchique pour la représentation et lexploration des résultats des algorithmes darbre de décision lutilisateur peut ainsi extraire facilement des règles dinduction et élaguer larbre obtenu dans une phase de posttraitement cela lui permet davoir une meilleure compréhension des résultats obtenus les résultats des tests numériques avec des ensembles de données réelles montrent que la méthode proposée permet une bien meilleure compréhension des résultats des arbres de décision\n",
      "webdocenrich  enrichissement sémantique flexible de documents semistructurés\n",
      "webdocenrich est une approche denrichissement sémantique automatique de documents html hétérogènes qui exploite une description du domaine pour enrichir le contenu des documents et les représenter en xml\n",
      "accès aux connaissances orales par le résumé automatique\n",
      "le temps nécessaire pour écouter un flux audio est un facteur réduisant laccès efficace àde grandes archives de parole une première approche la structuration automatique des donnéespermet dutiliser un moteur de recherche pour cibler plus rapidement linformation leslistes de résultats générées sont longues dans un souci dexhaustivité alors que pour des documentstextuels un coup doeil discrimine un résultat interessant dun résultat non pertinantil faut écouter laudio dans son intégralité pour en capturer le contenu nous proposons doncdutiliser le résumé automatique afin de structurer les résultats des recherches et den réduirela redondance\n",
      "affectation pondérée sur des données de type intervalle\n",
      "on sintéresse à la construction darbres de décision sur des données symboliques de type intervalle en utilisant le critère de découpage binaire de kolmogorovsmirnov nous proposons une approche permettant daffecter un individu à la fois aux deux noeuds fils générés par le partitionnement dun noeud non terminal le but de cette méthode est de prendre en compte le positionnement de la donnée à classer par rapport à la donnée seuil de coupure\n",
      "aide en gestion hospitalière par visualisation des composantes de nonpertinence\n",
      "nan\n",
      "algorithme semiinteractif pour la sélection de dimensions\n",
      "nous présentons un algorithme génétique semiinteractif de sélectionde dimensions dans les grands ensembles de données pour la détectiondindividus atypiques outliers les ensembles de données possédant unnombre élevé de dimensions posent de nombreux problèmes aux algorithmesde fouille de données une solution est deffectuer un prétraitement afin de neretenir que les dimensions intéressantes nous utilisons un algorithmegénétique pour le choix du sousensemble de dimensions à retenir par ailleursnous souhaitons donner un rôle plus important à lutilisateur dans le processusde fouille nous avons donc développé un algorithme génétique semiinteractifoù lévaluation des solutions nélimine pas complètement la fonctiondévaluation mais la couple avec une évaluation de lutilisateur enfinlimportante réduction du nombre de dimensions nous permet de visualiser lesrésultats de lalgorithme de détection doutlier cette visualisation permet àlexpert des données détiqueter les éléments atypiques erreurs ou simplementdes individus différents de la masse\n",
      "alignement extensionnel et asymétrique de hiérarchies conceptuelles par découverte dimplications entre concepts\n",
      "dans la littérature de nombreux travaux traitent de méthodes dalignementdontologies ils utilisent pour la plupart des relations basées sur desmesures de similarité qui ont la particularité dêtre symétriques cependant peude travaux évaluent lintérêt dutiliser des mesures dappariement asymétriquesdans le but denrichir lalignement produit ainsi nous proposons dans ce papierune méthode dalignement extensionnelle et asymétrique basée sur la découvertedes implications significatives entre deux ontologies notre approchebasée sur le modèle probabiliste décart à lindépendance appelé intensité dimplicationest divisée en deux parties consécutives  1 lextraction à partir ducorpus textuel associé à lontologie et lassociation des termes aux concepts2 la découverte et sélection des implications génératrices les plus significativesentre les concepts la méthode proposée est évaluée sur deux jeux de donnéesréels portant respectivement sur des profils dentreprises et sur des cataloguesde cours duniversités les résultats obtenus montrent que lon peut trouver desrelations pertinentes qui sont ignorées par un alignement basé seulement sur desmesures de similarité\n",
      "amélioration des indicateurs techniques pour lanalyse du marché financier\n",
      "la technique des motifs fréquents a été utilisée pour améliorer lepouvoir prédictif des stratégies quantitatives innovant dans le contexte desmarchés financiers notre méthode associe une signature aux configurations demarché fréquentes un système de « trading » automatique sélectionne lesmeilleures signatures par une procédure de « back testing » itérative et les utiliseen combinaison avec lindicateur technique pour améliorer sa performancelapplication des motifs fréquents à cette problématique des indicateurstechniques est une contribution originale au sens du test t de studentnotre méthode améliore nettement les approches sans signatures la techniquea été testé sur des données journalières type taux dintérêt et actions notreanalyse des indicateurs williamsr bn et croisement des moments a montréque quune approche par signatures est particulièrement bien adaptée auxstratégies à mémoire courte\n",
      "analyse du comportement des utilisateurs exploitant une base de données vidéo\n",
      "dans cet article nous présentons un modèle de fouille des usages dela vidéo pour améliorer la qualité de lindexation nous proposons une approchebasée sur un modèle à deux niveaux représentant le comportement des utilisateursexploitant un moteur de recherche vidéo le premier niveau consiste àmodéliser le comportement lors de la lecture dune vidéo unique comportementintra vidéo le second à modéliser le comportement sur lensemble dune sessioncomportement inter video a partir de cette représentation nous avonsdéveloppé un algorithme de regroupement adapté à la nature particulière de cesdonnées lanalyse des usages de la vidéo nous permet daffiner lindexationvidéo sur la base de lintérêt des utilisateurs\n",
      "annotation sémantique de pages web\n",
      "cet article présente un système automatique dannotation sémantiquede pages web les systèmes dannotation automatique existants sont essentiellementsyntaxiques même lorsque les travaux visent à produire une annotationsémantique la prise en compte dinformations sémantiques sur le domaine pourlannotation dun élément dans une page web à partir dune ontologie supposedaborder conjointement deux problèmes  1 lidentification de la structuresyntaxique caractérisant cet élément dans la page web et 2 lidentification duconcept le plus spécifique en termes de subsumption dans lontologie dontlinstance sera utilisée pour annoter cet élément notre démarche repose sur lamise en oeuvre dune technique dapprentissage issue initialement des wrappersque nous avons articulée avec des raisonnements exploitant la structure formellede lontologie\n",
      "apprentissage de la structure des réseaux bayésiens à partir des motifs fréquents corrélés  application à lidentification des facteurs environnementaux du cancer du nasopharynx\n",
      "lapprentissage de structure des réseaux bayésien à partir de donnéesest un problème npdifficile pour lequel de nombreuses heuristiques ont été proposéesdans cet article nous proposons une nouvelle méthode inspirée des travauxsur la recherche de motifs fréquents corrélés pour identifier les causalitésentre les variables lalgorithme opère en quatre temps  1 la découvertepar niveau des motifs fréquents corrélés minimaux  2 la construction dungraphe non orienté à partir de ces motifs  3 la détection des vstructures etlorientation partielle du graphe  4 lélimination des arêtes superflues par destests dindépendance conditionnelle la méthode appliquée au réseau asia permetde retrouver la structure du graphe initial nous lappliquons ensuite auxdonnées dune étude épidémiologique castémoins du cancer du nasopharynxnpc lobjectif est de dresser un profil statistique type de la population étudiéeet dapporter un éclairage utile sur les différents facteurs impliqués dans lenpc\n",
      "approche entropique pour lanalyse de modèle de chroniques\n",
      "cet article propose dutiliser lentropie informationnelle pouranalyser des modèles de chroniques découverts selon une approchestochastique bouché et le goc 2005 il décrit une adaptation de lalgorithmetemporalid3 console et picardi 2003 permettant de découvrir des modèlesde chroniques à partir dun ensemble dapprentissage contenant des séquencesdoccurrences dévénements discrets ces séquences représentent des suitesdalarmes générées par un système à base de connaissance de monitoring et dediagnostic de systèmes dynamiques on montre sur un exemple que lapprocheentropique complète lapproche stochastique en identifiant les classesdévénements qui contribuent le plus significativement à la prédiction duneoccurrence dune classe particulière\n",
      "arabase  base de données web pour lexploitation en reconnaissance optique de lécriture arabe\n",
      "nan\n",
      "arbres de décision multi modes et multi cibles\n",
      "nous présentons une nouvelle méthode dinduction darbre de décision appelée mumtree pour multi models tree utilisable pour les modes dapprentissage supervisé non supervisé supervisé à plusieurs variables cibles nous présentons les différents principes nécessaires pour réaliser un tel arbre de décision nous illustrons ensuite sur un cas de modélisation multicibles les avantages de cette méthode par rapport à un arbre de décision classique\n",
      "archiview un outil de visualisation topographique des paramètres dun hôpital\n",
      "nan\n",
      "biclustering of gene expression data based on local nearness\n",
      "the analysis of gene expression data in dna chips is an importanttool used in genomic research whose main objectives range from the study ofthe functionality of specific genes and their participation in biological processto the reconstruction of diseasess conditions and their subsequent prognosisgene expression data are arranged in matrices where each gene corresponds toone row and every column represents one specific experimental condition thebiclustering techniques have the purpose of finding subsets of genes that showsimilar activity patterns under a subset of conditions our approach consists ofa biclustering algorithm based on local nearness the algorithm searches forbiclusters in a greedy fashion starting with two–genes biclusters and includingas much as possible depending on a distance threshold which guarantees thesimilarity of gene behaviors\n",
      "bordures statistiques pour la fouille incrémentale de données dans les data streams\n",
      "récemment la communauté extraction de connaissances sest intéressée à de nouveaux modèles où les données arrivent séquentiellement sous la forme dun flot rapide et continu ie les data streams lune des particularités importantes de ces flots est que seule une quantité dinformation partielle est disponible au cours du temps ainsi après différentes mises à jour successives il devient indispensable de considérer lincertitude inhérente à linformation retenue dans cet article nous introduisons une nouvelle approche statistique en biaisant les valeurs supports pour les motifs fréquents cette dernière a lavantage de maximiser lun des deux paramètres précision ou rappel déterminés par lutilisateur tout en limitant la dégradation sur le paramètre non choisi pour cela nous définissons les notions de bordures statistiques cellesci constituent les ensembles de motifs candidats qui savèrent très pertinents à utiliser dans le cas de la mise à jour incrémentale des streams les différentes expérimentations effectuées dans le cadre de recherche de motifs séquentiels ont montré lintérêt de lapproche et le potentiel des techniques utilisées\n",
      "carte autoorganisatrice probabiliste sur données binaires\n",
      "lesméthodes factorielles danalyse exploratoire statistique définissentdes directions orthogonales informatives à partir dun ensemble de donnéeselles conduisent par exemple à expliquer les proximités entre individus à laidedun groupe de variables caractéristiquesdans le contexte du datamining lorsqueles tableaux de données sont de grande taille une méthode de cartographie synthétiquesavère intéressante ainsi une carte autoorganisatrice som est uneméthode de partitionnement munie dune structure de graphe de voisinage surles classes le plus souvent planaire des travaux récents sont développés pourétendre le som probabiliste generative topographic mapping gtm aux modèlesde mélanges classiques pour données discrètes dans ce papier nous présentonset étudions un modèle génératif symétrique de carte autoorganisatricepour données binaires que nous appelons bernoulli aspect topological modelbatm nous introduisons un nouveau lissage et accélérons la convergence delestimation par une initialisation originale des probabilités en jeu\n",
      "champs de markov conditionnels pour le traitement de séquences\n",
      "les modèles conditionnels du type modèles de markov dentropiemaximale et champs de markov conditionnels apportent des réponses auxlacunes des modèles de markov cachés traditionnellement employés pour laclassification et la segmentation de séquences ces modèles conditionnels ontété essentiellement utilisés jusquà présent dans des tâches dextractiondinformation ou détiquetage morphosyntaxique cette contribution explorelemploi de ces modèles pour des données de nature différente de type« signal » telles que la parole ou lécriture en ligne nous proposons desarchitectures de modèles adaptées à ces tâches pour lesquelles nous avonsdérivé les algorithmes dinférence et dapprentissage correspondant nousfournissons des résultats expérimentaux pour deux tâches de classification etdétiquetage de séquences\n",
      "choix du taux délagage pour lextraction de la terminologie une approche fondée sur les courbes roc\n",
      "le choix du taux délagage est crucial dans le but dacquérir une terminologiede qualité à partir de corpus de spécialité cet article présente uneétude expérimentale consistant à déterminer le taux délagage le plus adaptéplusieurs mesures dévaluation peuvent être utilisées pour déterminer ce tauxtels que la précision le rappel et le fscore cette étude sappuie sur une autremesure dévaluation qui semble particulièrement bien adaptée pour lextractionde la terminologie  les courbes roc receiver operating characteristics\n",
      "classification dun tableau de contingence et modèle probabiliste\n",
      "ces dernières années la classification croisée ou classification parblocs cestàdire la recherche simultanée dune partition des lignes et dunepartition des colonnes dun tableau de données est devenue un outil très utiliséen fouille de données dans ce domaine linformation se présente souvent sousforme de tableaux de contingence ou tableaux de cooccurrence croisant les modalitésde deux variables qualitatives dans cet article nous étudions le problèmede la classification croisée de ce type de données en nous appuyant sur un modèlede mélange probabiliste en utilisant lapproche vraisemblance classifiantenous proposons un algorithme de classification croisée basé sur la maximisationalternée de la vraisemblance associée à deux mélanges multinomiaux classiqueset nous montrons alors que sous certaines contraintes restrictives on retrouveles critères du chi2 et de linformation mutuelle des résultats sur des donnéessimulées et des données réelles illustrent et confirment lefficacité et lintérêt decette approche\n",
      "classification de documents xml à partir dune représentation linéaire des arbres de ces documents\n",
      "cet article présente un nouveau modèle de représentation pour la classificationde documents xml notre approche permet de prendre en compte soitla structure seule soit la structure et le contenu de ces documents lidée estde représenter un document par lensemble des souschemins de larbre xmlde longueur comprise entre n et m deux valeurs fixées a priori ces cheminssont ensuite considérés comme de simples mots sur lesquels on peut appliquerdes méthodes standards de classification par exemple kmeans nous évaluonsnotre méthode sur deux collections la collection inex et les rapports dactivitéde linria nous utilisons un ensemble de mesures bien connues dans le domainede la recherche dinformation lorsque les classes sont connues a priorilorsquelles ne sont pas connues nous proposons une analyse qualitative desrésultats qui sappuie sur les mots chemins les plus caractéristiques des classesgénérées\n",
      "classification des comptesrendus mammographiques à partir dune ontologie radiologique en owl\n",
      "dans cet article nous proposons un système de classification descomptesrendus mammographiques reposant sur une ontologie radiologiquedécrivant les signes radiologiques et les différentes classes de la classificationacr des systèmes birads dans le langage owl le système est conçu pourextraire les faits issus des textes libres de comptesrendus en étant dirigé parlontologie puis inférer la classe correspondante et en déduire lattitude à tenirà partir de la classification acr ce travail présente la construction dune ontologieradiologique mammaire dans le langage owl et son intérêt pour classerautomatiquement les comptesrendus de mammographies\n",
      "classification nonsupervisée de données relationnelles\n",
      "nan\n",
      "classifications hiérarchiques factorielles de variables\n",
      "on présente deux méthodes de classification hiérarchique ascendantede variables quantitatives et de fréquences chaque noeud de ces hiérarchiesregroupe deux classes de variables à partir dune analyse factorielle particulièrebasée sur les variables représentatives de ces deux classes par cette méthodeon dispose à chaque pas dun plan factoriel permettant de représenter àla fois les variables des deux classes fusionnées et lensemble des individusces derniers se positionnent dans ce plan suivant leurs valeurs pour les variablesconsidérées ainsi linterprétation des noeuds obtenus seffectue facilementà partir de lexamen de ces représentations factorielles la répartition desindividus observée dans chacun de ces plans factoriels permet également dedéfinir une segmentation des individus en total accord avec la hiérarchie desvariables obtenues on montre le fonctionnement des méthodes sur des exemplesréels\n",
      "clustering dynamique dun flot de données  un algorithme incrémental et optimal de détection des maxima de densité\n",
      "lextraction non supervisée et incrémentale de classes sur un flot dedonnées data stream clustering est un domaine en pleine expansion la plupartdes approches visent lefficacité informatique la nôtre bien que se prêtantà un passage à léchelle en mode distribué relève dune problématiquequalitative applicable en particulier au domaine de la veille informationnelle faire apparaître les évolutions fines les « signaux faibles » à partir des thématiquesextraites dun flot de documents notre méthode germen localise defaçon exhaustive les maxima du paysage de densité des données à linstant ten identifiant les perturbations locales du paysage à t1 et modifications defrontières induites par le document présenté son caractère optimal provient deson exhaustivité à une valeur du paramètre de localité correspond un ensembleunique de maxima et un découpage unique des classes qui la rend indépendantede tout paramètre dinitialisation et de lordre des données\n",
      "combinaison de lapproche inductive progressive et linguistique pour létiquetage morphosyntaxique des corpus de spécialité\n",
      "les étiqueteurs morphosyntaxiques sont de plus en plus performantset cependant un véritable problème apparaît lorsque nous voulons étiqueterdes corpus de spécialité pour lesquels nous navons pas de corpus annotés lacorrection des ambiguïtés difficiles est une étape importante pour obtenir uncorpus de spécialité parfaitement étiqueté pour corriger ces ambiguïtés et diminuerle nombre de fautes nous utilisons une approche itérative appelée inductionprogressive cette approche est une combinaison dapprentissage automatiquede règles rédigées par lexpert et de corrections manuelles qui secombinent itérativement afin dobtenir une amélioration de létiquetage tout enrestreignant les actions de lexpert à la résolution de problèmes de plus en plusdélicats lapproche proposée nous a permis dobtenir un corpus de biologiemoléculaire « correctement » étiqueté en utilisant ce corpus nous avons effectuéune étude comparative de quatre étiqueteurs supervisés\n",
      "comment formaliser les connaissances tacites dune organisation  le cas de la conduite du changement à la sncf\n",
      "nan\n",
      "comparaison de deux modes de représentation de données faiblement structurées en sciences du vivant\n",
      "cet article présente deux modes de représentation de linformationdans le cadre dune problématique en sciences du vivant le premier appliqué àla microbiologie prévisionnelle sappuie sur deux formalismes le modèle relationnelet les graphes conceptuels interrogés uniformément via une même interfacele second appliqué aux technologies des céréales utilise le seul modèlerelationnel cet article décrit les caractéristiques des données et compare les solutionsde représentation adoptées dans les deux systèmes\n",
      "comparaison de dissimilarités pour lanalyse de lusage dun site web\n",
      "lobtention dune classification des pages dun site web en fonctiondes navigations extraites des fichiers logs du serveur peut savérer très utilepour évaluer ladéquation entre la structure du site et lattente des utilisateurs onconstruit une telle typologie en sappuyant une mesure de dissimilarité entre lespages définie à partir des navigations le choix de la mesure la plus appropriéeà lanalyse du site est donc fondamental dans cet article nous présentons unsite de petite taille dont les pages sont classées en catégories sémantiques parun expert nous confrontons ce classement aux partitions obtenues à partir dediverses dissimilarités afin den étudier les avantages et inconvénients\n",
      "comparaison des mammographies par des méthodes dapprentissage\n",
      "nan\n",
      "comparaison des mesures dintérêt de règles dassociation  une approche basée sur des graphes de corrélation\n",
      "le choix des mesures dintérêt mi afin dévaluer les règles dassociationest devenu une question importante pour le posttraitement des connaissanceen ecd dans la littérature de nombreux auteurs ont discuté et comparéles propriétés des mi afin daméliorer le choix des meilleures mesures cependantil savère que la qualité dune règle est contextuelle  elle dépend à la fois dela structure de données et des buts du décideur ainsi certaines mesures peuventêtre appropriées dans un certain contexte mais pas dans dautres dans cet articlenous présentons une nouvelle approche contextuelle mise en applicationpar un nouvel outil arqat permettant à un décideur dévaluer et de comparerle comportement des mi sur ses jeux de données spécifiques cette approche estbasée sur lanalyse visuelle dun graphe de corrélation entre des mi objectivesnous employons ensuite cette approche afin de comparer et de discuter le comportementde trentesix mesures dintérêt sur deux ensembles de données a prioritrès opposés  un premier dont les données sont fortement corrélées et un secondaux données faiblement corrélées alors que nous attendions des différences importantesentre les graphes de corrélation de ces deux jeux dessai nous avonspu observer des stabilités de corrélation entre certaines mi qui sont révélatricesde propriétés indépendantes de la nature des données observées ces stabilitéssont récapitulées et analysées\n",
      "confrontation de points de vue dans le système porphyry\n",
      "nan\n",
      "credit scoring statistique et apprentissage\n",
      "basel 2 regulations brought new interest in supervised classification methodologies for predicting default probability for loans an important feature of consumer credit is that predictors are generally categorical logistic regression and linear discriminant analysis are the most frequently used techniques but are often unduly opposed vapniks statistical learning theory explains why a prior dimension reduction eg by means of multiple correspondence analysis improves the robustness of the score function ridge regression linear svm pls regression are also valuable competitors predictive capability is measured by auc or ginis index which are related to the well known nonparametric wilcoxonmannwhitney test among methodological problems reject inference is an important one since most samples are subject to a selection bias there are many methods none being satisfactory distinguish between good and bad customers is not enough especially for longterm loans the question is then not only “if” but “when” the customers default survival analysis provides new types of scores\n",
      "critère vt100 de sélection des règles dassociation\n",
      "lextraction de règles dassociation génère souvent un grand nombrede règles pour les classer et les valider de nombreuses mesures statistiquesont été proposées  elles permettent de mettre en avant telles ou telles caractéristiquesdes règles extraites elles ont pour point commun dêtre fonctioncroissante du nombre de transactions et aboutissent bien souvent àlacceptation de toutes les règles lorsque la base de données est de grandetaille dans cet article nous proposons une mesure inspirée de la notion de valeurtest elle présente comme principale caractéristique dêtre insensible à lataille de la base évitant ainsi lécueil des règles fallacieusement significativeselle permet également de mettre sur un même pied et donc de les comparerdes règles qui auront été extraites de bases de données différentes elle permetenfin de gérer différents seuils de signification des règles le comportement dela mesure est détaillé sur un exemple\n",
      "de lanalyse didactique à la modélisation informatique pour la conception dun eiah en chirurgie orthopédique\n",
      "lobjet de la recherche présentée est de concevoir un environnementinformatique dapprentissage qui permette de réduire lécart entre la formationthéorique des chirurgiens et leur formation pratique qui se dérouleprincipalement sur le mode du compagnonnage larticle expose laméthodologie et quelques illustrations du travail didactique danalyse desconnaissances et du système denseignement  apprentissage en milieuhospitalier chirurgie orthopédique ainsi que partie de la formalisationinformatique de cette connaissance cette modélisation permet la prise encompte dans lenvironnement informatique de connaissances pragmatiquespour le diagnostic des connaissances de lutilisateur en fonction des actionsquil effectue à linterface pendant la résolution dun problème pose de visdans le bassin et la prise de décision didactique qui suit  quelle rétroactionfournir pour affiner le diagnostic etou permettre lapprentissage souhaité\n",
      "définition et diffusion de signatures sémantiques dans les systèmes pairàpair\n",
      "les systèmes pairàpair peertopeer p2p égalàégal se sont popularisésces dernières années avec les systèmes de partage de fichiers sur internetde nombreuses recherches concernant loptimisation de la localisationdes données ont émergé et constituent un axe de recherche très actif la priseen compte de la sémantique du contenu des pairs dans le routage des requêtespermet daméliorer considérablement la localisation des données nous nousconcentrons sur lapproche planetp faisant usage de la notion de filtre de bloomqui consiste à propager une signature sémantique des pairs filtres de bloom àtravers le réseau nous présentons cette approche et en proposons une amélioration la création de filtres de bloom dynamiques dans le sens où leur tailledépend de la charge des pairs nombre de documents partagés\n",
      "des motifs séquentiels généralisés aux contraintes de temps étendues\n",
      "dans de nombreux domaines la recherche de connaissances temporellesest très appréciée des techniques ont été proposées aussi bien en fouille dedonnées quen apprentissage afin dextraire et de gérer de telles connaissancesen les associant également à la spécification de contraintes temporelles eg fenêtretemporelle maximale notamment dans le contexte de la recherche de motifsséquentiels cependant ces contraintes sont souvent trop rigides ou nécessitentune bonne connaissance du domaine pour ne pas extraire des informationserronées cest pourquoi nous proposons une approche basée sur la constructionde graphes de séquences afin de prendre en compte des contraintes de tempsplus souples ces contraintes sont relâchées par rapport aux contraintes de tempsprécédemment proposées elles permettent donc dextraire plus de motifs pertinentsafin de guider lanalyse des motifs obtenus nous proposons égalementun niveau de précision des contraintes temporelles pour les motifs extraits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eda  algorithme de désuffixation du langage médical\n",
      "nan\n",
      "enrichissement dontologies dans le secteur de leau douce en environnement internet distribué et multilingue\n",
      "nan\n",
      "esiea datalab logiciel de nettoyage et préparation de données\n",
      "nan\n",
      "exploration des paramètres discriminants pour les représentations vectorielles de la sémantique des mots\n",
      "les méthodes de représentation sémantique des mots à partir dune analyse statistique sont basées sur des comptes de cooccurences entre mots et unités textuelles ces méthodes ont des paramétrages complexes notamment le type dunité textuelle utilisée comme contexte ces paramètres déterminent fortement la qualité des résultats obtenus dans cet article nous nous intéressons au paramètrage de la technique dite hyperspace analogue to language halnous proposons une nouvelle méthode pour explorer ses paramètres discriminants cette méthode est basée sur lanalyse dun graphe de voisinage dune liste de mots de référence préclassés nous expérimentons cette méthode et en donnons les premiers résultats qui renforcent et complètent des résultats issus de travaux précédents\n",
      "exploration interactive de bases de connaissances  un retour dexpérience\n",
      "la navigation au sein de bases de connaissances reste un problèmeouvert sil existe plusieurs paradigmes de visualisation peu de travaux sur lesretours dexpérience sont disponibles dans le cadre de cet article nous noussommes intéressés aux différents paradigmes de navigation interactive au seinde bases documentaires annotées sémantiquement  laccès à la base deconnaissances seffectuant à travers lontologie du domaine dapplication cesparadigmes ont été évalués dans le cadre dune application industriellemécanique des fluides et échangeurs thermiques en fonction de critèresdéfinis par les utilisateurs lanalyse des retours dexpérience1 nous a permisde spécifier et de réaliser un nouveau navigateur dédié à la gestion dedocuments techniques annotés par une ontologie de domaine  le « eye tree »navigateur de type « polar fisheye view »\n",
      "extension de lalgorithme cure aux fouilles de données volumineuses\n",
      "nan\n",
      "extraction automatique de champs numériques dans des documents manuscrits\n",
      "nous décrivons dans cet article une chaine de traitement complète etgénérique permettant dextraire automatiquement les champs numériques numérosde téléphone codes clients codes postaux dans des documents manuscritslibres notre chaïne de traitement est constituée des trois étapes suivanteslocalisation des champs numériques potentiels selon une approche markoviennesans reconnaissance chiffre ni segmentation reconnaissance des séquences extraiteset vérification des hypothèses de localisation  reconnaissance en vue delimiter la fausse alarme génerée lors de létape de localisation lévaluation denotre système sur une base de 300 courriers manuscrits montre des performancesen rappelprécision intéressantes\n",
      "extraction dobjets vidéo  une approche combinant les contours actifs et le flot optique\n",
      "dans cet article nous présentons une méthode mixte de segmentationdobjets visuels dans une séquence dimages dune vidéo combinant à la foisune segmentation basée régions et lestimation de mouvement par flot optiquelapproche développée est basé sur une minimisation dune fonctionnelledénergie e qui fait intervenir les probabilités dappartenance densité avecune gaussienne en tenant compte des informations perceptuelles de couleur etde texture des régions dintérêt pour améliorer la méthode de détection et desuivi nous avons étendu la formulation énergétique de notre modèle decontour actif en incluant une force supplémentaire issue du calcul du flot optiquenous montrons lintérêt de cette approche mixte en terme de temps de calculet dextraction dobjets vidéo complexes et nous présentons les résultatsobtenus sur des séquences de corpus vidéo couleur\n",
      "extraction de motifs séquentiels dans les flots de données dusage du web\n",
      "ces dernières années de nouvelles contraintes sont apparues pour lestechniques de fouille de données ces contraintes sont typiques dun nouveaugenre de données  les “data streams” dans un processus de fouille appliquésur un data stream lutilisation de la mémoire est limitée de nouveaux élémentssont générés en permanence et doivent être traités le plus rapidement possibleaucun opérateur bloquant ne peut être appliqué sur les données et cellesci nepeuvent être observées quune seule fois a lheure actuelle la majorité des travauxrelatifs à lextraction de motifs dans les data streams ne concernent pas lesmotifs temporels nous montrons dans cet article que cela est principalement dûau phénomène combinatoire qui est lié à lextraction de motifs séquentiels nousproposons alors un algorithme basé sur lalignement de séquences pour extraireles motifs séquentiels dans les data streams afin de respecter la contrainte dunepasse unique sur les données une heuristique gloutonne est proposée pour segmenterles séquences nous montrons enfin que notre proposition est capabledextraire des motifs pertinents avec un support très faible\n",
      "extraction de relations dans les documents web\n",
      "nous présentons un système pour linférence de programmes dextraction de relations dans les documents web il utilise les vues textuelle et structurelle sur les documents lextraction des relations est incrémentale et utilise des méthodes de composition et denrichissement nous montrons que notre système est capable dextraire des relations pour les organisations existantes dans les documents web listes  tables tables tournées tables croisées\n",
      "extraction et identification dentités complexes à partir de textes biomédicaux\n",
      "nous présentons ici un système dextraction et didentification dentitésnommées complexes à lintention des corpus de spécialité biomédicale nousavons développé une méthode qui repose sur une approche mixte à base densemblede règles a priori et de dictionnaires contrôlés cet article expose lestechniques que nous avons mises en place pour éviter ou minimiser les problèmesde synonymie de variabilité des termes et pour limiter la présence denoms ambigus nous décrivons lintégration de ces méthodes au sein du processusde reconnaissance des entités nommées lintérêt de cet outil réside dans lacomplexité et lhétérogénéité des entités extraites cette méthode ne se limitepas à la détection des noms des gènes ou des protéines mais sadapte à dautresdescripteurs biomédicaux nous avons expérimenté cette approche en mesurantles performances obtenues sur le corpus de référence genia\n",
      "extraction multilingue de termes à partir de leur structure morphologique\n",
      "nan\n",
      "fabrcl  méthode de classification croisée de protéines\n",
      "dans cet article nous proposons une méthode de classification croiséepermettant de classer des protéines dune part et de classer des descripteurs 3grammes selon leurs pertinences par rapport aux groupes de protéines obtenusdautres part\n",
      "faire vivre un référentiel métier dans lindustrie  le système de gestion de connaissances icare\n",
      "la gestion des connaissances enjeu majeur pour lindustrie est entréedans une phase concrète de déploiement la conjonction dune maturitédes organisations dans la maîtrise de leur métier la consolidation de méthodeset les outils évolutifs pour faire vivre un patrimoine de connaissances favorisentlémergence de projets significatifs et leur diffusion opérationnelle au seinde grands groupes industriels icare chez psa peugeot citroën réalisé aveclenvironnement ardans knowledge maker en est ici lexemple\n",
      "fastmgb  nouvelle base générique minimale de règles associatives\n",
      "le problème de lexploitation des règles associatives est devenu primordialpuisque le nombre des règles associatives extraites des jeux de donnéesréelles devient très élevé une solution possible consiste à ne dériver quunebase générique de règles associatives cet ensemble de taille réduite permet degénérer toutes les règles associatives via un système axiomatique adéquat danscet article nous proposons une nouvelle approche fastmgb qui permet dedériver directement à partir du contexte dextraction formel une base génériqueminimale de règles associatives\n",
      "finding fragments of orders and total orders from 01 data\n",
      "highdimensional collections of 01 data occur in many applications the attributes insuch data sets are typically considered to be unordered however in many cases there is anatural total or partial order underlying the variables of the data set examples of variablesfor which such orders exist include terms in documents and paleontological sites in fossil datacollections we describe methods for finding fragments of total orders from such data basedon finding frequently occurring patterns we also discuss techniques for finding good totalorderings seriation based on spectral ordering and mcmc methods\n",
      "fouille de données dans les systèmes pairàpair pour améliorer la recherche de ressources\n",
      "la quantité de sources dinformation disponible sur internet fait dessystèmes déchanges pairàpair p2p un genre nouveau darchitecture qui offreà une large communauté des applications pour partager des fichiers des calculsdialoguer ou communiquer en temps réel dans cet article nous proposonsune nouvelle approche pour améliorer la localisation dune ressource sur un réseaup2p non structuré en utilisant une nouvelle heuristique nous proposonsdextraire des motifs qui apparaissent dans un grand nombre de noeuds du réseaucette connaissance est très utile pour proposer aux utilisateurs des fichierssouvent demandés en requête ou en téléchargement et éviter une trop grandeconsommation de la bande passante\n",
      "fouille de données spatiales approche basée sur la programmation logique inductive\n",
      "ce qui caractérise la fouille de données spatiales est la nécessité de prendre en compte les interactions des objets dans lespace les méthodes classiques de fouille de données sont mal adaptées pour ce type danalyse nous proposons dans cet article une approche basée sur la programmation logique inductive elle se base sur deux idées la première consiste à matérialiser ces interactions spatiales dans des tables de distances ramenant ainsi la fouille de données spatiales à la fouille de fonnées multitables la seconde transforme les données en logique du premier ordre et applique ensuite la programmation logique inductive cet article présentera cette approche il décrira son application à la classification supervisée par arbre de décision spatial il présentera aussi les expérimentations réalisées et les résultats obtenus sur lanalyse de la contamination des coquillages dans la lagune de thau\n",
      "gestion de connaissances  compétences et ressources pédagogiques\n",
      "nan\n",
      "graphes de voisinage pour lindexation et linterrogation dimages par le contenu\n",
      "la découverte dinformations cachées dans les bases de données multimédiasest une tâche difficile à cause de leur structure complexe et à la subjectivitéliée à leur interprétation face à cette situation lutilisation dun indexest primordiale un index multimédia permet de regrouper les données selondes critères de similarité nous proposons dans cet article dapporter une améliorationà une approche déjà existante dinterrogation dimages par le contenu nous proposons une méthode efficace pour mettre à jour localement les graphesde voisinage qui constituent notre structure dindex multimédia cette méthodeest basée sur une manière intelligente de localisation de points dans un espacemultidimensionnel des résultats prometteurs sont obtenus après des expérimentationssur diverses bases de données\n",
      "isemantec  une plateforme collaborative de capitalisation des connaissances métier en conception de produits industriels\n",
      "nan\n",
      "indexation de vues virtuelles dans un médiateur xml pour le traitement de xquery text\n",
      "intégrer le traitement de requêtes de recherche dinformation dans unmédiateur xml est un problème difficile ceci est notamment dû au fait quecertaines sources de données ne permettent pas de recherche sur motclefs etdistance ni de classer les résultats suivant leur pertinence dans cet article nousabordons lintégration des fonctionnalités principales du standard xquery textdans xlive un médiateur xmlxquery pour cela nous avons choisidindexer des vues virtuelles de documents les documents virtuelssélectionnés sont transformés en objets des sources lopérateur de sélectiondu médiateur est étendu pour supporter des recherches dinformation sur lesdocuments de la vue la recherche sur motsclefs et le classement de résultatsont ainsi supportés notre formule de classement de résultats est adaptée auformat de données semistructurées basé sur le nombre de motsclefs dans lesdifférents éléments et la distance entre les éléments dun résultat\n",
      "interrogation et vérification de documents owl dans le modèle des graphes conceptuels\n",
      "owl est un langage pour la description dontologies sur le web cependanten tant que langage owl ne fournit aucun moyen pour interpréter lesontologies quil décrit et étant orienté machine il reste difficilement compréhensiblepar lhumain on propose une approche de visualisation dinterrogationet de vérification de documents owl regroupées dans un unique environnementgraphique  le modèle des graphes conceptuels\n",
      "la fouille de graphes dans les bases de données réactionnelles au service de la synthèse en chimie organique\n",
      "la synthèse en chimie organique consiste à concevoir de nouvellesmolécules à partir de réactifs et de réactions les experts de la synthèse sappuientsur de très grandes bases de données de réactions quils consultent à traversdes procédures dinterrogation standard un processus de découverte denouvelles réactions leur permettrait de mettre au point de nouveaux procédés desynthèse cet article présente une modélisation des réactions par des graphes etintroduit une méthode de fouille de ces graphes de réaction qui permet de faireémerger des motifs génériques utiles à la prédiction de nouvelles réactions enfinlarticle fait le point sur létat actuel de ce travail de recherche en présentantle modèle général dans lequel sintégrera un nouvel algorithme de fouille deréactions chimiques\n",
      "le forage distribué des données  une méthode simple rapide et efficace\n",
      "dans cet article nous nous attaquons au problème du forage de trèsgrandes bases de données distribuées le résultat visé est un modèle qui soit etprédictif et descriptif appelé métaclassificateur pour ce faire nous proposonsde miner à distance chaque base de données indépendamment puis il sagitde regrouper les modèles produits appelés classificateurs de base sachant quechaque forage produira un modèle prédictif et descriptif représenté pour nos besoinspar un ensemble de règles de classification afin de guider lassemblage delensemble final de règles qui sera lunion des ensembles individuels de règlesun coefficient de confiance est attribué à chaque règle de chaque ensemble cecoefficient calculé par des moyens statistiques représente la confiance que nouspouvons avoir dans chaque règle en fonction de sa couverture et de son taux derreurface à sa capacité dêtre appliquée correctement sur de nouvelles donnéesnous démontrons dans cet article que grâce à ce coefficient de confiance lagrégationpure et simple de tous les classificateurs de base pour obtenir un agrégatde règles produit un métaclassificateur rapide et efficace par rapport aux techniquesexistantes\n",
      "maintaining an online bibliographical database the problem of data quality\n",
      "citeseer and googlescholar are huge digital libraries which provideaccess to computerscience publications both collections are operated likespecialized search engines they crawl the web with little human interventionand analyse the documents to classify them and to extract some metadata fromthe full texts on the other hand there are traditional bibliographic data baseslike inspec for engineering and pubmed for medicine for the field of computerscience the dblp service evolved from a small specialized bibliographyto a digital library covering most subfields of computer science the collectionsof the second group are maintained with massive human effort on the longterm this investment is only justified if data quality of the manually maintainedcollections remains much higher than that of the search engine style collectionsin this paper we discuss management and algorithmic issues of data quality wefocus on the special problem of person names\n",
      "méthode de récolte de traces de navigation sur interface graphique et visualisation de parcours\n",
      "nan\n",
      "modèle conceptuel pour bases de données multidimensionnelles annotées\n",
      "nos travaux visent à proposer une mémoire dexpertises décisionnellespermettant de conserver et de manipuler non seulement les données décisionnellesmais aussi lexpertise analytique des décideurs les données décisionnellessont représentées au travers de concepts multidimensionnels etlexpertise associée est matérialisée grâce au concept dannotation\n",
      "modèle décisionnel basé sur la qualité des données pour sélectionner les règles dassociations légitimement intéressantes\n",
      "dans cet article nous proposons dexploiter des mesures décrivant laqualité des données pour définir la qualité des règles dassociations résultantdun processus de fouille nous proposons un modèle décisionnel probabilistebasé sur le coût de la sélection de règles légitimement potentiellement intéressantesou inintéressantes si la qualité des données à lorigine de leur calcul estbonne moyenne ou douteuse les expériences sur les données de kddcup98 montrent que les 10 meilleures règles sélectionnées daprès leurs mesuresde support et confiance ne sont intéressantes que dans le cas où la qualité deleurs données est correcte voire améliorée\n",
      "modélisation informationnelle  un cadre méthodologique pour représenter des connaissances évolutives spatialisables\n",
      "pour comprendre et représenter les évolutions du bâti question renouvelée avec le développement des ntic lanalyste sappuie sur des connaissances évolutives ayant dans notre champ dapplication  le patrimoine architectural – un caractère spatialisable par lattachement à un lieu lambda mais aussi des caractéristiques handicapantes hétérogénéité incertitudes et contradictions etc en réponse nous utilisons ce caractère spatialisable pour intégrer les ressources constituant le jeu de connaissances propre à chaque édifice théorie sources documentaires observations cette démarche que nous nommons modélisation informationnelle a pour objectif un gain de compréhension du lieu architectural et des informations qui lui sont associées notre contribution introduit les filiations de cette démarche le cadre méthodologique qui la matérialise et discute de son application au cas concret de la place centrale de cracovie rynek glowny pour en évaluer lapport potentiel en matière de gestion et de visualisation de connaissances\n",
      "multicatégorisation de textes juridiques et retour de pertinence\n",
      "la fouille de données textuelles constitue un champ majeur dutraitement automatique des données une large variété de conférences commetrec lui sont consacrées dans cette étude nous nous intéressons à la fouillede textes juridiques dans lobjectif est le classement automatique de ces textesnous utilisons des outils danalyses linguistiques extraction de terminologiedans le but de repérer les concepts présents dans le corpus ces conceptspermettent de construire un espace de représentation de faible dimensionnalitéce qui nous permet dutiliser des algorithmes dapprentissage basés sur desmesures de similarité entre individus comme les graphes de voisinage nouscomparons les résultats issus du graphe et de c45 avec les svm qui eux sontutilisés sans réduction de la dimensionnalité\n",
      "outil de datamining spatial appliqué à lanalyse des risques liés au territoire\n",
      "nan\n",
      "prédiction de solubilité de molécules à partir des seules données relationnelles\n",
      "la recherche de médicaments passe par la synthèse de molécules candidatesdont lefficacité est ensuite testée ce processus peut être accéléré enidentifiant les molécules non solubles car cellesci ne peuvent entrer dans lacomposition dun médicament et ne devraient donc pas être étudiées des techniquesont été développées pour induire un modèle de prédiction de lindice desolubilité utilisant principalement des réseaux de neurones ou des régressionslinéaires multiples la plupart des travaux actuels visent à enrichir les donnéesde caractéristiques supplémentaires sur les molécules dans cet article nous étudionslintérêt de la construction automatique dattributs basée sur la structureintrinsèquement multirelationnelle des données les attributs obtenus sont utilisésdans un algorithme darbre de modèles auquel on associe une méthodede bagging les tests réalisés montrent que ces méthodes donnent des résultatscomparables aux meilleures méthodes du domaine qui travaillent sur des attributsconstruits par les experts\n",
      "préparation des données radar pour la reconnaissanceidentification de cibles aériennes\n",
      "la problématique générale présentée dans ce papier concerne lessystèmes intelligents dédiés pour laide à la prise de décision dans le domaineradar les premiers travaux ont donc consisté après avoir adapté le processusdextraction de connaissances à partir de données ecd au domaine radar àmettre en oeuvre les étapes en amont de la phase de fouille de données nousnous limitons dans ce papier à la phase de préparation des données imagesisar  inverse synthetic aperture radar nous introduisons ainsi la notion dequalité comme moyen dévaluer limperfection dans les données radarsexpérimentales\n",
      "prétraitement de grands ensembles de données pour la fouille visuelle\n",
      "nous présentons une nouvelle approche pour le traitement des ensemblesde données de très grande taille en fouille visuelle de données les limitesde lapproche visuelle concernant le nombre dindividus et le nombre dedimensions sont connues de tous pour pouvoir traiter des ensembles de donnéesde grande taille une solution possible est deffectuer un prétraitement delensemble de données avant dappliquer lalgorithme interactif de fouille visuellepour ce faire nous utilisons la théorie du consensus avec une affectationvisuelle des poids nous évaluons les performances de notre nouvelle approchesur des ensembles de données de luci et du kent ridge bio medicaldataset repository\n",
      "recherche de règles non redondantes par vecteurs de bits dans des grandes bases de motifs \n",
      "nan\n",
      "recherche de sousstructures fréquentes pour lintégration de schémas xml\n",
      "la recherche dun schéma médiateur à partir dun ensemble de schémasxml est une problématique actuelle où les résultats de recherche issusde la fouille de données arborescentes peuvent être adoptés dans ce contexteplusieurs propositions ont été réalisées mais les méthodes de représentation desarborescences sont souvent trop coûteuses pour permettre un véritable passageà léchelle dans cet article nous proposons des algorithmes de recherche desousschémas fréquents basés sur une méthode originale de représentation deschémas xml nous décrivons brièvement la structure adoptée pour ensuitedétailler les algorithmes de recherche de sousarbres fréquents sappuyant surune telle structure la représentation proposée et les algorithmes associés ontété évalués sur différentes bases synthétiques de schémas xml montrant ainsilintérêt de lapproche proposée\n",
      "recherche en temps réel de préfixes massifs hiérarchiques dans un réseau ip à laide de techniques de stream mining\n",
      "au cours de ces dernières années de nombreuses techniques de streammining ont été proposées afin danalyser des flux de données en temps réeldans cet article nous montrons comment nous avons utilisé des techniques destream mining permettant la recherche dobjets massifs hiérarchiques hierarchicalheavy hitters dans un flux de données pour identifier en temps réel dans unréseau ip les préfixes dont la contribution au trafic dépasse une certaine proportionde ce trafic pendant un intervalle de temps donné\n",
      "reconnaissance automatique dévènements survenant sur patients en réanimation à laide dune méthode adaptative dextraction en ligne dépisodes temporels\n",
      "ce papier présente la version adaptative dun algorithmedextraction dépisodes temporels développé précédemment les trois paramètres de réglages de lalgorithme ne sont plus fixes ils sont modifiés en ligne enfonction de la variance estimée du signal que lon veut décomposer en épisodes temporels la version adaptative de lalgorithme a été utilisée pour reconnaître automatiquement des aspirations trachéales à partir de plusieures variables physiologiques enregistrés sur des patients hospitalisés en réanimationdes résultats préliminaires sont présentés dans ce papier\n",
      "reconnaissance automatique de concepts à partir dune ontologie\n",
      "ce papier présente une approche qui sappuie sur une ontologie pourreconnaître automatiquement des concepts spécifiques à un domaine dans uncorpus en langue naturelle la solution proposée est nonsupervisée et peutsappliquer à tout domaine pour lequel une ontologie a été déjà construite uncorpus du domaine est utilisé dans lequel les concepts seront reconnus dansune première phase des connaissances sont extraites de ce corpus en faisantappel à des fouilles de textes une ontologie du domaine est utilisée pour étiqueterces connaissance le papier donne un aperçu des techniques de fouillesemployées et décrit le processus d ‘étiquetage les résultats d‘une premièreexpérimentation dans le domaine de laccidentologie sont aussi présentés\n",
      "règles dassociation avec une prémisse composée  mesure du gain dinformation\n",
      "la communauté de fouille de données a développé un grand nombre dindices permettantde mesurer la qualité des règles dassociation ra selon diverses sémantiques guillet2004 cependant ces sémantiques qui permettent dinterpréter les règles simples savèrentdutilisation trop complexe pour un expert dans le cas de règles à prémisse composée notreobjectif est donc de sélectionner les règles à prémisse composée de type ab8594c quiapportent une information supplémentaire à celle des règles simples a8594c et b8594c pourcela nous définissons un indice de gain dune règle composée par rapport aux règles simplesdans lapplication présentée nous extrayons des ra de résultats de classifications pouren faciliter lanalyse  le gain a permis de filtrer des règles dinterprétation simple\n",
      "représentation dexpertise psychologique sous la forme de graphes orientés codés en rdf\n",
      "nan\n",
      "représentation des connaissances appliquées à la géotechnique  une approche\n",
      "nan\n",
      "sélection de variables et modélisation dexpression démotion dans les dialogues hommemachine\n",
      "nan\n",
      "sélection supervisée dinstances  une approche descriptive\n",
      "la classification suivant le plus proche voisin est une règle simple etperformante sa mise en oeuvre pratique nécessite tant pour des raisons de coûtde calcul que de robustesse de sélectionner les instances à conserver la partitionde voronoi induite par les prototypes constitue la structure sousjacente àcette règle dans cet article on introduit un critère descriptif dévaluation dunetelle partition quantifiant le compromis entre nombre de cellules et discriminationde la variable cible entre les cellules une heuristique doptimisation estproposée tirant partie des propriétés des partitions de voronoi et du critère laméthode obtenue est comparée avec les standards sur une vingtaine de jeux dedonnées de luci notre technique ne souffre daucun défaut de performanceprédictive tout en sélectionnant un minimum dinstances de plus elle ne surapprendpas\n",
      "svm incrémental parallèle et distribué pour le traitement de grandes quantités de données\n",
      "nous présentons un nouvel algorithme de svm support vectormachine ou séparateur à vaste marge linéaire et nonlinéaire parallèle etdistribué permettant le traitement de grands ensembles de données dans untemps restreint sur du matériel standard a partir de lalgorithme de newtongsvm proposé par mangasarian nous avons construit un algorithmeincrémental parallèle et distribué permettant daméliorer les performances entemps dexécution et mémoire en sexécutant sur un groupe dordinateurs cenouvel algorithme a la capacité de classifier un million dindividus en 20dimensions et deux classes en quelques secondes sur un ensemble de dix pc\n",
      "système daide à la décision pour la surveillance de la qualité de lair intérieur\n",
      "nan\n",
      "techniques de fouille de données pour la réécriture de requêtes en présence de contraintes de valeurs\n",
      "dans cet article nous montrons comment les techniques de fouilles de données peuvent résoudre efficacement le problème de la réécriture de requêtes en termes de vues en présence de contraintes de valeurs a partir dune formalisation du problème de la réécriture dans le cadre de la logique de description alnov nous montrons comment ce problème se rattache à un cadre de découverte de connaissances dans les bases de données lexploitation de ce cadre nous permet de bénéficier de solutions algorithmiques existantes pour la résolution du problème de réécriture nous proposons une implémentation de cette approche puis nous lexpérimentons les premiers résultats démontrent lintérêt dune telle approche en termes de capacité à traiter un grand nombre de sources de données\n",
      "teximus expertise  un logiciel de gestion de connaissances\n",
      "le logiciel teximus expertise est un outil évolué de gestion dynamiquede connaissances basé sur les notions de référentiel sémantique cette suiteintégrée facilite le partage de connaissances et dinformations dans les entreprises\n",
      "typicalité et contribution des sujets et des variables supplémentaires en analyse statistique implicative\n",
      "lanalyse statistique implicative traite des tableaux sujets xvariables afin dextraire règles et métarègles statistiques entre les variableslarticle interroge les structures obtenues représentées par graphe et hiérarchieorientés afin de dégager la responsabilité des sujets ou des groupes de sujetsvariables supplémentaires dans la constitution des chemins du graphe ou desclasses de la hiérarchie on distingue les concepts de typicalité pour signifier laproximité des sujets avec le comportement moyen de la population envers lesrègles statistiques extraites puis de contribution pour quantifier le rôlequauraient les sujets par rapport aux règles strictes associées un exemple dedonnées réelles traité à laide du logiciel chic illustre et montre lintérêt deces deux concepts\n",
      "un automate pour évaluer la nature des textes\n",
      "on ne peut sintéresser aux textes sans sintéresser à leur nature la nature des textes permet de distinguer les textes dun point de vue primaire elle est utilisée pour identifier les textes artificiels pour la reconnaissance de la langue afin didentifier les spams en ce sens la méthode la plus connue reste encore la méthode de zipf cet article propose une nouvelle méthode basée sur un automate lautomate construit un signal pour chaque texte lautomate est présenté en détail et des expérimentations montrent son utilité dans les domaines aussi divers que ceux cités précédemment\n",
      "un logiciel permettant dapprendre des règles et leurs exceptions  area\n",
      "nan\n",
      "un modèle de qualité de linformation\n",
      "ce travail sintègre dans la problématique générale de la recherchedinformation  et plus particulièrement dans la personnalisation et la qualitédinformation dans cet article nous proposons un modèle multidimensionnelde la qualité de linformation décrivant les différents facteurs de qualité influantsur la personnalisation de linformation ce modèle permet de structurerles différents facteurs de qualité de linformation dans une hiérarchie afindassister lutilisateur dans la construction de son propre profil selon ses besoinset ses exigences en termes de qualité\n",
      "un modèle métier extensible adapté à la gestion de dépêches dagences de presse\n",
      "nan\n",
      "une approche distribuée pour lextraction de connaissances  application à lenrichissement de laspect factuel des bdg\n",
      "les systèmes dinformations géographiques sig sont utilisés pouraméliorer lefficacité des entreprises et des services publics en associantméthodes doptimisation et prise en compte de la dimension géographiquecependant les bases de données géographiques bdg stockées dans les sigsont restreintes à lapplication pour laquelle elles ont été conçues souvent lesutilisateurs demeurent contraints de lexistant et se trouvent dans le besoin dedonnées complémentaires pour une prise de décision adéquate doù lidée delenrichissement de laspect descriptif des bdg existantes pour atteindre cetobjectif nous proposons une approche qui consiste à intégrer un module defouille de données textuelles au sig lui même il sagit de proposer uneméthode distribuée de résumé de documents multiples à partir de corpus enlignelidée est de faire coopérer un ensemble dagents sentraidant afindaboutir à un résumé optimal\n",
      "une approche multiagent adaptative pour la simulation de schémas tactiques\n",
      "ce papier est consacré à la simulation ou à la réalisation automatiquede schémas tactiques par un groupe d´agents footballeurs autonomes son objectifest de montrer ce que peuvent apporter des techniques dapprentissagepar renforcement à des agents réactifs conçus pour cette tâche dans un premiertemps nous proposons une plateforme et une architecture dagents capabledeffectuer des schémas tactiques dans des cas relativement simples ensuitenous mettons en oeuvre un algorithme dapprentissage par renforcementpour permettre aux agents de faire face à des situations plus complexes enfinune série dexpérimentations montrent le gain apporté aux agents réactifs parlutilisation dalgorithmes dapprentissage\n",
      "une approche simple inspirée des réseaux sociaux pour la hiérarchisation des systèmes autonomes de linternet\n",
      "le transit des flux dinformation dans le réseau internet à léchellemondiale est régi par des accords commerciaux entre systèmes autonomes accordsqui sont mis en oeuvre via le protocole de routage bgp la négociationde ces accords commerciaux repose implicitement sur une hiérarchie des systèmesautonomes et la position relative de deux systèmes débouche sur un accordde type clientfournisseur un des systèmes le client est nettement mieuxclassé que lautre le fournisseur et le client paye le fournisseur pour le transitdes flux dinformation ou sur un accord de type peering transit gratuit dutrafic entre les deux systèmes en dépit de son importance il nexiste pas dehiérarchie officielle de linternet les clauses commerciales des accords entresystèmes autonomes ne sont pas nécessairement publiques ni de consensus surla façon détablir une telle hiérarchie nous proposons une heuristique simpleinspirée de la notion de centralité spectrale issue de lanalyse des réseaux sociauxpour analyser la position relative des systèmes autonomes de linternet àpartir des informations des seules informations de connectivité entre systèmesautonomes\n",
      "une comparaison de certains indices de pertinence des règles dassociation\n",
      "cet article propose une comparaison graphique de certains indices depertinence pour évaluer lintérêt des règles dassociation nous nous sommesappuyés sur une étude existante pour sélectionner quelques indices auxquelsnous avons ajouté lindice de jaccard et lindice daccords désaccords iadces deux derniers nous semblent plus adaptés pour discriminer les règles intéressantesdans le cas où les items sont des événements peu fréquents une applicationest réalisée sur des données réelles issues du secteur automobile\n",
      "une mesure de proximité et une méthode de regroupement pour laide à lacquisition dontologies spécialisées\n",
      "cet article traite du regroupement dunités textuelles dans une perspectivedaide à lélaboration dontologies spécialisées le travail présenté sinscritdans le cadre du projet biotim nous nous concentrons ici sur lune desétapes de construction semiautomatique dune ontologie qui consiste à structurerun ensemble dunités textuelles caractéristiques en classes susceptibles dereprésenter les concepts du domaine lapproche que nous proposons sappuiesur la dé\u0002nition dune nouvelle mesure nonsymétrique permettant dévaluer laproximité entre lemmes en utilisant leurs contextes dapparition dans les documentsen complément de cette mesure nous présentons un algorithme declassi\u0002cation nonsupervisée adapté à la problématique et aux données traitéesles premières expérimentations présentées sur les données botaniques laissentpercevoir des résultats pertinents pouvant être utilisés pour assister lexpert dansla détermination et la structuration des concepts du domaine\n",
      "une nouvelle mesure sémantique pour le calcul de la similarité entre deux concepts dune même ontologie\n",
      "les ontologies sont au coeur du processus de gestion des connaissancesdifférentes mesures sémantiques ont été proposées dans la littératurepour évaluer quantitativement limportance de la liaison sémantique entre pairesde concepts cet article propose une synthèse analytique des principales mesuressémantiques basées sur une ontologie modélisée par un graphe et restreinte iciaux liens hiérarchiques isa après avoir mis en évidence différentes limites desmesures actuelles nous en proposons une nouvelle la pss proportion of sharedspecificity qui sans corpus externe tient compte de la densité des liens dans legraphe reliant deux concepts\n",
      "utilisation de métadonnées pour laide à linterprétation de classes et de partitions\n",
      "les résultats des méthodes de fouille de données sont difficilementinterprétables par un utilisateur nayant pas lexpertise requise dans ce papiernous proposons un outil permettant aux utilisateurs dinterpréter les résultatsissus des méthodes de classification non supervisée cet outil est basé sur desmétadonnées utilisées pour formaliser le processus dinterprétationautomatique ces métadonnées vont servir à lutilisateur pour comprendre dansquelles circonstances les données originales ont été collectées et de quellemanière elles ont été agrégées puis classifiées lintérêt de ce travail porte surla souplesse quauront les utilisateurs à pouvoir interpréter facilement lesclasses obtenues nous développons notre approche basée sur lutilisation desmétadonnées nous traduirons notre méthodologie par un exemple concret\n",
      "utilisation des réseaux bayésiens dans le cadre de lextraction de règles dassociation\n",
      "cet article aborde le problème de lutilisation dun modèle de connaissancedans un contexte de fouille de données lapproche méthodologique proposéemontre lintérêt de la mise en oeuvre de réseaux bayésiens couplée à lextractionde règles dassociation dites deltafortes membre gauche minimal fréquenceminimale et niveau de confiance contrôlé la découverte de règles potentiellementutiles est alors facilitée par lexploitation des connaissances décritespar lexpert et représentées dans le réseau bayésien cette approche estvalidée sur un cas dapplication concernant la fouille de données dinterruptionsopérationnelles dans lindustrie aéronautique\n",
      "vers lextraction de motifs rares\n",
      "un certain nombre de travaux en fouille de données se sont intéressés à lextraction de motifs et à la génération de règles dassociation à partir de ces motifs cependant ces travaux se sont jusquà présent centrés sur la notion de motifs fréquents le premier algorithme à avoir permis lextraction de tous les motifs fréquents est apriori mais dautres ont été mis au point par la suite certains nextrayant que des sousensembles de ces motifs motifs fermés fréquents motifs fréquents maximaux générateurs minimaux dans cet article nous nous intéressons aux motifs rares qui peuvent également véhiculer des informations importantes les motifs rares correspondent au complémentaire des motifs fréquents a notre connaissance ces motifs nont pas encore été étudiés malgré lintérêt que certains domaines pourraient tirer de ce genre de modèle cest en particulier le cas de la médecine où par exemple il est important pour un praticien de repérer les symptômes non usuels ou les effets indésirables exceptionnels qui peuvent se déclarer chez un patient pour une pathologie ou un traitement donné\n",
      "visualisation en gestion des connaissances développement dun nouveau modèle graphique graphatanor\n",
      "les systèmes de gestion des connaissances servent de support pour lacréation et la diffusion de mémoires dentreprises qui permettent de capitaliserconserver et enrichir les connaissances des experts dans ces systèmes linteractionavec les experts est effectuée avec des outils adaptés dans lesquels uneformalisation graphique des connaissances est utilisée cette formalisation estsouvent basée au niveau théorique sur des modèles de graphes mais de façonpratique les représentations visuelles sont souvent des arbres et des limitationsapparaissent par rapport aux représentations basées sur des graphes dans cetarticle nous présentons le modèle utilisé par le serveur de connaissances atanorqui utilise des arbres pour visualiser les connaissances et nous développons unenouvelle approche qui permet de représenter les mêmes connaissances sous laforme de graphes en niveaux une analyse comparative des deux méthodes dansun contexte industriel de maintenance permet de mettre en valeur lapport desgraphes dans le processus de visualisation graphique des connaissances\n",
      "visualisation interactive de données avec des méthodes à base de points dintérêt\n",
      "nous présentons dans cet article une méthode de visualisation interactivede données numériques ou symboliques permettant à un utilisateur expertdu domaine dobtenir des informations et des connaissances pertinentes nousproposons une approche nouvelle en adaptant lutilisation des points dintérêtsdans un contexte de fouille visuelle de données a partir dun ensemble de pointsdintérêt disposés sur un cercle les données sont visualisées à lintérieur de cecercle en fonction de leur similarité à ces points dintérêt des opérations interactivessont alors définies  sélectionner zoomer changer dynamiquement lespoints dintérêts nous évaluons les propriétés dune telle visualisation sur desdonnées aux caractéristiques connues nous décrivons une application réelle encours dans le domaine de lexploration de données issues denquêtes de satisfaction\n",
      "web sémantique pour la mémoire dexpériences dune communauté scientifique  le projet meat\n",
      "cet article décrit le projet meat mémoire dexpériences pourlanalyse du transcriptome dont le but est dassister les biologistes travaillantdans le domaine des puces à adn pour linterprétation et la validation de leursrésultats nous proposons une aide méthodologique et logicielle pour construireune mémoire dexpériences pour ce domaine notre approche basée surles technologies du web sémantique repose sur lutilisation des ontologies etdes annotations sémantiques sur des articles scientifiques et dautres sourcesde connaissances du domaine notre approche peut être généralisée à dautresdomaines requérant des expérimentations et traitant un grand flux de donnéesprotéomique chimieetc\n",
      "web usage mining  extraction de périodes denses à partir des logs\n",
      "les techniques de web usage mining existantes sont actuellementbasées sur un découpage des données arbitraire eg un log par mois ou guidépar des résultats supposés eg quels sont les comportements des clients pourla période des achats de noël   ces approches souffrent des deux problèmessuivants dune part elles dépendent de cette organisation arbitraire des donnéesau cours du temps dautre part elles ne peuvent pas extraire automatiquementdes pics saisonniers dans les données stockées nous proposons dexploiterles données pour découvrir de manière automatique des périodes denses decomportements une période sera considérée comme dense si elle contient aumoins un motif séquentiel fréquent pour lensemble des utilisateurs qui étaientconnectés sur le site à cette période\n",
      "acka  une approche dacquisition coopérative de connaissances pour la construction dun modèle de simulation multiagents\n",
      "cet article présente une approche acka an approach for cooperative knowledge acquisition participative et coopérative dacquisition de connaissances nécessaires pour la construction dun modèle de simulation basé sur des agents elle est basée sur le principe de jeu de rôles dans une réunion dentreprise nous proposons de construire un modèle multiacteurs représentant un modèle initial du système multiagents dans cette étude nous appliquons acka pour construire un modèle multiacteurs pour la compréhension des processus de décision dans les rmes de la liere avicole en particulier nous cherchons à comprendre les impacts des comportements individuels sur la gestion de lutilisation des matières premières agricoles\n",
      "acquisition et exploitation de connaissances dans un contexte multiexperts pour un système daide à la décision\n",
      "nous présentons une méthodologie dextraction de gestion et dexploitation de connaissances dans un contexte multiexperts elle repose sur trois étapes  extraction des connaissances de chaque expert gestion des connaissances individuelles afin de constituer une base de connaissances commune et exploitation de cette base afin de fournir une aide à la décision aux experts la méthodologie proposée a été mise en œuvre au cameroun avec cinq experts en microfinance elle a donné des résultats en adéquation avec les pratiques des experts audelà on envisage de mettre en œuvre un système de capitalisation des connaissances il doit permettre danalyser rapidement un plus grand nombre de situations les experts restant en nombre limité et contribuer à un transfert de compétences pour former les décideurs locaux en effet les experts sont en général membres dong et restent rarement plus de deux ans sur place\n",
      "aid  un framework intégré de conception dun schéma objetrelationnel\n",
      "devant la prolifération des données complexes qui ne cessent de croître et la diversité des structures qui se multiplient la conception des schémas de base de données en général et des schémas objetrelationnels en particulier est devenue une activité difficile et complexe qui fait appel à des connaissances variées lors de la conception dun schéma lutilisateur non averti doit connaître la théorie sousjacente au modèle de données de façon à énoncer son modèle syntaxiquement correct lui permettant de construire un schéma de base de données objetrelationnel répondant à ses besoins plusieurs outils spécialisés dans la conception de schémas de base de données provenant aussi bien de la communauté académique que du monde industriel tels super totem rationalrose etc ont été développés dans des contextes et avec des buts souvent très différents affin de répondre à ce besoin pressant nous avons proposé une solution consistant en lélaboration denvironnements intégrés facilitant la cohabitation de plusieurs modèles et techniques utilisés lors de la conception dun schéma de base de données il sagit doffrir une plateforme logicielle appelée aid aided interface for database design offrant des mécanismes opératoires uniformes représentant un soutien graphique et interactif pour une conception incrémentale basée sur des manipulations directes et systémiques des graphes au travers dune palette graphique dopérateurs linnovation daid est son approche systémique qui facilite lexpression des besoins par le concepteur averti ou non en lui automatisant sa tâche\n",
      "amélioration de la performance de lanalyse de la sémantique latente pour des corpus de petite taille\n",
      "nan\n",
      "analyse comparative de classifications  apport des règles dassociation floues\n",
      "notre travail sappuie sur lanalyse dun corpus bibliographique dans le domaine de la géotechnique à laide de cartes réalisées avec la plateforme stanalyst® celuici intègre un algorithme de classification automatique non hiérarchique les kmeans axiales donnant des résultats dépendant du nombre de classes demandé cette instabilité rend difficile toute comparaison entre classifications et laisse un doute quant au choix du nombre de classes nécessaire pour représenter correctement un domaine nous comparons les résultats de classifications selon 3 protocoles  1 analyse des intitulés des classes  2 relations entre les classes à partir des membres communs  3 règles dassociation floues les graphes obtenus présentant des similitudes remarquables nous privilégions les règles dassociation floues  elles sont extraites automatiquement et se basent sur la description des classes et non des membres ceci nous permet donc danalyser des classifications issues de corpus différents\n",
      "analyse de données symboliques et graphe de connaissances dun agent\n",
      "dans cet article nous appliquons lanalyse de données symboliques au graphe de connaissances dun agent nous présentons une mesure de similarité entre des données symboliques adaptée à nos graphes de connaissances nous utilisons les pyramides symboliques pour extraire un nouvel objet symbolique le nouvel objet est ensuite réinséré dans le graphe où il peut être utilisé par lagent faisant ainsi évoluer sa sémantique il peut alors servir dindividu lors des analyses ultérieures permettant de découvrir de nouveaux concepts prenant en compte lévolution de la sémantique\n",
      "analyse géométrique des données pour laffinement de la connaissance  cas des données epgy education program for gifted students stanford university\n",
      "nan\n",
      "analyse stochastique de séquences dévénements discrets pour la découverte de signatures\n",
      "cet article concerne la découverte de signatures ou modèles de chroniques à partir dune séquence dévénements discrets alarmes générée par un agent cognitif de surveillance monitoring cognitive agent ou mcaconsidérant un couple processus mca comme un générateur stochastique dévénements discrets deux représentations complémentaires permettent de caractériser les propriétés stochastiques et temporelles dun tel générateur  une chaîne de markov à temps continu et une superposition de processus de poisson létude de ces deux représentations duales permet de découvrir des signatures décrivant les relations stochastiques et temporelles entre événements dans une séquence ces signatures peuvent alors être utilisées pour reconnaître des comportements spécifiques comme le montre lapplication de lapproche à un outil de production industriel piloté par un système sachem le mca développé et utilisé par le groupe arcelor pour aider au pilotage de ses outils de production\n",
      "annotation de textes par extraction dinformations lexicosyntaxiques  et acquisition de schémas conceptuels de causalité\n",
      "nous présentons la méthode insyse interface syntaxe semantique pour lannotation de documents textuels notre objectif est de construire des annotations sémantiques de ces résumés pour interroger le corpus sur la fonction des gènes et leurs relations de causalité avec certaines maladies notre approche est semiautomatique centrée sur 1 lextraction dinformations lexicosyntaxiques à partir de certaines phrases du corpus comportant des lexèmes de causation et 2 lélaboration de règles basées sur des grammaires dunification permettant dacquérir à partir de ces informations des schémas conceptuels instanciés ceuxci sont traduits en annotations rdfs sur la base desquelles le corpus de textes peut être interrogé avec le moteur de recherche sémantique corese\n",
      "apprentissage automatique des modèles structurels dobjets cartographiques\n",
      "pour reconnaitre les objets cartographiques dans les images satellitales on a besoin dun modèle dobjet quon recherche nous avons développé un système dapprentissage qui construit le modèle structurel dobjets cartographiques automatiquement a partir des images satellitales segmentées les images contenants les objets sont décomposées en formes primitives et sont transformées en graphes relationnels attribués args nous avons généré les modèles dobjets a partir de ces graphes en utilisant des algorithmes dappariement de graphes la qualité dun modèle est évaluée par la distance dédition des exemples a ce modèle nous sommes parvenus a obtenir des modèles de ponts et de rondspoints qui sont compatibles avec les modèles construits manuellement\n",
      "apprentissage de scénarios à partir de séries temporelles multivariées\n",
      "nan\n",
      "apprentissage de signatures de facteurs de transcription à partir de données dexpression\n",
      "linférence de signatures de facteurs de transcription à partir des données puces à adn a déjà été étudié dans la communauté bioinformatique la principale difficulté à résoudre est de trouver un ensemble dheuristiques pertinentes afin de contrôler la complexité de résolution de ce problème npdifficile nous proposons dans cet article une solution heuristique alternative à celles utilisées dans les approches bayésiennes fondée sur la recherche de motifs fréquents maximaux dans une matrice discrétisée issue des données numériques de puces adn notre méthode est appliquée sur des données de cancer de vessie de linstitut curie et de lhôpital henri mondor de créteil\n",
      "apprentissage de structures de réseaux bayésiens et données incomplètes\n",
      "le formalisme des modèles graphiques connait actuellement un essor dans les domaines du machine learning en particulier les réseaux bayésiens sont capables deffectuer des raisonnements probabilistes à partir de données incomplètes alors que peu de méthodes sont actuellement capables dutiliser les bases dexemples incomplètes pour leur apprentissage en sinspirant du principe de amsem proposé par friedman 1997 et des travaux dechow  liu 1968 nous proposons une méthode permettant de faire lapprentissage de réseaux bayésiens particuliers de structure arborescente à partir de données incomplètes une étude expérimentale expose ensuite des résultats préliminaires quil est possible dattendre dune telle méthode puis montre le gain potentiel apporté lorsque nous utilisons les arbres obtenus comme initialisation dune méthode de recherche gloutonne comme amsem\n",
      "apprentissage non supervisé de séries temporelles à laide des kmeans et dune nouvelle méthode dagrégation de séries\n",
      "lutilisation dun algorithme dapprentissage non supervisé de type kmeans sur un jeu de séries temporelles amène à se poser deux questions  celle du choix dune mesure de similarité et celle du choix dune méthode effectuant lagrégation de plusieurs séries afin den estimer le centre ie calculer les k moyennes afin de répondre à la première question nous présentons dans cet article les principales mesures de similarité existantes puis nous expliquons pourquoi lune dentre elles appelée dynamic time warping nous paraît la plus adaptée à lapprentissage non supervisé la deuxième question pose alors problème car nous avons besoin dune méthode dagrégation respectant les caractéristiques bien particulières du dynamic time warping nous pensons que lassociation de cette mesure de similarité avec lagrégation euclidienne peut générer une perte dinformations importante dans le cadre dun apprentissage sur la forme des séries nous proposons donc une méthode originale dagrégation de séries temporelles compatible avec le dynamic time warping qui améliore ainsi les résultats obtenus à laide de lalgorithme des kmeans\n",
      "apprentissage supervisé pour la classification des images basé sur la structure ptree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un problème important de la production automatique de règles de classification concerne la durée de génération de ces règles  en effet les algorithmes mis en œuvre produisent souvent des règles pendant un certain temps assez long nous proposons une nouvelle méthode de classification à partir dune base de données images cette méthode se situe à la jonction de deux techniques  lalgèbre de ptree et larbre de décision en vue daccélérer le processus de classification et de recherche dans de grandes bases dimages la modélisation que nous proposons se base dune part sur les descripteurs visuels tels que la couleur la forme et la texture dans le but dindexer les images et dautre part sur la génération automatique des règles de classification à laide dun nouvel algorithme c45ptree pour valider notre méthode nous avons développé un système baptisé ciadptree qui a été implémenté et confronté à une application réelle dans le domaine du traitement dimages les résultats expérimentaux montrent que cette méthode réduit efficacement le temps de classification\n",
      "arbre de décision sur des données de type intervalle  évaluation et comparaison\n",
      "le critère de découpage binaire de kolmogorovsmirnov nécessite un ordre total des valeurs prises par les variables explicatives nous pouvons ordonner des intervalles fermés bornés de nombres réels de différentes façons notre contribution dans cet article consiste à évaluer et à comparer des arbres de décision obtenus sur des données de type intervalle à laide du critère de découpage binaire de kolmogorovsmirnov étendu à ce type de données mballo et al 2004 pour ce faire nous axons notre attention sur le taux derreur mesuré sur léchantillon de test pour estimer ce paramètre nous divisons aléatoirement chaque base de données en deux parties égales en terme deffectif à un objet près pour construire deux arbres ces deux arbres sont dabord testés par un même échantillon puis par deux échantillons différents\n",
      "caractérisation dune région dintérêt dans les images\n",
      "une image est un support dinformation qui a montré son efficacité néanmoins une image comporte souvent plusieurs zones larrière plan et une zone dintérêt privilégiée la vision humaine permet la segmentation de manière naturelle et intégrant toute la connaissance que le sujet peut avoir de lobjectif visé par limage nous proposons ici une méthode de détermination des régions dintérêt dune image numérique comme zones saillantes les lois de zipf et zipf inverse sont adaptées au traitement des images et permettent dévaluer la complexité structurelle dune image une comparaison des modèles locaux évalués sur des imagettes permet de mettre en évidence une région de limage deux méthodes de classification ont été utilisées pour la détermination de la région dintérêt  la partition dun nuage de points représentant les caractéristiques associées aux imagettes et les réseaux de neurones cette méthode de détection permet dobtenir des zones dintérêt conformes à la perception humaine on opère une hiérarchisation sur les zones en fonction de la structuration de linformation élémentaire les pixels\n",
      "chic  traitement de données avec lanalyse implicative\n",
      "cet article a pour but de montrer les possibilités offertes par le logiciel chic classification hiérarchique implicative et cohésitive pour effectuer certaines analyses de données il est basé sur la théorie de lanalyse statistique implicative ou asi développée par régis gras et ses collaborateurs le principe premier de lasi repose sur la problématique dune mesure des règles dassociation du type  «si a alors b» dans une population instanciant les variables a et b chic enrichit sa réponse établie sur des bases statistiques en évaluant la responsabilité des sujets dans lélection de la règle larticle présent explique la démarche à suivre pour utiliser le logiciel ainsi que les possibilités offertes par celuici\n",
      "classification 23 hiéarchique de données du web\n",
      "nan\n",
      "classification dun tableau de contingence et modèle probabiliste\n",
      "les modèles de mélange qui supposent que léchantillon est formé de souspopulations caractérisées par une distribution de probabilité constitue un support théorique intéressant pour étudier la classification automatique on peut ainsi montrer que lalgorithme des kmeans peut être vu comme une version classifiante de lalgorithme destimation em dans un cas particulièrement simple de mélange de lois normales lorsque lon cherche à classifier les lignes ou les colonnes dun tableau de contingence il est possible dutiliser une variante de lalgorithme des kmeans appelé mndki2 en sappuyant sur la notion de profil et sur la distance du khi2 on obtient ainsi une méthode simple et efficace pouvant sutiliser conjointement à lanalyse factorielle des correspondances qui sappuie sur la même représentation des données malheureusement et contrairement à lalgorithme des kmeans classique les liens qui existent entre les modèles de mélange et la classification ne sappliquent pas directement à cette situation dans ce travail nous montrons que lalgorithme mndki2 peut être associé à une approximation près à un modèle de mélange de lois multinomiales\n",
      "classification non supervisée et visualisation 3d de documents\n",
      "le nombre de documents issus dune requête sur le web devient de plus en plus important cela nous amène à chercher des solutions pour aider lutilisateur qui est confronté à cette masse de données une alternative possible à un affichage linéaire non triée selon un critère consiste à effectuer une classification des résultats cest dans ce but que lon sintéresse aux cartes autoorganisatrices de kohonen qui sont issues dun dalgorithme de classification non supervisée cependant il faut ajouter des contraintes à cet algorithme afin quil soit adapté à la classification des résultats dune requête par exemple il doit être déterministe de plus la classification obtenue dépend fortement de la distance utilisée pour comparer deux documents on évalue alors limpact de différentes distances ou dissimilarités afin de trouver la plus adaptée à notre problème un compromis doit également être trouvé entre le temps dexécution de lalgorithme et la qualité de la classification obtenue pour cela lutilisation dun échantillonnage est envisagée enfin ces travaux sont intégrés dans un prototype qui permet de visualiser les résultats en trois dimensions et dinteragir avec eux\n",
      "classifying xml materialized views for their maintenance on distributed web sources\n",
      "ces dernières années ont mis en évidence la croissance et la diversité des informations électroniques accessibles sur le web cest ainsi que les systèmes dintégration de données tels que des médiateurs ont été conçus pour intégrer ces données distribuées et hétérogènes dans une vue uniforme pour faciliter lintégration des données à travers différents systèmes xml a été adopté comme format standard pour échanger des informations xquery est un langage dintégration des données à travers différents systèmes xml a été adopté comme format standard pour échanger des informations xquery est un langage dinterrogation pour xml qui sest imposé pour les systèmes basés sur xml ainsi xquery est employé sur des systèmes de médiation pour concevoir des vues définies sur plusieurs sources pour optimiser lévaluation de requêtes les vues sont matérialisées lors de la mise à jour des sources car dans le contexte de sources web très peu dinformations sont fournies par les sources les méthodes habituellement proposées ne peuvent pas être appliquées cet article étudie comment mettre à jour des vues matérialisées xml sur des sources web au sein dune architecture de médiation\n",
      "combinaison de fonctions de préférence par boosting pour la recherche de passages dans les systèmes de questionréponse\n",
      "nous proposons une méthode dapprentissage automatique pour la sélection de passages susceptibles de contenir la réponse à une question dans les systèmes de questionréponse qr les systèmes de ri ad hoc ne sont pas adaptés à cette tâche car les passages recherchés ne doivent pas uniquement traiter du même sujet que la question mais en plus contenir sa réponse pour traiter ce problème les systèmes actuels réordonnent les passages renvoyés par un moteur de recherche en considérant des critères sous forme dune somme pondérée de fonctions de scores nous proposons dapprendre automatiquement les poids de cette combinaison grâce à un algorithme de réordonnancement défini dans le cadre du boosting qui sont habituellement déterminés manuellement en plus du cadre dapprentissage proposé loriginalité de notre approche réside dans la définition des fonctions allouant des scores de pertinence aux passages nous validons notre travail sur la base de questions et de réponses de lévaluation trec11 des systèmes de qr les résultats obtenus montrent une amélioration significative des performances en terme de rappel et de précision par rapport à un moteur de recherche standard et à une méthode dapprentissage issue du cadre de la classification\n",
      "de la statistique des données à la statistique des connaissances  avancées récentes en analyse des données symboliques\n",
      "nan\n",
      "élagage et aide à linterprétation symbolique et graphique dune pyramide\n",
      "le but de ce travail est de faciliter linterprétation dune classification pyramidale construite sur un tableau de données symboliques alors que dans une hiérarchie binaire le nombre de paliers est égal à n1 si n est le nombre dindividus à classer dans le cas dune pyramide ce dernier peut atteindre nn12 afin de réduire ce nombre on élague la pyramide et on utilise un critère de sélection de paliers basé sur la hauteur de plus on décrit tous les paliers retenus par des variables que lon sélectionne également en utilisant le degré de généralité ainsi que des mesures de dissimilarités de type symboliquenumérique laide à linterprétation se sert doutils graphiques et interactifs grâce à la bibliothèque opengl enfin une simulation montre comment évoluent ces sélections quand le nombre de classes et de variables croit\n",
      "enrichissement sémantique de documents xml représentant des tableaux\n",
      "ce travail a pour objectif la construction automatique dun entrepôt thématique de données à partir de documents de format divers provenant du web lexploitation de cet entrepôt est assurée par un moteur dinterrogation fondé sur une ontologie notre attention porte plus précisément sur les tableaux extraits de ces documents et convertis au format xml aux tags exclusivement syntaxiques cet article présente la transformation de ces tableaux sous forme xml en un formalisme enrichi sémantiquement dont la plupart des tags et des valeurs sont des termes construits à partir de lontologie\n",
      "entrepôt de données spatiales basé sur gml  politique  de gestion de cache\n",
      "nan\n",
      "évaluation des algorithmes lem et elem pour données continues\n",
      "très populaire et très efficace pour lestimation de paramètres dun modèle de mélange lalgorithme em présente linconvénient majeur de converger parfois lentement son application sur des tableaux de grande taille devient ainsi irréalisable afin de remédier à ce problème plusieurs méthodes ont été proposées nous présentons ici le comportement dune méthode connue lem et dune variante que nous avons proposée récemment elem cellesci permettent daccélérer la convergence de lalgorithme tout en obtenant des résultats similaires à celuici dans ce travail nous nous concentrons sur laspect classification et nous illustrons le bon comportement de notre variante sur des données continues simulées et réelles\n",
      "expériences de classification dune collection de documents xml de structure homogène\n",
      "cet article présente différentes expériences de classification de documents xml de structure homogène en vue dexpliquer et de valider une présentation organisationnelle préexistante le problème concerne le choix des éléments et mots utilisés pour la classification et son impact sur la typologie induite pour cela nous combinons une sélection structurelle basée sur la nature des éléments xml et une sélection linguistique basée sur un typage syntaxique des mots nous illustrons ces principes sur la collection des rapports dactivité 2003 des équipes de recherche de linria en cherchant des groupements déquipes thèmes à partir du contenu de différentes parties de ces rapports nous comparons nos premiers résultats avec les thèmes de recherche officiels de linria\n",
      "expérimentations sur un modèle de recherche dinformation utilisant les liens hypertextes des pages web\n",
      "la fonction de correspondance qui permet de sélectionner et de classer les documents par rapport à une requête est un composant essentiel dans tout système de recherche dinformation nous proposons de modéliser une fonction de correspondance prenant en compte à la fois le contenu et les liens hypertextes des pages web nous avons expérimenté notre système sur la collection de test trec9 et nous concluons que pour certains types de requêtes inclure le texte ancre associé aux liens hypertextes des pages dans la fonction de similarité savère plus efficace\n",
      "extension de lalgorithme apriori et des règles dassociation aux cas des données symboliques diagrammes et intervalles\n",
      "nous traitons lextension de lalgorithme apriori et des règles dassociation aux cas des données symboliques diagrammes et intervalles la méthode proposée nous permet de découvrir des règles dassociation au niveau des concepts cette extension implique notamment de nouvelles définitions pour le support et la confiance afin dexploiter la structure symbolique des données au fil de larticle lexemple classique du panier de la ménagère est développé ainsi plutôt que dextraire des règles entre différents articles appartenant à des mêmes transactions enregistrées dans un magasin comme dans le cas classique nous extrayons des règles dassociation au niveau des clients afin détudier leurs comportements dachat\n",
      "extension des bases de données inductives pour la découverte de chroniques\n",
      "les bases de données inductives intègrent le processus de fouille de données dans une base de données qui contient à la fois les données et les connaissances induites nous nous proposons détendre les données traitées afin de permettre lextraction de motifs temporels fréquents et non fréquents à partir dun ensemble de séquences dévènements les motifs temporels visés sont des chroniques qui permettent dexprimer des contraintes numériques sur les délais entre les occurrences dévènements\n",
      "extraction bayésienne et intégration de patterns représentés suivant les k plus proches voisins pour le go 19x19\n",
      "cet article décrit la génération automatique et lutilisation dune base de patterns pour le go 19x19 la représentation utilisée est celle des k plus proches voisins les patterns sont engendrés en parcourant des parties de professionnels les probabilités dappariement et de jeu des patterns sont également estimées à ce moment là la base créée est intégrée dans un programme existant indigo soit elle est utilisée comme un livre douvertures en début de partie soit comme une extension des bases préexistantes du générateur de coups du programme en terme de niveau de jeu le gain résultant est estimé à 15 points en moyenne\n",
      "extraction bilingue de termes médicaux dans un corpus  parallèle anglaisfrançais\n",
      "le catalogue et index des sites médicaux francophones cismef recense les principales ressources institutionnelles de santé en français la description de ces ressources puis leur accès par les utilisateurs se fait grâce à la terminologie cismef fondée sur le thésaurus américain medical subject headings mesh la version française du mesh comprend tous les descripteurs mesh mais de nombreux synonymes américains restent à traduire afin denrichir la terminologie nous proposons ici une méthode de traduction automatique de ces synonymes pour ce faire nous avons constitué deux corpus parallèles anglaisfrançais du domaine médical après alignement semiautomatique des corpus paragraphe à paragraphe nous avons procédé automatiquement à lappariement bilingue des termes pour cela le lexique constitué des descripteurs mesh américains et de leur traduction en français a fourni les couples amorces qui ont servi de point de départ à la propagation syntaxique des liens dappariement 217 synonymes ont pu être traduits avec une précision de 70\n",
      "extraction de la localisation des termes pour le classement des documents\n",
      "trouver et classer les documents pertinents par rapport à une requête est fondamental dans le domaine de la recherche dinformation notre étude repose sur la localisation des termes dans les documents nous posons lhypothèse que plus les occurrences des termes dune requête se retrouvent proches dans un document alors plus ce dernier doit être positionné en tête de la liste de réponses nous présentons deux variantes de notre modèle à zone dinfluence la première est basée sur une notion de proximité floue et la seconde sur une notion de pertinence locale\n",
      "extraction de règles dassociation quantitatives application à des données médicales\n",
      "lextraction de règles dassociation est devenue aujourdhui une tâche populaire en fouille de données cependant lalgorithme apriori et ses variantes restent dédiés aux bases de données renfermant des informations catégoriquesnous proposons dans cet article quantminer qui est un outil que nous avons développé dans le but dextraire des règles dassociation gérant variables catégoriques et numériques loutil que nous proposons repose sur un algorithme génétique permettant de découvrir de façon dynamique les intervalles des variables numériques apparaissant dans les règlesnous présentons également une application réelle de notre outil sur des données médicales relatives à la maladie de lathérosclérose et donnons des résultats de notre expérience pour la description et la caractérisation de cette maladie\n",
      "extraction de termes centrée autour de lexpert\n",
      "nous développons un logiciel exit capable daider un expert à extraire des termes quil trouve pertinents dans des textes de spécialité tout est mis en place pour faciliter le travail de lexpert afin quil puisse consacrer son temps à la seule reconnaissance des termes pertinents pour cela différentes mesures statistiques et de nombreuses options dextraction sont disponibles dans exit afin dutiliser au mieux les connaissances de lexpert notre approche est semiautomatique de plus lexpert construit des termes pouvant inclure des termes précédemment extraits ce qui rend itératif et constructif notre processus de formation des termes enfin lergonomie du logiciel a profité des enseignements tirés lors de son utilisation pour une compétition internationale dextraction de connaissances\n",
      "extraction des connaissances pour lenrichissement des bases  de données géographiques\n",
      "nan\n",
      "fonctions doubli et conservation de détail dans les entrepôts de données\n",
      "nan\n",
      "forage distribué des données  une comparaison entre lagrégation déchantillons et lagrégation de règles\n",
      "pour nous attaquer au problème du forage de très grandes bases de données distribuées nous proposons détudier deux approches la première est de télécharger seulement un échantillon de chaque base de données puis dy effectuer le forage la deuxième approche est de miner à distance chaque base de données indépendamment puis de télécharger les modèles résultants sous forme de règles de classification dans un site central où lagrégation de ces derniers est réalisée dans cet article nous présentons une vue densemble des techniques déchantillonnage les plus communes nous présentons ensuite cette nouvelle technique de forage distribué des données où la mécanique dagrégation est basée sur un coefficient de confiance attribué à chaque règle et sur de très petits échantillons de chaque base de données le coefficient de confiance dune règle est calculé par des moyens statistiques en utilisant le théorème limite centrale en conclusion nous présentons une comparaison entre les meilleures techniques déchantillonnage que nous avons trouvées dans la littérature et notre approche de forage distribué des données fdd basée sur lagrégation de modèles\n",
      "fouille de données relationnelles dans les sgbd\n",
      "nan\n",
      "fouille de graphes et découverte de règles dassociation  application à lanalyse dimages de document\n",
      "cet article présente une méthode permettant la découverte non supervisée de motifs fréquents représentatifs de symboles sur des images de documents les symboles sont considérés comme des entités graphiques porteurs dinformation et les images de document sont représentées par des graphes relationnels attribués dans un premier temps la méthode réalise la découverte de sousgraphes disjoints fréquents et fait correspondre pour chacun deux un symbole différent une recherche des règles dassociation entre ces symboles permet alors daccéder à une partie des connaissances du domaine décrit par ces symboles lobjectif à terme est dutiliser les symboles découverts pour la classification ou la recherche dimages dans un flux hétérogène de document là ou une approche supervisée nest pas envisageable\n",
      "fouille de textes pour orienter la construction dune ressource terminologique\n",
      "la finalité de ce papier est danalyser lapport de techniques de fouille de données textuelles à une méthodologie de construction dontologie à partir de textes le domaine dapplication de cette expérimentation est celui de laccidentologie routière dans ce contexte les résultats des techniques de fouille de données textuelles sont utilisés pour orienter la construction dune ressource terminologique à partir de procèsverbaux daccidents la méthode terminae et loutil du même nom offrent le cadre général pour la modélisation de la ressource le papier présente les techniques de fouille employées et lintégration des résultats des fouilles dans les différentes étapes du processus de construction de la ressource\n",
      "hiérarchisation des règles dassociation en fouille de textes\n",
      "lextraction de règles dassociation est souvent exploitée comme méthode de fouille de données cependant une des limites de cette approche vient du très grand nombre de règles extraites et de la difficulté pour lanalyste à appréhender la totalité de ces règles nous proposons donc de pallier ce problème en structurant lensemble des règles dassociation en hiérarchies la structuration des règles se fait à deux niveaux un niveau global qui a pour objectif de construire une hiérarchie structurant les règles extraites des données nous définissons donc un premier type de subsomption entre règles issue de la subsomption dans les treillis de galois le second niveau correspond à une analyse locale des règles et génère pour une règle donnée une hiérarchie de généralisation de cette règle qui repose sur des connaissances complémentaires exprimées dans un modèle terminologique ce niveau fait appel à un second type de subsomption inspiré de la subsomption en programmation logique inductive nous définissons ces deux types de subsomptions développons un exemple montrant lintérêt de lapproche pour lanalyste et étudions les propriétés formelles des hiérarchies ainsi proposées\n",
      "intégration efficace des arbres de décision dans les sgbd  utilisation des index bitmap\n",
      "nous présentons dans cet article une nouvelle approche de fouille qui permet dappliquer des algorithmes de construction darbres de décision en répondant à deux objectifs  1 traiter des bases volumineuses 2 en des temps de traitement acceptables le premier objectif est atteint en intégrant ces algorithmes au cœur des sgbd en utilisant uniquement les outils fournis par ces derniers toutefois les temps de traitement demeurent longs en raison des nombreuses lectures de la base nous montrons que grâce aux index bitmap nous réduisons à la fois la taille de la base dapprentissage et les temps de traitements pour valider notre approche nous avons implémenté la méthode id3 sous forme dune procédure stockée dans le sgbd oracle\n",
      "lautomate textuel pour la prise en compte de lévolution du texte\n",
      "il nest plus à rappeler que le corpus textuel est tel quil est actuellement intraitable à léchelle que sa croissance nous confirme lobligation dutiliser des outils automatique de traitement cet article sintéresse plus particulièrement à la caractérisation de textes et par là même à celle dauteurs a lheure actuelle toutes les méthodes existant travaillent sur le document fini sans admettre quun cheminement existe entre le début du document et sa fin nous proposons une méthode tentant dapporter cette notion dévolution textuelle en traitant le texte par un automate et lévaluation choisie puis nous présenterons des résultats validés par des experts obtenus sur un corpus dentretiens sociologiques\n",
      "la démarche ontologique pour la gestion des compétences et des connaissances\n",
      "la gestion des ressources humaines repose dune part sur la connaissance des individus et de leurs compétences et dautre part sur la connaissance de lorganisation et de ses métiers cest par la mise en correspondance de ces connaissances quil est possible daméliorer lemploi de valoriser les connaissances et les compétences individuelles et de mieux gérer lorganisation cette mise en correspondance nécessite une représentation explicite des connaissances ce qui permet de répondre à de nouveaux besoins  annuaire de compétences gestion des projets et des retours dexpériences identification des connaissances à risques etcnous verrons dans le cadre de cet article lintérêt de lapproche ontologique tant dun point de vue méthodologique pour la clarification des notions mises en jeu dans le cadre de la gpecc gestion prévisionnelle des emplois des compétences et des connaissances que pour la construction la représentation et la maintenance des référentiels des compétences des connaissances et des métiers elle permet en particulier une gestion de linformation par la terminologie et le sens métier propre à lorganisation\n",
      "la réussite universitaire  prédictions par génération de règles\n",
      "nan\n",
      "les ntic au services de la capitalisation des connaissances\n",
      "nan\n",
      "logiciel daide à létiquetage morphosyntaxique de  textes de spécialité\n",
      "la compréhension de textes de spécialité nécessite un étiquetage morphosyntaxique de bonne qualité or lorsque les textes étudiés sont issus de domaines spécifiques et peu usités il est rare de disposer de dictionnaires et autres ressources lexicales fiables le logiciel que nous proposons permet dutiliser un étiquetage réalisé par un étiqueteur généraliste puis daméliorer cet étiquetage en intégrant des connaissances dexperts du domaine étudié grâce au logiciel développé il est relativement aisé pour un expert du domaine de détecter des erreurs détiquetage et de mettre en place des règles de réétiquetage ces règles peuvent être obtenues de deux manières différentes  1 soit en utilisant un langage de programmation permettant dexprimer des règles complexes de réétiquetage 2 soit par apprentissage automatique des règles à partir dexemples corrigés au moyen dune interface dédiée cet apprentissage propose de nouvelles règles à lexpert acquises automatiquement\n",
      "manipulation et fusion de données multidimensionnelles\n",
      "cet article définit une algèbre permettant de manipuler des tables dimensionnelles extraites dune base de données multidimensionnelles lalgèbre intègre un noyau minimum dopérateurs unaires permettant deffectuer les analyses décisionnelles par combinaison dopérateurs cette algèbre intègre un opérateur binaire permettant la fusion de tables dimensionnelles facilitant les corrélations des sujets analysés\n",
      "méthode de construction dontologie de termes à partir du treillis de liceberg de galois\n",
      "lapproche présentée dans cet article a pour objectif la construction dune ontologie à partir du treillis de liceberg de galois nous entendons par ontologie un ensemble de termes structurés entre eux par un ensemble de liens de divers types dans notre cas détude cette ontologie constitue un support de connaissances documentaires en effet elle peut être utilisée dans diverses applications en recherche dinformation ri telles que lindexation automatique et lexpansion de requêtes ainsi quen textmining la méthode de construction que nous proposons est fondée sur lanalyse formelle de concepts afc et plus précisément la structure du treillis de liceberg de galois en utilisant cette structure hiérarchique partiellement ordonnée nous présentons une translation directe des relations laticielles vers celles ontologiques nous proposons ainsi denrichir lontologie dérivée par des règles associatives génériques entre termes découvertes dans le cadre dun processus de textmining\n",
      "microarray data mining  recent advances\n",
      "nan\n",
      "mining frequent queries in star schemes\n",
      "lextraction de toutes les requêtes fréquentes dans une base de données relationnelle est un problème di±cile même si lon ne considère que des requêtes conjonctives nous montrons que ce problème devient possible dans le cas suivant  le schéma de la base est un schéma en étoile et les données satisfont un ensemble de dépendances fonctionnelles et de contraintes référentielles de plus les schémas en étoile sont appropriés pour les entrepôts de données et que les dépendances fonctionnelles et les contraintes référentielles sont les contraintes les plus usuelles dans les bases de données en considérant le modèle des instances faibles nous montrons que les requêtes fréquentes exprimées par sélectionprojection peuvent être extraites par des algorithmes de type apriori\n",
      "modélisation dobjets mobiles dans un entrepôt de données\n",
      "la gestion dobjets mobiles a connu un regain dintérêt ces dernières années particulièrement dans le but de gérer et de prédire la localisation dobjets mobiles cependant il y a peu de recherches sur lexploitation dhistoriques de bases dobjets mobiles la première étape dans ce processus est la mise en œuvre dun entrepôt dobjets mobiles seulement les modèles dentrepôts existants ne permettent pas de traiter directement ce type de données complexes cet article présente une approche originale pour pallier ce problème cette approche offre la puissance de lalgèbre olap sur toute combinaison de données classiques spatiales etou temporelles et mobiles elle a été validée par un prototype et appliquée à lanalyse de la mobilité urbaine1 les résultats de lexpérimentation montrent la validité de lapproche et les tests de performances son efficacité\n",
      "modélisation dun agent émotionnel en uml et rdf\n",
      "pouvoir extraire de la connaissance à partir dune plateforme de simulation est aujourdhui envisageable en conjuguant les avancées obtenues en intelligence artificielle autour des systèmes multiagents et les méthodes de formalisation et dextraction des connaissances cest donc dans un cadre général de gestion des connaissances que nous proposons de modéliser un agent artificiel doté de connaissances et démotions pour cela une expertise psychologique a été recueillie et formalisée de manière à être stockée dans une base de connaissances sous forme de règles et de classes en uml et rdf limplémentation du modèle permet dentrevoir les perspectives dune telle simulation  enrichissement par des données issues de simulations découverte de nouvelles connaissances par lapplication de processus decd\n",
      "modélisation de connaissances pour un système de médiation\n",
      "travaillant sur lélaboration dune méthodologie de développement de systèmes de médiation intégrés dans des systèmes coopératifs nous avons proposé une architecture à 3 composants  le premier concerne la coopération le second lassistance et le troisième est relatif aux connaissances nécessaires aux 2 précédents dans cet article nous présentons plus particulièrement le point de vue des connaissances ces connaissances sont de 2 natures  des connaissances statiques sur le domaine par exemple et des connaissances acquises pendant lutilisation coopérative du système notamment la mémoire des activités et les descriptions des actes de résolutions de problèmes pour illustrer cette modélisation de connaissances nous nous intéresserons aux activités coopératives de suivi de gestion et dévaluation de projets détudiants assistées par loutil ipédagogique\n",
      "modélisation de la cognition sociale – propositions autour de  lutilisation de schémas cognitifs\n",
      "nan\n",
      "modélisation des individus et de leurs relations pour laide à lintégration des individus dans lorganisation\n",
      "lobjectif de ce papier est de présenter une contribution à la modélisation des individus et de leurs relations pour permettre laide à lintégration des acteurs dans une organisation nous étudions en particulier le cas du remplacement dun acteur « turnover » dans ce cadre nous proposons un modèle regroupant un ensemble de données relatives à un individu aux relations que celuici entretient avec les autres acteurs et à son espace informationnel létude porte sur la mise en oeuvre de mécanismes daide fournissant à un acteur les moyens de son intégration  la mise à disposition dune image des espaces informationnels et relationnels de son prédécesseur ainsi que la mise en relation de lacteur avec les autres acteurs de lorganisation cette étude est menée en partenariat avec des experts en grh\n",
      "modélisation des interactions entre individus avec agentuml\n",
      "pour faciliter létude de certains phénomènes des outils de simulation ont été créés dans de nombreux domaines létude du comportement humain à jusque là échappé à cette tendance aujourdhui les systèmes multiagents couplés aux avancées des sciences humaines fournissent les bases nécessaires à lélaboration de ce type doutil cet article sinscrit ainsi dans cette dynamique avec lobjectif de développer un outil de simulation du comportement dindividus traumatisés crâniens sur une chaîne de production cet outil doit permettre la collecte de la connaissance relative au système étudié et fournir une aide à la décision pour les responsables de lentreprise cet article propose une modélisation des interactions entre individus dans le formalisme agentuml une implémentation du modèle au sein dun outil de simulation fonctionnel et les résultats obtenus seront également présentés a terme le but est la production de données de simulation exploitables par des techniques decd\n",
      "motifs séquentiels flous  un peu beaucoup passionément\n",
      "la plupart des bases de données issues du monde réel sont constituées de données numériques et historiées données de capteurs données scientifiques données démographiques dans ce cadre les algorithmes dextraction de motifs séquentiels sils sont adaptés au caractère temporel des données ne permettent pas le traitement de données numériques es données sont alors prétraitées pour les transformer en données binaire ce qui entraîne une perte dinformation des algorithmes ont donc été proposés pour traiter les données numériques sous forme dintervalles et dintervalles flous notamment en ce qui concerne la recherche de motifs séquentiels fondée sur des intervalles flous les deux méthodes de la littérature ne sont pas satisfaisantes car incomplètes soit dans le traitement des séquences soit dans le calcul du support dans cet article nous proposons donc trois méthodes dextraction de motifs séquentiels flous speedyfuzzy minifuzzy et totallyfuzzy et en détaillons les algorithmes sousjacents en soulignant les différents niveaux de fuzzification ces algorithmes sont implémentés et évalués à travers différentes expérimentations menées sur des jeux de tests synthétiques\n",
      "notion de sémantiques bienformées pour les règles\n",
      "la notion de règles entre attributs est très générale allant des règles dassociation en fouille de données aux dépendances fonctionnelles df en bases de données malgré cette diversité la syntaxe des règles est toujours la même seule leur sémantique diffère pour une sémantique donnée en fonction des propriétés induites des techniques algorithmiques sont mises en oeuvre pour découvrir les règles à partir des données a partir dun ensemble de règles il est aussi utile en pratique de raisonner sur ces règles comme cela est le cas par exemple avec les axiomes darmstrong pour les dépendances fonctionnelles dans cet article nous proposons un cadre qui permet de sassurer quune sémantique donnée pour les règles est bienformée ie les axiomes darmstrong sont justes et complets pour cette sémantique les propositions faites dans ce papier proviennent du contexte applicatif de lanalyse de données de biopuces a partir de plusieurs sémantiques pour les données dexpression de gènes nous montrons comment ces sémantiques sintègrent dans le cadre présenté\n",
      "outil de classification et de visualisation de grands volumes de données mixtes\n",
      "nous avons conçu un outil de classification de données original que nous détaillons dans le présent article cet outil comporte un module de création de résumés et un module daffichage le module de visualisation permet une lecture aisée des résumés grâce à une interface graphique évoluée permettant la présentation et lexploration des résumés sous forme dune hiérarchie de profils ou dun tableau de profils chaque profil donne de manière claire les informations relatives au résumé de données correspondant la lecture de la hiérarchie et du tableau est aussi grandement facilitée par les choix dun ordre optimal pour la présentation des variables et des résumés\n",
      "prise en compte des « points de vue » pour lannotation dun processus dextraction de connaissances à partir de données\n",
      "dans cet article on propose une nouvelle approche qui rend explicite la notion de point de vue dans une analyse multivues issue dun processus dextraction de connaissances à partir de données ecd par point de vue nous entendons la vision particulière dun analyste lors de son processus ecd vision référant à un corps de connaissances qui lui est spécifique on cherche dune part à faciliter la réutilisabilité et ladaptabilité du processus et dautre part à garder une trace des points de vues sousjacents aux analyses faites le processus decd sera vu comme un processus de génération et de transformation de vues qui seront annotées par des métadonnées pour garder la sémantique de la connaissance extraite un positionnement de notre approche visàvis des travaux méthodologiques du processus decd sera donné des éléments de modélisation du processus ecd basé sur les points de vue seront décrits au niveau ontologique enfin on illustrera notre approche sur lanalyse des usages dun site web à partir des fichiers log selon le point de vue fiabilité\n",
      "problématiques de gestion de connaissances dans le cadre de lenseignement à distance sur linternet\n",
      "le développement des réseaux à hautdébit et de linternet fournit un nouveau support à lenseignement à distance aujourdhui de nombreux acteurs dans le domaine de lenseignement ont mis en place des dispositifs de formation en ligne ceuxci se composent généralement dune sélection de matériaux organisés et présentés de manière à suivre un programme pédagogique particulier de mécanismes de communication entre apprenants et enseignants et doutils de suivi des apprenants les platesformes denseignement à distance devenant de plus en plus génériques des nouveaux modèles ont été définis standardisés ou normalis és permettant la formalisation de métadonnées pédagogiques ou tentant dévaluer les connaissances acquises par les apprenants en nous appuyant sur ces modèles nous proposons de construire une base de connaissances associant notamment les termes des domaines enseignés en relations à sémantique pédagogique lexploitation de cette base de connaissances fournit un premier niveau daide à lingénierie pédagogique en particulier lorsque le volume de contenus en ligne est important des inférences mettant en jeu ces connaissances permettent alors un meilleur suivi du dispositif denseignement\n",
      "processus de traitement de données radar pour la reconnaissanceidentification de cibles aériennes\n",
      "nan\n",
      "raisonnement en gestion des compétences\n",
      "nous nous intéressons au raisonnement sur les compétences des ressources humaines pour simplifier leur gestion dans cet article nous proposons une méthode de raisonnement pour laide à lidentification des compétences dun individu un processus de knowledgemining défini par analogie avec lextraction de règles dassociation en datamining est proposé afin dinduire une base de règles à partir dune base de connaissances sur le domaine de plus un prototype a été développé pour expérimenter notre approche sur un exemple académique\n",
      "rasma  une approche multiagent pour lamélioration de lalgorithme des règles dassociations spatiales\n",
      "nan\n",
      "réécriture de requêtes multimédias  approche basée sur lusage dune ontologie\n",
      "nous proposons dans cet article une stratégie de réécriture de requêtes sur des données multimédias décrites moyennant le standard mpeg7 ce standard se base sur xml schéma qui permet de décrire la structure des données cependant aucune sémantique nest assignée à cette structure nous proposons détendre ce standard dune ontologie permettant dexprimer les connaissances du domaine ainsi lontologie sera utilisée durant lindexation des données multimédias et la réécriture de requêtes le but de la réécriture de requêtes est de transformer une requête initiale en une ou plusieurs requêtes équivalentes ou sémantiquement proches compte tenu des connaissances représentées dans lontologie\n",
      "règles de propagation pour la création dontologies dannotation de ressources\n",
      "lannotation se distingue de lindexation automatique par lutilisation dune ou plusieurs ontologies qui définissent un domaine global de référence permettant de cadrer et de normaliser les annotations effectuées par ailleurs une ressource annotée doit lêtre non pas par une liste de mots clefs mais bien par une ou plusieurs ontologies malheureusement il est peu réaliste de penser que les centaines de millions de ressources mises à disposition sur le web puissent être annotées par leurs auteurs pour résoudre ce problème notre démarche consiste à indexer les documents en se basant sur lontologie globale et ensuite propager les annotations en utilisant des documents déjà annotés pour annoter dautres documents référencés par ceuxci la propagation des annotations suit des règles que nous proposons dans cet article lillustration est effectuée sur un corpus de livres dont le thème relève de linformatique\n",
      "réponses coopératives dans linterrogation de documents rdf\n",
      "le développement du web sémantique a conduit à lélaboration de standards pour la représentation des connaissances sur le web rdf comme un de ces standards est devenu une recommandation du w3c même sil a été conçu pour être interprétable par lhomme et la machine encodage xml triplets graphes étiquetés rdf na pas été fourni avec des services dinterrogation et de raisonnement la plupart des travaux concernant linterrogation de documents rdf se sont concentrés sur lusage de techniques issues de la programmation logique et sur des extensions de sql nous portons un nouveau regard sur les techniques dinterrogation et de raisonnement sur les documents rdf et nous montrons que la sémantique des termes osf order sorted features est compatible avec la représentation isomorphique triplets des propositions rdf cette transformation permet lordonnancement des ressources en ontologies et à travers ceci des meilleurs mécanismes de réponses par approximation et recouvrement aux interrogations de documents rdf\n",
      "restructuration automatique de documents dans les corpus semistructurés hétérogènes\n",
      "linterrogation de grandes bases de documents semistructurés type xml est un problème ouvert important en effet pour interroger un document dont le schéma est nouveau un système doit pouvoir soit adapter la requête posée au document soit adapter le document pour pouvoir lui appliquer la requête nous nous positionnons ici dans le cadre de la restructuration de documents qui consiste à transformer des documents semistructurés issus de diverses sources dans un schéma de médiation connu nous proposons un cadre statistique général à la problématique de la restructuration de documents et détaillons une instance dun modèle stochastique de documents structurés appliquée à cette problématique nous détaillons enfin un ensemble dexpériences effectuées sur les documents du corpus inex afin de mesurer la capacité de notre modèle\n",
      "sélection de modèles par des méthodes à noyaux pour la classification de données séquentielles\n",
      "ce travail concerne le développement de méthodes de classification discriminantes pour des données séquentielles quelques techniques ont été proposées pour étendre aux séquences les méthodes discriminantes comme les machines à vecteurs supports par nature plus adaptées aux données en dimension fixe elles permettent de classifier des séquences complètes mais pas de réaliser la segmentation qui consiste à reconnaître la séquence dunités phonèmes ou lettres par exemple correspondant à un signal en utilisant une correspondance donnée  modèle nous transformons le problème de lapprentissage des modèles à partir de données par un problème de sélection de modèles qui peut être attaqué via des méthodes du type machines à vecteurs supports nous proposons et évaluons divers noyaux pour cela et fournissons des résultats expérimentaux pour deux problèmes de classification\n",
      "semisupervised incremental clustering of categorical data\n",
      "le clustering semisupervisé combine lapprentissage supervisé et nonsupervisé pour produire meilleurs clusterings dans la phase initiale supervisée de lalgorithme un échantillon dapprentissage est produit par sélection aléatoire on suppose que les exemples de léchantillon dapprentissage sont étiquetés par un attribut de classe puis un algorithme incrémentiel développé pour les données catégoriques est utilisé pour produire un ensemble de clusters pur tels que les exemple de chaque cluster ont la même étiquette qui servent de seeding clusters pour la deuxième phase nonsupervisée de lalgorithme dans cette phase lalgorithme incrémentiel est appliqué aux données non étiquetées la qualité du clustering est évaluée par lindex de gini moyen des clusters les expériences démontrent que des très bons clusterings peuvent être obtenus avec des petits échantillons dapprentissage\n",
      "seqtree un outil de fouille de données séquentielles par visualisation\n",
      "dans cet article nous présentons un outil de visualisation de séquences modélisées par des arbres de suffixes probabilistes prediction suffix trees  pst ce type darbre permet de représenter une chaîne de markov dordre variable dans différentes application il sest avéré plus efficace quune chaîne de markov dordre fixe avec un coût calculatoire moindre pour ces raisons il nous a paru intéressant dexploiter le caractère arborescent de ce mode de représentation non seulement dun point de vue algorithmique mais aussi dun point de vue visuel\n",
      "ssc  statistical subspace clustering\n",
      "cet article se place dans le cadre du subspace clustering dont la problématique est double  identifier simultanément les clusters et le sousespace spécifique dans lequel chacun est défini et caractériser chaque cluster par un nombre minimal de dimensions permettant ainsi une présentation des résultats compréhensible par un expert du domaine dapplication les méthodes proposées jusquà présent pour cette tâche ont le défaut de se restreindre à un cadre numérique lobjectif de cet article est de proposer un algorithme de subspace clustering capable de traiter des données décrites à la fois par des attributs continus et des attributs catégoriels nous présentons une méthode basée sur lalgorithme classique em mais opérant sur un modelé simplifié des données et suivi dune technique originale de sélection dattributs pour ne garder que les dimensions pertinentes de chaque cluster les expérimentations présentées ensuite menées sur des bases de données aussi bien artificielles que réelles montrent que notre algorithme présente des résultats robustes en termes de qualité de la classification et de compréhensibilité des clusters obtenus\n",
      "svm et visualisation pour la fouille de grands ensembles de données\n",
      "nous présentons un algorithme de svm et des méthodes graphiques pour le traitement de grands ensembles de données pour pouvoir traiter de tels ensembles de données nous utilisons une représentation des données de plus haut niveau sous forme symbolique lalgorithme de séparateur à vaste marge svm est adapté pour pouvoir traiter ce nouveau type de données nous construisons un nouveau noyau rbf radial basis function que lalgorithme utilise à la fois pour la classification la régression et la détection dindividus atypiques dans des données de type intervalle nous utilisons ensuite des méthodes de visualisation interactive elles aussi adaptées au cas des variables de type intervalle pour expliquer les résultats obtenus par les svm la méthode est évaluée sur des ensembles de données symboliques existant ou créés artificiellement\n",
      "tableau de bits indexé tbi  pour la recherche de séquences fréquentes\n",
      "nan\n",
      "tanagra  un logiciel gratuit pour lenseignement et la recherche\n",
      "tanagra est un logiciel « open source » librement accessible sur le web il tente de concilier deux types dutilisation dune part en proposant une interface suffisamment conviviale il est accessible aux utilisateurs non spécialistes qui veulent effectuer des études sur des données réelles dautre part en définissant une architecture simplifiée à lextrême les efforts de développement portent sur lessentiel à savoir la mise au point et lintégration dalgorithmes de fouille de données les chercheurs peuvent ainsi mener des expérimentations sur les méthodes dans cet article nous présentons les principales fonctionnalités du logiciel en essayant de le positionner sur léchiquier des très nombreux logiciels diffusés actuellement\n",
      "tendances dans les expressions de gènes   application à lanalyse du transcriptome  de plasmodium falciparum\n",
      "létude de lexpression des gènes est depuis quelques années révolutionnée par les puces à adn les méthodes habituellement mises en oeuvre pour analyser ces données sappuient sur des algorithmes de partitionnement comme les clustering hiérarchiques et sur une hypothèse communément admise qui associe à un ensemble de profils dexpression similaires une fonction identique cette analyse étudie lensemble des gènes sans distinction lapproche que nous proposons deux catégories de gènes  connus ou putatifs pour chaque gène nayant pas dinformation rattachée nous étudions son voisinage afin dy trouver des motifs fréquents itemsets ensuite lanalyse est guidée par linterprétation biologique afin de faire émerger des propriétés intéressantes un premier jeu de test sur plasmodium falciparum agent de la malaria nous a permis de mettre en évidence en nous intéressant aux items relatifs à la glycolyse un transporteur de nucléosides qui intervient au niveau énergétique dans la phase ring précoce du parasite\n",
      "un automate pour la génération complète ou partielle des concepts du treillis de galois\n",
      "cet article se situe dans le domaine de lanalyse formelle de concepts et du treillis de concepts treillis de galois lequel est un cadre théorique intéressant pour le regroupement conceptuel des données et la génération des règles dassociation puisque la prospection de données data mining est utilisée comme support à la prise de décision par des analystes rarement intéressés par la liste exhaustive souvent très longue des concepts et des règles lélaboration dune solution approximative sera dans la plupart des cas un compromis satisfaisant et relativement moins coûteux quune solution exhaustive dans cet article on propose une approche appelée ciga closed itemset generation using an automata de génération partielle ou complète de concepts par la construction et le parcours dun automate à états finis la génération des concepts permet lidentification des itemsets fermés fréquents étape cruciale pour lextraction des règles dassociation\n",
      "un critère dévaluation pour la sélection de variables\n",
      "cet article aborde le problème de la sélection de variables dans le cadre de la classification supervisée les méthodes de sélection reposent sur un algorithme de recherche et un critère dévaluation pour mesurer la pertinence des sousensembles potentiels de variables nous présentons un nouveau critère dévaluation fondé sur une mesure dambigüité cette mesure est fondée sur une combinaison détiquettes représentant le degré de spécificité ou dappartenance aux classes en présence les tests menés sur de nombreux jeux de données réels et artificiels montrent que notre méthode est capable de sélectionner les variables pertinentes et daugmenter dans la plupart des cas les taux de bon classement\n",
      "un système daide à la navigation dans des hypermédias\n",
      "avec le développement dinternet et dapplications hypermédias la construction et lexploitation de profils ou modèles des utilisateurs deviennent capitaux dans de nombreux domaines pouvoir cibler un utilisateur dun hypermédia ou dun site web afin de lui proposer ce quil attend devient essentiel par exemple lorsque lon veut lui présenter les produits quil est le plus susceptible dacheter ou bien plus généralement à chaque fois que lon veut éviter de noyer lutilisateur dans un flot dinformations nous présentons un système daide à la navigation intégrant un système de modélisation du comportement de navigation et un stratège qui met en œuvre en fonction du comportement détecté une aide visant à recommander des liens particuliers\n",
      "une approche filtre pour la sélection de variables en apprentissage non supervisé\n",
      "la sélection de variable sv constitue une technique efficace pour réduire la dimension des espaces dapprentissage et savère être une méthode essentielle pour le prétraitement de données afin de supprimer les variables bruitées etou inutiles peu de méthodes de sv ont été proposées dans le cadre de lapprentissage non supervisé et la plupart dentre elles sont des méthodes dites enveloppes nécessitant lutilisation dun algorithme dapprentissage pour évaluer les sous ensembles de variables or lapproche enveloppe est largement mal adaptée à une utilisation lors de cas réels en effet dune part ces méthodes ne sont pas indépendantes vis à vis des algorithmes dapprentissage non supervisé qui nécessitent le plus souvent de fixer un certain nombre de paramètres  mais surtout il nexiste pas de critères bien adaptés à lévaluation de la qualité dapprentissage non supervisé dans des sous espaces différents nous proposons et évaluons dans ce papier une méthode filtre et donc indépendante des algorithmes dapprentissage non supervisé cette méthode sappuie sur deux indices permettant dévaluer ladéquation entre deux ensembles de variables entre deux sous espaces\n",
      "une méthode dévaluation de la pertinence des pages web dans websum\n",
      "dans cet article nous présentons une méthode dévaluation de la pertinence des pages web retournées par un moteur de recherche\n",
      "usage non classificatoire darbres de classification  enseignements dune analyse de la participation féminine à lemploi en suisse\n",
      "cet article présente une application en grandeur réelle des arbres de classification dans un contexte non classificatoire les arbres générés visent à mettre en lumière les différences régionales dans la façon dont les femmes décident de leur participation au marché du travail laccent est donc mis sur la capacité descriptive plutôt que prédictive des arbres lapplication porte sur des données relatives à la participation féminine au marché du travail issues du recensement suisse de la population de lan 2000 ce vaste ensemble de données a été analysé en deux phases un premier arbre exploratoire a mis en évidence la nécessité de procéder à des études séparées pour les non mères les mères mariées ou veuves et les mères célibataires ou divorcées nous nous limitons ici aux résultats de ce dernier groupe pour lequel nous avons généré un arbre séparé pour chacune des trois régions linguistiques principales les arbres obtenus font apparaître des différences culturelles fondamentales entre régions du point de vue méthodologique la principale difficulté de cet usage non classificatoire des arbres concerne leur validation puisque le taux derreur de classification généralement retenu perd tout son sens dans ce contexte nous commentons cet aspect et illustrons lusage dalternatives plus pertinentes et facilement calculables\n",
      "utilisation des technologies xml pour la formalisation de lontologie de modèles ebusiness\n",
      "notre travail de recherche consiste à représenter lontologie des modèles ebusiness ebmo par le langage bm²l spécifié sur la base dun métamodèle xml bm²l est comparé à dautres langages de définition dontologie à savoir rdfs daml  oil et owl et ce selon un framework établis sur les spécificités de cette ontologie aussi introduisons nous une application web ebmh pour la conception et lexploitation des modèles ebusiness conformément à lontologie\n",
      "validation statistique des cartes de kohonen en apprentissage supervisé\n",
      "en apprentissage supervisé la prédiction de la classe est le but ultime plus largement on attend dune bonne méthodologie dapprentissage quelle permette une représentation des données susceptible de faciliter la navigation de lutilisateur dans la base dexemples et daider au choix des exemples et des variables pertinents tout en assurant une prédiction de qualité dont on comprenne les ressorts différents travaux ont montré laptitude des graphes de voisinage issus des prédicteurs à fonder une telle méthodologie ainsi le graphe des voisins relatifs de toussaint cependant la complexité de leur construction en on3 reste élevée dans le cas de données volumineuses nous proposons de substituer aux graphes de voisinage les cartes de kohonen construites sur les prédicteurs après un bref rappel du principe des cartes de kohonen en apprentissage non supervisé nous montrons comment cellesci peuvent fonder une stratégie dapprentissage optimisée nous proposons ensuite dévaluer la qualité de cette stratégie par une statistique originale qui est étroitement corrélée au taux derreur en généralisation différentes expérimentations montrent la faisabilité de cette approche on dispose alors dun critère fiable pour sélectionner les individus et les attributs pertinents\n",
      "visualisation de la perception dun site web par ses utilisateurs\n",
      "nous proposons dans cet article une méthode de visualisation de lactivité des utilisateurs dun site web qui permet dévaluer qualitativement ladéquation entre son architecture logique et la perception de celleci par les internautes nous travaillons sur les parcours des internautes sur le site étudié après reconstruction de ceuxci grâce aux fichiers logs des serveurs concernés nous utilisons la structure logique des sites étudiés pour simplifier la représentation des parcours en ne tenant pas compte de lordre de visite des catégories sémantiques du site les parcours simplifiés sont utilisés pour calculer une dissimilarité entre les catégories sémantiques qui sont ensuite représentées dans un plan par multi dimensional scaling nous complétons cette visualisation densemble par une représentation de larbre couvrant minimal des catégories sémantiques qui permet de mieux appréhender certaines interactions nous illustrons lintérêt de la méthode en lappliquant au site de linria\n",
      "« la connaissance de la connaissance »  une réflexion sur la triangulation des analyses textuelles à partir dun corpus spécialisé en gouvernance dentreprise\n",
      "suite à la survenue récente de scandales financiers la synthèse des idées mobilisables en gouvernance dentreprise semble désormais essentielle si lon veut sécuriser les investisseurs dans cette perspective le présent projet de recherche consiste à mettre en œuvre un panel doutils danalyse de données textuelles alceste syntex tropeszoomdecision explorer wordmapper weblex afin dévaluer les moyens dont peut disposer un analyste désireux dextraire des connaissances contenues dans un ensemble darticles académiques la qualité de représentation du corpus dans sa globalité est tout dabord testée létude est ensuite centrée sur le concept même de connaissance mobilisé dans la théorie de la gouvernance des entreprises la convergence et la complémentarité des approches méthodologiques sont alors explicitées il en est de même pour ce qui concerne la capacité dextraction dune connaissance pertinente à partir des textes étudiés\n",
      "a galois connecion semanticsbased approach for deriving generic bases of association rules\n",
      "laugmentation vertigineuse de la taille des données textuelles ou transactionnelles est un défi constant pour la scalabilité des techniques dextraction des connaissances dans ce papier on présente une approche pour la dérivation des bases génériques de règles associatives les principales caract éristiques de cette approches sont les suivantes dune part lintroduction dune structure de données appelée trieitemset pour le stockage de la relation en entrée dautre part on utilise une méthode diviser pour régner pour réduire le coût de construction de structures partiellement ordonnées à partir desquelles les bases génériques de règles sont directement extraites\n",
      "a metric approach to supervised discretization\n",
      "nous présentons une nouvelle approche à la discrétisation supervisée des attributs continues qui se sert de lespace métrique des partitions dun ensemble fini nous discutons deux nouvelles idées fondamentales  une généralisation des techniques de discrétisation de fayyadirani basée sur une distance sur des partitions dérivée de lentropie généralisée de daroczy et un nouveau critère géométrique pour arrêter lalgorithme de discrétisation les arbres de décision résultants sont plus petits ont moins de feuilles et montrent des niveaux plus élevés dexactitude établis par la validation croisée stratifiée\n",
      "a robust method for partitioning the values of categorical attributes\n",
      "dans le domaine de lapprentissage supervisé les méthodes de groupage des modalités dun attribut symbolique permettent de construire un nouvel attribut synthétique conservant au maximum la valeur informationnelle de lattribut initial et diminuant le nombre de modalités nous proposons ici une généralisation de lalgorithme de discrétisation khiops pour le problème du groupage des modalités lalgorithme proposé permet de contrôler a priori le risque de surapprentissage et daméliorer significativement la robustesse des groupages produits cette caractéristique de robustesse a été obtenue en étudiant la statistique des variations du critère du khi2 lors de regroupements de lignes dun tableau de contingence et en modélisant le comportement statistique de lalgorithme khiops des expérimentations intensives ont permis de valider cette approche et ont montré que la méthode de groupage khiops aboutit à des groupages performants à la fois en terme de qualité prédictive et de faible nombre de groupes\n",
      "accélération de em pour données qualitatives  études comparative de différentes versions\n",
      "lalgorithme em est très populaire et très efficace pour lestimation de paramètres dun modèle de mélange linconvénient majeur de cet algorithme est la lenteur de sa convergence son application sur des tableaux de grande taille pourrait ainsi prendre énormément de temps afin de remédier à ce problème nous étudions ici le comportement de plusieurs variantes connus de em ainsi quune nouvelle méthode cellesci permettent daccélérer la convergence de lalgorithme tout en obtenant des résultats similaires à celuici dans ce travail nous nous concentrons sur laspect classification nous réalisons une étude comparative entre les différentes variantes sur des données simulées et réelles et proposons une stratégie dutilisation de notre méthode qui savère très efficace\n",
      "acquisition de données vs gestion de connaissances  patrimoniales  le cas des vestiges du théâtre antique darles\n",
      "quy a til de commun aujourdhui entre lacquisition de données 3d la gestion dinformations patrimoniales ou encore la modélisation tridimensionnelle en temps réel  bien peu force est de le constater si ce nest que lédifice patrimonial sert là souvent de terrain dexpérimentation pourtant il ne saurait être réduit à ce seul statut  il est objet de connaissances dont létude doit bénéficier de différents jeux de technologies notre proposition expérimentée sur des vestiges du théâtre antique darles place cet édifice au centre dun dispositif visant à intégrer au sein dun système dinformations architecturales 3d en devenir les résultats de différentes phases de son étude un jeu de connaissances formalisé sur lédifice sert de dénominateur commun depuis lacquisition de données 3d jusquà la représentation dans une maquette temps réel pour la toile cette maquette devient outil de navigation dans le jeu dinformations et de savoirs qui caractérise lédifice\n",
      "analyse dinformation relationnelle par des graphes interactifs de grandes tailles\n",
      "la découverte de connaissances à partir dimportantes masses de données hétérogènes débouche le plus souvent sur lanalyse relationnelle la recherche dinformations stratégiques sappuie en effet sur les liens fonctionnels et sémantiques entre documents acteurs terminologie et concepts dun domaine sans oublier le paramètre temps de nombreuses méthodes sont proposées pour identifier analyser et visualiser les mécanismes mis à jour  analyse relationnelle classifications supervisées et non supervisées analyse factorielle analyse sémantique cartes dendogrammes … mais ces approches demandent souvent une expertise non négligeable pour être comprises et ne sadressent donc pas aux non initiés par contre la vue dun graphe mettant en relation une ou deux classes déléments interdépendants est directement assimilable par tout le monde nous proposons donc un ensemble de visualisations interactives de graphes dont la manipulation doit permettre une découverte de connaissances intuitive et basée sur un langage graphique naturel nous illustrons notre propos de nombreux exemples tirés de cas réels danalyses stratégiques qui ont permis dévaluer cette approche sur un panel très large de données\n",
      "annotation automatique de documents xml\n",
      "nous proposons dans cet article un mécanisme automatique dannotation de documents ce mécanisme sappuie sur une opération de composition permettant de créer de nouveaux documents à partir de documents existants et sur un algorithme permettant dinférer lannotation dun document composé à partir dannotation de ses parties notre modèle est illustré par une étude de cas consacrée à la mise en commun de documents pédagogiques au format xml dans un environnement coopératif denseignement à distance nous décrivons un prototype permettant dannoter ces documents et dengendrer une description rdf contenant les annotations\n",
      "apprentissage des réseaux bayésiens avec des graphes chaînés maximaux\n",
      "nan\n",
      "apprentissage et optimisation conjoints  extraction de connaissances pertinentes sur les systèmes de production\n",
      "nan\n",
      "apprentissage incrémental des profils dans un système de filtrage dinformation\n",
      "cet article présente une méthode dapprentissage des profils dans les systèmes de filtrage dinformation le processus dapprentissage est effectué dune manière incrémentale au fur et à mesure que les informations sont filtrées et jugées par lutilisateur des expérimentations effectuées sur une collection de test de référence trec montrent que la méthode permet effectivement lamélioration des profils\n",
      "approche binaire pour la génération de fortes règles dassociation\n",
      "dans ce papier nous proposons une nouvelle méthode dextraction des règles dassociation dans des bases de données relationnelles basée sur la technologie des arbres de peano ptree la structure de données utilisée pour représenter la base de données est un ensemble de ptrees de base représentant chacun un vecteur binaire et tous ces ptrees sont stockés dans des fichiers binaires nous montrons que la structure ptree combinée avec la technique de réduction appelée élagage par support minimum produisent des règles dassociation fortes et réduisent considérablement le temps de construction de lassociation en effet notre approche présente lavantage de ne pas effectuer des parcours coûteux de la base de données cette approche a été testée à travers un prototype que nous avons implémenté les résultats expérimentaux montrent que les règles dassociation fortes sont générées dans un temps minimum comparativement à dautres travaux\n",
      "approche innovante pour la recherche et lextractin coopérative et dynamique dinformations sur internet\n",
      "il existe de nombreuses techniques qui permettent de classifier les documents textuels en fonction de lintérêt dun utilisateur knn svm  malheureusement lintégration de ces méthodes dans les platesformes de textmining est souvent très statique au cours du temps le but de cet article est de présenter une plateforme de webmining dans laquelle les données hétérogènes sont représentées uniformément selon un formalisme xmltei et où lutilisateur peut interagir sur les processus de récupération et danalyse de ces données pour cela les modules de traitements sont représentés par des agents fonctionnant sur la plateforme madkit et lapprentissage se fait par une méthode dérivée de vsm et tfidf utilisant un principe de listes noires pondérées permettant la reconnaissance de documents indésirables la dynamique de la plateforme repose principalement sur la possibilité dajouter à la volée des agents de traitement et de pouvoir modifier lordre et les paramètres danalyse des documents\n",
      "beluga  un outil pour lanalyse dynamique des connaissances de la littérature scientifique dun domaine première application au cas des maladies à prions\n",
      "un projet ciblé sur létude du domaine des maladies à prions à permis de formaliser une méthodologie commune sociologique et informatique de compréhension de sa dynamique par lanalyse thématique nous avons créé une plate forme dindexation de notices bibliographiques dont le but est dextraire des associations évoluant à travers des intervalles de temps beluga propose une chaîne de traitement basée sur lindexation des documents en unités de base  références auteurs termes simples et composés organismes loutil est fondé sur une double approche dapprentissage et de visualisation qui automatise les processus dextraction de groupes dauteurs et de termes et permet à lutilisateur de revenir aux données documentaires sources lanalyse diachronique de corpus de documents électroniques nous permet danalyser comment la terminologie est structurée en thématiques émergentes\n",
      "booloader  un chargeur efficace dédié aux bases de transactions denses\n",
      "nous nous intéressons à la représentation et au chargement de bases de transactions en mémoire pour cela nous proposons dutiliser un format condensé fondé sur les diagrammes de décision binaires et nous présentons un algorithme que nous avons implanté en un système baptisé booloader pour charger des bases de transactions nous donnons également des résultats expérimentaux de notre système sur des bases éparses et denses\n",
      "caractérisation de signatures complexes dans des familles de protéines distantes\n",
      "lidentification de signatures de protéines est un problème majeur pour la découverte de nouveaux membres dans des familles de protéines connues le concept de signature qui permet de caractériser ces familles est généralement basé sur la définition de motifs communs il savère que les familles de protéines connues le concept de signature qui permet de caractériser ces familles est généralement basé sur la définition de motifs communs il savère que les familles distantes sont trop hétérogènes pour quon puisse identifier les régions conservées à partir des algorithmes classiques de la bioinformatique nous proposons une approche génétique pour la découverte de motifs hiérarchiques lalgorithme suit une démarche descendante en sappuyant dans une première phase sur les classes physicochimiques des acides aminés les signatures sont ensuite définies par des séquences des motifs ainsi obtenus elles sont extraites au moyen dun algorithme de découverte ditemsets séquentiels où les motifs jouent le rôle ditems une dernière étape consiste à fouiller dans cette base ditemsets pour nen retenir quun ensemble réduit de signatures plusieurs stratégies sont proposés pour déterminer un ensemble optimal de signatures qui respecte des contraintes de complétude de cardinalité et de spécificité nous appliquons notre démarche sur la famille des cytokines lanalyse de la base de protéines scop a montré que les groupes de signatures que nous avons extrait cible spécifiquement cette famille dintérêt\n",
      "caractérisation globale de lexécution de jobs\n",
      "la caractérisation globale de lexécution de jobs passe par lexploitation de mesures recueillies sur les machines en production afin de répondre à la problématique il est nécessaire de tenir compte des différents types de données ainsi que de la dualité de la caractérisation  statique et dynamique une solution technique répondant aux contraintes est proposée elle repose sur lutilisation de svm afin de détecter des phases et à un niveau supérieur à un réseau bayésien afin dautomatiser lanalyse de modèles de markov enrichis ceuxci sont introduits comme la base formelle et synthétique de description du comportement du job aussi bien sur un système batch que parallèle enfin les résultats obtenus à laide dun prototype sont discutés\n",
      "cartographie sémantique des connaissances à la carte\n",
      "nan\n",
      "classer pour découvrir  une nouvelle méthode danalyse du comportement de tous les utilisateurs dun site web\n",
      "lanalyse du comportement des utilisateurs dun site web est un domaine riche et complexe le grand nombre de méthodes dextraction de connaissances appliquées aux logs web ainsi que la diversité du type de ces méthodes en est une preuve cependant compte tenu de cette complexité nous posons dans cet article la question suivante  estil possible de combiner des méthodes existantes pour proposer une analyse qui tire profit des résultats de plusieurs spécialités et extraire par exemple des comportements fréquents minoritaires notre étude à donc porté sur une nouvelle approche hybride issue de la classification neuronale et de la recherche de motifs séquentiels visant à classer les navigations des utilisateurs dun site à laide de leurs résumés sémantiques puis pour chaque classe de navigations den extraire les comportements fréquents notre objectif est 1 de pallier les limites de lextraction de motifs fréquents par rapport à la quantité de données à traiter et aussi par rapport à la qualité des résultats et 2 de pallier les limites dune première méthode danalyse du comportement appelée diviser pour découvrir que nous avons proposé en 2003 nous avons mené des expérimentations sur les logs http des sites inria les résultats obtenus confirment le bien fondé de notre approche vis à vis de létat de lart\n",
      "classification automatique dimages\n",
      "nan\n",
      "construction de variables et arbre de décision\n",
      "nan\n",
      "contrôle du risque multiple pour la sélection de règles dassociation significatives\n",
      "les algorithmes dextraction de règles dassociation parcourent efficacement le treillis des itemsets pour constituer une base de règles admissibles à des seuils de support et de confiance mais donnent une multitude de règles peu exploitables nous suggérons dépurer de telles bases en éliminant les règles non statistiquement significatives la multitude de tests pratiqués conduit mécaniquement à multiplier les règles sélectionnées à tort après avoir présenté des procédures issues de la biostatistique qui contrôlent non pas le risque mais le nombre de fausses découvertes nous proposons bsdf un algorithme original fondé sur le bootstrat qui sélectionne les règles significatives en contrôlant le nombre de fausses découvertes des expérimentations montrer lefficacité de ces procédures\n",
      "découverte de régularités pour lintégration de  données semi structurées\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cet article présente lutilisation dune technique de fouille de données pour aider à la spécification de vues sur des sources xml notre langage de vues permet dintégrer des données xml provenant de sources hétérogènes cependant la définition de motifs sur les sources permettant de spécifier les données à extraire est souvent difficile car la structure des données nest pas toujours connue nous proposons dextraire les structures fréquentes dans les données des sources pour spécifier des motifs pertinents à utiliser dans la spécification des vues\n",
      "détection par svm  application à la détection de churn en téléphonie mobile prépayée\n",
      "nan\n",
      "etiq un étiqueteur inductif convivail pour les corpus de spécialité\n",
      "nan\n",
      "étude de textes par leur image\n",
      "nous proposons une méthode automatique de comparaison de textes reposant sur une technique de transformation dun texte en une image de taille donnée et lanalyse à laide des outils de la géométrie fractale nous présentons une application à létude dun corpus de 90 textes longs\n",
      "étude expérimentale de mesures de qualité de règles dassociation\n",
      "la validation des connaissances extraites dun processus decd par un expert métier nécessite de filtrer ces connaissances pour ce faire de nombreuses mesures ont été proposées chacune répondant à des besoins spécifiques ces mesures présentent des caractéristiques variées et parfois contradictoires quil convient alors dexaminer arguant du fait que la sélection des bonnes connaissances passe aussi par lutilisation dun ensemble de mesures adaptées au contexte nous présentons dans cet article une étude expérimentale de différentes mesures cette étude est mise en regard dune étude formelle synthétisant les qualités des mesures\n",
      "exit  extraction itérative de la terminologie\n",
      "nan\n",
      "extraction de connaissances grâce à un outil de textmining application à la veille informationnelle dans le cadre policier\n",
      "nan\n",
      "extraction de processus fonctionnels en génétique des  microbes à partir de résumés medline\n",
      "après lère du décodage des génomes les biologistes sont de plus en plus confrontés à lintégration de myriades de connaissances parcellaires stockées majoritairement sous forme textuelle nous montrons à travers un exemple concret que la conjonction de deux chaînes de traitement faisant appel de façon modérée à lexpertise humaine offre au biologiste une aide utile pour parcourir cette littérature à partir dune structuration sans a priori de son corpus  il sagit ici de résumés medline indexés par les gènes et protéines quils citent et que lalgorithme structure sans superviseur en principales voies métaboliques et de régulation présentes dans le corpus choisi 1 une chaîne dindexation par les noms de gènes et protéines inclut un expert pour valider 2 un environnement interactif de clustering thématique attribue des valeurs graduées de centralité dans chaque thème aux résumés comme aux noms comme à toute autre variable illustrative autres termes bio mesh …\n",
      "extraction of text summary using latent semantic indexing and information retrieval technique  comparison of four strategies\n",
      "in this paper we present four generic text summarization techniques each technique extracts a text summary by ranking and extracting sentences from an original document the first method summarizer 1 uses standard information retrieval ir methods to rank sentences the second method summarizer 2 uses the latent semantic analysis lsa technique to identify semantically important sentences for summary creations the third method summarizer 3 uses a combination of the latent semantic analysis technique reduction and relevance measure the fourth method simply uses the tfidf term frequency  inverse document frequency weighting scheme evaluations of the four methods are conducted using document understanding conferences duc datasets from nist we have compared the summary of each method with the manual summaries summarizer 4 with its lowest overhead has comparable performance to summarizer 1 analysis shows that a combination of lsa technique and the relevance measure summarizer 3 has the best performance on an average\n",
      "fonctionnement dun système informatique daide à la décision siad\n",
      "cet article présente le fonctionnement dun siad  alimentation traitement des données qui lalimentent production des résultats outils de consultation mis à la disposition des utilisateurs exploitation éditoriale\n",
      "fonctions doubli dans les entrpôts de données\n",
      "les entrepôts de données stockent des quantités de données de plus en plus massives en particulier du fait de la constitution dhistoriques nous proposons ici une solution pour éviter la saturation des entrepôts de données nous définissons un langage de spécifications de fonctions doubli des données les plus anciennes permettant de déterminer ce qui doit être présent dans lentrepôt de données à chaque instant ces spécifications de fonctions doubli se traduisent par des opérations de résumé par agrégation et par des opérations de suppression des données anciennes réalisées de façon mécanique à chaque pas de mise à jour la communication présente tout dabord une description syntaxique du langage de spécifications des fonctions doubli les contraintes à vérifier pour assurer la cohérence du langage sont ensuite décrites enfin nous proposons des structures de données adaptées au stockage des données nécessaires à la gestion des fonctions doubli\n",
      "fouille dans la structure de documents xml\n",
      "la prolifération des documents xml appelle des techniques appropriées pour extraire et exploiter linformation contenue dans ces documents on distingue deux approches de fouille  xml content mining portant sur le contenu et xml structure lining qui a trait à la structure des documents combiner ces deux approches est très intéressant les informations contenues dans la structure orientent la fouille sur le contenu nous présentons la première étape de cette démarche  une nouvelle méthode dextraction des règles dassociation à partir de la structure des documents xml qui permet de gérer les aspects hiérarchiques de ces documents tout en améliorant les mécanismes dextraction grâce à la création dune structure spéciale représentant la hiérarchie des balises rencontrées\n",
      "fouille de grands ensembles de données avec un boosting proximal svm\n",
      "les svm support vector machines ont montré leur efficacité dans plusieurs domaines dapplication lapprentissage des svm se ramène à résoudre un programme quadratique dont la mise en oeuvre est en général coûteuse en temps une reformulation plus récente des svm proximal svm proposée par fung et mangasarian ne nécessite que la résolution dun système linéaire cet algorithme de psvm est plus efficace et permet de traiter des données dont le nombre dindividus est très important 109 et le nombre dattributs plus restreint 104 nous proposons dutiliser la formule de shermanmorrisonwoodbury pour adapter le psvm à la fouille densembles de données dont le nombre dattributs est très important et le nombre dindividus plus restreint sur un matériel standard puis nous présentons un algorithme de boosting de psvm pour classifier des données de très grandes tailles en nombre dindividus et dattributs nous évaluons les performances du nouvel algorithme sur les ensembles de données de luci twonorm ringnorm reuters21578 et ndc\n",
      "gestion de données hétérogènes dans un entrepôt de données\n",
      "nan\n",
      "gvsr  un annuaire de logiciels de manipulation et dédition de graphes\n",
      "nan\n",
      "how well go lattice algorithms on currently used machine leaning testbeds \n",
      "many research papers in classification or association rules increase the interest of concept lattices structures for data mining dm and machine learning ml to increase the efficiency of concept latticebases algorithms in ml it is necessary to make us of an efficient algorithms to build concept lattices in fact more than ten algorithms for generating concept lattices were published as real data sets for data mining are very large concept lattice structure suffers form its complexity issues on such data the efficiency and performance of concept lattices algorithms are very different from one to another so we need to compare the existing lattice algorithms with large data we implemented the four first algorithms in java environment and compared these algorithms on about 30 datasets of the uci repository that are well established to be used to compare ml algorithms preliminary results give preference to ganters algorithm and then to bordats algorithm which do not fil well with the recommendations of kuznetsov and obiedkov furthermore we analyzed the duality of latticebased algorithms\n",
      "identification de blocs homogènes sur des données continues\n",
      "contrairement aux méthodes usuelles de classification ne cherchant généralement quune seule partition soit des instances soit des attributs les méthodes de classification croisée et de classification directe fournissent des blocs de données liant des instances à des attributs les premières consistent à chercher simultanément une partition en lignes et une partition en colonnes les secondes elles sappliquent directement sur les données et permettent dobtenir des blocs de données homogènes de toutes tailles ainsi que des hiérarchies de classes en lignes et en colonnes combinant les avantages des deux méthodes nous présentons ici une méthodologie permettant de travailler sur de grandes bases de données\n",
      "induction extensionnelle  définition et application à lacquisition de concepts à partir de textes\n",
      "lorsque des outils inductifs sont inclus dans un système dacquisition des connaissances on dit que lon construit un système apprenti cest dans le but de soulager la charge de travail de lexpert du domaine que cette forme dapprentissage comporte des outils inductifs la difficulté tient en ce que lénumération des connaissances expertes produit des données peu bruitées mais très incomplètes que les itérations successives dinduction vont compléter toutefois en y ajoutant de grandes quantités de bruit il en résulte quon doit utiliser des procédures inductives spéciales adaptées à lapprentissage par croissance de noyaux de connaissance supervisée en particulier pour résoudre le problème difficile de la reconnaissance de concepts dans les textes nous avons défini une forme dapprentissage qui intègre lapprentissage à partir dinstances et les systèmes apprentis que nous nommons induction extensionnelle un oxymoron qui souligne que malgré labsence de création dun modèle explicite une induction prend effectivement place\n",
      "intégration efficace de méthodes  de fouille de données dans les sgbd\n",
      "cet article présente une nouvelle approche permettant dappliquer des algorithmes de fouille en particulier dapprentissage supervisé à de grandes bases de données et en des temps de traitement acceptables cet objectif est atteint en intégrant ces algorithmes dans un sgbd ainsi nous ne sommes limités que par la taille du disque et plus par celle de la mémoire cependant les entréessorties nécessaires pour accéder à la base engendrent des temps de traitement longs nous proposons donc dans cet article une méthode originale pour réduire la taille de la base dapprentissage en construisant sa table de contingence les algorithmes dapprentissage sont alors adaptés pour sappliquer à la table de contingence afin de valider notre approche nous avons implémenté la méthode de construction darbre de décision id3 et montré que lutilisation de la table de contingence permet dobtenir des temps de traitements équivalents à ceux des logiciels classiques\n",
      "interrogation de sources biomédicales  prise en compte des préférences de lutilisateur\n",
      "nous nous plaçons dans le cadre dun projet de constitution dune plateforme intégrative de données biomédicales pour létude génomique des cancers la plateforme comporte entre autres un certain nombre de scénarios danalyse qui sont proposés à lutilisateur a chaque étape dun scénario quil a choisi de réaliser pour les besoins de son étude lutilisateur peut être amené à poser une requête nécessitant daccéder à différentes sources et il doit alors choisir les sources pertinentes nous proposons un guide à lutilisateur sous forme dun algorithme de sélection de sources adapté à sa requête et à ses préférences pour cela nous explorons quelques spécificités des banques de données biomédicales et définissons différents critères de préférence utiles pour les biologistes nous illustrons notre démarche avec un exemple de requête biomédicale\n",
      "le elien une solution pour lextraction et le partage de connaissances structurées dans les documents hypertextuels\n",
      "nan\n",
      "les règles dassociation comme outil de catégorisation textuelle\n",
      "nan\n",
      "maintenance de bases de connaissances terminologiques\n",
      "lacquisition des connaissances terminologiques de lentreprise se fait souvent à partir des textes quelle utilise dans le cadre de ce travail la base de connaissances terminologiques repose sur la modélisation des conceptsmétier sous la forme dune ontologie le problème de la maintenance de cette base et de cette ontologie doit alors être traitédans cet article après avoir donné une définition dune base de connaissances terminologiques bct et des problèmes de diachronie nous présentons notre modèle et notre méthode dacquisition des connaissances terminologiques de lentreprise nous exposons alors notre proposition pour maintenir au cours du temps la base de connaissances terminologiques ainsi construitenous illustrons ce travail sur une base de connaissance terminologique sur le cinéma danimation en décrivant le problème de la maintenance dans une reconstitution historique de différents états de cette base lors de lapparition des techniques numériques danimation\n",
      "manipulation de représentations de cubes de données\n",
      "nan\n",
      "mediating the semantic web\n",
      "cet article développe une extension dune architecture de médiation pour intégrer le web sémantique plus précisément xlive est un médiateur tout xml développé à prism il permet dexécuter des xquery sur des sources de données hétérogènes après une rapide présentation de xlive et du web sémantique une architecture à trois niveaux dontologies et de schémas est introduite pour connecter des adaptateurs pour le web sémantique cette architecture vise à intégrer des sources de type web service dinformation conformément à une ontologie globale de référence elle conduit à étendre xlive avec le support de vues un outil de conception de vues et de mappings et des adaptateurs pour les web services\n",
      "mesurer la qualité des règles et de leurs contraposées avec le taux informationnel tic\n",
      "la validation des connaissances est lune des étapes les plus problématiques dun processus de découverte de règles dassociation pour que le décideur expert des données puisse trouver des connaissances intéressantes dans les grandes quantités de règles produites par les algorithmes de fouille de données il est nécessaire de mesurer la qualité des règles nous insérant dans le cadre de lanalyse statistique implicative nous proposons dans cet article dévaluer les règles en considérant leur contenu informationnel à travers un nouvel indice de qualité fondé sur lentropie de shannon  tic taux informationnel modulé par la contraposée cet indice a lavantage dêtre bien adapté à la sémantique des règles puisque dune part il respecte leur caractère asymétrique et dautre part il tire profit de leurs contraposées par ailleurs cest à notre connaissance la seule mesure de qualité de règles qui intègre à la fois indépendance et déséquilibre cestàdire qui permette de rejeter simultanément les règles entre variables corrélées négativement et les règles qui possèdent plus de contreexemples que dexemples des comparaisons de tic avec la jmesure linformation mutuelle lindice de gini et la confiance sont réalisées sur des simulations numériques\n",
      "mesurer les usages dinternet\n",
      "nous rendons compte dune démarche mise en place pour construire une représentation fine des usages dinternet et de leur évolution en procédant à du traitement secondaire de données de trafic provenant de panels représentatifs dinternautes après avoir présenté les caractéristiques des cohortes étudiées et les différents modes denrichissement des données de trafic mis en place nous présentons quelques résultats construits à partir de ces données enrichies et en particulier une segmentation des internautes construite sur la base de lentrelacement des pratiques de communication et de navigation\n",
      "mise en oeuvre des méthodes de fouille de données spatiales alternatives et performances\n",
      "la fouille de données spatiales nécessite lanalyse des interactions dans lespace ces interactions peuvent être matérialisées dans des tables de distances ramenant ainsi la fouille de données spatiales à lanalyse multitables or les méthodes de fouilles de données traditionnelles considèrent une seule table en entrée où chaque tuple est une observation à analyser de simples jointures entre ces tables ne résoud pas le problème et fausse les résultats en raison du comptage multiple des observations nous proposons trois alternatives de fouille de données multitables dans le cadre de la fouille des données spatiales la première consiste à interroger à la volée les différentes tables et modifie en dur les algorithmes existants la seconde est une optimisation de la première qui pré calcule les jointures et adapte les algorithmes existants la troisième réorganise les données dans une table unique en complétant  et non en joignant la table danalyse par les données présentes dans les autres tables ensuite applique un algorithme standard sans modification cet article présente ces trois alternatives il décrit leur implémentation pour la classification supervisée et compare leur performance\n",
      "modèle de gestion intégrée des compétences et connaissances\n",
      "la compétence et la connaissance sont deux concepts qui nous semblent fortement conjoints cependant ils sont rarement étudiés et gérés ensemble nous cherchons donc à identifier les liens et frontières qui peuvent exister entre eux ceci a pour objectif de développer un modèle de représentation et de gestion intégré aux connaissances et aux compétences dans cet article est tout dabord présentée une synthèse sur les concepts de compétence et de connaissance ensuite les modèles et outils de gestion de ces concepts sont exposés puis le modèle ckim competency and knowledge integrated model développé est défini les utilités de ce modèle et son exploitation sont discutées en quatrième partie la dernière partie représente un prototype dimplantation du modèle ckim réalisé sur le serveur de connaissances athanor\n",
      "modèle topologique pour linterrogation des bases dimages\n",
      "nous proposons dans cet article un modèle topologique de représentation de bases dimages chaque image est représentée à laide dun vecteur de caractéristiques dans rp et figure comme noeud dans un graphe de voisinage lexploration du graphe correspond à la navigation dans la base de données les voisins dun noeud représentent des images similaires afin de pouvoir traiter des requêtes nous définissons un modèle topologique limage requête est représentée par un vecteur de caractéristiques dans rp et insérée dans le graphe en mettant à jour localement les relations de voisinage ce travail se positionne dans le domaine de la fouille de données complexes\n",
      "modélisation dynamique et temporelle de lutilisateur pour un filtrage personnalisé de documents textuels\n",
      "lapprentissage efficace du profil utilisateur est un challenge car il évolue sans cesse dans cet article nous proposons une nouvelle approche pour lapprentissage du profil longterme de lutilisateur pour le filtrage de documents textuels dans ce cadre les documents consultés sont classés de manière dynamique et nous analysons la répartition dans le temps des classes de documents afin de déterminer le mieux possible les classes dintérêts de lutilisateur létude empirique confirme la pertinence de notre approche pour une meilleure personnalisation de documents\n",
      "musette  a framework for knowledge capture from experience\n",
      "nous présentons dans cet article une nouvelle approche de modélisation de lexpérience dutilisation dun système informatique avec pour objectif de réutiliser cette expérience en contexte pour assister lutilisateur à effectuer sa tâche quatre scénarios illustrent cette approche\n",
      "opac  opérateur danalyse en ligne basé sur une technique de fouilles de données\n",
      "lanalyse en ligne olap online analysis processing et la fouille de données data mining sont deux champs de recherche qui ont connu depuis quelques années des évolutions parallèles et indépendantes de récentes études ont montré limportance et lintérêt de lassociation entre ces deux domaines scientifiques a lheure actuelle on assiste à laccroissement du besoin dune analyse en ligne plus élaborée nous pensons que le couplage entre olap et la fouille de données pourra apporter des réponses à ce besoin dans cet article nous proposons dadopter ce couplage en vue de créer un nouvel opérateur baptisé opac opérateur dagrégation par classification danalyse en ligne des données multidimensionnelles opac consiste particulièrement en lagrégation sémantique des modalités dune dimension dun cube de données en se basant sur la technique de la classification ascendante hiérarchique\n",
      "optimisation des requêtes temporelles sur le web\n",
      "nan\n",
      "outil de représentation des évolutions de communautés dintérêts\n",
      "cet article présente un système de visualisation permettant lobservation des comportements collectifs implicites il sagit de reconnaître et de représenter des communautés à partir des connexions internet des utilisateurs  les utilisateurs sont répartis en communautés en fonction des similarités entre des listes de termes établies sur lanalyse des documents consultés par chacun deux létude est rendue dynamique par la comparaison des communautés reconnues sur des périodes de temps connexes loutil décrit ci après offre deux représentations différentes de ces communautés  une vision des liaisons thématiques entre les utilisateurs sur chaque période étudiée et une vue comparative des communautés reconnues sur toute la durée de létude\n",
      "poboc  un algorithme de \n",
      "nous décrivons lalgorithme poboc polebased overlapping clustering qui génère un ensemble de clusters nondisjoints ou softclusters présentés sous forme dune hiérarchie de concepts à partir de la seule matrice de similarités sur les données considérées nous évaluons lapproche sur deux situations dapprentissage  la classification par apprentissage de règles et lorganisation de données plus complexes et peu structurées telles que les données textuellesla validation des méthodes de clustering est une étape difficile résolue le plus souvent par une évaluation dexperts les deux applications proposées permettent de valider la méthode dorganisation selon deux points de vue  dune part quantitativement en évaluant linfluence de la méthode pour la classification dautre part en permettant une analyse humaine du résultat dans le cas des données textuelles nous mettons en évidence lintérêt de poboc comparativement à dautres approches dapprentissage nonsupervisé\n",
      "positionnement multidimensionnel et partitionnement pour la visualisation de données multivariées\n",
      "nan\n",
      "qualité et datawarehouse dans le milieu hospitalier\n",
      "nan\n",
      "recherche ciblée de documents sur le web\n",
      "les langages de requêtes motsclés pour le web manquent souvent de précision lorsquil sagit de rechercher des documents particuliers difficilement caractérisables par de simples motsclés exemple  des cours java ou des photos de formule 1 nous proposons un langage multicritères de type attributvaleur pour augmenter la précision de la recherche de documents sur le webnous avons expérimentalement montré le gain de précision de la recherche de documents basé sur ce langage\n",
      "recherche dans de grandes bases dimages fixes  une nouvelle approche guidée par les règles dassociation\n",
      "une base dimages fixes peut être décrite de plusieurs façons notamment par des descripteurs visuels globaux de couleur de texture ou de forme les requêtes les plus fréquentes impliquent et combinent les résultats de plusieurs types de descripteurs  par exemple retrouver toutes les images ayant une couleur et une texture semblables à celles dune image requête donnée pour retrouver plus efficacement et plus rapidement une image dans une grande base nous exploitons des combinaisons appropriées de descripteurs et étudions lintérêt des règles dassociation entre clusters de descripteurs pour accélérer le temps de réponse à des requêtes sur de grandes bases dimages fixes\n",
      "recherche de règles dassociation hiérarchiques par une approche anthropocentrée\n",
      "lextraction de connaissances dans la bases de données est devenue pour les banques une alternative au problème lié à la quantité de données qui sont stockées et qui ne cessent daugmenter ceci aboutit à un paradoxe puisquil faut mieux cibler la clientèle susceptible dêtre intéressée par une offre en utilisant des méthodes qui ne permettent plus de traiter le nombre croissant denregistrements des bases de données nos travaux se situent dans la continuité dune étude que nous avons réalisée sur la recherche de règles dassociation appliquée au marketing bancaire en effet des premiers résultats encourageants nous ont conduit à approfondir nos travaux vers une recherche de règles dassociation hiérarchiques utilisant non plus une approche automatique mais une approche anthropocentrée il sagit dune approche dans laquelle lexpert fait partie intégrante du processus en jouant le rôle dheuristique évolutive cet article présente les résultats de notre démarche de recherche\n",
      "réduction dun jeu de règles dassociation par des métarègles issues de la logique du \n",
      "nan\n",
      "réduction du coût dévaluation dune règle relationnelle\n",
      "de nombreuses tâches en fouille de données visent à extraire des connaissances exprimées sous la forme dun ensemble de règles les algorithmes dédiés à ces tâches engendrent des règles dont ladéquation aux données doit être évaluée on se place dans le cadre où cette évaluation est réalisée directement en lançant des requêtes de dénombrement sur la base de données et où cette base est relationnelle les requêtes comptent les données qui sapparient avec la règle calcul qui peut être extrêmement coûteux dans cet article nous étudions limpact dune approche déchantillonnage visant à réduire le coût de lévaluation des règles relationnelles en tenant compte des spécificités structurelles des requêtes induites\n",
      "règles didentification et méthodes de visualisation dobjets architecturaux\n",
      "dans létude du patrimoine bâti la gestion dinformations pose aujourdhui des problèmes dinterfaçage non triviaux notamment par la masse la diversité la complexité et le caractère hétérogène des contenus la représentation tridimensionnelle du tissu urbain à différentes échelles de la ville au corpus architectural parce quelle localise spatialement linformation à délivrer et lattache à la morphologie de lédifice apparaît comme une des réponses possibles cette réponse semble par ailleurs bien adaptée aux problématiques spécifiques de lanalyse architecturale du patrimoine que sont par exemple la restitution dédifices disparus et les notions dincertitude qui sy attachent ou le réemploi déléments de corpus pourtant la représentation tridimensionnelle dans notre champ dapplication est aujourdhui loin de remplir ce rôle notre contribution vise à discuter quelques uns des prérequis qui nous semblent simposer à la lumière de nos expériences pour faire de la maquette 3d un outil dinvestigation des connaissances sur lédifice\n",
      "régression linéaire symbolique avec variables taxonomiques\n",
      "le présent papier concerne lextension des méthodes classiques de régression linéaire aux cas des données symboliques et fait suite à de précédents travaux de billard et diday sur la régression linéaire avec variables intervalles et histogrammes dans ce papier nous présentons des méthodes de régression avec variables taxonomiques les variables taxonomiques sont des variables organisées en arbre exprimant plusieurs niveaux de généralité les villes sont regroupées en régions qui sont ellesmêmes regroupées en pays la méthode proposée sera testée sur données simulées finalement nous observerons que ces méthodes nous permettent dutiliser la régression linéaire pour étudier des concepts et pour réduire le nombre de données afin daméliorer les résultats obtenus par rapport à une régression classique\n",
      "relations entre gènes impliqués dans les cancers de la thyroïde\n",
      "des relations entre gènes et protéines impliqués dans les cancers de la thyroïde ont été mises en évidence par lanalyse dun important corpus de résumés de  la base de données bibliographique medline une approche pluridisciplinaire biologistes cliniciens linguistes et chercheurs en sciences de linformation a permis lindexation automatique et lanalyse de ce corpus lindexation contrôlée structurée en classes sémantiques à partir de vastes ressources hétérogènes les bases biomédicales et génétiques umls et locuslink prend en compte la spécificité des termes  nomenclatures biochimiques acronymes de gènes aberrations chromosomiques ou encore variantes linguistiques de termes les deux méthodes de classification complémentaires appliquées révèlent un réseau lexical dense de gènes concurrents autour de trois principales pathologies de la thyroïde  les cancers médullaires papillaires et des dysfonctionnements du système immunitaire les développements apportés aux outils de visualisation interactifs du serveur visa de linist facilitent lecture et navigation au sein des documents\n",
      "représentation condensée de motifs émergents\n",
      "les motifs émergents sont des associations de caractéristiques fortement présentes dans une classe et rares dans les autres ils font ressortir les distinctions entre classes et se révèlent particulièrement efficaces pour construire des classifieurs et apporter une aide au diagnostic à cause de la forte combinatoire du problème la recherche et la représentation des motifs émergents restent des tâches complexes pour de grandes bases de données nous proposons ici une représentation condensée exacte des motifs émergents ie les motifs et leurs taux de croissance sont directement obtenus depuis la représentation condensée lidée principale est de sappuyer sur les récents résultats relatifs aux représentations condensées de motifs fermés fréquents à partir de cette représentation nous donnons aussi une méthode aisée à mettre en oeuvre pour obtenir les motifs émergents ayant les meilleurs taux de croissance ces motifs appelés motifs émergents forts ont été exploités avec succès dans une collaboration avec la société philips\n",
      "représentation de graphes par acp granulaire\n",
      "lextraction dinformation de grands graphes repose le plus souvent sur leur représentation dans des espaces de dimension réduite et on utilise généralement des méthodes factorielles appliquées à des mesures de dissimilarités calculées à partir des matrices associée du graphe ou lanalyse spectrale de leur laplacien discret efficaces pour dégager les structures globales ces représentations sont parfois peu exploitables dès lors que lon sintéresse à une perspective du graphe à partir de certains sommets privilégiés or linformation recherchée a souvent un caractère local pour représenter le graphe du point de vue dun ou plusieurs sommets sélectionnés nous proposons une méthode danalyse en composantes principales granulaire consistant à appliquer une acp filtrée à un tableau de proximités la visualisation dun graphe de dictionnaire dont la mesure de proximité est obtenue à partir dun algorithme original illustre notre propos\n",
      "résumé de cubes de données multidimensionnelles à laide de règles floues\n",
      "dans le contexte des entrepôts de données et des magasins de données multidimensionnelles les outils olap fournissent des moyens aux utilisateurs de naviguer dans leur données afin dy découvrir des informations pertinentes cependant les données à traiter sons souvent très volumineuses et ne permettent pas une exploration systématique et exhaustive il sagit donc de développer des traitements automatisés facilitant la visualisation et la navigation dans les données dans cet article nous étudions une méthode originale permettant de construire et didentifier de manière automatique et efficace des blocs de données similaires présents dans les cubes de données pouvant être exprimés sous la forme de règles cette méthode est fondée sur lutilisation combinée dun algorithme par niveaux de type apriori et de la théorie des sousensembles flous cette théorie nous permet en effet de pallier les problèmes posés par le fait que les blocs de données calculés par notre algorithme peuvent se recouvrir\n",
      "sélection dattributs et classification dobjets complexes\n",
      "nan\n",
      "sélection rapide en apprentissage supervisé\n",
      "la sélection de variables sdv permet de réduire lespace de représentation des données ce processus est de plus en plus critique en raison de laugmentation de la taille des bases de données traditionnellement les méthodes de sdv nécessitent plusieurs accès au jeu de données ce qui peut représenter une part relativement importante du temps dexécution de ces algorithmes nous proposons une nouvelle méthode efficiente et rapide ne nécessitant quun unique accès aux données cette méthode utilise les algorithmes génétiques ainsi que des mesures de validité de classification non supervisée cns\n",
      "sousensembles flous définis sur une ontologie\n",
      "les sousensembles flous peuvent être utilisés pour représenter des valeurs imprécises comme un intervalle aux limites mal définies ils peuvent également servir à lexpression de préférences dans les critères de sélection de requêtes en bases de données en représentation des connaissances lutilisation de hiérarchies de types est largement répandue afin de modéliser les relations existant entre les types dobjets dun domaine donné nous nous intéressons aux sousensembles flous dont le domaine de définition est une hiérarchie déléments partiellement ordonnés par la relation sorte de que nous appelons ontologie nous introduisons la notion de sousensemble flou défini sur une partie de lontologie puis sa forme développée définie sur lensemble de lontologie que nous appelons extension du sousensemble flou des classes déquivalence de sousensembles flous définis sur une ontologie peuvent être caractérisées par un représentant unique que nous appelons sousensemble flou minimal nous concluons par un exemple dapplication dans un système dinformation relatif à la prévention du risque microbiologique en sécurité alimentaire\n",
      "uitliation de connaissances pour laide à la recherche documentaire fondée sur le contenu\n",
      "nan\n",
      "un algorithme de génération des itemsets fermés pour la fouille de données\n",
      "le traitement de grand volume de données est un problème pour lextraction de connaissances la fouille de données nécessite des méthodes de résolution efficaces le treillis de concepts treillis de galois est un outil utile pour lanalyse de données des travaux en classification et sur les règles dassociation ont permis daccroître son intérêt plusieurs algorithmes de génération on été proposés parmi lesquels nextclosure est lun des meilleurs pour traiter des données de grande taillemais la complexité de nextclosure reste malgré tout très élevé aussi nous proposons un nouvel algorithme efficace nommé scalingnextclosure et basé sur une méthode de partitionnement de données pour générer de manière indépendante les itemsets fermés de chaque partition les résultats expérimentaux montrer que cette technique de partitionnement améliore efficacement nextclosure\n",
      "une approche probabiliste pour le classement dobjets incomplets dans un arbre de décision\n",
      "nan\n",
      "une étude dalgorithmes de classification supervisée basée sur les treillis de galois\n",
      "nan\n",
      "une méthode pour lappropriation de savoirfaire capitalisé avec mask\n",
      "la gestion explicite des savoirs et savoirfaire occupe une place de plus en plus importante dans les organisations la construction de mémoires dentreprise dans un but de préservation et de partage est devenu une pratique assez courante cependant on oublie trop suivent que lefficacité de ces activités est étroitement liée aux capacités dappropriation et dapprentissage des acteurs de lorganisationdans cet article nous proposons des démarches générales daccompagnement permettant de faciliter le processus dappropriation des mémoires dentreprise construits avec la méthode mask en exploitant des techniques dingénierie pédagogique\n",
      "utilisation des graphes de proximité dans le cadre de lapprentissage basé sur les voisins\n",
      "la classification suivant les plus proches voisins est une règle simple et attractive basée sur une définition paramétrique du voisinage les graphes des proximité quand à eux induisent des notions plus souples de voisinage il sagit ici deffectuer la substitutionles variantes obtenues peu testées dans la bibliographie ont été soumises à une expérimentation intensive sur bases de données de luci et de france télécom on a ainsi considéré divers types de prétraitement des données et plusieurs catégories de graphes de plus on a caractérisé les effets du piège de la dimension sur le comportement théorique de tous les graphes présentés une quantification empirique du phénomène ayant été réaliséeil ressort de notre étude que lutilisation du voisinage de gabriel provoque une amélioration en moyenne et que le prétraitement basé sur la statistique de rang est le plus adéquate quoiquil arrive des précautions doivent être prises en grande dimension\n",
      "validation de graphes conceptuels\n",
      "les travaux menés en validation des connaissances visent à améliorer la qualité des bases de connaissances le modèle des graphes conceptuels est un modèle de représentation des connaissances de la famille des réseaux sémantiques fondé sur la théorie des graphes et sur la logique du premier ordre nous proposons une solution pour valider sémantiquement une base de connaissances composée de graphes conceptuels la validation sémantique dune base de connaissance consiste à confronter ses connaissances à des contraintes certifiées fiables nous proposons dutiliser des contraintes descriptives exprimées sous forme de graphes conceptuels qui permettent de poser des conditions sur la représentation de certaines connaissance dans la base ces contraintes introduisent une notion de cardinalités et sont soit minimales soit maximales elles permettent respectivement dexprimer si a alors au moins ou au plus n fois b la satisfaction de ces contraintes par une base de connaissances repose sur lutilisation de lopération de base du modèle des graphes conceptuels  la projection\n",
      "veille technologique assistée par la fouille de textes\n",
      "le domaine de la veille technologique vise à récolter traiter et analyser des informations scientifiques et techniques utiles aux acteurs économiques dans cet article nous proposons dutiliser des techniques de fouille de textes pour automatiser le processus de traitement des données issues de bases de textes scientifiques toutefois la veille introduit une difficulté inhabituelle par rapport aux domaines dapplication classiques des techniques de fouille de textes puisquau lieu de rechercher de la connaissances fréquente cachée dans les données il faut rechercher de la connaissance inattendue les mesures usuelles dextraction de la connaissance à partir de textes doivent de ce fait être revues pour ce faire nous avons développé le système unexpectedminer dans lequel de nouvelles mesures permettent destimer le caractère inattendu dun document notre système est évalué sur une base darticles dans le domaine de lapprentissage automatique\n",
      "vers un entrepôt de données pour la gestion des risques naturels\n",
      "les entrepôts de données sont lun des plus importants développements dans le domaine des systèmes dinformations ils permettent dintégrer des données de plusieurs sources souvent très volumineux distribuées et hétérogènes dans cet article nous examinons la possibilité dutiliser la technique dentrepôt de données dans la gestion des risques naturels nous présentons un modèle conceptuel pour lentrepôt proposé avec la présence de formats et types variés de données tel que des données géographiques et multimédia nous proposons également des opérations olap pour la navigation des informations stockées dans le cube de données\n"
     ]
    }
   ],
   "source": [
    "resume = [tokenize(doc[\"title\"][0].lower())]\n",
    "abstract = [tokenize(str(doc[\"abstract\"][0].lower()))]\n",
    "for line in range(len(doc)): # title et abstract ont la même taille.\n",
    "    if line != 0:\n",
    "        resume.append(tokenize(doc[\"title\"][line].lower()))\n",
    "        abstract.append(tokenize(str(doc[\"abstract\"][line]).lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le traitment des données est acceptable. Un meilleur traitement pourrait être envisagé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut obtenir un seul jeu de données avec les titres et les abstracts pour pouvoir les traiter et éliminer les cas qui n'ont pas d'abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible que seul le titre suffise. Il est possible que la racinisation ne soit pas nécéssaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in range(len(abstract)):\n",
    "    if abstract[line] != \"nan\":\n",
    "        for element in abstract[line]:\n",
    "            resume[line].append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention : l'étape suivante est longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dico_time = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140258"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico = []\n",
    "for line in resume:\n",
    "    for word in line:\n",
    "        dico.append(word)\n",
    "for word in dico:\n",
    "    if dico.count(word) != 1:\n",
    "        dico.remove\n",
    "len(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2103.98 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % round(time.process_time() - dico_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15079"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico = list(set(dico))\n",
    "len(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du Tf.\n",
    "tf = []\n",
    "for x in range(len(resume)):\n",
    "    tf.append([])\n",
    "    for y in range(len(resume[x])):\n",
    "        tf[x].append(resume[x].count(resume[x][y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention : l'étape suivante est longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du Df.\n",
    "df = {}\n",
    "for x in range(len(dico)):\n",
    "    sum = 0\n",
    "    for y in range(len(resume)):\n",
    "        if dico[x] in resume[y]:\n",
    "            sum = sum + 1\n",
    "    df[dico[x]] = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 186.41 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % round(time.process_time() - df_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'Idf\n",
    "idf = {}\n",
    "for word in df:\n",
    "    idf[word] = np.log10(len(resume)/df[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1269"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul du Tf-Idf.\n",
    "tfidf = []\n",
    "for x in range(len(resume)):\n",
    "    tfidf.append({})\n",
    "    for y in range(len(resume[x])):\n",
    "        tfidf[x][resume[x][y]] = tf[x][y] * idf[resume[x][y]]\n",
    "len(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut trier les Tf-Idf par valeur et récupérer les 5 meilleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = []\n",
    "for item in tfidf:\n",
    "    topic = \"\"\n",
    "    trier = sorted(item.items(), key=lambda kv: kv[1])\n",
    "    trier.reverse()\n",
    "    if len(item)<5:\n",
    "        top = len(item)\n",
    "    else:\n",
    "        top = 5\n",
    "    for i in range(top):\n",
    "        topic = topic + trier[i][0] + \" \"\n",
    "    best.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['politique idéo2017 citoyen tweets candidat ',\n",
       " 'coclustering modl gagne taille passent ',\n",
       " 'recommandation mobilité factorisation dintérêts inféré ',\n",
       " 'arabe sentiment commentaire marocain dialectal ',\n",
       " 'cds résumé texte composant rôle ',\n",
       " 'big scénario ontologique data analyse ',\n",
       " 'tentative décès supervisées patient risque ',\n",
       " 'formés majoritaire vote global obtenus ',\n",
       " 'label heureux morceau relation musique ',\n",
       " 'ab test procédure stratification contextuel ',\n",
       " 'dynamics power understanding big human ',\n",
       " 'incrémentales cc clustering som collaboratif ',\n",
       " 'motsclés darticles catégorisation scientifique relation ',\n",
       " 'cardiaque similarité quasiarithmétiques moyenne type ',\n",
       " 'community complex network in structure ',\n",
       " 'limportance noeud réseau influe différencie ',\n",
       " 'similarité campagne sémantique vectorielles complémentarité ',\n",
       " 'tempsréel oblige liot pertinence démontrées ',\n",
       " 'complétude prescriptives commande contrainte vérifier ',\n",
       " 'treillis distributif fca concept médians ',\n",
       " 'gpo séquence ordonnés graduel partiellement ',\n",
       " 'dbpédia dassociations catégorie apparentés lacune ',\n",
       " 'spark tempsréel singularité basés combinaison ',\n",
       " 'motif norme aléatoire séquentiels rejet ',\n",
       " 'edoi multicouches itérative exploration lutilisateur ',\n",
       " 'elaboration délaboration poster géotechnique entreprise ',\n",
       " 'lien wikipédia interlangues édition erronés ',\n",
       " 'métier antécédent recrutent lerecrutement sociaux ',\n",
       " 'darticles thématique scientifique sémantique corpus ',\n",
       " 'dinfluenceurs centralité dalgorithmes comparative évaluation ',\n",
       " 'météorologiques journée mesurées série ville ',\n",
       " 'chemin linformation propagation trajectoire retrouver ',\n",
       " 'défaillance dessieux compteur cause événement ',\n",
       " 'temporalité graduel fermé fréquents contrainte ',\n",
       " 'événement négatif motif électricité ntgsp ',\n",
       " '’ d document interrogation schéma ',\n",
       " 'apprenant leader dentre eux chacun ',\n",
       " 'recommandation dhôtels contextuelles distinctives volatilité ',\n",
       " 'ontobiotope vie lontologie microbiens lagriculture ',\n",
       " 'longrange influence network social in ',\n",
       " 'bord personnalité média communauté suivi ',\n",
       " 'nnms meanshift kplus scalable voisin ',\n",
       " 'ordinale métaanalyse ordre enquête dopinion ',\n",
       " 'approximatifs déséquilibré incrémental décision mai2p ',\n",
       " 'microblogs localisation extraire dapprentissage nan ',\n",
       " 'métadonnées vault physique data stockage ',\n",
       " 'blockchain notarisation nfb protocole document ',\n",
       " 'approximatifs massives théorie caractéristique sélection ',\n",
       " 'palm lespace treillis parallèle branche ',\n",
       " 'peerus dexperts scientifique review entrainé ',\n",
       " 'capacitaire planning perforecast tôt service ',\n",
       " 'solaire rayonnement prédiction météorologiques régression ',\n",
       " 'thr inventaire satellitaires image terrain ',\n",
       " 'indexation performante prise compte document ',\n",
       " 'financement campagne participatif proposition prédiction ',\n",
       " 'nos questce machine évolué lapprentissage ',\n",
       " 'personnalisées motsclés réponse fournir seulement ',\n",
       " 'manuscrit indexation historique chancellerie registre ',\n",
       " 'linéaire shift déploiement distribution variées ',\n",
       " 'dassainissement date conduite pose reconstitution ',\n",
       " 'âgées personne chute information bayésien ',\n",
       " 'artificielle voir dela vision savoir ',\n",
       " 'neuroimagerie dobservation réaliste réutilisation cliniciens ',\n",
       " 'verbalisation fait dindices temporel formalisation ',\n",
       " 'coclustering bayésien critère modèle mixtes ',\n",
       " 'recommandation personnalisées dactualité hybride échelle ',\n",
       " 'carreau désagrégation population bâtiment ouvertes ',\n",
       " 'unitexgramlab grammaire sétend dunitexgramlab marnelavallée ',\n",
       " 'universalendpointcom web daccès plateforme sparql ',\n",
       " 'thématique nouveauté émergentes dobserver scénario ',\n",
       " 'cardiovasculaires maladie facteur risque interaction ',\n",
       " 'textuel lignée su influencers hybrid ',\n",
       " 'dévolution satellitaires série temporelles dimages ',\n",
       " 'sujet dinvestigation haut biclustering variante ',\n",
       " 'table anonymiser publiées individu coclustering ',\n",
       " 'binarisées variable coclustering party étape ',\n",
       " 'item zone intermédiaire » « ',\n",
       " 'structuration multiinstance cadre ensemble taxonomique ',\n",
       " 'crf dappels définissent doffres séquentielles ',\n",
       " 'flux parallélisme opérateur traitement degré ',\n",
       " 'méta devaluation analyse cadre nan ',\n",
       " 'cah part formule ascendant noyau ',\n",
       " 'sousparties discriminantes aléatoire 3d dobjets ',\n",
       " 'label relation dapprendre dignorer cycliques ',\n",
       " 'dtcwt phase transform isar reconnaissance ',\n",
       " 'coclustering mixtes table continues bloc ',\n",
       " 'treillis similarité concept mesure basées ',\n",
       " 'ab généraliste conception lévaluation test ',\n",
       " 'carlo monte bs sd sousgroupes ',\n",
       " 'city captured cities and of ',\n",
       " 'costsensitive précisionrappel maladie ville défi ',\n",
       " 'lutilisateur motif préféré implicitement transaction ',\n",
       " 'multimodales faux sociaux vers détection ',\n",
       " 'ratings recommendation useruser filtering enhanced ',\n",
       " 'communauté stabilité représentatives période temporelle ',\n",
       " 'normalité singularité expression naturel langage ',\n",
       " 'paysage limage enjeu dautomatisation alliant ',\n",
       " 'chronique discriminantes motif discriminant séquence ',\n",
       " 'entité événement relation lexicosémantique rachetées ',\n",
       " 'récurrentes attribué graphe unique évolution ',\n",
       " 'chaînage dentretiens histoire supervisés science ',\n",
       " 'géométriques 3d dassemblages propriété raisonnement ',\n",
       " 'télévisés darchives face2graph archive visage ',\n",
       " 'témoignage saisi rédigeant saisie préserver ',\n",
       " 'format rdf sparql sparqlgenerate nonrdf ',\n",
       " 'waves dénotée îledefrance potable souterrain ',\n",
       " 'rdf web format service objet ',\n",
       " 'ksc centroïd kspectral translation barycentre ',\n",
       " 'apps android through text features ',\n",
       " 'could the for knowledge ontology ',\n",
       " 'confiance source dinformations navire dinformation ',\n",
       " 'resp attribut objet treillis correspondance ',\n",
       " 'pli léchelle lasubsomption dacteurs de\\x12subsomption ',\n",
       " 'colonne nosql orienté entrepôt hbaseavec ',\n",
       " 'pharmacovigilance web social fondé sémantique ',\n",
       " 'porgy simulationainsi pilotés modélisationde rewriting ',\n",
       " 'numéro défi multilabel tâche été ',\n",
       " 'financement campagne montant levé participatif ',\n",
       " 'ferré prévision bayésiens réseau court ',\n",
       " 'client laide profil prototype différentesvisualisations ',\n",
       " 'recommandation folksonomie filtrage préférence basées ',\n",
       " 'décision justice crf hmm dentités ',\n",
       " 'ciblée descripteur visuel dimages dassociation ',\n",
       " 'multilabel prétraiter label sélection variable ',\n",
       " 'flux clustering didentifer clusteringsur dusubspace ',\n",
       " 'réseau lien conceptuels clusters noeud ',\n",
       " 'personnalisés rdfsparql littéral type rdf ',\n",
       " 'télédétection référence bonne crowdsourcinget réalignement ',\n",
       " 'prédictives kmoyennes lindice mesurer lalgorithme ',\n",
       " 'communautaire générateur graphe réseau dynamique ',\n",
       " 'lbsn recommandation dintérêt poisson factorisation ',\n",
       " 'graduel dordre groupement variation temporel ',\n",
       " 'neutralité personnalité innovante diffusion compréhension ',\n",
       " 'dassociation règle fouille indirectes ferméeset ',\n",
       " 'société numériques calcul vie nos ',\n",
       " 'dexpertise crowdsourcing participant campagne degré ',\n",
       " 'rôle communautaires centralité mesure trait ',\n",
       " 'dopinions twitter recommandation plateforme danalyse ',\n",
       " 'veille rewatch thème web pertinence ',\n",
       " 'transformé échantillonnage flux vers nan ',\n",
       " 'nell instance français chaîne nouvelleinstance ',\n",
       " 'label multilabel court interactif texte ',\n",
       " 'engagement user the search click ',\n",
       " 'passage question reclassement retourner ngrammes ',\n",
       " 'mappings soc lévolutiondes biomédical changement ',\n",
       " 'users survey have the of ',\n",
       " 'coviz variable khiops visualisation catégorielles ',\n",
       " 'conférence publication egc 3 série ',\n",
       " 'thématique publication conférence somme scientifique ',\n",
       " 'electricity long the provider temporalseries ',\n",
       " 'we neighborhoodbased group clustering new ',\n",
       " 'model training tree method and ',\n",
       " 'agroalimentaire – acteur décision vienten ',\n",
       " 'the learning to approach characterization ',\n",
       " 'catégorisation intérêt individu enutilisant renseignent ',\n",
       " 'clustering attribut lutilisateur préférencesest guidéespar ',\n",
       " 'extrait unjournal accepté etpurement présentéafin ',\n",
       " 'discovery wepropose metabolomic biomarkers methodologiesto ',\n",
       " 'suicide drift avecsuccès dapprentissagedont personnesmonitorées ',\n",
       " 'lexploration visuel dimages construite structure ',\n",
       " 'of the 2colorability hypergraphs property ',\n",
       " 'label doublon binaires lexploration treillis ',\n",
       " 'trace unitaire ni motif collection ',\n",
       " 'egc mot thématique topic 2016 ',\n",
       " 'collaboration tendance egc descriptive réseau ',\n",
       " 'motif méthodeapprochée fpof daberration aberrantes ',\n",
       " 'message system and the aismessages ',\n",
       " 'multidimensionnel hiérarchique hiérarchie factuelles architecturerolap ',\n",
       " 'groupe centralité collaboration scientifique thématique ',\n",
       " '2016 egc défi dinformationlogiques surun ',\n",
       " 'csparql flux extension raisonnement préservationde ',\n",
       " 'chimiques nommées dentités reconnaissance deles ',\n",
       " 'clé liage publiées candidat pertinenceet ',\n",
       " 'commentaire commentsminer publiquementaccessible représentatif 84 ',\n",
       " 'pervasifs treillis formelle desmétriques généraliserlextraction ',\n",
       " 'factory network social overloading subtypingand ',\n",
       " 'in the data and this ',\n",
       " 'multistratégie fodomust interface plateforme temporelles ',\n",
       " 'approchesde asp motif encodage programmation ',\n",
       " 'duplicats redondantes quelle dargumentation transparenteet ',\n",
       " 'clustering contrainte satellite lexpert priori ',\n",
       " 'semantic of identification relation in ',\n",
       " 'sentiment new the social smscorpus ',\n",
       " 'recommandation lbsn géographique temporelle jusquà ',\n",
       " 'multitables khiops million variable cas ',\n",
       " 'pomotifs sousséquences relationnelle concept ététesté ',\n",
       " 'time candidateto seems chorems meteorology ',\n",
       " 'mi pattern the sequential to ',\n",
       " 'révolution captation risque lassureur canal ',\n",
       " 'the project and of learning ',\n",
       " 'protocole stockage libre cassandrales évaluépar ',\n",
       " 'myocarde linfarctus hospitalièresplus pmsi fonctionnementde ',\n",
       " 'the their of semantics to ',\n",
       " 'clowdflows fouille donnéesrelationnelles webpermettant venons ',\n",
       " 'forum réputation vote message vis ',\n",
       " 'spectral arbitraire latent transformation théorie ',\n",
       " 'recommandation tags persorec ressource quadratiques ',\n",
       " 'plongement isométrique métrique lch chodorow ',\n",
       " 'plateforme collaboratives qualité noeud relation ',\n",
       " 'hyperplan parallèle point phase commune ',\n",
       " 'logistique régression dimages échelle parallèle ',\n",
       " 'skyline retournés relaxéest preferred pluspréférés ',\n",
       " 'requête négatif discriminantes lexploration exemple ',\n",
       " 'géographiques spatiales dassociations régissant saffietqui ',\n",
       " 'sarem the architectureextraction softwarearchitecture specifies ',\n",
       " 'comportementale client segmentation adapterloffre ensembleplus ',\n",
       " 'sousensemble topologique sélection discrimination induite ',\n",
       " 'slider to reasoner the more ',\n",
       " 'haie markov hilbert courbe densité ',\n",
       " 'moving objects the done trip ',\n",
       " 'tom topic and modeling browsing ',\n",
       " 'mettons egc thématique décrivonsune thématiquesde ',\n",
       " 'constraint programming generic solvers settings ',\n",
       " 'transmute trace linterprétation motif àse ',\n",
       " 'cosc télédétection collaboratif segmentation thématique ',\n",
       " 'egc 2016 thème défi lorsdes ',\n",
       " 'desdonnées propriété textuelles représentationsphonologiques unicode ',\n",
       " 'lexicoscientométrique egc 2016 défi websoustendu ',\n",
       " 'défaillance détection système robotisé mixtes ',\n",
       " 'lod létiquetage définition dontologie raisonnement ',\n",
       " 'data both knowledge and tbox ',\n",
       " 'réduction dimensionnalité dagrégation préférence despremiers ',\n",
       " 'phrase similarité noyau sémantique extrait ',\n",
       " 'mobilité trace lindividu motif divers ',\n",
       " 'kmoyennes centre vise kmoyennesstandard quelpoint ',\n",
       " 'the variant extract topics analytics ',\n",
       " 'carte utilisateur d c cartographie ',\n",
       " 'rdfsowl schema to data the ',\n",
       " 'segmentation maillage lannotation annotation ontologie ',\n",
       " 'paramètre étaient dinformation quels recherche ',\n",
       " 'dopinions veille amiei leweb danalyse ',\n",
       " 'blog dexpérience retour olap projet ',\n",
       " 'cybercriminalité mondiale déplaisant dinterconnecter mondialisation ',\n",
       " 'of the bilingual multilingual document ',\n",
       " 'advantage to window the consider ',\n",
       " 'the data will explore and ',\n",
       " 'big data research the is ',\n",
       " 'and the to — help ',\n",
       " 'proximité topologique mesure discriminante discrimination ',\n",
       " 'secm évidentielle croyance doptimisation fonction ',\n",
       " 'multilabel économique centrée lindexation raisonnement ',\n",
       " 'gstream flux clustering topologique gas ',\n",
       " 'base – rdf jour soit ',\n",
       " 'critère lecart partition modularité ayant ',\n",
       " 'précisionrappel compromis performance indice fonction ',\n",
       " 'skyline calcul candidat réduction pénalisé ',\n",
       " 'd113 flux centrerons équipement transitant ',\n",
       " 'analogiques proportion analogique paire nuplets ',\n",
       " 'mot reformulation plagiat détection détecter ',\n",
       " 'détection plagiat passage auteur devient ',\n",
       " 'risque chimique alimentaire confondue substance ',\n",
       " 'stream shedding load the data ',\n",
       " 'collection function of is proportional ',\n",
       " 'pondérés chemin condensé complète motiver ',\n",
       " 'mf recommandation technique item utilisateur ',\n",
       " 'mahout forest random of the ',\n",
       " 'manquant hydrologie gapit hydrométriques station ',\n",
       " 'knowledge uncertainty representation the an ',\n",
       " 'mappings adaptation ontologie lévolution guidant ',\n",
       " 'dauteurs auteur panclef rédigé dauthentification ',\n",
       " 'recommandation utilisateur sociale préférence identification ',\n",
       " 'amazighe langue repérage nommées entité ',\n",
       " 'and property re realestate the ',\n",
       " 'fusion éventuel driven linked conflit ',\n",
       " 'multidimensional big data as and ',\n",
       " 'the network actor centrality of ',\n",
       " 'mot texte intersection copiercoller étant ',\n",
       " 'mine classe new mixture labeling ',\n",
       " 'biclustering mapreduce dataset the cores ',\n",
       " 'tweets vocabulary this to the ',\n",
       " 'croisé item collaboratif filtrage exploitation ',\n",
       " '2d projection interactif loutil clustering ',\n",
       " 'complexité motif axiome évaluation lié ',\n",
       " 'rankmerging lien réseau classement épars ',\n",
       " 'cpt prédiction compact ppm allkorder ',\n",
       " 'règle dattributs liaison dapprentissage attribut ',\n",
       " 'élastique noyau régularisation kdtw nonlinéaire ',\n",
       " 'évidentielles skyline évidentiel pareto incertaines ',\n",
       " 'the of method and with ',\n",
       " 'tweets of the in creation ',\n",
       " 'ultramétricité dissimilaritées dultramétricité regroupement genere ',\n",
       " 'composante parcimonieuse em principal probabiliste ',\n",
       " 'icm compacité haute convergence résolution ',\n",
       " 'dinterrogation graphe conceptuels lhomomorphisme optionnel ',\n",
       " 'multiplexe réseau graine communauté centrée ',\n",
       " 'propagation comparer modèle réécriture analytique ',\n",
       " 'changement composé formalisation ontologiques élémentaires ',\n",
       " 'sémiotique style indicateur usage expliquerons ',\n",
       " 'petl massives etl parallèle plateforme ',\n",
       " 'interaction site social recueillis informatif ',\n",
       " 'the stemma codicum triplet obtained ',\n",
       " 'sousgroupes molécule olfactives neuroscientifiques descriptives ',\n",
       " 'hotspots hotspot photographie relation fendu ',\n",
       " 'xplor xewgraph everywhere and newest ',\n",
       " '1dsax sax série symbolisation temporelles ',\n",
       " 'représentation importantspar respectent opérateursdagrégation expériencesrapportées ',\n",
       " 'liées nalt avecagrovoc duneontologie ontologiesource ',\n",
       " 'document administratif lhomme ledocument oudun ',\n",
       " 'mapreduce musée paradigme personne casdétudes ',\n",
       " 'protéinearn rosettadock score fonction poids ',\n",
       " 'naïf bayésien logvraisemblance variablesexplicatives classifieur ',\n",
       " 'phrase traduisant syntaxique dépendance mot ',\n",
       " 'typés fusion formelle grammaire dontologies ',\n",
       " 'sommet multirésolution dinformationnous dedécrire sontassociés ',\n",
       " 'drift drifted the new sudden ',\n",
       " 'the data and broad of ',\n",
       " 'stsurf reconnaissance descripteur dactions dictionnaire ',\n",
       " 'solaire prédiction rayonnementssolaires photovoltaïque flux ',\n",
       " 'bayes naïf classifieur pondéré explicatives ',\n",
       " 'clustering fonctionnerdans détournant validonsexpérimentalement attributsvaleurs ',\n",
       " 'grille dimension séquence dévènements clustering ',\n",
       " 'fcl conceptuels communauté intersection lien ',\n",
       " 'lénoncé obtenusconduisent syndrome phénomèneet situationshumaines ',\n",
       " 'cluster borne laffectation passe incrémental ',\n",
       " 'chemin caractérisation voisinage deséléments lexception ',\n",
       " 'compréhension cuisine recette site partagede ',\n",
       " 'cube olap larchitecture orientée calcul ',\n",
       " 'préférence profil contextuelles séquentiels recommandationsjustes ',\n",
       " 'logiciel enrevue passé leçon prototypeles ',\n",
       " 'volume descripteur influençant étudiéen diminue ',\n",
       " 'humanité matériau numériques tenterons numérique ',\n",
       " 'endétectant précieusesinformations aumonde polarité tweet ',\n",
       " 'changement qualitatives détection flot cdcstream ',\n",
       " 'domicile personne mouvement risque situation ',\n",
       " 'géographiques openjump generatoret gdb remplissage ',\n",
       " 'prédictiondes communauté réseau lafaisabilité précisionla ',\n",
       " 'pertinence confusionnative intrinsèquement utilisantle présentonségalement ',\n",
       " 'chanson parole collection dexplorer interface ',\n",
       " 'thème pixel doccupation classificationcouplant finaledétiquetage ',\n",
       " 'attribués orientés isomorphisme graphe sousgraphes ',\n",
       " 'dépisodes prédictiondinformations précieuseleur lesblogs déposés ',\n",
       " 'minimaux motif profondeur densembles polynomialspace ',\n",
       " 'kdariane déploiement programmation traitementspour visuelleariane ',\n",
       " 'stratégie agent trace lélicitation méthodologie ',\n",
       " 'recouvrement kmoyennes contrôler groupe généralisation ',\n",
       " 'textuel extrait prend ontologie génération ',\n",
       " 'attribués sommet hiérarchie motif dextrairedes ',\n",
       " 'densité groupe différentes observation proposées ',\n",
       " 'rôle réseau communautaire twitter noeud ',\n",
       " 'social techniquesnonincrémentales jourincrémentalement attributsinconnus médiassociaux ',\n",
       " 'modeling ocelet spatial format dynamics ',\n",
       " 'géographique référentiel thématique profit source ',\n",
       " 'dinteractions dévénements flot démarcheexploratoire événementspertinents ',\n",
       " 'nommées entité lexpansion requête concept ',\n",
       " 'subjectivité médical médecin discours lexicales ',\n",
       " 'lincertitude théorie distribution due unique ',\n",
       " 'traverse minimales localgenerator régner diviser ',\n",
       " 'locuteur 3way parler moins tableau ',\n",
       " 'crowd the for as mining ',\n",
       " 'caméra opérateur trajectoire donnéesélectionner dassistance ',\n",
       " 'motif récursifs séquentielles hiérarchique résumé ',\n",
       " 'recouvrante noyau pourrépondre lerecours recouvrementde ',\n",
       " 'pondération bipartitionnement variable topologique bloc ',\n",
       " 'analogique manquant celui attributsbooléens transactionnelle ',\n",
       " 'forum sentiment leurs patient santé ',\n",
       " 'across profiles snss of individual ',\n",
       " 'dévènements reconstruction chronologie enquêteur denquête ',\n",
       " 'traduction rim rail interlangues multilingue ',\n",
       " 'the of samples models learned ',\n",
       " 'skyline point anomalie requête présence ',\n",
       " 'multilabel ebr ecc chains suivide ',\n",
       " 'knn k voisin proche prototype ',\n",
       " 'élastique laxe temporel réduction noyau ',\n",
       " 'multicritères conflit collaborative initiateur 015 ',\n",
       " 'symétrie motif ensemblistes délagagebasé expériencesmenées ',\n",
       " 'the of smarter computers dream ',\n",
       " 'twitter the can stream system ',\n",
       " 'consensus partition departitions adjoint pourlequel ',\n",
       " 'topologiques statis carte partition compromis ',\n",
       " 'etdéclaratif destechniques demotifs ppc contrainte ',\n",
       " 'mlearning mobile desparcours nouvellearchitecture apprentissagemobile ',\n",
       " 'amènent peucoûteuse lalgorithmespectral approchée notoirement ',\n",
       " 'genre profil adonné hybridequi desauteurs ',\n",
       " 'nodaux noeud communauté réseau topologiques ',\n",
       " 'populaires thématique twitter message expérimentationsmenées ',\n",
       " 'métrique détiquetage sélection variable donnéestextuelles ',\n",
       " 'dimages ontologiques terme tomodensitométriques image ',\n",
       " 'textual data representation of the ',\n",
       " 'simplifiés décision arbre pouradapter difficilesà ',\n",
       " 'modularité 2modlouvain linertie newman vectorielles ',\n",
       " 'prosopographiques portail visualisation laccès fonctionnalitésdinterrogation ',\n",
       " 'ralentissement quantitative bibliographique découverte motif ',\n",
       " '3d stéréoscopique stéréoscopie exploratoire perspective ',\n",
       " 'the of environments pos tagging ',\n",
       " 'catégorisation texte coût parmi proche ',\n",
       " 'cabine simulation conception confort passager ',\n",
       " 'ex réseau concept formelle influents ',\n",
       " 'réclamation typologie allocataire caf dallocataires ',\n",
       " 'concept larc relationnelle relationnelles treillis ',\n",
       " 'objet orientée haute région résolution ',\n",
       " 'protéiques epsilon aligneurs multiétiquettes alignement ',\n",
       " 'routier trajectoire réseau contrainte lempruntent ',\n",
       " 'gisement historique dentrer évaluer projet ',\n",
       " 'série coclustering temporelles descripteur objetsattributs ',\n",
       " 'skypatterns softskypatterns toxicophores chémoinformatique autrement ',\n",
       " 'plagiarism methods academic to by ',\n",
       " 'traverse minimales hypergraphe hypergraphes imtextractor ',\n",
       " 'tendance commerciale enseigne clientèle précoce ',\n",
       " 'dontologie page noyau jardinage fiche ',\n",
       " 'dantennes antenne habitant france mobile ',\n",
       " 'évolutifs dinférence floue incrémental récursifs ',\n",
       " 'naires ontologie dédiée relation représentation ',\n",
       " 'aboutissons acycliques extrayant pondérés acyclique ',\n",
       " 'attribués fréquents motif arbre sousarbres ',\n",
       " 'betti génératif simplicial complexe csg ',\n",
       " 'syntagme nominaux dindexation sri filtrage ',\n",
       " 'positives négative règle rapn dassociation ',\n",
       " 'changement étiqueté fenêtre aucun détection ',\n",
       " 'tags relation taux annotateur encourageant ',\n",
       " 'protéine trimères coli escherichia complexe ',\n",
       " 'régulation réseau sortie dinteraction linférence ',\n",
       " 'twitter capitaliste sociaux réseau graphe ',\n",
       " 'ri sociale social modèle collection ',\n",
       " 'text the groups of representation ',\n",
       " 'bitm bipartitionnement topologique carte simultané ',\n",
       " 'choquet lintégrale dontologies alignement paramétrage ',\n",
       " 'classe itératif supervisée dextraction lapproche ',\n",
       " 'dintégration réécriture requête adressées phase ',\n",
       " 'motsclés document similitude présentant similaires ',\n",
       " 'formateur lactivité nucléaire pleine simulateur ',\n",
       " 'variable hiérarchiques non sélection mesurer ',\n",
       " 'snow subspace copac dénommé sousespaces ',\n",
       " 'factorisation note recommandation prédiction utilisateur ',\n",
       " 'text2geo létang géospatiales dinformations thau ',\n",
       " 'réseau entité relation létendant revisiter ',\n",
       " 'of in and work the ',\n",
       " 'secondaire table variable construites multitables ',\n",
       " 'dontologies ràpc composition dinformation recherche ',\n",
       " 'ppc contrainte programmation maximal clusters ',\n",
       " 'généralisée vraisemblance thématique méthode press ',\n",
       " 'videos tags video we system ',\n",
       " 'carte cognitive valident critère influence ',\n",
       " 'évolutif statique suivi clustering ordinaire ',\n",
       " 'pco strate multicouche spécialisation mixte ',\n",
       " 'variable construction table constructibles choisissant ',\n",
       " 'séquence similarité mesure efficacement dexplorations ',\n",
       " 'parallélisation cpu gpu radiale configuration ',\n",
       " 'antipatterns antipattern bad ontology queries ',\n",
       " 'rsndf bootstrap filtre orthogonale rééchantillonnage ',\n",
       " 'poids discriminante score linéaire àlutilisation ',\n",
       " 'event biological of and the ',\n",
       " 'tca triadiques biclusters numériques biclustering ',\n",
       " 'intervalle généralisation concept communepour sontobtenus ',\n",
       " 'vigilance électrode 58 eeg pls ',\n",
       " 'maximisation modularité spectrale catégorielles optimalemaximisant ',\n",
       " 'instant séquentielles probabiliste sonttrès ina ',\n",
       " 'probabiliste catégorielles topologique sontencourageants performancesont ',\n",
       " 'procédure chirurgien dtw chirurgicales chirurgicale ',\n",
       " 'clusters courbe paramétrique hiérarchique donnéesfonctionnelles ',\n",
       " 'multiniveaux topologique hiérarchique clustering graphe ',\n",
       " 'caractéristique combinaison elles classificateur sélection ',\n",
       " 'théorie supervisée classificateur croyance fonction ',\n",
       " 'relationship attribute community detection network ',\n",
       " 'maritime surveillance desrisques navire accident ',\n",
       " 'gof outliers continuerdans ougroupe chaquegroupe ',\n",
       " 'éprouvée idéalcette pluspertinents pourcette optimalesnous ',\n",
       " 'recommender the encouraged research project ',\n",
       " 'cooperherskovitz simplified criterion bayesian the ',\n",
       " 'diamètre derreur graphe rapide algorithme ',\n",
       " 'taxonomie lexique usage depositionner destaxonomies ',\n",
       " 'opinion internaute dopinions sera mot ',\n",
       " 'covariations propriété sommet réseau motif ',\n",
       " 'approximatives df modifiée exactes fonctionnelles ',\n",
       " 'régularité lien desnoeuds traditionnellesqui flmin ',\n",
       " 'intervalle séquence temporelles uneautre menonsquelques ',\n",
       " 'sousparties généraliste particulière enrichir ontologie ',\n",
       " 'vidéo concept caractéristique lindexation définir ',\n",
       " 'ditemsets incrémentale fréquentes flux séquence ',\n",
       " 'robot hog svm réalisés mobile ',\n",
       " 'boycott caractérisation identification danalyse différent ',\n",
       " 'client typologie campagne kmoyennes score ',\n",
       " 'dépendance règle analogie multivaluées définies ',\n",
       " 'négative règle métarègles lextraction êtreformalisées ',\n",
       " 'the genetic of biological interaction ',\n",
       " 'domotiques supervision capteur réaliserdu informationssur ',\n",
       " 'analysis correlation pls rgcca multiblock ',\n",
       " 'secondaire discrétisation variable table multitables ',\n",
       " 'légende concevoir corese règle adaptées ',\n",
       " 'agrégée élément xml évidencelimpact inex2009 ',\n",
       " 'spatial learning relational and already ',\n",
       " 'olap réorganisation cube réorganisationdans évaluéepar ',\n",
       " 'impact service recommandation découverte web ',\n",
       " 'ricsh corpus fragment thématique contextuelle ',\n",
       " 'jointe distribution modèle grille densité ',\n",
       " 'the analytics and visual to ',\n",
       " 'jurisprudence décision juridique arabe langue ',\n",
       " 'wiki isicil projet social lecadre ',\n",
       " 'tmdminer membre diffuseurset dediffuseur représentationdu ',\n",
       " 'clustering the and of network ',\n",
       " 'transfert matricielle topologique pondéré lapprentissage ',\n",
       " 'dissimilarité matrice partition àpriori connaissons ',\n",
       " 'assistant paramétrages appariement utilisateur visuel ',\n",
       " 'quantification dimages grand descripteur imagesdimagenet ',\n",
       " 'diffusion linformation individuel menéesmontrent multidimensionnelledes ',\n",
       " 'distance nominaux histogramme dhistogrammes entité ',\n",
       " 'why and has this in ',\n",
       " 'transfert interdomaines deressources complétion dinformationssur ',\n",
       " 'décomposition graphe introduitenous cadreune parblondel ',\n",
       " 'agronomiques limprécision gérant agricoles quantitative ',\n",
       " 'motif expérimentationsréalisées égalementune motifsspatioséquentiels denguedans ',\n",
       " 'hiérarchie taxonomie construction etmultiniveaux valeursdattributs ',\n",
       " 'marquage sein encomparaison duprojet lauteur ',\n",
       " 'nucléaire krex explicites tacites maîtrise ',\n",
       " 'journalistiques porteur tweets dinformations nan ',\n",
       " 'prétopologique lexicosémantiques structuration texte codant ',\n",
       " 'tarification nonvie risque dassurance généralisés ',\n",
       " 'électriques compteur communicant duplication agrégées ',\n",
       " 'suspect visuel comportement suivant communication ',\n",
       " 'exhaustif professionnel guidé recommandation expert ',\n",
       " 'textuelles ressource analysons construction méthodologie ',\n",
       " 'liaison dindices va comportement probabiliste ',\n",
       " 'contingence lafc tableau dimages mot ',\n",
       " 'comptage spatiotemporelle blob franchissant ligne ',\n",
       " 'transduction annotation couverture nommées dentités ',\n",
       " 'connaissances1 iconique coopérative catégorisation apport ',\n",
       " 'coldstart collaboratives recommandation logs froid ',\n",
       " 'som topologiques carte contrainte triviale ',\n",
       " 'logique clause prédicat markov réseau ',\n",
       " 'carte cognitives cognitive dinfluences vue ',\n",
       " 'mesure dégager règle 61 propriété ',\n",
       " 'fa me aléatoires voisinage coller ',\n",
       " 'pose isar cible transformée image ',\n",
       " 'representative rules output its an ',\n",
       " 'discriminante échantillon virtuel normalisée grosse ',\n",
       " 'as information to and processing ',\n",
       " 'tanagra cellulaire discrétisation implémentation intégration ',\n",
       " 'renforcement transport automatisés sécurité daide ',\n",
       " 'champignon ontologique dexpression séquence construction ',\n",
       " 'histograms summarization online stream by ',\n",
       " 'satellite dévolution sits série dimages ',\n",
       " 'sociaux graphe réseau document nan ',\n",
       " 'flux changement détection favorablement évitent ',\n",
       " 'tableau guidée sousensembles floues flou ',\n",
       " 'profil utilisateur courtterme longterme dadaptation ',\n",
       " 'early in will accuracy sequences ',\n",
       " 'the criterion similarity with two ',\n",
       " 'motif transaction support pondérant reçoive ',\n",
       " 'proximité topologique léquivalence mesure plan ',\n",
       " 'arc graphe clusters densité taille ',\n",
       " 'usager dinternet être telle question ',\n",
       " 'acabit quezao terminologique laspect 2424actu ',\n",
       " 'client motif lachat contextuels séquentiels ',\n",
       " 'dévénements temporel motif intervalle représentatifs ',\n",
       " 'relationnelles réseau sociaux létape dagrégation ',\n",
       " 'clique détiquettes densembles homogènes sommet ',\n",
       " 'ensemblistes motif bruités bruit heuristique ',\n",
       " 'barrière format transformation brut utilisateur ',\n",
       " 'haptiques simulateur eiah chirurgie centrée ',\n",
       " 'roc courbe interprétation graphique nan ',\n",
       " 'spectrale relationnelle problème lagrange multiplicateur ',\n",
       " 'territoriale collectivité progiciel lingénierie introduction ',\n",
       " 'dintelligence isicil intégration travers communauté ',\n",
       " 'moteur wikis wiki sémantique état ',\n",
       " 'm3a assisté dingénierie maintenance plateforme ',\n",
       " 'concordance mesure réduire source évidentielles ',\n",
       " 'participant dhétérogénéité p2p disparité considérant ',\n",
       " 'glose testing » « mot ',\n",
       " 'mobility and of the data ',\n",
       " 'linéarité énoncé français phénomène catégorie ',\n",
       " 'rto terminoontologique lannotation tableau naires ',\n",
       " 'phénomène spatiotemporels spatiotemporelles séquence motif ',\n",
       " 'simulation propagation linformation publication reproduire ',\n",
       " 'moteur réponse question web sémantique ',\n",
       " 'wikipedia moteur permis question typer ',\n",
       " 'motif deltalibres séquentiels difficile produit ',\n",
       " 'matching métadonnées assurer mumie langage ',\n",
       " 'géolocalisée nomao personnalisée nan recherche ',\n",
       " 'graphe acréduits intéressante sousgraphes projection ',\n",
       " 'contrainte lalignement différence programmation prête ',\n",
       " 'naïf bayésien variable classifieur directe ',\n",
       " 'yacaree parameterfree rule association with ',\n",
       " 'sociosemantic view of network based ',\n",
       " 'pondération codées mixtes simultanée binaire ',\n",
       " 'pmi ppmi positives variante formelle ',\n",
       " 'heure cyclone longitude latitude 6 ',\n",
       " 'fusion prise dinformations source compte ',\n",
       " 'attribut propositionalisation gèrent agréger discrétiser ',\n",
       " 'the learning and data failure ',\n",
       " 'action estimés magnitude séquence vidéo ',\n",
       " 'logs requête logarithme olap résumé ',\n",
       " 'variable unàplusieurs multitables cible relationnel ',\n",
       " 'audiovisuel web30 service contenu nan ',\n",
       " 'répétition télévisuels structuration supervisé flux ',\n",
       " 'musique morceau calme perception adaptable ',\n",
       " 'demploi offre catégorisation internet choisis ',\n",
       " 'the engines of search are ',\n",
       " 'skylines skycube treillis accord skycuboïdes ',\n",
       " 'règle robustes critère robustesse bayésien ',\n",
       " 'folksonomies tagging cycle complet lenrichissement ',\n",
       " 'géolocalisation dactualité laccès faciliter résumé ',\n",
       " 'espace navigation outil sémantique nan ',\n",
       " 'cnss cellulaire dinduction neurosymbolique va ',\n",
       " 'floues contextuelles préférence requête règle ',\n",
       " 'ontologie homologue distance légères calcule ',\n",
       " 'client méthodologie économique recommandation lactionnabilité ',\n",
       " 'opinion médiocre vocable critère film ',\n",
       " 'treemap grille topologique hiérarchique partition ',\n",
       " 'géographiques vis dentités ontologie globale ',\n",
       " 'courriel indésirables cellulaire utilisation machine ',\n",
       " 'enrichir dalignement ontologie taxomap topographie ',\n",
       " 'diagnostique codage partielle fusion hétérogènes ',\n",
       " 'description structure visualisation intergroupe segmentés ',\n",
       " '” 945 paire hautement corrélées ',\n",
       " 'metaactions rules action and nan ',\n",
       " 'publicité clic enévidence loptimum atteignent ',\n",
       " 'convexes géométrie fermeture topologie agrégation ',\n",
       " 'maintenance préventive ferroviaire prendredes trainset ',\n",
       " 'contrainte naires motif locaux csps ',\n",
       " 'pédagogiques document discursifs lanalysesémantique documentspédagogiques ',\n",
       " 'traminer dévénements séquence analyse nan ',\n",
       " 'opérateur olap lanalyse ligne factorielle ',\n",
       " 'foule évènements scène flux mélange ',\n",
       " 'pair routage incrémentale usage requête ',\n",
       " 'logic to nonrelational markov namely ',\n",
       " 'climatiques engendrés spatiales apport risque ',\n",
       " 'patron lexicosyntaxiques identifier exprimantdes limplémentationdun ',\n",
       " 'csp spécification apprentissage nan de ',\n",
       " 'nominales adaptatif formels supervisé apprentissage ',\n",
       " 'visualisation quantité réduirelensemble donnéesune grandissante ',\n",
       " 'ancien destraits détailléesdont complexitéest etlindexation ',\n",
       " 'privée préservation média vie sociaux ',\n",
       " 'cube universitéconfirment hal lesexpériences hiérarchiesassociées ',\n",
       " 'usager santé terminologie accès ontologie ',\n",
       " 'casi cartocel cartographie booléenne donnéeorchestrée ',\n",
       " 'chorml géographiques résumé visuel nan ',\n",
       " 'séquence doutils notion différence dévénements ',\n",
       " 'structurelle document classe distance structure ',\n",
       " 'multimédia recherche modèle ii catégorie ',\n",
       " 'copartitionnement variable groupement préparation discrétisation ',\n",
       " 'cndcube cube “ ” concise ',\n",
       " 'codex maya élément interprétables situant ',\n",
       " 'réconciliation lalignement numérique combiner logique ',\n",
       " 'disparité dexpertise créés sein blog ',\n",
       " 'critère lintégration sontanalysés puretédes commecellesci ',\n",
       " 'nonsupervisé sousensembles lesdifférences comparersont méthodebasée ',\n",
       " 'composition réseau service social membresdu ',\n",
       " 'darbres noyau induit expérimentationslutilisation danslespace ',\n",
       " 'cube émergent quotient fermé cubique ',\n",
       " 'dafoe thésaurus plateforme construire texte ',\n",
       " 'plcm fermé ditemsets densesaméliorant creuses ',\n",
       " 'dfc fonctionnelles conditionnelles dépendance df ',\n",
       " 'the data of stream change ',\n",
       " 'data statecharts integration using over ',\n",
       " 'anormal vidéo mouvement détection nan ',\n",
       " 'weka formels basées développement plateforme ',\n",
       " 'gmmsmos locuteur variante vecteur lidentification ',\n",
       " 'etude comparative langage lien complexe ',\n",
       " 'protéiques stabilité etude séquence sélection ',\n",
       " 'sql algorithmedéfini lorsquecellesci luipermettre aiderlutilisateur ',\n",
       " 'réconciliation colorés petri guidées estparticulièrement ',\n",
       " 'fonctionnelles exploration dépendance olap dassociation ',\n",
       " 'distinctifs flux ditemsets résultatsdexpérimentations idkf ',\n",
       " 'obstacle région personne dintérêt extraction ',\n",
       " 'motif graduel élevé surde graduelsen ',\n",
       " 'dassociation événement risque règle sousséquences ',\n",
       " 'traduction ta rail corpus parallèle ',\n",
       " 'vdm réalité graphique virtuelle taxonomie ',\n",
       " 'amo droit gestion daccès stratégie ',\n",
       " 'communities network the of presence ',\n",
       " 'dépendance fonctionnelles incfds dinférer dinférencedes ',\n",
       " 'dimages gpu afc incrémental thème ',\n",
       " 'complexité état indice successifsqui deuxaspects ',\n",
       " 'bayesienne dentropie inférence maximum cancer ',\n",
       " 'dentropie priori machine maximum derreur ',\n",
       " 'contrainte ajoutées interactive réduction similaires ',\n",
       " 'sgfd flux portent récentes période ',\n",
       " 'lab kwords dexplorer clé scientifique ',\n",
       " 'graal abstraite kgram graphe naturel ',\n",
       " 'conflit théorie croyance commentsupprimer définitionsdu ',\n",
       " 'mot dépendance langue seconde delangue ',\n",
       " 'xml multidimensionnelles entrepôt laidedu exécute ',\n",
       " 'your mysins make semantic system ',\n",
       " 'régles á mésures confiance confidence ',\n",
       " 'recouvrantes recouvrante osom carte autoorganisatrices ',\n",
       " 'pattern the past future mining ',\n",
       " 'cycliques proposévs pcarcaractérisé letemps cyclique ',\n",
       " 'motif validéepar lemultithreading doncdans volumineusesen ',\n",
       " 'vidéo série temporelles prédiction séquence ',\n",
       " 'pretopolib librairie java ensemblistescelleci laprétopologie ',\n",
       " 'dopérateurs multidimensionnel olap proposition dobjets ',\n",
       " 'règle associative classe classifieur génération ',\n",
       " 'protein pgr graphe repository graph ',\n",
       " 'intervalvalued partitioning advances recent algorithms ',\n",
       " 'modulaires cas requête pertinents raisonnement ',\n",
       " 'reconnaissance lapprentissage concept basée nan ',\n",
       " 'bidirectionnelle image réduction desversions objetsdes ',\n",
       " 'série mémoire 2003 al accordant ',\n",
       " 'textuelles nommer discussion regrouper groupe ',\n",
       " 'préférence gros skyline requête utilisateur ',\n",
       " 'flux résumé sgfd généraliste variées ',\n",
       " 'merger rss nan ',\n",
       " 'multidimensionnels motif entrepôt séquentiels automate ',\n",
       " 'entropie catégorisation textuels descripteur sélection ',\n",
       " 'segmentation client différentessegmentations latransformation segmentationsalternatives ',\n",
       " 'gène séquentiels dappréhenderde visualisationnuages laccompagnement ',\n",
       " 'siam médicaux dindexation nan système ',\n",
       " 'vol enregistrées perte techniquesdextraction dinformationsceci ',\n",
       " 'pair p2p simtole plateforme dalignement ',\n",
       " 'sotree hiérarchique topologique ” partition ',\n",
       " 'souséchantillonnage déséquilibre aspect dapprentissage décisioncomme ',\n",
       " 'dautomobiles ascendant suivi hiérarchique nan ',\n",
       " 'dynamique bayésiens décision temporelles connaissancesà ',\n",
       " 'tulip graph framework and representations ',\n",
       " 'croyance masse posteriori probabilité maximum ',\n",
       " 'relation candidat sémantique association dontologies ',\n",
       " 'prédicat initiale corrélation réponse prochessémantiquement ',\n",
       " 'lissage communauté modèle lidentification probabiliste ',\n",
       " 'lashms imc enfant précoce charge ',\n",
       " '8743 correspondance ontologie étudiées dalignement ',\n",
       " 'stratégie bayésienne échelon unidimensionnelles comparatives ',\n",
       " 'inventif lacquisition ontologie conception laclarification ',\n",
       " 'flot fenêtre impossible ditemsets rend ',\n",
       " 'essentielles traduction idée utilisation texte ',\n",
       " 'colocalisations expert géologiques étémenées unprototype ',\n",
       " 'to and patches analogy contentbased ',\n",
       " 'wikipedia qualité requis significativementle réduisait ',\n",
       " 'wcum lanalyse lusage site partition ',\n",
       " 'user the profile contextualization and ',\n",
       " '21ème siècle début dexpérience retour ',\n",
       " 'ei dépendance 755 677 conduisentà ',\n",
       " 'skin3d calibration réalité virtuelle matériel ',\n",
       " 'semistructured retrieval in document structuring ',\n",
       " 'risk multiarmed the bandit approach ',\n",
       " 'dissimilarités facteur détats dinduction variabilité ',\n",
       " 'variable procédure prédire identifiées prédictives ',\n",
       " 'dopérations investissement commerciale optimiser régression ',\n",
       " 'matériaux dopérations retour marché commerciale ',\n",
       " 'olap lopération rolap implantelopération deshiérarchies ',\n",
       " 'owldl sémantique individu entreindividus lapprochemise ',\n",
       " 'assessing uncertainty knn fusion data ',\n",
       " 'pattern graphs sequence databases association ',\n",
       " 'pondération observation variable caractérisation dexhiber ',\n",
       " 'règle cibler décideur intéressantes plusutiles ',\n",
       " 'ldrègles cisna gérer hybride nan ',\n",
       " 'envi télédétection innovants pixelsclassique fxtm ',\n",
       " 'intrusion detection anomaly ids as ',\n",
       " 'syntaxiques induites valider relationsyntaxique unevalidation ',\n",
       " 'induit déquivalence mesure ordre degré ',\n",
       " 'programming constraint mining for data ',\n",
       " 'bruit bruités descripteur construction qualitésobtenues ',\n",
       " 'contrôle flux observation traitement facteur100 ',\n",
       " 'galois correspondance cettecorrespondance donnéessimples degalois ',\n",
       " 'dbfrequentqueries fréquentes requête extraction nan ',\n",
       " 'multiagents communication cmp sma symbolique ',\n",
       " 'stratégie robot observables humains boucle ',\n",
       " 'adn puce demon séquentiels expressionsde ',\n",
       " 'demonvisualisation biologiques extrait séquentiels visualisation ',\n",
       " 'desesper hydraulique surveillance centrale appliqué ',\n",
       " 'signature attaque collaboratif organisation détection ',\n",
       " 'multirésolution atypiques flot dobjets détection ',\n",
       " 'dordre markov démontronsexpérimentalement inégalité rechercheet ',\n",
       " 'croki2 classe validation traversun dedéterminer ',\n",
       " 'diagnostic adaptatif diagnostiqueurs multisources vérifiée ',\n",
       " 'reposant caractérisation treillis lefiltrage ligneillustre ',\n",
       " 'rfid traçabilité groupe spatiotemporelles densité ',\n",
       " 'vente performantsdaide 2007montre classifieurbayesien isolément ',\n",
       " 'explorer3d visualisation nan classification donnée ',\n",
       " 'naires bruitées fermé relation propositionpour ',\n",
       " 'corrélation décisionnelles contingence vecteur lectique ',\n",
       " 'moins graduelles réelsmontrent associésdes gradualité ',\n",
       " 'fpgrowth fcpgrowth adaptation générer dassociation ',\n",
       " 'dontologies riche schéma hiérarchie destructures ',\n",
       " 'fusion heuristiquesmises télévisées dexpérimentations soulignent ',\n",
       " 'formels concept classification classifieur boosting ',\n",
       " 'tournebool mot corpus reuters randomisation ',\n",
       " 'the of in answer text ',\n",
       " 'gène al formelle dhypothèses motameny ',\n",
       " 'ghsom som outil pourrendre danalyseexploratoire ',\n",
       " 'créativité calculatoire synthèse lilp prédicat ',\n",
       " 'syr symbolique logiciel lanalyse nan ',\n",
       " 'dtmvic inférence text logiciel » ',\n",
       " 'culturel patrimoine management domaine nan ',\n",
       " 'voisinage quiconsidère sontproches paramétriques automatiquenon ',\n",
       " 'préférence contextuelles olap contextedanalyse lesdonnées ',\n",
       " 'tei spécialisées bibliothèque structuresarborescentes justifions ',\n",
       " 'wokm okmed okm classe métrique ',\n",
       " 'audit unlabelled adaptive anomaly intrusion ',\n",
       " 'dalignement dontologies bloc partitionnement ontologie ',\n",
       " 'data the will personal new ',\n",
       " 'voting multiclassifier probabilistic rule svms ',\n",
       " 'relationnelles logiciel aussiun processuspeut supporté ',\n",
       " 'approcheautomatique siglesissues définition biomédicaux sigle ',\n",
       " 'résumé requête obtenussont kdd99 nousutilisons ',\n",
       " 'chaîne jaccard caractère lindice caractèrescomme ',\n",
       " 'stream spam séquentiels transaction motif ',\n",
       " 'incrémental processeur gpu parallèle svm ',\n",
       " 'taaable recipes dish replacing theconstraints ',\n",
       " 'librairie traminer r séquentielles lanalyse ',\n",
       " '· réseau décomposition doit changement ',\n",
       " 'larbre bayésienne darbres décision larttout ',\n",
       " 'aléatoires forêt oblique darbres algorithme ',\n",
       " 'multimétiers crosslingue européen dentreprise prototype ',\n",
       " 'médicale génomique corrélation linéaire lextraction ',\n",
       " 'obtenu premierplan learningchallenge pascal aposteriori ',\n",
       " 'segmentation pixel image intensité supervisée ',\n",
       " 'dimages lafc hors adt afc ',\n",
       " 'changement simulation danalyser cour dusageà ',\n",
       " 'échelle symbolique vers traitement grand ',\n",
       " 'graphique relation tentons interactionplutôt dintégrerce ',\n",
       " 'rough in the set of ',\n",
       " 'nsvm boosting lssvm psvm machine ',\n",
       " 'film rapprochement montrerons vocabulaire site ',\n",
       " 'définition svm nomsadjectifs investigués auquelle ',\n",
       " 'événement presse automatique contenant annotev ',\n",
       " 'visage reconnaissance classification galois hybride ',\n",
       " 'ngrammes vie parcours séquence précisera ',\n",
       " 'plainte pollution réalisable dassigner apparie ',\n",
       " 'binaires probabiliste carte bernoulli gtm ',\n",
       " 'sgbd nautilus métier optimisés lalimentation ',\n",
       " 'gène cellulaire cycle dexpression référence ',\n",
       " 'petit monde vue dapprentissage réseau ',\n",
       " 'clusterings individuel clustering méthode dimensionalité ',\n",
       " 'ssvc étoile coordonnée optimale linterface ',\n",
       " 'coclassification contrainte quadratiques résidu somme ',\n",
       " 'asti spatiotemporelle concepteur dinformation conception ',\n",
       " 'video the of in people ',\n",
       " 'séquentiels inattendus motif fréquence inattendues ',\n",
       " 'délestage dégradation flux cube mécanisme ',\n",
       " 'atypiques salaire groupe variable faible ',\n",
       " 'bootstrap coupure ouvrons systématiquement chimerge ',\n",
       " 'forêt détérioré contourner minoritaire déséquilibre ',\n",
       " 'flot séquentiels déchantillonnage hypothèse motif ',\n",
       " 'flux distribués consommation électriques capteur ',\n",
       " 'file personal tags context on ',\n",
       " 'okm recouvrante moc théoriques mélange ',\n",
       " 'dinfluence étape linflué maximisant règle ',\n",
       " 'asymétriques dentropie arbre décision asymétrique ',\n",
       " 'lsa grammaticales conceptuelle éducatives syntaxicosémantiques ',\n",
       " 'période compact ditemsets itemsets deico ',\n",
       " 'drone élémentaires photographie zone fine ',\n",
       " 'multidimensionnels motif séquentiels clos densemble ',\n",
       " 'annotation contextuelles sémantique émanant transmettre ',\n",
       " 'croisement validation ontologie relation extraction ',\n",
       " 'itemset fiasco item nouvel batches ',\n",
       " 'acoustique mot 41 homophone sélectionné ',\n",
       " 'the of and to in ',\n",
       " 'vidéo soft condensé computing longueur ',\n",
       " 'prototypicalité gradient endogroupe pragmatique lexicale ',\n",
       " 'depotentiel calcul serveur client communiquent ',\n",
       " 'je entreprise mining produire théoriques ',\n",
       " 'contrainte médicales carte version mélanome ',\n",
       " 'probabiliste document tenir structure modèle ',\n",
       " 'récit voyage litinéraire attendu ditinéraires ',\n",
       " 'segmentation lexpert évolutive dimages limage ',\n",
       " 'variable supervisé loutil khiops millier ',\n",
       " 'geodoc territoire politique diagnostic document ',\n",
       " 'graphe période sommet relationnelles décomposer ',\n",
       " 'fia itemset flot itemsets automate ',\n",
       " 'sociaux réseau lordonnancement parlerons prisée ',\n",
       " 'soda récentes avancée analyser visualiser ',\n",
       " 'cognitives carte hiérarchiques linconvénient concepteur ',\n",
       " 'hiérarchiques hiérarchie lévaluation mesure fscore ',\n",
       " 'degré dévaluation évaluation ontologiques méthodologie ',\n",
       " 'instrumental plateau créativité eservices méthodologie ',\n",
       " 'trees the of unlabeled are ',\n",
       " 'trajectoire arrêt mouvement ni temporel ',\n",
       " 'mot axe recherche image qualité ',\n",
       " 'risque industriel raisonnement ineris national ',\n",
       " 'primal optimisation svm shrinking différentiables ',\n",
       " 'neurone rbfgene rbf poids régression ',\n",
       " 'pondération locale carte variable segmentation ',\n",
       " 'réaction schéma chimiste graphe chimiques ',\n",
       " 'symbolique concept histogrammesuites lavariation analysantces ',\n",
       " 'sigle dacquisition dictionnaire présenté sappuie ',\n",
       " 'dintrusions associatives détection générique sdis ',\n",
       " 'spatiale lintroduction multidimensionnelle lanalyse opérateur ',\n",
       " 'licorn adaptative corégulation régulation vessie ',\n",
       " 'noyau graphe région chaîne caltech ',\n",
       " 'bibliothèque personnalisée numériques retriés nos ',\n",
       " 'routier trafic atypiques urbain spatiotemporels ',\n",
       " 'alternative requête génomique multiniveaux entrepôt ',\n",
       " 'référent carte pondérée sera voisinage ',\n",
       " 'fenêtrage spatial traitées temporel requête ',\n",
       " 'dontologie générique semiautomatisation conceptualisation terminae ',\n",
       " 'wordnet som basés textuels document ',\n",
       " 'superposées fenêtre basées stratégie repérer ',\n",
       " 'conditional entropy bayesian generalized network ',\n",
       " 'itemsets clé suppression essentiel non ',\n",
       " 'décideur argumentative cruciales multiagent conflit ',\n",
       " 'groupe déterminer nombre stabilité classification ',\n",
       " 'cartogramme ex trois spatiotemporelles dimension ',\n",
       " 'noyau vectoriel latent cvsm despace ',\n",
       " 'dontologies comprenant descriptifs algèbre dalignement ',\n",
       " 'nk soi immunitaire artificiel système ',\n",
       " 'denrichissement sig dutilisateurs accomplie offert ',\n",
       " 'vote classification jugement thématiquement dopinion ',\n",
       " 'somerdfs mappings mediad rd telecom ',\n",
       " 'boosting ensembliste finale inspirée supervisée ',\n",
       " 'conformité contrôle norme c3r bâtiment ',\n",
       " 'jmesure élaguer chronique orientée nan ',\n",
       " 'treillis navigation concept conceptuel niveau ',\n",
       " 'bruitées dadaboost lerreur boosting dagrégation ',\n",
       " 'intervalle divisive homogène partie poisson ',\n",
       " 'relation répartie prédicatsarguments prédicatives recherchée ',\n",
       " 'diffusion liste faq cop sémantique ',\n",
       " 'svm noire boite actionnables quant ',\n",
       " 'capacité progresse lourde focalisation trouvé ',\n",
       " 'cube olap lintégration vers prédiction ',\n",
       " 'brevet document patent unifiées office ',\n",
       " 'ancien français extrait séquentiels motif ',\n",
       " 'vie parcours méthodologie suisse premier ',\n",
       " 'page site étape descripteur textuelle ',\n",
       " 'ressource entité dappariement lalignement règle ',\n",
       " 'archéologiques navigation annotation implémentée approximatifs ',\n",
       " 'colonne symbolique annotation numériques floue ',\n",
       " 'banc pmms npc dessai nasopharynx ',\n",
       " 'moteur entreprise jaune géolocalisation côté ',\n",
       " 'hommemachine redirection émotion dappels dialogue ',\n",
       " 'dordonnancement semisupervisé bénéfiques non–étiquetées cacm ',\n",
       " 'étiquetées topologie delaunay euclidien génératif ',\n",
       " 'cancer profil noncancer npc épidémiologique ',\n",
       " 'réconciliation schéma logique référence picsel ',\n",
       " 'cube visualisation pixel orientée calcul ',\n",
       " 'temporisées conversation transition service logs ',\n",
       " 'détenu lorganisation connaissance relatif acteur ',\n",
       " 'dimplication règle conclusion darbres validation ',\n",
       " 'xml document classement dinformation item ',\n",
       " 'distribution coupure lemplacement infinie fonctionnelles ',\n",
       " 'lssvm boosting grand machine ensemble ',\n",
       " 'séquence biologiques substitution protéiques matrice ',\n",
       " 'quelquesunes espérant relevées heuristic modelbased ',\n",
       " 'classement ctsvm modèle mixtes carte ',\n",
       " 'lactivité al ancrer herrmann seeme ',\n",
       " 'construction dontologie lieu texte treillis ',\n",
       " 'comportement dusage raison site jour ',\n",
       " 'fourmi graphe artificielles incrémentale voisinage ',\n",
       " 'datées dévénements discrets fabrication supervision ',\n",
       " 'doubli spécification fonction entrepôt intelligentes ',\n",
       " 'consommation abonné téléphonie détermination flou ',\n",
       " 'carte volumineuses prédiction pertinente lié ',\n",
       " 'conceptuelle linertie sens tableau impliquetil ',\n",
       " 'préparation protocole fiabilité représentation métrique ',\n",
       " 'inconsistance annotation sémantique lontologie lévolution ',\n",
       " 'floue proximité terme avantageux modèle ',\n",
       " 'document collection dentités liste espérons ',\n",
       " 'dadaptation laca connaissance cas cabamaka ',\n",
       " 'retroweb internet décrit migrateur dé\\x02nies ',\n",
       " 'divergentes convergente multidimensionnelles m2scd srikantmême ',\n",
       " 'approximeretpousser topk contrainte motif globales ',\n",
       " 'webangels filter violent structurel textuel ',\n",
       " 'lequel motif sousclasses quelconques découverte ',\n",
       " 'médicales image région dannotation fusion ',\n",
       " 'patron couple damorce phrase liste ',\n",
       " 'entrepôt hiérarchie sialors représentons danalyse ',\n",
       " 'interestingness measures the of mining ',\n",
       " 'communauté pratique lémergence membre connaissance ',\n",
       " 'sdet géographiques enrichment supplément limitées ',\n",
       " 'itemsets concises essentiel fermeture représentation ',\n",
       " 'milieu parfois indice catégorisation adapté ',\n",
       " 'dentropie mesure linsensibilité engendrer soixante ',\n",
       " 'déséquilibré symétrique modalité bâtir endogène ',\n",
       " 'thermique compact ajustés rc renforcé ',\n",
       " 'appariement polygone géographiques fodomust dobjets ',\n",
       " 'ip instantanées communication toip messagerie ',\n",
       " 'recouvrement classe applicatifs motivées part ',\n",
       " 'the of piecewise fisher histogram ',\n",
       " 'diamètre fort degré faible réseau ',\n",
       " 'dexception possiblement surprenantes utile simultanée ',\n",
       " 'privées service remplaçabilité protocole conversation ',\n",
       " 'ras citation dannotation outil document ',\n",
       " 'étape candidat réordonnancement transformation document ',\n",
       " 'vidéo acp bloc dimension réduire ',\n",
       " 'sonar imperfection imprécision incertitude théorie ',\n",
       " 'vecteur thématique segmentation deft06 recherchant ',\n",
       " 'instantané global – contexte cestàdire ',\n",
       " 'kfaibles sousbases valides confiance sens ',\n",
       " 'incomplètes contiennent temporairement éliminer représentative ',\n",
       " 'rdf graphe combinaison noncontradiction contredisent ',\n",
       " 'électrique consommation sgfd gestion flux ',\n",
       " 'web logarithme fichier serveur usage ',\n",
       " 'multiagent dontologies construction algorithme aménagement ',\n",
       " 'motif utilisateur théorique collection dapprofondir ',\n",
       " 'gène dexpression réseau tigr mev ',\n",
       " 'guidé phrase tirons nutilisons segmenteur ',\n",
       " 'série bioprocédé temporelles singularité fedbatch ',\n",
       " 'rang lestimateur prédicteurs estimateur univarié ',\n",
       " 'kilomètre sociotechnique lapproche laspect vision ',\n",
       " 'neurone multicouches darchitecture couche choix ',\n",
       " 'nexi xquery extension intégrer xml ',\n",
       " 'sortie dinterpréter limportance dinterprétation variable ',\n",
       " 'variable exogène paire partitionnement exogènes ',\n",
       " 'fcm dca dc floue programmation ',\n",
       " 'dalignement owllite dontologies circularité remédiant ',\n",
       " 'dexception c règle r b ',\n",
       " 'catégorisation wordnet multilingue monolingue consacré ',\n",
       " 'bootstrap réplication total corrige autoorganisées ',\n",
       " 'multiagents clustering permanence dynamique dadapter ',\n",
       " 'cerveau irm anatomiques humain symbolique ',\n",
       " 'projet biographiques bontology connaissance aperçu ',\n",
       " 's motif borne condensée représentation ',\n",
       " 'règle dassociation visualisation générique lécran ',\n",
       " 'appui tulip interactive graphe visualisation ',\n",
       " 'décision darbre résultat compréhension focuscontext ',\n",
       " 'webdocenrich document html semistructurés flexible ',\n",
       " 'écouter résumé réduirela doncdutiliser laudio ',\n",
       " 'intervalle noeud affectation terminal fils ',\n",
       " 'nonpertinence hospitalier composante aide gestion ',\n",
       " 'dimension semiinteractif atypiques génétique simplementdes ',\n",
       " 'implication desmesures asymétrique alignement ignorées ',\n",
       " 'signature financier indicateur améliorer courte ',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le LSA va calculer, pour un document donné, les documents les plus similaires à son sujet. On classe le résultat le plus similaire dans le cluster du document donné. On reproduit cette étape et on arrête quand à un nombre de clusters ou une similarité trop faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En gros, le LSA nous fournit une similarité qu'on utilise pour former une classification hiérarchique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On aura donc des clusters par sujets. On pourra élaborer nos techniques de datation pour déterminer les tendances et, si possible, créer de nouveaux clusters (avec les K-moyennes) plus précis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vectorisation\n",
    "# Le tf-idf ne sert à rien d'autre que de convertir notre liste en un vecteur utilisable.\n",
    "vectorizer = TfidfVectorizer(min_df =1)\n",
    "\n",
    "dtm = vectorizer.fit_transform(best)\n",
    "\n",
    "## Document Term Matrix vers Latent Sementic Analysis\n",
    "lsa =TruncatedSVD(2, algorithm = 'randomized')\n",
    "\n",
    "dtm_lsa = lsa.fit_transform(dtm)\n",
    "\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>politique idéo2017 citoyen tweets candidat</th>\n",
       "      <th>coclustering modl gagne taille passent</th>\n",
       "      <th>recommandation mobilité factorisation dintérêts inféré</th>\n",
       "      <th>arabe sentiment commentaire marocain dialectal</th>\n",
       "      <th>cds résumé texte composant rôle</th>\n",
       "      <th>big scénario ontologique data analyse</th>\n",
       "      <th>tentative décès supervisées patient risque</th>\n",
       "      <th>formés majoritaire vote global obtenus</th>\n",
       "      <th>label heureux morceau relation musique</th>\n",
       "      <th>ab test procédure stratification contextuel</th>\n",
       "      <th>...</th>\n",
       "      <th>flou sousensembles appelons sousensemble défini</th>\n",
       "      <th>uitliation documentaire fondé contenu laide</th>\n",
       "      <th>nextclosure fermé itemsets partitionnement treillis</th>\n",
       "      <th>incomplets classement probabiliste dobjets arbre</th>\n",
       "      <th>galois dalgorithmes treillis supervisée étude</th>\n",
       "      <th>mask savoirfaire dappropriation dentreprise mémoire</th>\n",
       "      <th>voisinage graphe voisin proximité prétraitement</th>\n",
       "      <th>conceptuels graphe connaissance contrainte validation</th>\n",
       "      <th>veille technologique texte rechercher scientifique</th>\n",
       "      <th>naturel risque entrepôt dentrepôt examinons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>politique idéo2017 citoyen tweets candidat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.657267</td>\n",
       "      <td>0.668790</td>\n",
       "      <td>0.866566</td>\n",
       "      <td>0.663839</td>\n",
       "      <td>0.967810</td>\n",
       "      <td>0.686585</td>\n",
       "      <td>0.703059</td>\n",
       "      <td>0.810150</td>\n",
       "      <td>0.658327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671391</td>\n",
       "      <td>0.672399</td>\n",
       "      <td>0.672567</td>\n",
       "      <td>0.668669</td>\n",
       "      <td>0.672624</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.667256</td>\n",
       "      <td>0.674420</td>\n",
       "      <td>0.673066</td>\n",
       "      <td>0.671789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coclustering modl gagne taille passent</th>\n",
       "      <td>0.657267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.193443</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.446426</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.998047</td>\n",
       "      <td>0.974296</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.999811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommandation mobilité factorisation dintérêts inféré</th>\n",
       "      <td>0.668790</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208522</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.460148</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.998891</td>\n",
       "      <td>0.977648</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arabe sentiment commentaire marocain dialectal</th>\n",
       "      <td>0.866566</td>\n",
       "      <td>0.193443</td>\n",
       "      <td>0.208522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202024</td>\n",
       "      <td>0.964277</td>\n",
       "      <td>0.232128</td>\n",
       "      <td>0.254348</td>\n",
       "      <td>0.409488</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211948</td>\n",
       "      <td>0.213278</td>\n",
       "      <td>0.213499</td>\n",
       "      <td>0.208363</td>\n",
       "      <td>0.213575</td>\n",
       "      <td>0.201709</td>\n",
       "      <td>0.206506</td>\n",
       "      <td>0.215948</td>\n",
       "      <td>0.214159</td>\n",
       "      <td>0.212473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cds résumé texte composant rôle</th>\n",
       "      <td>0.663839</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.202024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454242</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.998556</td>\n",
       "      <td>0.976231</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big scénario ontologique data analyse</th>\n",
       "      <td>0.967810</td>\n",
       "      <td>0.446426</td>\n",
       "      <td>0.460148</td>\n",
       "      <td>0.964277</td>\n",
       "      <td>0.454242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481497</td>\n",
       "      <td>0.501448</td>\n",
       "      <td>0.636529</td>\n",
       "      <td>0.447686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463256</td>\n",
       "      <td>0.464461</td>\n",
       "      <td>0.464662</td>\n",
       "      <td>0.460003</td>\n",
       "      <td>0.464730</td>\n",
       "      <td>0.453956</td>\n",
       "      <td>0.458316</td>\n",
       "      <td>0.466881</td>\n",
       "      <td>0.465260</td>\n",
       "      <td>0.463732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tentative décès supervisées patient risque</th>\n",
       "      <td>0.686585</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.232128</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.481497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999738</td>\n",
       "      <td>0.982450</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.999703</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.999514</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.999797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formés majoritaire vote global obtenus</th>\n",
       "      <td>0.703059</td>\n",
       "      <td>0.998047</td>\n",
       "      <td>0.998891</td>\n",
       "      <td>0.254348</td>\n",
       "      <td>0.998556</td>\n",
       "      <td>0.501448</td>\n",
       "      <td>0.999738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986465</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999049</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.998539</td>\n",
       "      <td>0.998791</td>\n",
       "      <td>0.999220</td>\n",
       "      <td>0.999146</td>\n",
       "      <td>0.999073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label heureux morceau relation musique</th>\n",
       "      <td>0.810150</td>\n",
       "      <td>0.974296</td>\n",
       "      <td>0.977648</td>\n",
       "      <td>0.409488</td>\n",
       "      <td>0.976231</td>\n",
       "      <td>0.636529</td>\n",
       "      <td>0.982450</td>\n",
       "      <td>0.986465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978379</td>\n",
       "      <td>0.978659</td>\n",
       "      <td>0.978706</td>\n",
       "      <td>0.977614</td>\n",
       "      <td>0.978722</td>\n",
       "      <td>0.976161</td>\n",
       "      <td>0.977213</td>\n",
       "      <td>0.979218</td>\n",
       "      <td>0.978844</td>\n",
       "      <td>0.978490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab test procédure stratification contextuel</th>\n",
       "      <td>0.658327</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.447686</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>0.974612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.999838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    politique idéo2017 citoyen tweets candidat   \\\n",
       "politique idéo2017 citoyen tweets candidat                                             1.000000   \n",
       "coclustering modl gagne taille passent                                                 0.657267   \n",
       "recommandation mobilité factorisation dintérêts...                                     0.668790   \n",
       "arabe sentiment commentaire marocain dialectal                                         0.866566   \n",
       "cds résumé texte composant rôle                                                        0.663839   \n",
       "big scénario ontologique data analyse                                                  0.967810   \n",
       "tentative décès supervisées patient risque                                             0.686585   \n",
       "formés majoritaire vote global obtenus                                                 0.703059   \n",
       "label heureux morceau relation musique                                                 0.810150   \n",
       "ab test procédure stratification contextuel                                            0.658327   \n",
       "\n",
       "                                                    coclustering modl gagne taille passent   \\\n",
       "politique idéo2017 citoyen tweets candidat                                         0.657267   \n",
       "coclustering modl gagne taille passent                                             1.000000   \n",
       "recommandation mobilité factorisation dintérêts...                                 0.999882   \n",
       "arabe sentiment commentaire marocain dialectal                                     0.193443   \n",
       "cds résumé texte composant rôle                                                    0.999962   \n",
       "big scénario ontologique data analyse                                              0.446426   \n",
       "tentative décès supervisées patient risque                                         0.999216   \n",
       "formés majoritaire vote global obtenus                                             0.998047   \n",
       "label heureux morceau relation musique                                             0.974296   \n",
       "ab test procédure stratification contextuel                                        0.999999   \n",
       "\n",
       "                                                    recommandation mobilité factorisation dintérêts inféré   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                   0.668790         \n",
       "coclustering modl gagne taille passent                                                       0.999882         \n",
       "recommandation mobilité factorisation dintérêts...                                           1.000000         \n",
       "arabe sentiment commentaire marocain dialectal                                               0.208522         \n",
       "cds résumé texte composant rôle                                                              0.999978         \n",
       "big scénario ontologique data analyse                                                        0.460148         \n",
       "tentative décès supervisées patient risque                                                   0.999707         \n",
       "formés majoritaire vote global obtenus                                                       0.998891         \n",
       "label heureux morceau relation musique                                                       0.977648         \n",
       "ab test procédure stratification contextuel                                                  0.999902         \n",
       "\n",
       "                                                    arabe sentiment commentaire marocain dialectal   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                 0.866566   \n",
       "coclustering modl gagne taille passent                                                     0.193443   \n",
       "recommandation mobilité factorisation dintérêts...                                         0.208522   \n",
       "arabe sentiment commentaire marocain dialectal                                             1.000000   \n",
       "cds résumé texte composant rôle                                                            0.202024   \n",
       "big scénario ontologique data analyse                                                      0.964277   \n",
       "tentative décès supervisées patient risque                                                 0.232128   \n",
       "formés majoritaire vote global obtenus                                                     0.254348   \n",
       "label heureux morceau relation musique                                                     0.409488   \n",
       "ab test procédure stratification contextuel                                                0.194824   \n",
       "\n",
       "                                                    cds résumé texte composant rôle   \\\n",
       "politique idéo2017 citoyen tweets candidat                                  0.663839   \n",
       "coclustering modl gagne taille passent                                      0.999962   \n",
       "recommandation mobilité factorisation dintérêts...                          0.999978   \n",
       "arabe sentiment commentaire marocain dialectal                              0.202024   \n",
       "cds résumé texte composant rôle                                             1.000000   \n",
       "big scénario ontologique data analyse                                       0.454242   \n",
       "tentative décès supervisées patient risque                                  0.999524   \n",
       "formés majoritaire vote global obtenus                                      0.998556   \n",
       "label heureux morceau relation musique                                      0.976231   \n",
       "ab test procédure stratification contextuel                                 0.999973   \n",
       "\n",
       "                                                    big scénario ontologique data analyse   \\\n",
       "politique idéo2017 citoyen tweets candidat                                        0.967810   \n",
       "coclustering modl gagne taille passent                                            0.446426   \n",
       "recommandation mobilité factorisation dintérêts...                                0.460148   \n",
       "arabe sentiment commentaire marocain dialectal                                    0.964277   \n",
       "cds résumé texte composant rôle                                                   0.454242   \n",
       "big scénario ontologique data analyse                                             1.000000   \n",
       "tentative décès supervisées patient risque                                        0.481497   \n",
       "formés majoritaire vote global obtenus                                            0.501448   \n",
       "label heureux morceau relation musique                                            0.636529   \n",
       "ab test procédure stratification contextuel                                       0.447686   \n",
       "\n",
       "                                                    tentative décès supervisées patient risque   \\\n",
       "politique idéo2017 citoyen tweets candidat                                             0.686585   \n",
       "coclustering modl gagne taille passent                                                 0.999216   \n",
       "recommandation mobilité factorisation dintérêts...                                     0.999707   \n",
       "arabe sentiment commentaire marocain dialectal                                         0.232128   \n",
       "cds résumé texte composant rôle                                                        0.999524   \n",
       "big scénario ontologique data analyse                                                  0.481497   \n",
       "tentative décès supervisées patient risque                                             1.000000   \n",
       "formés majoritaire vote global obtenus                                                 0.999738   \n",
       "label heureux morceau relation musique                                                 0.982450   \n",
       "ab test procédure stratification contextuel                                            0.999271   \n",
       "\n",
       "                                                    formés majoritaire vote global obtenus   \\\n",
       "politique idéo2017 citoyen tweets candidat                                         0.703059   \n",
       "coclustering modl gagne taille passent                                             0.998047   \n",
       "recommandation mobilité factorisation dintérêts...                                 0.998891   \n",
       "arabe sentiment commentaire marocain dialectal                                     0.254348   \n",
       "cds résumé texte composant rôle                                                    0.998556   \n",
       "big scénario ontologique data analyse                                              0.501448   \n",
       "tentative décès supervisées patient risque                                         0.999738   \n",
       "formés majoritaire vote global obtenus                                             1.000000   \n",
       "label heureux morceau relation musique                                             0.986465   \n",
       "ab test procédure stratification contextuel                                        0.998134   \n",
       "\n",
       "                                                    label heureux morceau relation musique   \\\n",
       "politique idéo2017 citoyen tweets candidat                                         0.810150   \n",
       "coclustering modl gagne taille passent                                             0.974296   \n",
       "recommandation mobilité factorisation dintérêts...                                 0.977648   \n",
       "arabe sentiment commentaire marocain dialectal                                     0.409488   \n",
       "cds résumé texte composant rôle                                                    0.976231   \n",
       "big scénario ontologique data analyse                                              0.636529   \n",
       "tentative décès supervisées patient risque                                         0.982450   \n",
       "formés majoritaire vote global obtenus                                             0.986465   \n",
       "label heureux morceau relation musique                                             1.000000   \n",
       "ab test procédure stratification contextuel                                        0.974612   \n",
       "\n",
       "                                                    ab test procédure stratification contextuel   \\\n",
       "politique idéo2017 citoyen tweets candidat                                              0.658327   \n",
       "coclustering modl gagne taille passent                                                  0.999999   \n",
       "recommandation mobilité factorisation dintérêts...                                      0.999902   \n",
       "arabe sentiment commentaire marocain dialectal                                          0.194824   \n",
       "cds résumé texte composant rôle                                                         0.999973   \n",
       "big scénario ontologique data analyse                                                   0.447686   \n",
       "tentative décès supervisées patient risque                                              0.999271   \n",
       "formés majoritaire vote global obtenus                                                  0.998134   \n",
       "label heureux morceau relation musique                                                  0.974612   \n",
       "ab test procédure stratification contextuel                                             1.000000   \n",
       "\n",
       "                                                                        ...                       \\\n",
       "politique idéo2017 citoyen tweets candidat                              ...                        \n",
       "coclustering modl gagne taille passent                                  ...                        \n",
       "recommandation mobilité factorisation dintérêts...                      ...                        \n",
       "arabe sentiment commentaire marocain dialectal                          ...                        \n",
       "cds résumé texte composant rôle                                         ...                        \n",
       "big scénario ontologique data analyse                                   ...                        \n",
       "tentative décès supervisées patient risque                              ...                        \n",
       "formés majoritaire vote global obtenus                                  ...                        \n",
       "label heureux morceau relation musique                                  ...                        \n",
       "ab test procédure stratification contextuel                             ...                        \n",
       "\n",
       "                                                    flou sousensembles appelons sousensemble défini   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                  0.671391   \n",
       "coclustering modl gagne taille passent                                                      0.999821   \n",
       "recommandation mobilité factorisation dintérêts...                                          0.999994   \n",
       "arabe sentiment commentaire marocain dialectal                                              0.211948   \n",
       "cds résumé texte composant rôle                                                             0.999949   \n",
       "big scénario ontologique data analyse                                                       0.463256   \n",
       "tentative décès supervisées patient risque                                                  0.999786   \n",
       "formés majoritaire vote global obtenus                                                      0.999049   \n",
       "label heureux morceau relation musique                                                      0.978379   \n",
       "ab test procédure stratification contextuel                                                 0.999847   \n",
       "\n",
       "                                                    uitliation documentaire fondé contenu laide   \\\n",
       "politique idéo2017 citoyen tweets candidat                                              0.672399   \n",
       "coclustering modl gagne taille passent                                                  0.999795   \n",
       "recommandation mobilité factorisation dintérêts...                                      0.999988   \n",
       "arabe sentiment commentaire marocain dialectal                                          0.213278   \n",
       "cds résumé texte composant rôle                                                         0.999934   \n",
       "big scénario ontologique data analyse                                                   0.464461   \n",
       "tentative décès supervisées patient risque                                              0.999813   \n",
       "formés majoritaire vote global obtenus                                                  0.999108   \n",
       "label heureux morceau relation musique                                                  0.978659   \n",
       "ab test procédure stratification contextuel                                             0.999822   \n",
       "\n",
       "                                                    nextclosure fermé itemsets partitionnement treillis   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                   0.672567      \n",
       "coclustering modl gagne taille passent                                                       0.999790      \n",
       "recommandation mobilité factorisation dintérêts...                                           0.999987      \n",
       "arabe sentiment commentaire marocain dialectal                                               0.213499      \n",
       "cds résumé texte composant rôle                                                              0.999931      \n",
       "big scénario ontologique data analyse                                                        0.464662      \n",
       "tentative décès supervisées patient risque                                                   0.999817      \n",
       "formés majoritaire vote global obtenus                                                       0.999117      \n",
       "label heureux morceau relation musique                                                       0.978706      \n",
       "ab test procédure stratification contextuel                                                  0.999818      \n",
       "\n",
       "                                                    incomplets classement probabiliste dobjets arbre   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                   0.668669   \n",
       "coclustering modl gagne taille passent                                                       0.999884   \n",
       "recommandation mobilité factorisation dintérêts...                                           1.000000   \n",
       "arabe sentiment commentaire marocain dialectal                                               0.208363   \n",
       "cds résumé texte composant rôle                                                              0.999979   \n",
       "big scénario ontologique data analyse                                                        0.460003   \n",
       "tentative décès supervisées patient risque                                                   0.999703   \n",
       "formés majoritaire vote global obtenus                                                       0.998883   \n",
       "label heureux morceau relation musique                                                       0.977614   \n",
       "ab test procédure stratification contextuel                                                  0.999904   \n",
       "\n",
       "                                                    galois dalgorithmes treillis supervisée étude   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                0.672624   \n",
       "coclustering modl gagne taille passent                                                    0.999789   \n",
       "recommandation mobilité factorisation dintérêts...                                        0.999987   \n",
       "arabe sentiment commentaire marocain dialectal                                            0.213575   \n",
       "cds résumé texte composant rôle                                                           0.999930   \n",
       "big scénario ontologique data analyse                                                     0.464730   \n",
       "tentative décès supervisées patient risque                                                0.999819   \n",
       "formés majoritaire vote global obtenus                                                    0.999121   \n",
       "label heureux morceau relation musique                                                    0.978722   \n",
       "ab test procédure stratification contextuel                                               0.999817   \n",
       "\n",
       "                                                    mask savoirfaire dappropriation dentreprise mémoire   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                   0.663598      \n",
       "coclustering modl gagne taille passent                                                       0.999964      \n",
       "recommandation mobilité factorisation dintérêts...                                           0.999976      \n",
       "arabe sentiment commentaire marocain dialectal                                               0.201709      \n",
       "cds résumé texte composant rôle                                                              1.000000      \n",
       "big scénario ontologique data analyse                                                        0.453956      \n",
       "tentative décès supervisées patient risque                                                   0.999514      \n",
       "formés majoritaire vote global obtenus                                                       0.998539      \n",
       "label heureux morceau relation musique                                                       0.976161      \n",
       "ab test procédure stratification contextuel                                                  0.999975      \n",
       "\n",
       "                                                    voisinage graphe voisin proximité prétraitement   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                  0.667256   \n",
       "coclustering modl gagne taille passent                                                      0.999911   \n",
       "recommandation mobilité factorisation dintérêts...                                          0.999998   \n",
       "arabe sentiment commentaire marocain dialectal                                              0.206506   \n",
       "cds résumé texte composant rôle                                                             0.999990   \n",
       "big scénario ontologique data analyse                                                       0.458316   \n",
       "tentative décès supervisées patient risque                                                  0.999655   \n",
       "formés majoritaire vote global obtenus                                                      0.998791   \n",
       "label heureux morceau relation musique                                                      0.977213   \n",
       "ab test procédure stratification contextuel                                                 0.999929   \n",
       "\n",
       "                                                    conceptuels graphe connaissance contrainte validation   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                   0.674420        \n",
       "coclustering modl gagne taille passent                                                       0.999736        \n",
       "recommandation mobilité factorisation dintérêts...                                           0.999971        \n",
       "arabe sentiment commentaire marocain dialectal                                               0.215948        \n",
       "cds résumé texte composant rôle                                                              0.999899        \n",
       "big scénario ontologique data analyse                                                        0.466881        \n",
       "tentative décès supervisées patient risque                                                   0.999862        \n",
       "formés majoritaire vote global obtenus                                                       0.999220        \n",
       "label heureux morceau relation musique                                                       0.979218        \n",
       "ab test procédure stratification contextuel                                                  0.999767        \n",
       "\n",
       "                                                    veille technologique texte rechercher scientifique   \\\n",
       "politique idéo2017 citoyen tweets candidat                                                   0.673066     \n",
       "coclustering modl gagne taille passent                                                       0.999776     \n",
       "recommandation mobilité factorisation dintérêts...                                           0.999983     \n",
       "arabe sentiment commentaire marocain dialectal                                               0.214159     \n",
       "cds résumé texte composant rôle                                                              0.999923     \n",
       "big scénario ontologique data analyse                                                        0.465260     \n",
       "tentative décès supervisées patient risque                                                   0.999830     \n",
       "formés majoritaire vote global obtenus                                                       0.999146     \n",
       "label heureux morceau relation musique                                                       0.978844     \n",
       "ab test procédure stratification contextuel                                                  0.999805     \n",
       "\n",
       "                                                    naturel risque entrepôt dentrepôt examinons   \n",
       "politique idéo2017 citoyen tweets candidat                                              0.671789  \n",
       "coclustering modl gagne taille passent                                                  0.999811  \n",
       "recommandation mobilité factorisation dintérêts...                                      0.999992  \n",
       "arabe sentiment commentaire marocain dialectal                                          0.212473  \n",
       "cds résumé texte composant rôle                                                         0.999943  \n",
       "big scénario ontologique data analyse                                                   0.463732  \n",
       "tentative décès supervisées patient risque                                              0.999797  \n",
       "formés majoritaire vote global obtenus                                                  0.999073  \n",
       "label heureux morceau relation musique                                                  0.978490  \n",
       "ab test procédure stratification contextuel                                             0.999838  \n",
       "\n",
       "[10 rows x 1269 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calcul de similarité des Documents\n",
    "\n",
    "#Compute document similarity using LSA components\n",
    "\n",
    "similarity = np.asarray(np.asmatrix(dtm_lsa) * np.asmatrix(dtm_lsa).T)\n",
    "\n",
    "pd.DataFrame(similarity, index=best, columns=best).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Hiérarchique Ascendant (HAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le vrai point d'intérêt de cet algorithme est le seuil de similarité qui servira de point d'arrêt. Pour l'instant, je ne sais pas quel sera ce seuil, il faudra attendre les résultats du clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = AgglomerativeClustering(n_clusters=10).fit_predict(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = []\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "c6 = []\n",
    "c7 = []\n",
    "c8 = []\n",
    "c9 = []\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    if clusters[i] == 0:\n",
    "        c0.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 1:\n",
    "        c1.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 2:\n",
    "        c2.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 3:\n",
    "        c3.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 4:\n",
    "        c4.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 5:\n",
    "        c5.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 6:\n",
    "        c6.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 7:\n",
    "        c7.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 8:\n",
    "        c8.append({best[i]:doc[\"year\"][i]})\n",
    "    elif clusters[i] == 9:\n",
    "        c9.append({best[i]:doc[\"year\"][i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 21 4 73 13 19 31 2 1004 27\n"
     ]
    }
   ],
   "source": [
    "print(len(c0), len(c1), len(c2), len(c3), len(c4), len(c5), len(c6), len(c7), len(c8), len(c9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travail temporel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = []\n",
    "t1 = []\n",
    "t2 = []\n",
    "t3 = []\n",
    "t4 = []\n",
    "t5 = []\n",
    "t6 = []\n",
    "t7 = []\n",
    "t8 = []\n",
    "t9 = []\n",
    "\n",
    "for i in range(len(c0)):\n",
    "    t0.append(list(c0[i].values()))\n",
    "for i in range(len(c1)):\n",
    "    t1.append(list(c1[i].values()))\n",
    "for i in range(len(c2)):\n",
    "    t2.append(list(c2[i].values()))\n",
    "for i in range(len(c3)):\n",
    "    t3.append(list(c3[i].values()))\n",
    "for i in range(len(c4)):\n",
    "    t4.append(list(c4[i].values()))\n",
    "for i in range(len(c5)):\n",
    "    t5.append(list(c5[i].values()))\n",
    "for i in range(len(c6)):\n",
    "    t6.append(list(c6[i].values()))\n",
    "for i in range(len(c7)):\n",
    "    t7.append(list(c7[i].values()))\n",
    "for i in range(len(c8)):\n",
    "    t8.append(list(c8[i].values()))\n",
    "for i in range(len(c9)):\n",
    "    t9.append(list(c9[i].values()))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(c0)):\n",
    "    t0.append(t0[i][0])\n",
    "t0 = t0[int(len(t0)/2):]\n",
    "for i in range(len(c1)):\n",
    "    t1.append(t1[i][0])\n",
    "t1 = t1[int(len(t1)/2):]\n",
    "for i in range(len(c2)):\n",
    "    t2.append(t2[i][0])\n",
    "t2 = t2[int(len(t2)/2):]\n",
    "for i in range(len(c3)):\n",
    "    t3.append(t3[i][0])\n",
    "t3 = t3[int(len(t3)/2):]\n",
    "for i in range(len(c4)):\n",
    "    t4.append(t4[i][0])\n",
    "t4 = t4[int(len(t4)/2):]\n",
    "for i in range(len(c5)):\n",
    "    t5.append(t5[i][0])\n",
    "t5 = t5[int(len(t5)/2):]\n",
    "for i in range(len(c6)):\n",
    "    t6.append(t6[i][0])\n",
    "t6 = t6[int(len(t6)/2):]\n",
    "for i in range(len(c7)):\n",
    "    t7.append(t7[i][0])\n",
    "t7 = t7[int(len(t7)/2):]\n",
    "for i in range(len(c8)):\n",
    "    t8.append(t8[i][0])\n",
    "t8 = t8[int(len(t8)/2):]\n",
    "for i in range(len(c9)):\n",
    "    t9.append(t9[i][0])\n",
    "t9 = t9[int(len(t9)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [t0,t1,t2,t3,t4,t5,t6,t7,t8,t9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minYear(t):\n",
    "    return np.min(t)\n",
    "\n",
    "def maxYear(t):\n",
    "    return np.max(t)\n",
    "\n",
    "def moyYear(t):\n",
    "    return int(np.mean(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent = []\n",
    "ancien = []\n",
    "moyen = []\n",
    "mort = []\n",
    "nouveau = []\n",
    "\n",
    "# Si ancien = récent alors récent\n",
    "# Si récent = ancien alors ancien\n",
    "# Si moyenne = ancien alors ancien\n",
    "# Si moyenne = récent alors récent\n",
    "# Si moyenne = moyen alors moyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if minYear(t0) < 2011:\n",
    "    if maxYear(t0) < 2011:\n",
    "        mort.append(c0)\n",
    "    else:\n",
    "        if moyYear(t0) < 2009:\n",
    "            ancien.append(c0)\n",
    "        elif moyYear(t0) > 2014:\n",
    "            recent.append(c0)\n",
    "        else:\n",
    "            moyen.append(c0)\n",
    "elif minYear(t0) > 2011:\n",
    "    nouveau.append(c0)\n",
    "else:\n",
    "    if moyYear(t0) < 2011:\n",
    "        ancien.append(c0)\n",
    "    elif moyYear(t0) > 2011:\n",
    "        recent.append(c0)\n",
    "    else:\n",
    "        moyen.append(c0)\n",
    "        \n",
    "if minYear(t1) < 2011:\n",
    "    if maxYear(t1) < 2011:\n",
    "        mort.append(c1)\n",
    "    else:\n",
    "        if moyYear(t1) < 2009:\n",
    "            ancien.append(c1)\n",
    "        elif moyYear(t1) > 2014:\n",
    "            recent.append(c1)\n",
    "        else:\n",
    "            moyen.append(c1)\n",
    "elif minYear(t1) > 2011:\n",
    "    nouveau.append(c1)\n",
    "else:\n",
    "    if moyYear(t1) < 2011:\n",
    "        ancien.append(c1)\n",
    "    elif moyYear(t1) > 2011:\n",
    "        recent.append(c1)\n",
    "    else:\n",
    "        moyen.append(c1)  \n",
    "        \n",
    "if minYear(t2) < 2011:\n",
    "    if maxYear(t2) < 2011:\n",
    "        mort.append(c2)\n",
    "    else:\n",
    "        if moyYear(t2) < 2009:\n",
    "            ancien.append(c2)\n",
    "        elif moyYear(t2) > 2014:\n",
    "            recent.append(c2)\n",
    "        else:\n",
    "            moyen.append(c2)\n",
    "elif minYear(t2) > 2011:\n",
    "    nouveau.append(c2)\n",
    "else:\n",
    "    if moyYear(t2) < 2011:\n",
    "        ancien.append(c2)\n",
    "    elif moyYear(t2) > 2011:\n",
    "        recent.append(c2)\n",
    "    else:\n",
    "        moyen.append(c2)\n",
    "                \n",
    "if minYear(t3) < 2011:\n",
    "    if maxYear(t3) < 2011:\n",
    "        mort.append(c3)\n",
    "    else:\n",
    "        if moyYear(t3) < 2009:\n",
    "            ancien.append(c3)\n",
    "        elif moyYear(t3) > 2014:\n",
    "            recent.append(c3)\n",
    "        else:\n",
    "            moyen.append(c3)\n",
    "elif minYear(t3) > 2011:\n",
    "    nouveau.append(c3)\n",
    "else:\n",
    "    if moyYear(t3) < 2011:\n",
    "        ancien.append(c3)\n",
    "    elif moyYear(t3) > 2011:\n",
    "        recent.append(c3)\n",
    "    else:\n",
    "        moyen.append(c3)\n",
    "                \n",
    "if minYear(t4) < 2011:\n",
    "    if maxYear(t4) < 2011:\n",
    "        mort.append(c4)\n",
    "    else:\n",
    "        if moyYear(t4) < 2009:\n",
    "            ancien.append(c4)\n",
    "        elif moyYear(t4) > 2014:\n",
    "            recent.append(c4)\n",
    "        else:\n",
    "            moyen.append(c4)\n",
    "elif minYear(t4) > 2011:\n",
    "    nouveau.append(c4)\n",
    "else:\n",
    "    if moyYear(t4) < 2011:\n",
    "        ancien.append(c4)\n",
    "    elif moyYear(t4) > 2011:\n",
    "        recent.append(c4)\n",
    "    else:\n",
    "        moyen.append(c4)\n",
    "                \n",
    "if minYear(t5) < 2011:\n",
    "    if maxYear(t5) < 2011:\n",
    "        mort.append(c5)\n",
    "    else:\n",
    "        if moyYear(t5) < 2009:\n",
    "            ancien.append(c5)\n",
    "        elif moyYear(t5) > 2014:\n",
    "            recent.append(c5)\n",
    "        else:\n",
    "            moyen.append(c5)\n",
    "elif minYear(t5) > 2011:\n",
    "    nouveau.append(c5)\n",
    "else:\n",
    "    if moyYear(t5) < 2011:\n",
    "        ancien.append(c5)\n",
    "    elif moyYear(t5) > 2011:\n",
    "        recent.append(c5)\n",
    "    else:\n",
    "        moyen.append(c5)\n",
    "                \n",
    "if minYear(t6) < 2011:\n",
    "    if maxYear(t6) < 2011:\n",
    "        mort.append(c6)\n",
    "    else:\n",
    "        if moyYear(t6) < 2009:\n",
    "            ancien.append(c6)\n",
    "        elif moyYear(t6) > 2014:\n",
    "            recent.append(c6)\n",
    "        else:\n",
    "            moyen.append(c6)\n",
    "elif minYear(t6) > 2011:\n",
    "    nouveau.append(c6)\n",
    "else:\n",
    "    if moyYear(t6) < 2011:\n",
    "        ancien.append(c6)\n",
    "    elif moyYear(t6) > 2011:\n",
    "        recent.append(c6)\n",
    "    else:\n",
    "        moyen.append(c6)\n",
    "                \n",
    "if minYear(t7) < 2011:\n",
    "    if maxYear(t7) < 2011:\n",
    "        mort.append(c7)\n",
    "    else:\n",
    "        if moyYear(t7) < 2009:\n",
    "            ancien.append(c7)\n",
    "        elif moyYear(t7) > 2014:\n",
    "            recent.append(c7)\n",
    "        else:\n",
    "            moyen.append(c7)\n",
    "elif minYear(t7) > 2011:\n",
    "    nouveau.append(c7)\n",
    "else:\n",
    "    if moyYear(t7) < 2011:\n",
    "        ancien.append(c7)\n",
    "    elif moyYear(t7) > 2011:\n",
    "        recent.append(c7)\n",
    "    else:\n",
    "        moyen.append(c7)\n",
    "                \n",
    "if minYear(t8) < 2011:\n",
    "    if maxYear(t8) < 2011:\n",
    "        mort.append(c8)\n",
    "    else:\n",
    "        if moyYear(t8) < 2009:\n",
    "            ancien.append(c8)\n",
    "        elif moyYear(t8) > 2014:\n",
    "            recent.append(c8)\n",
    "        else:\n",
    "            moyen.append(c8)\n",
    "elif minYear(t8) > 2011:\n",
    "    nouveau.append(c8)\n",
    "else:\n",
    "    if moyYear(t8) < 2011:\n",
    "        ancien.append(c8)\n",
    "    elif moyYear(t8) > 2011:\n",
    "        recent.append(c8)\n",
    "    else:\n",
    "        moyen.append(c8)\n",
    "                \n",
    "if minYear(t9) < 2011:\n",
    "    if maxYear(t9) < 2011:\n",
    "        mort.append(c9)\n",
    "    else:\n",
    "        if moyYear(t9) <= 2010:\n",
    "            ancien.append(c9)\n",
    "        elif moyYear(t9) >= 2013:\n",
    "            recent.append(c9)\n",
    "        else:\n",
    "            moyen.append(c9)\n",
    "elif minYear(t9) > 2011:\n",
    "    nouveau.append(c9)\n",
    "else:\n",
    "    if moyYear(t9) < 2011:\n",
    "        ancien.append(c9)\n",
    "    elif moyYear(t9) > 2011:\n",
    "        recent.append(c9)\n",
    "    else:\n",
    "        moyen.append(c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent: []\n",
      "Ancien: []\n",
      "Moyen: [[{'label heureux morceau relation musique ': 2018}, {'motsclés darticles catégorisation scientifique relation ': 2018}, {'’ d document interrogation schéma ': 2018}, {'blockchain notarisation nfb protocole document ': 2018}, {'indexation performante prise compte document ': 2018}, {'unitexgramlab grammaire sétend dunitexgramlab marnelavallée ': 2018}, {'thématique nouveauté émergentes dobserver scénario ': 2018}, {'label relation dapprendre dignorer cycliques ': 2017}, {'normalité singularité expression naturel langage ': 2017}, {'entité événement relation lexicosémantique rachetées ': 2017}, {'pharmacovigilance web social fondé sémantique ': 2017}, {'dopinions twitter recommandation plateforme danalyse ': 2017}, {'egc mot thématique topic 2016 ': 2016}, {'clustering contrainte satellite lexpert priori ': 2016}, {'protocole stockage libre cassandrales évaluépar ': 2016}, {'plateforme collaboratives qualité noeud relation ': 2016}, {'gstream flux clustering topologique gas ': 2015}, {'recommandation utilisateur sociale préférence identification ': 2015}, {'hotspots hotspot photographie relation fendu ': 2015}, {'document administratif lhomme ledocument oudun ': 2014}, {'typés fusion formelle grammaire dontologies ': 2014}, {'grille dimension séquence dévènements clustering ': 2014}, {'chanson parole collection dexplorer interface ': 2014}, {'knn k voisin proche prototype ': 2014}, {'tags relation taux annotateur encourageant ': 2013}, {'ri sociale social modèle collection ': 2013}, {'motsclés document similitude présentant similaires ': 2013}, {'tca triadiques biclusters numériques biclustering ': 2012}, {'multiniveaux topologique hiérarchique clustering graphe ': 2012}, {'éprouvée idéalcette pluspertinents pourcette optimalesnous ': 2012}, {'journalistiques porteur tweets dinformations nan ': 2011}, {'territoriale collectivité progiciel lingénierie introduction ': 2011}, {'matching métadonnées assurer mumie langage ': 2011}, {'fusion prise dinformations source compte ': 2011}, {'musique morceau calme perception adaptable ': 2011}, {'diagnostique codage partielle fusion hétérogènes ': 2011}, {'pédagogiques document discursifs lanalysesémantique documentspédagogiques ': 2010}, {'structurelle document classe distance structure ': 2010}, {'cycliques proposévs pcarcaractérisé letemps cyclique ': 2010}, {'relation candidat sémantique association dontologies ': 2010}, {'dordre markov démontronsexpérimentalement inégalité rechercheet ': 2009}, {'naires bruitées fermé relation propositionpour ': 2009}, {'stream spam séquentiels transaction motif ': 2009}, {'graphique relation tentons interactionplutôt dintégrerce ': 2009}, {'okm recouvrante moc théoriques mélange ': 2008}, {'probabiliste document tenir structure modèle ': 2008}, {'geodoc territoire politique diagnostic document ': 2008}, {'wordnet som basés textuels document ': 2008}, {'relation répartie prédicatsarguments prédicatives recherchée ': 2008}, {'brevet document patent unifiées office ': 2008}, {'xml document classement dinformation item ': 2007}, {'document collection dentités liste espérons ': 2007}, {'ras citation dannotation outil document ': 2007}, {'étape candidat réordonnancement transformation document ': 2007}, {'webdocenrich document html semistructurés flexible ': 2007}, {'stream bordure statistique flot incrémentale ': 2006}, {'connues document xml mot collection ': 2006}, {'mi corrélation corrélées mesure dintérêt ': 2006}, {'stream motif séquentiels data contrainte ': 2006}, {'table relation document tournée web ': 2006}, {'territoire datamining spatial appliqué lié ': 2006}, {'sujet typicalité statistique implicative supplémentaires ': 2006}, {'chic implicative offertes b possibilité ': 2005}, {'document localisation terme tête positionné ': 2005}, {'acteur individu relation lorganisation mise ': 2005}, {'simulation agentuml outil production interaction ': 2005}, {'annotation ressource propagation document lillustration ': 2005}, {'rdf triplet linterrogation document dinterrogation ': 2005}, {'document restructuration semistructurés détaillons adapter ': 2005}, {'dordre markov chaîne arborescent paru ': 2005}, {'document dannotation xml mécanisme annotation ': 2004}, {'plateforme agent document noir madkit ': 2004}, {'xml document structure orientent lining ': 2004}, {'document filtrage lutilisateur textuels profil ': 2004}, {'motsclés langage précision document webnous ': 2004}], [{'politique idéo2017 citoyen tweets candidat ': 2018}, {'incrémentales cc clustering som collaboratif ': 2018}, {'âgées personne chute information bayésien ': 2018}, {'cardiovasculaires maladie facteur risque interaction ': 2018}, {'flux clustering didentifer clusteringsur dusubspace ': 2017}, {'clustering attribut lutilisateur préférencesest guidéespar ': 2016}, {'fusion éventuel driven linked conflit ': 2015}, {'2d projection interactif loutil clustering ': 2015}, {'social techniquesnonincrémentales jourincrémentalement attributsinconnus médiassociaux ': 2014}, {'modeling ocelet spatial format dynamics ': 2014}, {'populaires thématique twitter message expérimentationsmenées ': 2014}, {'évolutif statique suivi clustering ordinaire ': 2013}, {'boycott caractérisation identification danalyse différent ': 2012}, {'wiki isicil projet social lecadre ': 2012}, {'representative rules output its an ': 2011}, {'histograms summarization online stream by ': 2011}, {'folksonomies tagging cycle complet lenrichissement ': 2011}, {'metaactions rules action and nan ': 2010}, {'fusion heuristiquesmises télévisées dexpérimentations soulignent ': 2009}, {'clusterings individuel clustering méthode dimensionalité ': 2008}, {'multiagents clustering permanence dynamique dadapter ': 2007}], [{'endétectant précieusesinformations aumonde polarité tweet ': 2014}, {'formateur lactivité nucléaire pleine simulateur ': 2013}, {'taaable recipes dish replacing theconstraints ': 2009}, {'university stanford students gifted education ': 2005}], [{'city captured cities and of ': 2017}, {'apps android through text features ': 2017}, {'could the for knowledge ontology ': 2017}, {'engagement user the search click ': 2017}, {'users survey have the of ': 2016}, {'electricity long the provider temporalseries ': 2016}, {'model training tree method and ': 2016}, {'the learning to approach characterization ': 2016}, {'suicide drift avecsuccès dapprentissagedont personnesmonitorées ': 2016}, {'of the 2colorability hypergraphs property ': 2016}, {'message system and the aismessages ': 2016}, {'sentiment new the social smscorpus ': 2016}, {'mi pattern the sequential to ': 2016}, {'the project and of learning ': 2016}, {'the their of semantics to ': 2016}, {'sarem the architectureextraction softwarearchitecture specifies ': 2016}, {'slider to reasoner the more ': 2016}, {'moving objects the done trip ': 2016}, {'the variant extract topics analytics ': 2016}, {'advantage to window the consider ': 2015}, {'and the to — help ': 2015}, {'mahout forest random of the ': 2015}, {'knowledge uncertainty representation the an ': 2015}, {'and property re realestate the ': 2015}, {'the network actor centrality of ': 2015}, {'biclustering mapreduce dataset the cores ': 2015}, {'tweets vocabulary this to the ': 2015}, {'the of method and with ': 2015}, {'tweets of the in creation ': 2015}, {'the stemma codicum triplet obtained ': 2015}, {'drift drifted the new sudden ': 2014}, {'crowd the for as mining ': 2014}, {'across profiles snss of individual ': 2014}, {'the of samples models learned ': 2014}, {'the of smarter computers dream ': 2014}, {'the of environments pos tagging ': 2013}, {'plagiarism methods academic to by ': 2013}, {'text the groups of representation ': 2013}, {'of in and work the ': 2013}, {'antipatterns antipattern bad ontology queries ': 2012}, {'event biological of and the ': 2012}, {'relationship attribute community detection network ': 2012}, {'recommender the encouraged research project ': 2012}, {'cooperherskovitz simplified criterion bayesian the ': 2012}, {'the genetic of biological interaction ': 2012}, {'the analytics and visual to ': 2012}, {'clustering the and of network ': 2012}, {'as information to and processing ': 2011}, {'the criterion similarity with two ': 2011}, {'sociosemantic view of network based ': 2011}, {'the engines of search are ': 2011}, {'communities network the of presence ': 2010}, {'pattern the past future mining ': 2010}, {'to and patches analogy contentbased ': 2010}, {'user the profile contextualization and ': 2009}, {'risk multiarmed the bandit approach ': 2009}, {'intrusion detection anomaly ids as ': 2009}, {'the of in answer text ': 2009}, {'audit unlabelled adaptive anomaly intrusion ': 2009}, {'voting multiclassifier probabilistic rule svms ': 2009}, {'rough in the set of ': 2008}, {'video the of in people ': 2008}, {'the of and to in ': 2008}, {'trees the of unlabeled are ': 2008}, {'conditional entropy bayesian generalized network ': 2008}, {'interestingness measures the of mining ': 2007}, {'the of piecewise fisher histogram ': 2007}, {'gene of expression nearness condition ': 2006}, {'are regression the customers loans ': 2006}, {'the of computerscience quality are ': 2006}, {'pattern 19x19 go k programme ': 2005}, {'summarizer the uses summary method ': 2004}, {'algorithms lattices to millilitre the ': 2004}], [{'big scénario ontologique data analyse ': 2018}, {'commentaire commentsminer publiquementaccessible représentatif 84 ': 2016}, {'forum réputation vote message vis ': 2016}, {'mine classe new mixture labeling ': 2015}, {'interaction site social recueillis informatif ': 2015}, {'mapreduce musée paradigme personne casdétudes ': 2014}, {'clustering fonctionnerdans détournant validonsexpérimentalement attributsvaleurs ': 2014}, {'forum sentiment leurs patient santé ': 2014}, {'semistructured retrieval in document structuring ': 2009}, {'dtmvic inférence text logiciel » ': 2009}, {'file personal tags context on ': 2008}, {'bootstrap réplication total corrige autoorganisées ': 2007}, {'subspace cluster clustering compréhensibilité simplifié ': 2005}], [{'arabe sentiment commentaire marocain dialectal ': 2018}, {'dynamics power understanding big human ': 2018}, {'community complex network in structure ': 2018}, {'métadonnées vault physique data stockage ': 2018}, {'sujet dinvestigation haut biclustering variante ': 2017}, {'we neighborhoodbased group clustering new ': 2016}, {'factory network social overloading subtypingand ': 2016}, {'constraint programming generic solvers settings ': 2016}, {'of the bilingual multilingual document ': 2015}, {'stream shedding load the data ': 2015}, {'twitter the can stream system ': 2014}, {'snow subspace copac dénommé sousespaces ': 2013}, {'videos tags video we system ': 2013}, {'data statecharts integration using over ': 2010}, {'your mysins make semantic system ': 2010}, {'assessing uncertainty knn fusion data ': 2009}, {'programming constraint mining for data ': 2009}, {'orders finding total 01 data ': 2006}, {'microarray advances recent mining data ': 2005}], [{'apprenant leader dentre eux chacun ': 2018}, {'neuroimagerie dobservation réaliste réutilisation cliniciens ': 2018}, {'carlo monte bs sd sousgroupes ': 2017}, {'ratings recommendation useruser filtering enhanced ': 2017}, {'témoignage saisi rédigeant saisie préserver ': 2017}, {'ksc centroïd kspectral translation barycentre ': 2017}, {'porgy simulationainsi pilotés modélisationde rewriting ': 2017}, {'discovery wepropose metabolomic biomarkers methodologiesto ': 2016}, {'sousgroupes molécule olfactives neuroscientifiques descriptives ': 2015}, {'liées nalt avecagrovoc duneontologie ontologiesource ': 2014}, {'traverse minimales localgenerator régner diviser ': 2014}, {'amènent peucoûteuse lalgorithmespectral approchée notoirement ': 2014}, {'skypatterns softskypatterns toxicophores chémoinformatique autrement ': 2013}, {'traverse minimales hypergraphe hypergraphes imtextractor ': 2013}, {'gof outliers continuerdans ougroupe chaquegroupe ': 2012}, {'nucléaire krex explicites tacites maîtrise ': 2011}, {'sql algorithmedéfini lorsquecellesci luipermettre aiderlutilisateur ': 2010}, {'vol enregistrées perte techniquesdextraction dinformationsceci ': 2010}, {'syntaxiques induites valider relationsyntaxique unevalidation ': 2009}, {'vente performantsdaide 2007montre classifieurbayesien isolément ': 2009}, {'obtenu premierplan learningchallenge pascal aposteriori ': 2009}, {'plainte pollution réalisable dassigner apparie ': 2008}, {'prototypicalité gradient endogroupe pragmatique lexicale ': 2008}, {'récit voyage litinéraire attendu ditinéraires ': 2008}, {'capacité progresse lourde focalisation trouvé ': 2008}, {'quelquesunes espérant relevées heuristic modelbased ': 2007}, {'molécule médicament attributsconstruits résultatscomparables utilisésdans ': 2006}, {'lenseignement apprenant pédagogique denseignement linternet ': 2005}, {'siad fonctionnement éditoriale lalimentent alimentation ': 2004}, {'induction apprenti inductifs extensionnelle souligne ': 2004}, {'musette réutiliser capture illustrent experience ': 2004}], [{'coclustering modl gagne taille passent ': 2018}, {'recommandation mobilité factorisation dintérêts inféré ': 2018}, {'cds résumé texte composant rôle ': 2018}, {'tentative décès supervisées patient risque ': 2018}, {'formés majoritaire vote global obtenus ': 2018}, {'ab test procédure stratification contextuel ': 2018}, {'cardiaque similarité quasiarithmétiques moyenne type ': 2018}, {'limportance noeud réseau influe différencie ': 2018}, {'similarité campagne sémantique vectorielles complémentarité ': 2018}, {'tempsréel oblige liot pertinence démontrées ': 2018}, {'complétude prescriptives commande contrainte vérifier ': 2018}, {'treillis distributif fca concept médians ': 2018}, {'gpo séquence ordonnés graduel partiellement ': 2018}, {'dbpédia dassociations catégorie apparentés lacune ': 2018}, {'spark tempsréel singularité basés combinaison ': 2018}, {'motif norme aléatoire séquentiels rejet ': 2018}, {'edoi multicouches itérative exploration lutilisateur ': 2018}, {'elaboration délaboration poster géotechnique entreprise ': 2018}, {'lien wikipédia interlangues édition erronés ': 2018}, {'métier antécédent recrutent lerecrutement sociaux ': 2018}, {'darticles thématique scientifique sémantique corpus ': 2018}, {'dinfluenceurs centralité dalgorithmes comparative évaluation ': 2018}, {'météorologiques journée mesurées série ville ': 2018}, {'chemin linformation propagation trajectoire retrouver ': 2018}, {'défaillance dessieux compteur cause événement ': 2018}, {'temporalité graduel fermé fréquents contrainte ': 2018}, {'événement négatif motif électricité ntgsp ': 2018}, {'recommandation dhôtels contextuelles distinctives volatilité ': 2018}, {'ontobiotope vie lontologie microbiens lagriculture ': 2018}, {'bord personnalité média communauté suivi ': 2018}, {'nnms meanshift kplus scalable voisin ': 2018}, {'ordinale métaanalyse ordre enquête dopinion ': 2018}, {'approximatifs déséquilibré incrémental décision mai2p ': 2018}, {'microblogs localisation extraire dapprentissage nan ': 2018}, {'approximatifs massives théorie caractéristique sélection ': 2018}, {'palm lespace treillis parallèle branche ': 2018}, {'peerus dexperts scientifique review entrainé ': 2018}, {'capacitaire planning perforecast tôt service ': 2018}, {'solaire rayonnement prédiction météorologiques régression ': 2018}, {'thr inventaire satellitaires image terrain ': 2018}, {'financement campagne participatif proposition prédiction ': 2018}, {'nos questce machine évolué lapprentissage ': 2018}, {'personnalisées motsclés réponse fournir seulement ': 2018}, {'manuscrit indexation historique chancellerie registre ': 2018}, {'linéaire shift déploiement distribution variées ': 2018}, {'dassainissement date conduite pose reconstitution ': 2018}, {'artificielle voir dela vision savoir ': 2018}, {'verbalisation fait dindices temporel formalisation ': 2018}, {'coclustering bayésien critère modèle mixtes ': 2018}, {'recommandation personnalisées dactualité hybride échelle ': 2018}, {'carreau désagrégation population bâtiment ouvertes ': 2018}, {'universalendpointcom web daccès plateforme sparql ': 2018}, {'textuel lignée su influencers hybrid ': 2017}, {'dévolution satellitaires série temporelles dimages ': 2017}, {'table anonymiser publiées individu coclustering ': 2017}, {'binarisées variable coclustering party étape ': 2017}, {'item zone intermédiaire » « ': 2017}, {'structuration multiinstance cadre ensemble taxonomique ': 2017}, {'crf dappels définissent doffres séquentielles ': 2017}, {'flux parallélisme opérateur traitement degré ': 2017}, {'méta devaluation analyse cadre nan ': 2017}, {'cah part formule ascendant noyau ': 2017}, {'sousparties discriminantes aléatoire 3d dobjets ': 2017}, {'dtcwt phase transform isar reconnaissance ': 2017}, {'coclustering mixtes table continues bloc ': 2017}, {'treillis similarité concept mesure basées ': 2017}, {'ab généraliste conception lévaluation test ': 2017}, {'costsensitive précisionrappel maladie ville défi ': 2017}, {'lutilisateur motif préféré implicitement transaction ': 2017}, {'multimodales faux sociaux vers détection ': 2017}, {'communauté stabilité représentatives période temporelle ': 2017}, {'paysage limage enjeu dautomatisation alliant ': 2017}, {'chronique discriminantes motif discriminant séquence ': 2017}, {'récurrentes attribué graphe unique évolution ': 2017}, {'chaînage dentretiens histoire supervisés science ': 2017}, {'géométriques 3d dassemblages propriété raisonnement ': 2017}, {'télévisés darchives face2graph archive visage ': 2017}, {'format rdf sparql sparqlgenerate nonrdf ': 2017}, {'rdf web format service objet ': 2017}, {'confiance source dinformations navire dinformation ': 2017}, {'resp attribut objet treillis correspondance ': 2017}, {'pli léchelle lasubsomption dacteurs de\\x12subsomption ': 2017}, {'colonne nosql orienté entrepôt hbaseavec ': 2017}, {'numéro défi multilabel tâche été ': 2017}, {'financement campagne montant levé participatif ': 2017}, {'ferré prévision bayésiens réseau court ': 2017}, {'client laide profil prototype différentesvisualisations ': 2017}, {'recommandation folksonomie filtrage préférence basées ': 2017}, {'décision justice crf hmm dentités ': 2017}, {'ciblée descripteur visuel dimages dassociation ': 2017}, {'multilabel prétraiter label sélection variable ': 2017}, {'réseau lien conceptuels clusters noeud ': 2017}, {'personnalisés rdfsparql littéral type rdf ': 2017}, {'télédétection référence bonne crowdsourcinget réalignement ': 2017}, {'prédictives kmoyennes lindice mesurer lalgorithme ': 2017}, {'communautaire générateur graphe réseau dynamique ': 2017}, {'lbsn recommandation dintérêt poisson factorisation ': 2017}, {'graduel dordre groupement variation temporel ': 2017}, {'neutralité personnalité innovante diffusion compréhension ': 2017}, {'dassociation règle fouille indirectes ferméeset ': 2017}, {'société numériques calcul vie nos ': 2017}, {'dexpertise crowdsourcing participant campagne degré ': 2017}, {'rôle communautaires centralité mesure trait ': 2017}, {'veille rewatch thème web pertinence ': 2017}, {'transformé échantillonnage flux vers nan ': 2017}, {'nell instance français chaîne nouvelleinstance ': 2017}, {'label multilabel court interactif texte ': 2017}, {'passage question reclassement retourner ngrammes ': 2016}, {'mappings soc lévolutiondes biomédical changement ': 2016}, {'coviz variable khiops visualisation catégorielles ': 2016}, {'conférence publication egc 3 série ': 2016}, {'thématique publication conférence somme scientifique ': 2016}, {'agroalimentaire – acteur décision vienten ': 2016}, {'catégorisation intérêt individu enutilisant renseignent ': 2016}, {'extrait unjournal accepté etpurement présentéafin ': 2016}, {'lexploration visuel dimages construite structure ': 2016}, {'label doublon binaires lexploration treillis ': 2016}, {'trace unitaire ni motif collection ': 2016}, {'collaboration tendance egc descriptive réseau ': 2016}, {'motif méthodeapprochée fpof daberration aberrantes ': 2016}, {'multidimensionnel hiérarchique hiérarchie factuelles architecturerolap ': 2016}, {'groupe centralité collaboration scientifique thématique ': 2016}, {'2016 egc défi dinformationlogiques surun ': 2016}, {'csparql flux extension raisonnement préservationde ': 2016}, {'chimiques nommées dentités reconnaissance deles ': 2016}, {'clé liage publiées candidat pertinenceet ': 2016}, {'pervasifs treillis formelle desmétriques généraliserlextraction ': 2016}, {'multistratégie fodomust interface plateforme temporelles ': 2016}, {'approchesde asp motif encodage programmation ': 2016}, {'duplicats redondantes quelle dargumentation transparenteet ': 2016}, {'recommandation lbsn géographique temporelle jusquà ': 2016}, {'multitables khiops million variable cas ': 2016}, {'pomotifs sousséquences relationnelle concept ététesté ': 2016}, {'time candidateto seems chorems meteorology ': 2016}, {'révolution captation risque lassureur canal ': 2016}, {'clowdflows fouille donnéesrelationnelles webpermettant venons ': 2016}, {'spectral arbitraire latent transformation théorie ': 2016}, {'recommandation tags persorec ressource quadratiques ': 2016}, {'plongement isométrique métrique lch chodorow ': 2016}, {'hyperplan parallèle point phase commune ': 2016}, {'logistique régression dimages échelle parallèle ': 2016}, {'skyline retournés relaxéest preferred pluspréférés ': 2016}, {'requête négatif discriminantes lexploration exemple ': 2016}, {'géographiques spatiales dassociations régissant saffietqui ': 2016}, {'comportementale client segmentation adapterloffre ensembleplus ': 2016}, {'sousensemble topologique sélection discrimination induite ': 2016}, {'haie markov hilbert courbe densité ': 2016}, {'mettons egc thématique décrivonsune thématiquesde ': 2016}, {'transmute trace linterprétation motif àse ': 2016}, {'cosc télédétection collaboratif segmentation thématique ': 2016}, {'egc 2016 thème défi lorsdes ': 2016}, {'desdonnées propriété textuelles représentationsphonologiques unicode ': 2016}, {'lexicoscientométrique egc 2016 défi websoustendu ': 2016}, {'défaillance détection système robotisé mixtes ': 2016}, {'lod létiquetage définition dontologie raisonnement ': 2016}, {'réduction dimensionnalité dagrégation préférence despremiers ': 2016}, {'phrase similarité noyau sémantique extrait ': 2016}, {'mobilité trace lindividu motif divers ': 2016}, {'kmoyennes centre vise kmoyennesstandard quelpoint ': 2016}, {'carte utilisateur d c cartographie ': 2016}, {'segmentation maillage lannotation annotation ontologie ': 2015}, {'paramètre étaient dinformation quels recherche ': 2015}, {'dopinions veille amiei leweb danalyse ': 2015}, {'blog dexpérience retour olap projet ': 2015}, {'cybercriminalité mondiale déplaisant dinterconnecter mondialisation ': 2015}, {'proximité topologique mesure discriminante discrimination ': 2015}, {'secm évidentielle croyance doptimisation fonction ': 2015}, {'multilabel économique centrée lindexation raisonnement ': 2015}, {'base – rdf jour soit ': 2015}, {'critère lecart partition modularité ayant ': 2015}, {'précisionrappel compromis performance indice fonction ': 2015}, {'skyline calcul candidat réduction pénalisé ': 2015}, {'d113 flux centrerons équipement transitant ': 2015}, {'analogiques proportion analogique paire nuplets ': 2015}, {'mot reformulation plagiat détection détecter ': 2015}, {'détection plagiat passage auteur devient ': 2015}, {'risque chimique alimentaire confondue substance ': 2015}, {'pondérés chemin condensé complète motiver ': 2015}, {'mf recommandation technique item utilisateur ': 2015}, {'manquant hydrologie gapit hydrométriques station ': 2015}, {'mappings adaptation ontologie lévolution guidant ': 2015}, {'dauteurs auteur panclef rédigé dauthentification ': 2015}, {'amazighe langue repérage nommées entité ': 2015}, {'mot texte intersection copiercoller étant ': 2015}, {'croisé item collaboratif filtrage exploitation ': 2015}, {'complexité motif axiome évaluation lié ': 2015}, {'rankmerging lien réseau classement épars ': 2015}, {'cpt prédiction compact ppm allkorder ': 2015}, {'règle dattributs liaison dapprentissage attribut ': 2015}, {'élastique noyau régularisation kdtw nonlinéaire ': 2015}, {'évidentielles skyline évidentiel pareto incertaines ': 2015}, {'ultramétricité dissimilaritées dultramétricité regroupement genere ': 2015}, {'composante parcimonieuse em principal probabiliste ': 2015}, {'icm compacité haute convergence résolution ': 2015}, {'dinterrogation graphe conceptuels lhomomorphisme optionnel ': 2015}, {'multiplexe réseau graine communauté centrée ': 2015}, {'propagation comparer modèle réécriture analytique ': 2015}, {'changement composé formalisation ontologiques élémentaires ': 2015}, {'sémiotique style indicateur usage expliquerons ': 2015}, {'petl massives etl parallèle plateforme ': 2015}, {'1dsax sax série symbolisation temporelles ': 2014}, {'représentation importantspar respectent opérateursdagrégation expériencesrapportées ': 2014}, {'protéinearn rosettadock score fonction poids ': 2014}, {'naïf bayésien logvraisemblance variablesexplicatives classifieur ': 2014}, {'phrase traduisant syntaxique dépendance mot ': 2014}, {'sommet multirésolution dinformationnous dedécrire sontassociés ': 2014}, {'stsurf reconnaissance descripteur dactions dictionnaire ': 2014}, {'solaire prédiction rayonnementssolaires photovoltaïque flux ': 2014}, {'bayes naïf classifieur pondéré explicatives ': 2014}, {'fcl conceptuels communauté intersection lien ': 2014}, {'lénoncé obtenusconduisent syndrome phénomèneet situationshumaines ': 2014}, {'cluster borne laffectation passe incrémental ': 2014}, {'chemin caractérisation voisinage deséléments lexception ': 2014}, {'compréhension cuisine recette site partagede ': 2014}, {'cube olap larchitecture orientée calcul ': 2014}, {'préférence profil contextuelles séquentiels recommandationsjustes ': 2014}, {'logiciel enrevue passé leçon prototypeles ': 2014}, {'volume descripteur influençant étudiéen diminue ': 2014}, {'humanité matériau numériques tenterons numérique ': 2014}, {'changement qualitatives détection flot cdcstream ': 2014}, {'domicile personne mouvement risque situation ': 2014}, {'géographiques openjump generatoret gdb remplissage ': 2014}, {'prédictiondes communauté réseau lafaisabilité précisionla ': 2014}, {'pertinence confusionnative intrinsèquement utilisantle présentonségalement ': 2014}, {'thème pixel doccupation classificationcouplant finaledétiquetage ': 2014}, {'attribués orientés isomorphisme graphe sousgraphes ': 2014}, {'dépisodes prédictiondinformations précieuseleur lesblogs déposés ': 2014}, {'minimaux motif profondeur densembles polynomialspace ': 2014}, {'kdariane déploiement programmation traitementspour visuelleariane ': 2014}, {'stratégie agent trace lélicitation méthodologie ': 2014}, {'recouvrement kmoyennes contrôler groupe généralisation ': 2014}, {'textuel extrait prend ontologie génération ': 2014}, {'attribués sommet hiérarchie motif dextrairedes ': 2014}, {'densité groupe différentes observation proposées ': 2014}, {'rôle réseau communautaire twitter noeud ': 2014}, {'géographique référentiel thématique profit source ': 2014}, {'dinteractions dévénements flot démarcheexploratoire événementspertinents ': 2014}, {'nommées entité lexpansion requête concept ': 2014}, {'subjectivité médical médecin discours lexicales ': 2014}, {'lincertitude théorie distribution due unique ': 2014}, {'locuteur 3way parler moins tableau ': 2014}, {'caméra opérateur trajectoire donnéesélectionner dassistance ': 2014}, {'motif récursifs séquentielles hiérarchique résumé ': 2014}, {'recouvrante noyau pourrépondre lerecours recouvrementde ': 2014}, {'pondération bipartitionnement variable topologique bloc ': 2014}, {'analogique manquant celui attributsbooléens transactionnelle ': 2014}, {'dévènements reconstruction chronologie enquêteur denquête ': 2014}, {'traduction rim rail interlangues multilingue ': 2014}, {'skyline point anomalie requête présence ': 2014}, {'multilabel ebr ecc chains suivide ': 2014}, {'élastique laxe temporel réduction noyau ': 2014}, {'multicritères conflit collaborative initiateur 015 ': 2014}, {'symétrie motif ensemblistes délagagebasé expériencesmenées ': 2014}, {'consensus partition departitions adjoint pourlequel ': 2014}, {'topologiques statis carte partition compromis ': 2014}, {'etdéclaratif destechniques demotifs ppc contrainte ': 2014}, {'mlearning mobile desparcours nouvellearchitecture apprentissagemobile ': 2014}, {'genre profil adonné hybridequi desauteurs ': 2014}, {'nodaux noeud communauté réseau topologiques ': 2014}, {'métrique détiquetage sélection variable donnéestextuelles ': 2014}, {'dimages ontologiques terme tomodensitométriques image ': 2014}, {'simplifiés décision arbre pouradapter difficilesà ': 2014}, {'modularité 2modlouvain linertie newman vectorielles ': 2014}, {'prosopographiques portail visualisation laccès fonctionnalitésdinterrogation ': 2014}, {'ralentissement quantitative bibliographique découverte motif ': 2013}, {'3d stéréoscopique stéréoscopie exploratoire perspective ': 2013}, {'catégorisation texte coût parmi proche ': 2013}, {'cabine simulation conception confort passager ': 2013}, {'ex réseau concept formelle influents ': 2013}, {'réclamation typologie allocataire caf dallocataires ': 2013}, {'concept larc relationnelle relationnelles treillis ': 2013}, {'objet orientée haute région résolution ': 2013}, {'protéiques epsilon aligneurs multiétiquettes alignement ': 2013}, {'routier trajectoire réseau contrainte lempruntent ': 2013}, {'gisement historique dentrer évaluer projet ': 2013}, {'série coclustering temporelles descripteur objetsattributs ': 2013}, {'tendance commerciale enseigne clientèle précoce ': 2013}, {'dontologie page noyau jardinage fiche ': 2013}, {'dantennes antenne habitant france mobile ': 2013}, {'évolutifs dinférence floue incrémental récursifs ': 2013}, {'naires ontologie dédiée relation représentation ': 2013}, {'aboutissons acycliques extrayant pondérés acyclique ': 2013}, {'attribués fréquents motif arbre sousarbres ': 2013}, {'betti génératif simplicial complexe csg ': 2013}, {'syntagme nominaux dindexation sri filtrage ': 2013}, {'positives négative règle rapn dassociation ': 2013}, {'changement étiqueté fenêtre aucun détection ': 2013}, {'protéine trimères coli escherichia complexe ': 2013}, {'régulation réseau sortie dinteraction linférence ': 2013}, {'twitter capitaliste sociaux réseau graphe ': 2013}, {'bitm bipartitionnement topologique carte simultané ': 2013}, {'choquet lintégrale dontologies alignement paramétrage ': 2013}, {'classe itératif supervisée dextraction lapproche ': 2013}, {'dintégration réécriture requête adressées phase ': 2013}, {'variable hiérarchiques non sélection mesurer ': 2013}, {'factorisation note recommandation prédiction utilisateur ': 2013}, {'text2geo létang géospatiales dinformations thau ': 2013}, {'réseau entité relation létendant revisiter ': 2013}, {'secondaire table variable construites multitables ': 2013}, {'dontologies ràpc composition dinformation recherche ': 2013}, {'ppc contrainte programmation maximal clusters ': 2013}, {'généralisée vraisemblance thématique méthode press ': 2013}, {'carte cognitive valident critère influence ': 2013}, {'pco strate multicouche spécialisation mixte ': 2013}, {'variable construction table constructibles choisissant ': 2013}, {'séquence similarité mesure efficacement dexplorations ': 2013}, {'parallélisation cpu gpu radiale configuration ': 2013}, {'rsndf bootstrap filtre orthogonale rééchantillonnage ': 2012}, {'poids discriminante score linéaire àlutilisation ': 2012}, {'intervalle généralisation concept communepour sontobtenus ': 2012}, {'vigilance électrode 58 eeg pls ': 2012}, {'maximisation modularité spectrale catégorielles optimalemaximisant ': 2012}, {'instant séquentielles probabiliste sonttrès ina ': 2012}, {'probabiliste catégorielles topologique sontencourageants performancesont ': 2012}, {'procédure chirurgien dtw chirurgicales chirurgicale ': 2012}, {'clusters courbe paramétrique hiérarchique donnéesfonctionnelles ': 2012}, {'caractéristique combinaison elles classificateur sélection ': 2012}, {'théorie supervisée classificateur croyance fonction ': 2012}, {'maritime surveillance desrisques navire accident ': 2012}, {'diamètre derreur graphe rapide algorithme ': 2012}, {'taxonomie lexique usage depositionner destaxonomies ': 2012}, {'opinion internaute dopinions sera mot ': 2012}, {'covariations propriété sommet réseau motif ': 2012}, {'approximatives df modifiée exactes fonctionnelles ': 2012}, {'régularité lien desnoeuds traditionnellesqui flmin ': 2012}, {'intervalle séquence temporelles uneautre menonsquelques ': 2012}, {'sousparties généraliste particulière enrichir ontologie ': 2012}, {'vidéo concept caractéristique lindexation définir ': 2012}, {'ditemsets incrémentale fréquentes flux séquence ': 2012}, {'robot hog svm réalisés mobile ': 2012}, {'client typologie campagne kmoyennes score ': 2012}, {'dépendance règle analogie multivaluées définies ': 2012}, {'négative règle métarègles lextraction êtreformalisées ': 2012}, {'domotiques supervision capteur réaliserdu informationssur ': 2012}, {'analysis correlation pls rgcca multiblock ': 2012}, {'secondaire discrétisation variable table multitables ': 2012}, {'légende concevoir corese règle adaptées ': 2012}, {'agrégée élément xml évidencelimpact inex2009 ': 2012}, {'olap réorganisation cube réorganisationdans évaluéepar ': 2012}, {'impact service recommandation découverte web ': 2012}, {'ricsh corpus fragment thématique contextuelle ': 2012}, {'jointe distribution modèle grille densité ': 2012}, {'jurisprudence décision juridique arabe langue ': 2012}, {'tmdminer membre diffuseurset dediffuseur représentationdu ': 2012}, {'transfert matricielle topologique pondéré lapprentissage ': 2012}, {'dissimilarité matrice partition àpriori connaissons ': 2012}, {'assistant paramétrages appariement utilisateur visuel ': 2012}, {'quantification dimages grand descripteur imagesdimagenet ': 2012}, {'diffusion linformation individuel menéesmontrent multidimensionnelledes ': 2012}, {'distance nominaux histogramme dhistogrammes entité ': 2012}, {'transfert interdomaines deressources complétion dinformationssur ': 2012}, {'décomposition graphe introduitenous cadreune parblondel ': 2012}, {'agronomiques limprécision gérant agricoles quantitative ': 2012}, {'motif expérimentationsréalisées égalementune motifsspatioséquentiels denguedans ': 2012}, {'hiérarchie taxonomie construction etmultiniveaux valeursdattributs ': 2012}, {'marquage sein encomparaison duprojet lauteur ': 2012}, {'prétopologique lexicosémantiques structuration texte codant ': 2011}, {'tarification nonvie risque dassurance généralisés ': 2011}, {'électriques compteur communicant duplication agrégées ': 2011}, {'suspect visuel comportement suivant communication ': 2011}, {'exhaustif professionnel guidé recommandation expert ': 2011}, {'textuelles ressource analysons construction méthodologie ': 2011}, {'liaison dindices va comportement probabiliste ': 2011}, {'contingence lafc tableau dimages mot ': 2011}, {'comptage spatiotemporelle blob franchissant ligne ': 2011}, {'transduction annotation couverture nommées dentités ': 2011}, {'connaissances1 iconique coopérative catégorisation apport ': 2011}, {'coldstart collaboratives recommandation logs froid ': 2011}, {'som topologiques carte contrainte triviale ': 2011}, {'logique clause prédicat markov réseau ': 2011}, {'carte cognitives cognitive dinfluences vue ': 2011}, {'mesure dégager règle 61 propriété ': 2011}, {'fa me aléatoires voisinage coller ': 2011}, {'pose isar cible transformée image ': 2011}, {'discriminante échantillon virtuel normalisée grosse ': 2011}, {'tanagra cellulaire discrétisation implémentation intégration ': 2011}, {'renforcement transport automatisés sécurité daide ': 2011}, {'champignon ontologique dexpression séquence construction ': 2011}, {'satellite dévolution sits série dimages ': 2011}, {'sociaux graphe réseau document nan ': 2011}, {'flux changement détection favorablement évitent ': 2011}, {'tableau guidée sousensembles floues flou ': 2011}, {'profil utilisateur courtterme longterme dadaptation ': 2011}, {'motif transaction support pondérant reçoive ': 2011}, {'proximité topologique léquivalence mesure plan ': 2011}, {'arc graphe clusters densité taille ': 2011}, {'usager dinternet être telle question ': 2011}, {'acabit quezao terminologique laspect 2424actu ': 2011}, {'client motif lachat contextuels séquentiels ': 2011}, {'dévénements temporel motif intervalle représentatifs ': 2011}, {'relationnelles réseau sociaux létape dagrégation ': 2011}, {'clique détiquettes densembles homogènes sommet ': 2011}, {'ensemblistes motif bruités bruit heuristique ': 2011}, {'barrière format transformation brut utilisateur ': 2011}, {'haptiques simulateur eiah chirurgie centrée ': 2011}, {'roc courbe interprétation graphique nan ': 2011}, {'spectrale relationnelle problème lagrange multiplicateur ': 2011}, {'dintelligence isicil intégration travers communauté ': 2011}, {'moteur wikis wiki sémantique état ': 2011}, {'m3a assisté dingénierie maintenance plateforme ': 2011}, {'concordance mesure réduire source évidentielles ': 2011}, {'participant dhétérogénéité p2p disparité considérant ': 2011}, {'glose testing » « mot ': 2011}, {'linéarité énoncé français phénomène catégorie ': 2011}, {'rto terminoontologique lannotation tableau naires ': 2011}, {'phénomène spatiotemporels spatiotemporelles séquence motif ': 2011}, {'simulation propagation linformation publication reproduire ': 2011}, {'moteur réponse question web sémantique ': 2011}, {'wikipedia moteur permis question typer ': 2011}, {'motif deltalibres séquentiels difficile produit ': 2011}, {'géolocalisée nomao personnalisée nan recherche ': 2011}, {'graphe acréduits intéressante sousgraphes projection ': 2011}, {'contrainte lalignement différence programmation prête ': 2011}, {'naïf bayésien variable classifieur directe ': 2011}, {'pondération codées mixtes simultanée binaire ': 2011}, {'pmi ppmi positives variante formelle ': 2011}, {'heure cyclone longitude latitude 6 ': 2011}, {'attribut propositionalisation gèrent agréger discrétiser ': 2011}, {'action estimés magnitude séquence vidéo ': 2011}, {'logs requête logarithme olap résumé ': 2011}, {'variable unàplusieurs multitables cible relationnel ': 2011}, {'audiovisuel web30 service contenu nan ': 2011}, {'répétition télévisuels structuration supervisé flux ': 2011}, {'demploi offre catégorisation internet choisis ': 2011}, {'skylines skycube treillis accord skycuboïdes ': 2011}, {'règle robustes critère robustesse bayésien ': 2011}, {'géolocalisation dactualité laccès faciliter résumé ': 2011}, {'espace navigation outil sémantique nan ': 2011}, {'cnss cellulaire dinduction neurosymbolique va ': 2011}, {'floues contextuelles préférence requête règle ': 2011}, {'ontologie homologue distance légères calcule ': 2011}, {'client méthodologie économique recommandation lactionnabilité ': 2011}, {'opinion médiocre vocable critère film ': 2011}, {'treemap grille topologique hiérarchique partition ': 2011}, {'géographiques vis dentités ontologie globale ': 2011}, {'courriel indésirables cellulaire utilisation machine ': 2011}, {'enrichir dalignement ontologie taxomap topographie ': 2011}, {'description structure visualisation intergroupe segmentés ': 2011}, {'” 945 paire hautement corrélées ': 2010}, {'convexes géométrie fermeture topologie agrégation ': 2010}, {'maintenance préventive ferroviaire prendredes trainset ': 2010}, {'contrainte naires motif locaux csps ': 2010}, {'traminer dévénements séquence analyse nan ': 2010}, {'opérateur olap lanalyse ligne factorielle ': 2010}, {'foule évènements scène flux mélange ': 2010}, {'pair routage incrémentale usage requête ': 2010}, {'climatiques engendrés spatiales apport risque ': 2010}, {'patron lexicosyntaxiques identifier exprimantdes limplémentationdun ': 2010}, {'csp spécification apprentissage nan de ': 2010}, {'nominales adaptatif formels supervisé apprentissage ': 2010}, {'visualisation quantité réduirelensemble donnéesune grandissante ': 2010}, {'ancien destraits détailléesdont complexitéest etlindexation ': 2010}, {'privée préservation média vie sociaux ': 2010}, {'cube universitéconfirment hal lesexpériences hiérarchiesassociées ': 2010}, {'usager santé terminologie accès ontologie ': 2010}, {'casi cartocel cartographie booléenne donnéeorchestrée ': 2010}, {'chorml géographiques résumé visuel nan ': 2010}, {'séquence doutils notion différence dévénements ': 2010}, {'multimédia recherche modèle ii catégorie ': 2010}, {'copartitionnement variable groupement préparation discrétisation ': 2010}, {'cndcube cube “ ” concise ': 2010}, {'codex maya élément interprétables situant ': 2010}, {'réconciliation lalignement numérique combiner logique ': 2010}, {'disparité dexpertise créés sein blog ': 2010}, {'critère lintégration sontanalysés puretédes commecellesci ': 2010}, {'nonsupervisé sousensembles lesdifférences comparersont méthodebasée ': 2010}, {'composition réseau service social membresdu ': 2010}, {'darbres noyau induit expérimentationslutilisation danslespace ': 2010}, {'cube émergent quotient fermé cubique ': 2010}, {'dafoe thésaurus plateforme construire texte ': 2010}, {'plcm fermé ditemsets densesaméliorant creuses ': 2010}, {'dfc fonctionnelles conditionnelles dépendance df ': 2010}, {'anormal vidéo mouvement détection nan ': 2010}, {'weka formels basées développement plateforme ': 2010}, {'gmmsmos locuteur variante vecteur lidentification ': 2010}, {'etude comparative langage lien complexe ': 2010}, {'protéiques stabilité etude séquence sélection ': 2010}, {'réconciliation colorés petri guidées estparticulièrement ': 2010}, {'fonctionnelles exploration dépendance olap dassociation ': 2010}, {'distinctifs flux ditemsets résultatsdexpérimentations idkf ': 2010}, {'obstacle région personne dintérêt extraction ': 2010}, {'motif graduel élevé surde graduelsen ': 2010}, {'dassociation événement risque règle sousséquences ': 2010}, {'traduction ta rail corpus parallèle ': 2010}, {'vdm réalité graphique virtuelle taxonomie ': 2010}, {'amo droit gestion daccès stratégie ': 2010}, {'dépendance fonctionnelles incfds dinférer dinférencedes ': 2010}, {'dimages gpu afc incrémental thème ': 2010}, {'complexité état indice successifsqui deuxaspects ': 2010}, {'bayesienne dentropie inférence maximum cancer ': 2010}, {'dentropie priori machine maximum derreur ': 2010}, {'contrainte ajoutées interactive réduction similaires ': 2010}, {'sgfd flux portent récentes période ': 2010}, {'lab kwords dexplorer clé scientifique ': 2010}, {'graal abstraite kgram graphe naturel ': 2010}, {'conflit théorie croyance commentsupprimer définitionsdu ': 2010}, {'mot dépendance langue seconde delangue ': 2010}, {'xml multidimensionnelles entrepôt laidedu exécute ': 2010}, {'régles á mésures confiance confidence ': 2010}, {'recouvrantes recouvrante osom carte autoorganisatrices ': 2010}, {'motif validéepar lemultithreading doncdans volumineusesen ': 2010}, {'vidéo série temporelles prédiction séquence ': 2010}, {'pretopolib librairie java ensemblistescelleci laprétopologie ': 2010}, {'dopérateurs multidimensionnel olap proposition dobjets ': 2010}, {'règle associative classe classifieur génération ': 2010}, {'protein pgr graphe repository graph ': 2010}, {'modulaires cas requête pertinents raisonnement ': 2010}, {'reconnaissance lapprentissage concept basée nan ': 2010}, {'bidirectionnelle image réduction desversions objetsdes ': 2010}, {'série mémoire 2003 al accordant ': 2010}, {'textuelles nommer discussion regrouper groupe ': 2010}, {'préférence gros skyline requête utilisateur ': 2010}, {'flux résumé sgfd généraliste variées ': 2010}, {'merger rss nan ': 2010}, {'multidimensionnels motif entrepôt séquentiels automate ': 2010}, {'entropie catégorisation textuels descripteur sélection ': 2010}, {'segmentation client différentessegmentations latransformation segmentationsalternatives ': 2010}, {'gène séquentiels dappréhenderde visualisationnuages laccompagnement ': 2010}, {'siam médicaux dindexation nan système ': 2010}, {'pair p2p simtole plateforme dalignement ': 2010}, {'sotree hiérarchique topologique ” partition ': 2010}, {'souséchantillonnage déséquilibre aspect dapprentissage décisioncomme ': 2010}, {'dautomobiles ascendant suivi hiérarchique nan ': 2010}, {'dynamique bayésiens décision temporelles connaissancesà ': 2010}, {'croyance masse posteriori probabilité maximum ': 2010}, {'prédicat initiale corrélation réponse prochessémantiquement ': 2010}, {'lissage communauté modèle lidentification probabiliste ': 2010}, {'lashms imc enfant précoce charge ': 2010}, {'8743 correspondance ontologie étudiées dalignement ': 2010}, {'stratégie bayésienne échelon unidimensionnelles comparatives ': 2010}, {'inventif lacquisition ontologie conception laclarification ': 2010}, {'flot fenêtre impossible ditemsets rend ': 2010}, {'essentielles traduction idée utilisation texte ': 2010}, {'colocalisations expert géologiques étémenées unprototype ': 2010}, {'wikipedia qualité requis significativementle réduisait ': 2010}, {'wcum lanalyse lusage site partition ': 2010}, {'21ème siècle début dexpérience retour ': 2009}, {'ei dépendance 755 677 conduisentà ': 2009}, {'skin3d calibration réalité virtuelle matériel ': 2009}, {'dissimilarités facteur détats dinduction variabilité ': 2009}, {'variable procédure prédire identifiées prédictives ': 2009}, {'dopérations investissement commerciale optimiser régression ': 2009}, {'matériaux dopérations retour marché commerciale ': 2009}, {'olap lopération rolap implantelopération deshiérarchies ': 2009}, {'owldl sémantique individu entreindividus lapprochemise ': 2009}, {'pondération observation variable caractérisation dexhiber ': 2009}, {'règle cibler décideur intéressantes plusutiles ': 2009}, {'ldrègles cisna gérer hybride nan ': 2009}, {'envi télédétection innovants pixelsclassique fxtm ': 2009}, {'induit déquivalence mesure ordre degré ': 2009}, {'bruit bruités descripteur construction qualitésobtenues ': 2009}, {'contrôle flux observation traitement facteur100 ': 2009}, {'galois correspondance cettecorrespondance donnéessimples degalois ': 2009}, {'dbfrequentqueries fréquentes requête extraction nan ': 2009}, {'multiagents communication cmp sma symbolique ': 2009}, {'stratégie robot observables humains boucle ': 2009}, {'adn puce demon séquentiels expressionsde ': 2009}, {'demonvisualisation biologiques extrait séquentiels visualisation ': 2009}, {'desesper hydraulique surveillance centrale appliqué ': 2009}, {'signature attaque collaboratif organisation détection ': 2009}, {'multirésolution atypiques flot dobjets détection ': 2009}, {'croki2 classe validation traversun dedéterminer ': 2009}, {'diagnostic adaptatif diagnostiqueurs multisources vérifiée ': 2009}, {'reposant caractérisation treillis lefiltrage ligneillustre ': 2009}, {'rfid traçabilité groupe spatiotemporelles densité ': 2009}, {'explorer3d visualisation nan classification donnée ': 2009}, {'corrélation décisionnelles contingence vecteur lectique ': 2009}, {'moins graduelles réelsmontrent associésdes gradualité ': 2009}, {'fpgrowth fcpgrowth adaptation générer dassociation ': 2009}, {'dontologies riche schéma hiérarchie destructures ': 2009}, {'formels concept classification classifieur boosting ': 2009}, {'tournebool mot corpus reuters randomisation ': 2009}, {'gène al formelle dhypothèses motameny ': 2009}, {'ghsom som outil pourrendre danalyseexploratoire ': 2009}, {'créativité calculatoire synthèse lilp prédicat ': 2009}, {'syr symbolique logiciel lanalyse nan ': 2009}, {'culturel patrimoine management domaine nan ': 2009}, {'voisinage quiconsidère sontproches paramétriques automatiquenon ': 2009}, {'préférence contextuelles olap contextedanalyse lesdonnées ': 2009}, {'tei spécialisées bibliothèque structuresarborescentes justifions ': 2009}, {'wokm okmed okm classe métrique ': 2009}, {'dalignement dontologies bloc partitionnement ontologie ': 2009}, {'relationnelles logiciel aussiun processuspeut supporté ': 2009}, {'approcheautomatique siglesissues définition biomédicaux sigle ': 2009}, {'résumé requête obtenussont kdd99 nousutilisons ': 2009}, {'chaîne jaccard caractère lindice caractèrescomme ': 2009}, {'incrémental processeur gpu parallèle svm ': 2009}, {'librairie traminer r séquentielles lanalyse ': 2009}, {'· réseau décomposition doit changement ': 2009}, {'larbre bayésienne darbres décision larttout ': 2009}, {'aléatoires forêt oblique darbres algorithme ': 2009}, {'multimétiers crosslingue européen dentreprise prototype ': 2009}, {'médicale génomique corrélation linéaire lextraction ': 2009}, {'segmentation pixel image intensité supervisée ': 2009}, {'dimages lafc hors adt afc ': 2009}, {'changement simulation danalyser cour dusageà ': 2009}, {'échelle symbolique vers traitement grand ': 2009}, {'nsvm boosting lssvm psvm machine ': 2008}, {'film rapprochement montrerons vocabulaire site ': 2008}, {'définition svm nomsadjectifs investigués auquelle ': 2008}, {'événement presse automatique contenant annotev ': 2008}, {'visage reconnaissance classification galois hybride ': 2008}, {'ngrammes vie parcours séquence précisera ': 2008}, {'binaires probabiliste carte bernoulli gtm ': 2008}, {'sgbd nautilus métier optimisés lalimentation ': 2008}, {'gène cellulaire cycle dexpression référence ': 2008}, {'petit monde vue dapprentissage réseau ': 2008}, {'ssvc étoile coordonnée optimale linterface ': 2008}, {'coclassification contrainte quadratiques résidu somme ': 2008}, {'asti spatiotemporelle concepteur dinformation conception ': 2008}, {'séquentiels inattendus motif fréquence inattendues ': 2008}, {'délestage dégradation flux cube mécanisme ': 2008}, {'atypiques salaire groupe variable faible ': 2008}, {'bootstrap coupure ouvrons systématiquement chimerge ': 2008}, {'forêt détérioré contourner minoritaire déséquilibre ': 2008}, {'flot séquentiels déchantillonnage hypothèse motif ': 2008}, {'flux distribués consommation électriques capteur ': 2008}, {'dinfluence étape linflué maximisant règle ': 2008}, {'asymétriques dentropie arbre décision asymétrique ': 2008}, {'lsa grammaticales conceptuelle éducatives syntaxicosémantiques ': 2008}, {'période compact ditemsets itemsets deico ': 2008}, {'drone élémentaires photographie zone fine ': 2008}, {'multidimensionnels motif séquentiels clos densemble ': 2008}, {'annotation contextuelles sémantique émanant transmettre ': 2008}, {'croisement validation ontologie relation extraction ': 2008}, {'itemset fiasco item nouvel batches ': 2008}, {'acoustique mot 41 homophone sélectionné ': 2008}, {'vidéo soft condensé computing longueur ': 2008}, {'depotentiel calcul serveur client communiquent ': 2008}, {'contrainte médicales carte version mélanome ': 2008}, {'segmentation lexpert évolutive dimages limage ': 2008}, {'variable supervisé loutil khiops millier ': 2008}, {'graphe période sommet relationnelles décomposer ': 2008}, {'fia itemset flot itemsets automate ': 2008}, {'sociaux réseau lordonnancement parlerons prisée ': 2008}, {'soda récentes avancée analyser visualiser ': 2008}, {'cognitives carte hiérarchiques linconvénient concepteur ': 2008}, {'hiérarchiques hiérarchie lévaluation mesure fscore ': 2008}, {'degré dévaluation évaluation ontologiques méthodologie ': 2008}, {'instrumental plateau créativité eservices méthodologie ': 2008}, {'trajectoire arrêt mouvement ni temporel ': 2008}, {'mot axe recherche image qualité ': 2008}, {'risque industriel raisonnement ineris national ': 2008}, {'primal optimisation svm shrinking différentiables ': 2008}, {'neurone rbfgene rbf poids régression ': 2008}, {'pondération locale carte variable segmentation ': 2008}, {'réaction schéma chimiste graphe chimiques ': 2008}, {'symbolique concept histogrammesuites lavariation analysantces ': 2008}, {'sigle dacquisition dictionnaire présenté sappuie ': 2008}, {'dintrusions associatives détection générique sdis ': 2008}, {'spatiale lintroduction multidimensionnelle lanalyse opérateur ': 2008}, {'licorn adaptative corégulation régulation vessie ': 2008}, {'noyau graphe région chaîne caltech ': 2008}, {'bibliothèque personnalisée numériques retriés nos ': 2008}, {'routier trafic atypiques urbain spatiotemporels ': 2008}, {'alternative requête génomique multiniveaux entrepôt ': 2008}, {'référent carte pondérée sera voisinage ': 2008}, {'fenêtrage spatial traitées temporel requête ': 2008}, {'dontologie générique semiautomatisation conceptualisation terminae ': 2008}, {'superposées fenêtre basées stratégie repérer ': 2008}, {'itemsets clé suppression essentiel non ': 2008}, {'décideur argumentative cruciales multiagent conflit ': 2008}, {'groupe déterminer nombre stabilité classification ': 2008}, {'cartogramme ex trois spatiotemporelles dimension ': 2008}, {'noyau vectoriel latent cvsm despace ': 2008}, {'dontologies comprenant descriptifs algèbre dalignement ': 2008}, {'nk soi immunitaire artificiel système ': 2008}, {'denrichissement sig dutilisateurs accomplie offert ': 2008}, {'vote classification jugement thématiquement dopinion ': 2008}, {'somerdfs mappings mediad rd telecom ': 2008}, {'boosting ensembliste finale inspirée supervisée ': 2008}, {'conformité contrôle norme c3r bâtiment ': 2008}, {'jmesure élaguer chronique orientée nan ': 2008}, {'treillis navigation concept conceptuel niveau ': 2008}, {'bruitées dadaboost lerreur boosting dagrégation ': 2008}, {'intervalle divisive homogène partie poisson ': 2008}, {'diffusion liste faq cop sémantique ': 2008}, {'svm noire boite actionnables quant ': 2008}, {'cube olap lintégration vers prédiction ': 2008}, {'ancien français extrait séquentiels motif ': 2008}, {'vie parcours méthodologie suisse premier ': 2008}, {'page site étape descripteur textuelle ': 2008}, {'ressource entité dappariement lalignement règle ': 2007}, {'archéologiques navigation annotation implémentée approximatifs ': 2007}, {'colonne symbolique annotation numériques floue ': 2007}, {'banc pmms npc dessai nasopharynx ': 2007}, {'moteur entreprise jaune géolocalisation côté ': 2007}, {'hommemachine redirection émotion dappels dialogue ': 2007}, {'dordonnancement semisupervisé bénéfiques non–étiquetées cacm ': 2007}, {'étiquetées topologie delaunay euclidien génératif ': 2007}, {'cancer profil noncancer npc épidémiologique ': 2007}, {'réconciliation schéma logique référence picsel ': 2007}, {'cube visualisation pixel orientée calcul ': 2007}, {'temporisées conversation transition service logs ': 2007}, {'détenu lorganisation connaissance relatif acteur ': 2007}, {'dimplication règle conclusion darbres validation ': 2007}, {'distribution coupure lemplacement infinie fonctionnelles ': 2007}, {'lssvm boosting grand machine ensemble ': 2007}, {'séquence biologiques substitution protéiques matrice ': 2007}, {'classement ctsvm modèle mixtes carte ': 2007}, {'lactivité al ancrer herrmann seeme ': 2007}, {'construction dontologie lieu texte treillis ': 2007}, {'comportement dusage raison site jour ': 2007}, {'fourmi graphe artificielles incrémentale voisinage ': 2007}, {'datées dévénements discrets fabrication supervision ': 2007}, {'doubli spécification fonction entrepôt intelligentes ': 2007}, {'consommation abonné téléphonie détermination flou ': 2007}, {'carte volumineuses prédiction pertinente lié ': 2007}, {'conceptuelle linertie sens tableau impliquetil ': 2007}, {'préparation protocole fiabilité représentation métrique ': 2007}, {'inconsistance annotation sémantique lontologie lévolution ': 2007}, {'floue proximité terme avantageux modèle ': 2007}, {'dadaptation laca connaissance cas cabamaka ': 2007}, {'retroweb internet décrit migrateur dé\\x02nies ': 2007}, {'divergentes convergente multidimensionnelles m2scd srikantmême ': 2007}, {'approximeretpousser topk contrainte motif globales ': 2007}, {'webangels filter violent structurel textuel ': 2007}, {'lequel motif sousclasses quelconques découverte ': 2007}, {'médicales image région dannotation fusion ': 2007}, {'patron couple damorce phrase liste ': 2007}, {'entrepôt hiérarchie sialors représentons danalyse ': 2007}, {'communauté pratique lémergence membre connaissance ': 2007}, {'sdet géographiques enrichment supplément limitées ': 2007}, {'itemsets concises essentiel fermeture représentation ': 2007}, {'milieu parfois indice catégorisation adapté ': 2007}, {'dentropie mesure linsensibilité engendrer soixante ': 2007}, {'déséquilibré symétrique modalité bâtir endogène ': 2007}, {'thermique compact ajustés rc renforcé ': 2007}, {'appariement polygone géographiques fodomust dobjets ': 2007}, {'ip instantanées communication toip messagerie ': 2007}, {'recouvrement classe applicatifs motivées part ': 2007}, {'diamètre fort degré faible réseau ': 2007}, {'dexception possiblement surprenantes utile simultanée ': 2007}, {'privées service remplaçabilité protocole conversation ': 2007}, {'vidéo acp bloc dimension réduire ': 2007}, {'sonar imperfection imprécision incertitude théorie ': 2007}, {'vecteur thématique segmentation deft06 recherchant ': 2007}, {'instantané global – contexte cestàdire ': 2007}, {'kfaibles sousbases valides confiance sens ': 2007}, {'incomplètes contiennent temporairement éliminer représentative ': 2007}, {'rdf graphe combinaison noncontradiction contredisent ': 2007}, {'électrique consommation sgfd gestion flux ': 2007}, {'web logarithme fichier serveur usage ': 2007}, {'multiagent dontologies construction algorithme aménagement ': 2007}, {'motif utilisateur théorique collection dapprofondir ': 2007}, {'gène dexpression réseau tigr mev ': 2007}, {'guidé phrase tirons nutilisons segmenteur ': 2007}, {'série bioprocédé temporelles singularité fedbatch ': 2007}, {'rang lestimateur prédicteurs estimateur univarié ': 2007}, {'kilomètre sociotechnique lapproche laspect vision ': 2007}, {'neurone multicouches darchitecture couche choix ': 2007}, {'nexi xquery extension intégrer xml ': 2007}, {'sortie dinterpréter limportance dinterprétation variable ': 2007}, {'variable exogène paire partitionnement exogènes ': 2007}, {'fcm dca dc floue programmation ': 2007}, {'dalignement owllite dontologies circularité remédiant ': 2007}, {'dexception c règle r b ': 2007}, {'catégorisation wordnet multilingue monolingue consacré ': 2007}, {'cerveau irm anatomiques humain symbolique ': 2007}, {'projet biographiques bontology connaissance aperçu ': 2007}, {'s motif borne condensée représentation ': 2007}, {'règle dassociation visualisation générique lécran ': 2007}, {'appui tulip interactive graphe visualisation ': 2007}, {'décision darbre résultat compréhension focuscontext ': 2007}, {'écouter résumé réduirela doncdutiliser laudio ': 2006}, {'intervalle noeud affectation terminal fils ': 2006}, {'nonpertinence hospitalier composante aide gestion ': 2006}, {'dimension semiinteractif atypiques génétique simplementdes ': 2006}, {'implication desmesures asymétrique alignement ignorées ': 2006}, {'signature financier indicateur améliorer courte ': 2006}, {'vidéo comportement usage lindexationvidéo sessioncomportement ': 2006}, {'page élément web dannotation lidentification ': 2006}, {'corrélés motif cancer fréquents facteur ': 2006}, {'chronique duneoccurrence classesdévénements lapprocheentropique dediagnostic ': 2006}, {'arabase arabe lécriture optique reconnaissance ': 2006}, {'multi décision arbre supervisé mode ': 2006}, {'archiview hôpital topographique paramètre visualisation ': 2006}, {'carte som autoorganisatrice binaires probabiliste ': 2006}, {'conditionnel markov modèle champ séquence ': 2006}, {'délagage roc taux courbe terminologie ': 2006}, {'tableau croisé vraisemblance contingence mélange ': 2006}, {'comptesrendus owl mammographiques classerautomatiquement mammaire ': 2006}, {'nonsupervisée relationnelles nan classification donnée ': 2006}, {'factorielle variable plan classe deux ': 2006}, {'maximum flot paysage optimal densité ': 2006}, {'spécialité corpus ambiguïté étiqueté étiqueteur ': 2006}, {'sncf tacites conduite formaliser organisation ': 2006}, {'vivant mode appliqué science deux ': 2006}, {'site dissimilarités page navigation dediverses ': 2006}, {'mammographie comparaison dapprentissage nan méthode ': 2006}, {'porphyry confrontation vue point nan ': 2006}, {'règle dêtre telles extraites permetenfin ': 2006}, {'didactique orthopédique chirurgie diagnostic informatique ': 2006}, {'pair filtre bloom pairàpair signature ': 2006}, {'contrainte motif proposées temporelles égalementun ': 2006}, {'désuffixation eda médical langage nan ': 2006}, {'douce leau secteur multilingue distribué ': 2006}, {'datalab esiea nettoyage préparation logiciel ': 2006}, {'mot paramètre discriminant renforcent préclassés ': 2006}, {'navigateur dexpérience paradigme retour interactive ': 2006}, {'cure volumineuses extension lalgorithme fouille ': 2006}, {'champ code reconnaissance manuscrit numériques ': 2006}, {'vidéo flot mixte couleur actif ': 2006}, {'biomédicaux entité genia mesurantles dautresdescripteurs ': 2006}, {'morphologique multilingue terme extraction structure ': 2006}, {'protéine classer obtenusdautres 3grammes croiséepermettant ': 2006}, {'icare vivre lindustrie métier maker ': 2006}, {'associatives fastmgb règle générique génériqueminimale ': 2006}, {'pairàpair améliorer grandeconsommation téléchargement fichierssouvent ': 2006}, {'spatiales logique inductive présentera programmation ': 2006}, {'pédagogiques compétence ressource gestion nan ': 2006}, {'multimédia voisinage espacemultidimensionnel dindex améliorationà ': 2006}, {'isemantec capitalisation collaborative industriel métier ': 2006}, {'médiateur motsclefs virtuelles xquery vue ': 2006}, {'owl vérification conceptuels environnementgraphique dinterrogationet ': 2006}, {'réaction synthèse organique chimie graphe ': 2006}, {'forage métaclassificateur confiance descriptif règle ': 2006}, {'récolte parcours trace graphique interface ': 2006}, {'matérialisée etlexpertise décisionnellessont décisionnellesmais décisionnellespermettant ': 2006}, {'légitimement décisionnel dassociations qualité règle ': 2006}, {'spatialisable architectural informationnelle évolutives méthodologique ': 2006}, {'juridiques sontutilisés nouscomparons dimensionnalitéce conceptspermettent ': 2006}, {'radar préparation radarsexpérimentales dequalité imagesisar ': 2006}, {'visuel prétraitement medicaldataset kent affectationvisuelle ': 2006}, {'bit redondantes vecteur motif grand ': 2006}, {'xml schéma adopté recherche ensuitedétailler ': 2006}, {'préfixe ip trafic massif temps ': 2006}, {'adaptative temporel dépisodes patient version ': 2006}, {'uncorpus ‘ d ontologie domaine ': 2006}, {'composée règle prémisse gain ra ': 2006}, {'codés psychologique dexpertise orientés rdf ': 2006}, {'géotechnique appliquées représentation nan connaissance ': 2006}, {'démotion hommemachine dialogue dexpression modélisation ': 2006}, {'voronoi dinstances cellule partition surapprendpas ': 2006}, {'parallèle distribué svm 20dimensions cenouvel ': 2006}, {'intérieur lair surveillance daide décision ': 2006}, {'réécriture présence problème lexpérimentons rattache ': 2006}, {'teximus expertise logiciel suiteintégrée dynamiquede ': 2006}, {'texte lautomate sintéresser nature automate ': 2006}, {'exception dapprendre area logiciel leurs ': 2006}, {'linformation qualité facteur personnalisation besoinset ': 2006}, {'dagences dépêche extensible presse métier ': 2006}, {'bdg distribuée sig laspect géographiques ': 2006}, {'tactique agent réactifs schéma simulation ': 2006}, {'accord autonome linternet systèmesautonomes transit ': 2006}, {'indice lindice automobile applicationest intéressantesdans ': 2006}, {'dunités spécialisées regroupement dontologies textuelles ': 2006}, {'ontologie concept legraphe sharedspecificity pss ': 2006}, {'desmétadonnées métadonnées utilisateur traduirons lesclasses ': 2006}, {'bayésiens réseau aéronautique dinterruptionsopérationnelles estvalidée ': 2006}, {'motif rares fréquents certain lextraction ': 2006}, {'connaissance graphique graphe atanorqui limitationsapparaissent ': 2006}, {'point visualisation dintérêt zoomer interactivessont ': 2006}, {'dexpériences meat mémoire scientifique projet ': 2006}, {'période denses arbitraire eg usage ': 2006}, {'acka multiacteurs multiagents dacquisition coopérative ': 2005}, {'expert multiexperts œuvre connaissance exploitation ': 2005}, {'schéma conception systémique averti objetrelationnel ': 2005}, {'latente amélioration petit taille corpus ': 2005}, {'floues classe membre dassociation classification ': 2005}, {'symbolique graphe agent ultérieures dindividu ': 2005}, {'stochastique signature discrets mca dévénements ': 2005}, {'causalité lexicosyntaxiques annotation conceptuels corpus ': 2005}, {'cartographiques satellitales modèle dobjets image ': 2005}, {'multivariées scénario série temporelles apprentissage ': 2005}, {'transcription adn puce signature facteur ': 2005}, {'incomplètes bayésiens amsem actuellement capables ': 2005}, {'série warping dynamic kmeans dagrégation ': 2005}, {'ptree image classification règle génération ': 2005}, {'arbre kolmogorovsmirnov intervalle découpage échantillon ': 2005}, {'zone image dintérêt région imagettes ': 2005}, {'hiéarchique 23 web nan classification ': 2005}, {'mélange kmeans mndki2 lalgorithme loi ': 2005}, {'classification obtenue doit document triée ': 2005}, {'xml source xquery échanger matérialisées ': 2005}, {'passage qr questionréponse contenir question ': 2005}, {'statistique récentes avancée symbolique analyse ': 2005}, {'pyramide palier linterprétation nombre graphique ': 2005}, {'xml tableau tags format entrepôt ': 2005}, {'cache gml politique spatiales entrepôt ': 2005}, {'elem lem continues variante lentement ': 2005}, {'linria homogène xml thème mot ': 2005}, {'hypertexte page lien fonction correspondance ': 2005}, {'dassociation diagramme symbolique règle apriori ': 2005}, {'inductives dévènements chronique temporel fréquents ': 2005}, {'mesh américain synonyme paragraphe cismef ': 2005}, {'maladie médicales dassociation règlesnous apparaissant ': 2005}, {'lexpert terme exit pertinents logiciel ': 2005}, {'lenrichissement géographiques extraction nan connaissance ': 2005}, {'conservation détail doubli entrepôt fonction ': 2005}, {'forage lagrégation télécharger distribué déchantillonnage ': 2005}, {'sgbd relationnelles fouille nan donnée ': 2005}, {'symbole document découverte dimages image ': 2005}, {'orienter ressource terminologique fouille construction ': 2005}, {'subsomption règle hiérarchie structurant niveau ': 2005}, {'sgbd bitmap index traitement oracle ': 2005}, {'textuel texte cheminement admettre lobligation ': 2005}, {'compétence connaissance lorganisation métier gestion ': 2005}, {'universitaire réussite génération prédiction règle ': 2005}, {'ntic capitalisation service nan connaissance ': 2005}, {'étiquetage réétiquetage morphosyntaxique règle logiciel ': 2005}, {'dimensionnelles algèbre dopérateurs intègre multidimensionnelles ': 2005}, {'liceberg galois textmining treillis ontologie ': 2005}, {'référentielles étoile schéma fonctionnelles contrainte ': 2005}, {'mobile dobjets entrepôt urbaine1 dentrepôts ': 2005}, {'uml simulation connaissance agent rdf ': 2005}, {'connaissance médiation coopérative activité système ': 2005}, {'cognitifs cognition sociale autour – ': 2005}, {'flou séquentiels dintervalles motif numériques ': 2005}, {'règle sémantique darmstrong axiome fonctionnelles ': 2005}, {'résumé module profil lecture présentation ': 2005}, {'vue processus point ecd garder ': 2005}, {'reconnaissanceidentification radar aériennes cible traitement ': 2005}, {'compétence raisonnement expérimenter dinduire knowledgemining ': 2005}, {'rasma multiagent dassociations lamélioration spatiales ': 2005}, {'réécriture requête multimédia standard lontologie ': 2005}, {'discriminantes séquence séquentielles noyau vecteur ': 2005}, {'incrémentiel clusterings clusters phase échantillon ': 2005}, {'svm ensemble intervalle symbolique artificiellement ': 2005}, {'tbi indexé bit fréquentes tableau ': 2005}, {'logiciel tanagra accessible diffusés léchiquier ': 2005}, {'gène falciparum plasmodium parasite ring ': 2005}, {'génération concept treillis exhaustive automate ': 2005}, {'dévaluation variable critère sélection dambigüité ': 2005}, {'hypermédias navigation veut lui daide ': 2005}, {'supervisé enveloppe sv dapprentissage variable ': 2005}, {'page dévaluation retournées websum pertinence ': 2005}, {'arbre mère participation classificatoire féminine ': 2005}, {'ebusiness bm²l lontologie xml ebmh ': 2005}, {'kohonen fonder prédicteurs carte supervisé ': 2005}, {'site parcours catégorie internaute perception ': 2005}, {'gouvernance dentreprise connaissance textuelles explicitées ': 2005}, {'générique trieitemset éristique caract scalabilité ': 2004}, {'discrétisation partition stratifiée dexactitude feuille ': 2004}, {'groupage khiops modalité robustesse lalgorithme ': 2004}, {'em convergence comparative variante réalisons ': 2004}, {'lédifice darles antique théâtre vestige ': 2004}, {'relationnelle supervisées stratégiques analyse graphe ': 2004}, {'chaînés maximaux bayésiens apprentissage graphe ': 2004}, {'conjoint optimisation production pertinentes apprentissage ': 2004}, {'profil filtrage trec filtrées fur ': 2004}, {'ptrees ptree dassociation minimum fort ': 2004}, {'prion beluga maladie thématique diachronique ': 2004}, {'transaction booloader denses charger implanté ': 2004}, {'signature famille protéine distantes motif ': 2004}, {'job lexécution caractérisation globale dualité ': 2004}, {'cartographie carte sémantique nan connaissance ': 2004}, {'comportement site vis logs fréquents ': 2004}, {'dimages automatique nan classification ': 2004}, {'arbre décision construction variable nan ': 2004}, {'règle significatives multitude faux procédure ': 2004}, {'source spécifier spécification vue xml ': 2004}, {'prépayée churn téléphonie détection mobile ': 2004}, {'convivail etiq inductif étiqueteur spécialité ': 2004}, {'texte fractale image 90 géométrie ': 2004}, {'mesure étude expérimentale arguant dexaminer ': 2004}, {'exit itérative terminologie extraction nan ': 2004}, {'policier textmining informationnelle veille grâce ': 2004}, {'medline résumé nom biologiste protéine ': 2004}, {'doubli spécification fonction ancien langage ': 2004}, {'svm psvm proximal dindividus dattributs ': 2004}, {'entrepôt hétérogènes gestion nan donnée ': 2004}, {'gvsr annuaire dédition manipulation logiciel ': 2004}, {'bloc partition homogènes colonne instance ': 2004}, {'contingence table sgbd traitement dapprentissage ': 2004}, {'biomédicales préférence source lutilisateur scénario ': 2004}, {'hypertextuels elien partage structurées solution ': 2004}, {'textuelle catégorisation dassociation outil règle ': 2004}, {'terminologiques maintenance danimation connaissance lentreprise ': 2004}, {'manipulation cube représentation nan donnée ': 2004}, {'xlive adaptateur web architecture intégrer ': 2004}, {'tic règle informationnel contraposées qualité ': 2004}, {'trafic dinternet usage lentrelacement cohorte ': 2004}, {'table spatiales alternative fouille jointure ': 2004}, {'compétence ckim modèle connaissance gestion ': 2004}, {'rp topologique représentée vecteur voisinage ': 2004}, {'opac ligne couplage opérateur olap ': 2004}, {'optimisation temporelles requête web nan ': 2004}, {'communauté reconnues période utilisateur ci ': 2004}, {'poboc textuellesla softclusters polebased part ': 2004}, {'multivariées positionnement multidimensionnel partitionnement visualisation ': 2004}, {'datawarehouse hospitalier milieu qualité nan ': 2004}, {'fixe descripteur texture couleur dimages ': 2004}, {'anthropocentrée dassociation hiérarchiques recherche dheuristique ': 2004}, {'métarègles réduction logique dassociation issue ': 2004}, {'règle relationnelle requête coût sapparient ': 2004}, {'lédifice tridimensionnelle patrimoine aujourdhui réponse ': 2004}, {'régression taxonomiques linéaire variable regroupées ': 2004}, {'thyroïde gène cancer impliqués lindexation ': 2004}, {'émergents motif condensée représentation croissance ': 2004}, {'graphe granulaire acp sommet proximité ': 2004}, {'bloc multidimensionnelles cube théorie recouvrir ': 2004}, {'dattributs dobjets complexe sélection nan ': 2004}, {'sdv accès rapide cns efficiente ': 2004}, {'flou sousensembles appelons sousensemble défini ': 2004}, {'uitliation documentaire fondé contenu laide ': 2004}, {'nextclosure fermé itemsets partitionnement treillis ': 2004}, {'incomplets classement probabiliste dobjets arbre ': 2004}, {'galois dalgorithmes treillis supervisée étude ': 2004}, {'mask savoirfaire dappropriation dentreprise mémoire ': 2004}, {'voisinage graphe voisin proximité prétraitement ': 2004}, {'conceptuels graphe connaissance contrainte validation ': 2004}, {'veille technologique texte rechercher scientifique ': 2004}, {'naturel risque entrepôt dentrepôt examinons ': 2004}], [{'longrange influence network social in ': 2018}, {'in the data and this ': 2016}, {'semantic of identification relation in ': 2016}, {'tom topic and modeling browsing ': 2016}, {'data both knowledge and tbox ': 2016}, {'rdfsowl schema to data the ': 2015}, {'the data will explore and ': 2015}, {'big data research the is ': 2015}, {'collection function of is proportional ': 2015}, {'multidimensional big data as and ': 2015}, {'xplor xewgraph everywhere and newest ': 2015}, {'the data and broad of ': 2014}, {'textual data representation of the ': 2014}, {'spatial learning relational and already ': 2012}, {'why and has this in ': 2012}, {'early in will accuracy sequences ': 2011}, {'mobility and of the data ': 2011}, {'yacaree parameterfree rule association with ': 2011}, {'the learning and data failure ': 2011}, {'publicité clic enévidence loptimum atteignent ': 2010}, {'logic to nonrelational markov namely ': 2010}, {'the data of stream change ': 2010}, {'intervalvalued partitioning advances recent algorithms ': 2010}, {'tulip graph framework and representations ': 2010}, {'pattern graphs sequence databases association ': 2009}, {'data the will personal new ': 2009}, {'je entreprise mining produire théoriques ': 2008}]]\n",
      "Mort: []\n",
      "Nouveau: [[{'waves dénotée îledefrance potable souterrain ': 2017}, {'myocarde linfarctus hospitalièresplus pmsi fonctionnementde ': 2016}]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recent:\",recent)\n",
    "print(\"Ancien:\",ancien)\n",
    "print(\"Moyen:\",moyen)\n",
    "print(\"Mort:\",mort)\n",
    "print(\"Nouveau:\",nouveau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2317.86 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % round(time.process_time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation de la classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maximiser la distance inter cluster et minimiser la distance intra cluster\n",
    "\n",
    "Distance intra max < Distance inter min\n",
    "\n",
    "Comparons l'efficacité de la similarité de Jaccard et de la similarité Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(vec1, vec):\n",
    "    commun = 0\n",
    "    diff = 0\n",
    "    for key in vec1.keys():\n",
    "        if key in vec.keys():\n",
    "            commun = commun + 1\n",
    "        else:\n",
    "            diff = diff + 1\n",
    "    if diff == 0:\n",
    "        return -1\n",
    "    return commun/diff\n",
    "\n",
    "def cosine(vec1, vec2):\n",
    "    v1 = np.array(list(vec1.values()))\n",
    "    v2 = np.array(list(vec2.values()))\n",
    "    # La partie qui suit devra être retirée plus tard quand on aura des clusters normalisés.\n",
    "    if len(vec1) > len(vec2):\n",
    "        v1 = v1[:len(vec2)]\n",
    "    else:\n",
    "        v2 = v2[:len(vec1)]\n",
    "    return np.dot(v1, v2) / (np.sqrt(np.sum(v1**2)) * np.sqrt(np.sum(v2**2)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-9b539d24a348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"J\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjaccard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-b2a2714782a5>\u001b[0m in \u001b[0;36mjaccard\u001b[1;34m(vec1, vec)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcommun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvec1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mcommun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommun\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "print(\"J\",jaccard(c0,c1))\n",
    "print(\"C\",cosine(c0,c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % round(time.process_time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-soutenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réduire le vocabulaire.\n",
    "Augmenter les clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
