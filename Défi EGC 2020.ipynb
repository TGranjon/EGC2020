{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif du projet : Utiliser le corpus export_articles_EGC_2004_2018 et faire le bilan de l'évolution de la communauté EGC ces 20 dernières années et tenter d'en prédire l'avenir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Notes :\n",
    "J'ai abandonné l'utilisation de TreeTagger pour lemmatiser : j'ai pas réussi à le faire fonctionner.\n",
    "\n",
    "Ainsi que Gensim : la forme de ses corpus est étrange et je pense que c'est une perte de temps à se conformer à leur modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouverture du fichier de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fichier de données original.\n",
    "doc = pd.read_csv(\"export_articles_EGC_2004_2018.csv\", sep='\\t')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier de données corrigé.\n",
    "# La correction va jusqu'à la ligne 66.\n",
    "doc = pd.read_csv(\"export_articles_EGC_2004_2018_Copie.csv\", sep='\\t')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En travaillant avec title et abstract, on va réaliser les transformations.\n",
    "Tous les documents ont des titres mais ils n'ont pas tous d'abstract.\n",
    "On va donc utiliser une concaténation du titre et de l'abstract afin d'être sûr d'avoir de l'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisation et nettoyage des sujets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut mettre les textes en minuscules, tokeniser, retirer la ponctuation, retirer les stopwords puis lemmatiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        if item not in stopwords.words(\"french\"):\n",
    "            stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention : l'étape suivante est longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = [tokenize(doc[\"title\"][0].lower())]\n",
    "abstract = [tokenize(str(doc[\"abstract\"][0].lower()))]\n",
    "for line in range(len(doc)): # title et abstract ont la même taille.\n",
    "    if line != 0:\n",
    "        resume.append(tokenize(doc[\"title\"][line].lower()))\n",
    "        abstract.append(tokenize(str(doc[\"abstract\"][line]).lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le traitment des données est acceptable. Un meilleur traitement pourrait être envisagé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut obtenir un seul jeu de données avec les titres et les abstracts pour pouvoir les traiter et éliminer les cas qui n'ont pas d'abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible que seul le titre suffise. Il est possible que la racinisation ne soit pas nécéssaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in range(len(abstract)):\n",
    "    if abstract[line] != \"nan\":\n",
    "        for element in abstract[line]:\n",
    "            resume[line].append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention : l'étape suivante est longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = []\n",
    "for line in resume:\n",
    "    for word in line:\n",
    "        dico.append(word)\n",
    "for word in dico:\n",
    "    if dico.count(word) != 1:\n",
    "        dico.remove\n",
    "len(dico)\n",
    "# 93849 (2 fois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faudrait s'assurer que dico ne contienne que des mots distincts. Pour réduire sa taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du Tf.\n",
    "tf = []\n",
    "for x in range(len(resume)):\n",
    "    tf.append([])\n",
    "    for y in range(len(resume[x])):\n",
    "        tf[x].append(resume[x].count(resume[x][y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention : l'étape suivante est longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du Df.\n",
    "df = {}\n",
    "for x in range(len(dico)):\n",
    "    sum = 0\n",
    "    for y in range(len(resume)):\n",
    "        if dico[x] in resume[y]:\n",
    "            sum = sum + 1\n",
    "    df[dico[x]] = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'Idf\n",
    "idf = {}\n",
    "for word in df:\n",
    "    idf[word] = np.log10(len(resume)/df[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du Tf-Idf.\n",
    "tfidf = []\n",
    "for x in range(len(resume)):\n",
    "    tfidf.append({})\n",
    "    for y in range(len(resume[x])):\n",
    "        tfidf[x][resume[x][y]] = tf[x][y] * idf[resume[x][y]]\n",
    "len(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut trier les Tf-Idf par valeur et récupérer les 5 meilleurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le LSA va calculer, pour un document donné, les documents les plus similaires à son sujet. On classe le résultat le plus similaire dans le cluster du document donné. On reproduit cette étape et on arrête quand à un nombre de clusters ou une similarité trop faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En gros, le LSA nous fournit une similarité qu'on utilise pour former une classification hiérarchique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On aura donc des clusters par sujets. On pourra élaborer nos techniques de datation pour déterminer les tendances et, si possible, créer de nouveaux clusters (avec les K-moyennes) plus précis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Hiérarchique Ascendant (HAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le vrai point d'intérêt de cet algorithme est le seuil de similarité qui servira de point d'arrêt. Pour l'instant, je ne sais pas quel sera ce seuil, il faudra attendre les résultats du clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je suppose qu'on obtient une liste de listes (liste de tous les clusters individuels) à la fin du clustering.\n",
    "# On pourra modifier l'algorithme ou les données pour que cela fonctionne\n",
    "simi = 1 # Je crois que la similarité va de 0 à 1, à vérifier. # Similarité du dernier cluster retenu.\n",
    "seuil = # A voir\n",
    "num = 0 # Numéro du cluster actuellement étudié.\n",
    "qt = len(# Liste clusters) # Quantité de clusters, évolue au cours de l'algorithme.\n",
    "print(qt) # Nombre de clusters avant HAC.\n",
    "while similarity >= seuil:\n",
    "    num = randint(0,qt)\n",
    "    # Calcul de la similarité entre le cluster[num] et les autres\n",
    "    # Je suppose que la similarité renvoit un dictionnaire (cluster, similarité). A modifier sans doute.\n",
    "    simi = list(res.values())[0]\n",
    "    cluster[num].append(list(res.keys())[0])\n",
    "    # A voir si la liste de cluster évolue toute seule ou s'il faut manuellement retirer le cluster qu'on vient d'affecter.\n",
    "print(qt) # Nombre de clusters après HAC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation de la classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maximiser la distance inter cluster et minimiser la distance intra cluster\n",
    "\n",
    "Distance intra max < Distance inter min\n",
    "\n",
    "Comparons l'efficacité de la similarité de Jaccard et de la similarité Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(vec1, vec):\n",
    "    commun = 0\n",
    "    diff = 0\n",
    "    for key in vec1.keys():\n",
    "        if key in vec.keys():\n",
    "            commun = commun + 1\n",
    "        else:\n",
    "            diff = diff + 1\n",
    "    if diff == 0:\n",
    "        return -1\n",
    "    return commun/diff\n",
    "\n",
    "def cosine(vec1, vec2):\n",
    "    v1 = np.array(list(vec1.values()))\n",
    "    v2 = np.array(list(vec2.values()))\n",
    "    # La partie qui suit devra être retirée plus tard quand on aura des clusters normalisés.\n",
    "    if len(vec1) > len(vec2):\n",
    "        v1 = v1[:len(vec2)]\n",
    "    else:\n",
    "        v2 = v2[:len(vec1)]\n",
    "    return np.dot(v1, v2) / (np.sqrt(np.sum(v1**2)) * np.sqrt(np.sum(v2**2)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les exemples qui suivent sont basés sur les résultats du Tf-Idf. La véritable utilisation se fera entre deux clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distance entre tfidf[1] et tfidf[2]\")\n",
    "print(\"Jaccard :\",jaccard(tfidf[1],tfidf[2]))\n",
    "print(\"Cosine :\",cosine(tfidf[1],tfidf[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distance entre tfidf[1] et tfidf[3]\")\n",
    "print(\"Jaccard :\",jaccard(tfidf[1],tfidf[3]))\n",
    "print(\"Cosine :\",cosine(tfidf[1],tfidf[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distance entre tfidf[2] et tfidf[3]\")\n",
    "print(\"Jaccard :\",jaccard(tfidf[2],tfidf[3]))\n",
    "print(\"Cosine :\",cosine(tfidf[2],tfidf[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distance entre tfidf[1] et tfidf[1]\")\n",
    "print(\"Jaccard :\",jaccard(tfidf[1],tfidf[1]))\n",
    "print(\"Cosine :\",cosine(tfidf[1],tfidf[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50 nous informe que Jaccard est plus intéréssant si la répétition des mots dans le texte n'est pas important (notre cas). A voir plus tard lequel des deux on garde (ou les deux si possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
